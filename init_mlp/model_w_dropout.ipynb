{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0d840cf-e4af-4757-ad69-e7b31d92c66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "Shape of known_freqs tensor: torch.Size([10000, 3937])\n",
      "Shape of snv_freqs tensor: torch.Size([10000, 6520])\n",
      "Training set size: 8000\n",
      "Validation set size: 1000\n",
      "Test set size: 1000\n",
      "Known frequencies batch shape: torch.Size([1000, 3937])\n",
      "SNV frequencies batch shape: torch.Size([1000, 6520])\n",
      "First batch - SNV frequencies: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1515, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2375, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3867, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2101, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2746, 0.0000]],\n",
      "       device='mps:0')\n",
      "First batch - Known frequencies: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='mps:0')\n",
      "First batch - Known frequencies (non-zero) 0: tensor([0.0208, 0.0146, 0.0032, 0.0113, 0.0611, 0.0424, 0.0271, 0.0322, 0.0358,\n",
      "        0.0692, 0.0508, 0.0302, 0.0376, 0.0728, 0.0267, 0.0563, 0.0009, 0.0121,\n",
      "        0.0751, 0.0454, 0.0560, 0.0080, 0.0692, 0.0135, 0.0440, 0.0365, 0.0472],\n",
      "       device='mps:0')\n",
      "\n",
      "\n",
      "Validation Known frequencies batch shape: torch.Size([1000, 3937])\n",
      "Validation SNV frequencies batch shape: torch.Size([1000, 6520])\n",
      "Validation batch - SNV frequencies: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3113, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3477, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0508, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0657, 0.0000],\n",
      "        [0.0317, 0.0000, 0.0000,  ..., 0.0000, 0.1746, 0.0000]],\n",
      "       device='mps:0')\n",
      "Validation batch - Known frequencies: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='mps:0')\n",
      "Validation batch - Known frequencies (non-zero) 0: tensor([4.2380e-05, 7.1522e-02, 4.1552e-02, 2.4091e-02, 4.0234e-02, 3.3333e-02,\n",
      "        4.6237e-02, 6.4969e-02, 6.4492e-02, 1.6366e-02, 1.1730e-02, 2.0357e-02,\n",
      "        2.6997e-02, 3.9647e-02, 3.2443e-02, 5.5919e-03, 5.0660e-02, 6.9041e-02,\n",
      "        5.1344e-02, 7.3099e-02, 1.9849e-02, 6.1766e-02, 9.2811e-03, 7.0115e-02,\n",
      "        5.5241e-02], device='mps:0')\n",
      "\n",
      "\n",
      "Test Known frequencies batch shape: torch.Size([1000, 3937])\n",
      "Test SNV frequencies batch shape: torch.Size([1000, 6520])\n",
      "Test batch - SNV frequencies: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2764, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3949, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2777, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.4913, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0651, 0.4656, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2253, 0.0000]],\n",
      "       device='mps:0')\n",
      "Test batch - Known frequencies: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='mps:0')\n",
      "Test batch - Known frequencies (non-zero) 0: tensor([0.0183, 0.0274, 0.0586, 0.0352, 0.0407, 0.0312, 0.0171, 0.0706, 0.0082,\n",
      "        0.0560, 0.0004, 0.0338, 0.0800, 0.0506, 0.0116, 0.0602, 0.0617, 0.0060,\n",
      "        0.0393, 0.0204, 0.0805, 0.0620, 0.0563, 0.0018, 0.0722],\n",
      "       device='mps:0')\n",
      "\n",
      "Using mps device\n",
      "Epoch 1, Train loss: 0.037011, Validation loss: 0.010996\n",
      "Epoch 2, Train loss: 0.015103, Validation loss: 0.004288\n",
      "Epoch 3, Train loss: 0.008980, Validation loss: 0.002204\n",
      "Epoch 4, Train loss: 0.006274, Validation loss: 0.001025\n",
      "Epoch 5, Train loss: 0.004793, Validation loss: 0.000568\n",
      "Epoch 6, Train loss: 0.003952, Validation loss: 0.000459\n",
      "Epoch 7, Train loss: 0.003396, Validation loss: 0.000570\n",
      "Epoch 8, Train loss: 0.002996, Validation loss: 0.000774\n",
      "Epoch 9, Train loss: 0.002680, Validation loss: 0.000969\n",
      "Epoch 10, Train loss: 0.002425, Validation loss: 0.001048\n",
      "Epoch 11, Train loss: 0.002214, Validation loss: 0.001044\n",
      "Epoch 12, Train loss: 0.002047, Validation loss: 0.000987\n",
      "Epoch 13, Train loss: 0.001906, Validation loss: 0.000932\n",
      "Epoch 14, Train loss: 0.001797, Validation loss: 0.000796\n",
      "Epoch 15, Train loss: 0.001710, Validation loss: 0.000683\n",
      "Epoch 16, Train loss: 0.001644, Validation loss: 0.000564\n",
      "Epoch 17, Train loss: 0.001598, Validation loss: 0.000495\n",
      "Epoch 18, Train loss: 0.001560, Validation loss: 0.000439\n",
      "Epoch 19, Train loss: 0.001531, Validation loss: 0.000407\n",
      "Epoch 20, Train loss: 0.001507, Validation loss: 0.000349\n",
      "Epoch 21, Train loss: 0.001487, Validation loss: 0.000326\n",
      "Epoch 22, Train loss: 0.001472, Validation loss: 0.000306\n",
      "Epoch 23, Train loss: 0.001461, Validation loss: 0.000291\n",
      "Epoch 24, Train loss: 0.001447, Validation loss: 0.000277\n",
      "Epoch 25, Train loss: 0.001437, Validation loss: 0.000266\n",
      "Epoch 26, Train loss: 0.001427, Validation loss: 0.000255\n",
      "Epoch 27, Train loss: 0.001418, Validation loss: 0.000247\n",
      "Epoch 28, Train loss: 0.001408, Validation loss: 0.000238\n",
      "Epoch 29, Train loss: 0.001400, Validation loss: 0.000231\n",
      "Epoch 30, Train loss: 0.001391, Validation loss: 0.000224\n",
      "Epoch 31, Train loss: 0.001387, Validation loss: 0.000218\n",
      "Epoch 32, Train loss: 0.001380, Validation loss: 0.000212\n",
      "Epoch 33, Train loss: 0.001372, Validation loss: 0.000206\n",
      "Epoch 34, Train loss: 0.001367, Validation loss: 0.000202\n",
      "Epoch 35, Train loss: 0.001359, Validation loss: 0.000198\n",
      "Epoch 36, Train loss: 0.001355, Validation loss: 0.000194\n",
      "Epoch 37, Train loss: 0.001349, Validation loss: 0.000190\n",
      "Epoch 38, Train loss: 0.001343, Validation loss: 0.000186\n",
      "Epoch 39, Train loss: 0.001339, Validation loss: 0.000180\n",
      "Epoch 40, Train loss: 0.001332, Validation loss: 0.000177\n",
      "Epoch 41, Train loss: 0.001330, Validation loss: 0.000174\n",
      "Epoch 42, Train loss: 0.001324, Validation loss: 0.000170\n",
      "Epoch 43, Train loss: 0.001316, Validation loss: 0.000167\n",
      "Epoch 44, Train loss: 0.001315, Validation loss: 0.000164\n",
      "Epoch 45, Train loss: 0.001309, Validation loss: 0.000161\n",
      "Epoch 46, Train loss: 0.001305, Validation loss: 0.000158\n",
      "Epoch 47, Train loss: 0.001301, Validation loss: 0.000155\n",
      "Epoch 48, Train loss: 0.001296, Validation loss: 0.000153\n",
      "Epoch 49, Train loss: 0.001292, Validation loss: 0.000151\n",
      "Epoch 50, Train loss: 0.001288, Validation loss: 0.000148\n",
      "Epoch 51, Train loss: 0.001284, Validation loss: 0.000145\n",
      "Epoch 52, Train loss: 0.001280, Validation loss: 0.000143\n",
      "Epoch 53, Train loss: 0.001276, Validation loss: 0.000141\n",
      "Epoch 54, Train loss: 0.001274, Validation loss: 0.000139\n",
      "Epoch 55, Train loss: 0.001269, Validation loss: 0.000137\n",
      "Epoch 56, Train loss: 0.001266, Validation loss: 0.000135\n",
      "Epoch 57, Train loss: 0.001261, Validation loss: 0.000134\n",
      "Epoch 58, Train loss: 0.001258, Validation loss: 0.000132\n",
      "Epoch 59, Train loss: 0.001256, Validation loss: 0.000130\n",
      "Epoch 60, Train loss: 0.001252, Validation loss: 0.000127\n",
      "Epoch 61, Train loss: 0.001251, Validation loss: 0.000127\n",
      "Epoch 62, Train loss: 0.001247, Validation loss: 0.000125\n",
      "Epoch 63, Train loss: 0.001242, Validation loss: 0.000124\n",
      "Epoch 64, Train loss: 0.001240, Validation loss: 0.000122\n",
      "Epoch 65, Train loss: 0.001237, Validation loss: 0.000120\n",
      "Epoch 66, Train loss: 0.001233, Validation loss: 0.000119\n",
      "Epoch 67, Train loss: 0.001229, Validation loss: 0.000118\n",
      "Epoch 68, Train loss: 0.001226, Validation loss: 0.000116\n",
      "Epoch 69, Train loss: 0.001223, Validation loss: 0.000116\n",
      "Epoch 70, Train loss: 0.001219, Validation loss: 0.000114\n",
      "Epoch 71, Train loss: 0.001217, Validation loss: 0.000113\n",
      "Epoch 72, Train loss: 0.001213, Validation loss: 0.000112\n",
      "Epoch 73, Train loss: 0.001211, Validation loss: 0.000110\n",
      "Epoch 74, Train loss: 0.001208, Validation loss: 0.000108\n",
      "Epoch 75, Train loss: 0.001205, Validation loss: 0.000108\n",
      "Epoch 76, Train loss: 0.001203, Validation loss: 0.000107\n",
      "Epoch 77, Train loss: 0.001197, Validation loss: 0.000105\n",
      "Epoch 78, Train loss: 0.001195, Validation loss: 0.000104\n",
      "Epoch 79, Train loss: 0.001194, Validation loss: 0.000103\n",
      "Epoch 80, Train loss: 0.001189, Validation loss: 0.000102\n",
      "Epoch 81, Train loss: 0.001187, Validation loss: 0.000102\n",
      "Epoch 82, Train loss: 0.001185, Validation loss: 0.000100\n",
      "Epoch 83, Train loss: 0.001181, Validation loss: 0.000100\n",
      "Epoch 84, Train loss: 0.001178, Validation loss: 0.000099\n",
      "Epoch 85, Train loss: 0.001175, Validation loss: 0.000099\n",
      "Epoch 86, Train loss: 0.001173, Validation loss: 0.000097\n",
      "Epoch 87, Train loss: 0.001171, Validation loss: 0.000096\n",
      "Epoch 88, Train loss: 0.001166, Validation loss: 0.000095\n",
      "Epoch 89, Train loss: 0.001164, Validation loss: 0.000094\n",
      "Epoch 90, Train loss: 0.001162, Validation loss: 0.000094\n",
      "Epoch 91, Train loss: 0.001160, Validation loss: 0.000093\n",
      "Epoch 92, Train loss: 0.001156, Validation loss: 0.000093\n",
      "Epoch 93, Train loss: 0.001153, Validation loss: 0.000092\n",
      "Epoch 94, Train loss: 0.001150, Validation loss: 0.000091\n",
      "Epoch 95, Train loss: 0.001148, Validation loss: 0.000091\n",
      "Epoch 96, Train loss: 0.001144, Validation loss: 0.000090\n",
      "Epoch 97, Train loss: 0.001143, Validation loss: 0.000090\n",
      "Epoch 98, Train loss: 0.001139, Validation loss: 0.000090\n",
      "Epoch 99, Train loss: 0.001136, Validation loss: 0.000089\n",
      "Epoch 100, Train loss: 0.001135, Validation loss: 0.000088\n",
      "Epoch 101, Train loss: 0.001132, Validation loss: 0.000088\n",
      "Epoch 102, Train loss: 0.001130, Validation loss: 0.000087\n",
      "Epoch 103, Train loss: 0.001127, Validation loss: 0.000086\n",
      "Epoch 104, Train loss: 0.001126, Validation loss: 0.000086\n",
      "Epoch 105, Train loss: 0.001122, Validation loss: 0.000085\n",
      "Epoch 106, Train loss: 0.001119, Validation loss: 0.000084\n",
      "Epoch 107, Train loss: 0.001117, Validation loss: 0.000084\n",
      "Epoch 108, Train loss: 0.001113, Validation loss: 0.000085\n",
      "Epoch 109, Train loss: 0.001112, Validation loss: 0.000084\n",
      "Epoch 110, Train loss: 0.001109, Validation loss: 0.000083\n",
      "Epoch 111, Train loss: 0.001107, Validation loss: 0.000082\n",
      "Epoch 112, Train loss: 0.001104, Validation loss: 0.000082\n",
      "Epoch 113, Train loss: 0.001100, Validation loss: 0.000082\n",
      "Epoch 114, Train loss: 0.001099, Validation loss: 0.000082\n",
      "Epoch 115, Train loss: 0.001095, Validation loss: 0.000081\n",
      "Epoch 116, Train loss: 0.001095, Validation loss: 0.000081\n",
      "Epoch 117, Train loss: 0.001091, Validation loss: 0.000080\n",
      "Epoch 118, Train loss: 0.001087, Validation loss: 0.000080\n",
      "Epoch 119, Train loss: 0.001088, Validation loss: 0.000079\n",
      "Epoch 120, Train loss: 0.001082, Validation loss: 0.000079\n",
      "Epoch 121, Train loss: 0.001081, Validation loss: 0.000079\n",
      "Epoch 122, Train loss: 0.001079, Validation loss: 0.000078\n",
      "Epoch 123, Train loss: 0.001075, Validation loss: 0.000078\n",
      "Epoch 124, Train loss: 0.001076, Validation loss: 0.000078\n",
      "Epoch 125, Train loss: 0.001072, Validation loss: 0.000077\n",
      "Epoch 126, Train loss: 0.001069, Validation loss: 0.000078\n",
      "Epoch 127, Train loss: 0.001066, Validation loss: 0.000079\n",
      "Epoch 128, Train loss: 0.001063, Validation loss: 0.000077\n",
      "Epoch 129, Train loss: 0.001061, Validation loss: 0.000078\n",
      "Epoch 130, Train loss: 0.001060, Validation loss: 0.000076\n",
      "Epoch 131, Train loss: 0.001058, Validation loss: 0.000077\n",
      "Epoch 132, Train loss: 0.001054, Validation loss: 0.000077\n",
      "Epoch 133, Train loss: 0.001054, Validation loss: 0.000077\n",
      "Epoch 134, Train loss: 0.001050, Validation loss: 0.000077\n",
      "Epoch 135, Train loss: 0.001047, Validation loss: 0.000077\n",
      "Epoch 136, Train loss: 0.001044, Validation loss: 0.000078\n",
      "Epoch 137, Train loss: 0.001044, Validation loss: 0.000077\n",
      "Epoch 138, Train loss: 0.001039, Validation loss: 0.000076\n",
      "Epoch 139, Train loss: 0.001036, Validation loss: 0.000076\n",
      "Epoch 140, Train loss: 0.001034, Validation loss: 0.000076\n",
      "Epoch 141, Train loss: 0.001034, Validation loss: 0.000075\n",
      "Epoch 142, Train loss: 0.001030, Validation loss: 0.000076\n",
      "Epoch 143, Train loss: 0.001029, Validation loss: 0.000076\n",
      "Epoch 144, Train loss: 0.001025, Validation loss: 0.000075\n",
      "Epoch 145, Train loss: 0.001023, Validation loss: 0.000076\n",
      "Epoch 146, Train loss: 0.001022, Validation loss: 0.000074\n",
      "Epoch 147, Train loss: 0.001019, Validation loss: 0.000075\n",
      "Epoch 148, Train loss: 0.001015, Validation loss: 0.000075\n",
      "Epoch 149, Train loss: 0.001012, Validation loss: 0.000075\n",
      "Epoch 150, Train loss: 0.001013, Validation loss: 0.000075\n",
      "Epoch 151, Train loss: 0.001009, Validation loss: 0.000075\n",
      "Epoch 152, Train loss: 0.001006, Validation loss: 0.000073\n",
      "Epoch 153, Train loss: 0.001004, Validation loss: 0.000076\n",
      "Epoch 154, Train loss: 0.001003, Validation loss: 0.000075\n",
      "Epoch 155, Train loss: 0.001000, Validation loss: 0.000075\n",
      "Epoch 156, Train loss: 0.000997, Validation loss: 0.000076\n",
      "Epoch 157, Train loss: 0.000996, Validation loss: 0.000076\n",
      "Epoch 158, Train loss: 0.000992, Validation loss: 0.000076\n",
      "Epoch 159, Train loss: 0.000991, Validation loss: 0.000077\n",
      "Epoch 160, Train loss: 0.000988, Validation loss: 0.000077\n",
      "Epoch 161, Train loss: 0.000988, Validation loss: 0.000078\n",
      "Epoch 162, Train loss: 0.000985, Validation loss: 0.000077\n",
      "Epoch 163, Train loss: 0.000984, Validation loss: 0.000076\n",
      "Epoch 164, Train loss: 0.000980, Validation loss: 0.000076\n",
      "Epoch 165, Train loss: 0.000978, Validation loss: 0.000078\n",
      "Epoch 166, Train loss: 0.000977, Validation loss: 0.000078\n",
      "Epoch 167, Train loss: 0.000974, Validation loss: 0.000078\n",
      "Epoch 168, Train loss: 0.000974, Validation loss: 0.000078\n",
      "Epoch 169, Train loss: 0.000969, Validation loss: 0.000080\n",
      "Epoch 170, Train loss: 0.000968, Validation loss: 0.000079\n",
      "Epoch 171, Train loss: 0.000965, Validation loss: 0.000080\n",
      "Epoch 172, Train loss: 0.000963, Validation loss: 0.000079\n",
      "Epoch 173, Train loss: 0.000960, Validation loss: 0.000080\n",
      "Epoch 174, Train loss: 0.000957, Validation loss: 0.000080\n",
      "Epoch 175, Train loss: 0.000957, Validation loss: 0.000079\n",
      "Epoch 176, Train loss: 0.000953, Validation loss: 0.000082\n",
      "Epoch 177, Train loss: 0.000953, Validation loss: 0.000081\n",
      "Epoch 178, Train loss: 0.000952, Validation loss: 0.000081\n",
      "Epoch 179, Train loss: 0.000948, Validation loss: 0.000080\n",
      "Epoch 180, Train loss: 0.000944, Validation loss: 0.000082\n",
      "Epoch 181, Train loss: 0.000944, Validation loss: 0.000082\n",
      "Epoch 182, Train loss: 0.000941, Validation loss: 0.000081\n",
      "Epoch 183, Train loss: 0.000939, Validation loss: 0.000082\n",
      "Epoch 184, Train loss: 0.000938, Validation loss: 0.000080\n",
      "Epoch 185, Train loss: 0.000935, Validation loss: 0.000081\n",
      "Epoch 186, Train loss: 0.000930, Validation loss: 0.000082\n",
      "Epoch 187, Train loss: 0.000928, Validation loss: 0.000084\n",
      "Epoch 188, Train loss: 0.000928, Validation loss: 0.000082\n",
      "Epoch 189, Train loss: 0.000924, Validation loss: 0.000084\n",
      "Epoch 190, Train loss: 0.000923, Validation loss: 0.000084\n",
      "Epoch 191, Train loss: 0.000921, Validation loss: 0.000084\n",
      "Epoch 192, Train loss: 0.000920, Validation loss: 0.000086\n",
      "Epoch 193, Train loss: 0.000916, Validation loss: 0.000085\n",
      "Epoch 194, Train loss: 0.000915, Validation loss: 0.000085\n",
      "Epoch 195, Train loss: 0.000912, Validation loss: 0.000084\n",
      "Epoch 196, Train loss: 0.000909, Validation loss: 0.000085\n",
      "Epoch 197, Train loss: 0.000907, Validation loss: 0.000083\n",
      "Epoch 198, Train loss: 0.000904, Validation loss: 0.000085\n",
      "Epoch 199, Train loss: 0.000903, Validation loss: 0.000087\n",
      "Epoch 200, Train loss: 0.000901, Validation loss: 0.000086\n",
      "Epoch 201, Train loss: 0.000899, Validation loss: 0.000085\n",
      "Epoch 202, Train loss: 0.000894, Validation loss: 0.000086\n",
      "Epoch 203, Train loss: 0.000893, Validation loss: 0.000085\n",
      "Epoch 204, Train loss: 0.000891, Validation loss: 0.000089\n",
      "Epoch 205, Train loss: 0.000890, Validation loss: 0.000089\n",
      "Epoch 206, Train loss: 0.000887, Validation loss: 0.000088\n",
      "Epoch 207, Train loss: 0.000883, Validation loss: 0.000087\n",
      "Epoch 208, Train loss: 0.000883, Validation loss: 0.000089\n",
      "Epoch 209, Train loss: 0.000880, Validation loss: 0.000089\n",
      "Epoch 210, Train loss: 0.000877, Validation loss: 0.000089\n",
      "Epoch 211, Train loss: 0.000876, Validation loss: 0.000089\n",
      "Epoch 212, Train loss: 0.000872, Validation loss: 0.000090\n",
      "Epoch 213, Train loss: 0.000870, Validation loss: 0.000090\n",
      "Epoch 214, Train loss: 0.000870, Validation loss: 0.000091\n",
      "Epoch 215, Train loss: 0.000868, Validation loss: 0.000091\n",
      "Epoch 216, Train loss: 0.000864, Validation loss: 0.000092\n",
      "Epoch 217, Train loss: 0.000861, Validation loss: 0.000090\n",
      "Epoch 218, Train loss: 0.000858, Validation loss: 0.000092\n",
      "Epoch 219, Train loss: 0.000858, Validation loss: 0.000091\n",
      "Epoch 220, Train loss: 0.000855, Validation loss: 0.000094\n",
      "Epoch 221, Train loss: 0.000852, Validation loss: 0.000095\n",
      "Epoch 222, Train loss: 0.000851, Validation loss: 0.000095\n",
      "Epoch 223, Train loss: 0.000847, Validation loss: 0.000094\n",
      "Epoch 224, Train loss: 0.000846, Validation loss: 0.000094\n",
      "Epoch 225, Train loss: 0.000843, Validation loss: 0.000095\n",
      "Epoch 226, Train loss: 0.000839, Validation loss: 0.000096\n",
      "Epoch 227, Train loss: 0.000837, Validation loss: 0.000097\n",
      "Epoch 228, Train loss: 0.000837, Validation loss: 0.000095\n",
      "Epoch 229, Train loss: 0.000832, Validation loss: 0.000096\n",
      "Epoch 230, Train loss: 0.000830, Validation loss: 0.000097\n",
      "Epoch 231, Train loss: 0.000828, Validation loss: 0.000099\n",
      "Epoch 232, Train loss: 0.000826, Validation loss: 0.000098\n",
      "Epoch 233, Train loss: 0.000825, Validation loss: 0.000100\n",
      "Epoch 234, Train loss: 0.000823, Validation loss: 0.000100\n",
      "Epoch 235, Train loss: 0.000820, Validation loss: 0.000103\n",
      "Epoch 236, Train loss: 0.000818, Validation loss: 0.000101\n",
      "Epoch 237, Train loss: 0.000817, Validation loss: 0.000105\n",
      "Epoch 238, Train loss: 0.000813, Validation loss: 0.000102\n",
      "Epoch 239, Train loss: 0.000807, Validation loss: 0.000102\n",
      "Epoch 240, Train loss: 0.000805, Validation loss: 0.000104\n",
      "Epoch 241, Train loss: 0.000803, Validation loss: 0.000105\n",
      "Epoch 242, Train loss: 0.000800, Validation loss: 0.000101\n",
      "Epoch 243, Train loss: 0.000799, Validation loss: 0.000105\n",
      "Epoch 244, Train loss: 0.000796, Validation loss: 0.000106\n",
      "Epoch 245, Train loss: 0.000796, Validation loss: 0.000109\n",
      "Epoch 246, Train loss: 0.000791, Validation loss: 0.000109\n",
      "Epoch 247, Train loss: 0.000790, Validation loss: 0.000108\n",
      "Epoch 248, Train loss: 0.000787, Validation loss: 0.000110\n",
      "Epoch 249, Train loss: 0.000784, Validation loss: 0.000112\n",
      "Epoch 250, Train loss: 0.000780, Validation loss: 0.000112\n",
      "Epoch 251, Train loss: 0.000777, Validation loss: 0.000115\n",
      "Epoch 252, Train loss: 0.000776, Validation loss: 0.000114\n",
      "Early stopping on epoch 252\n",
      "Test Error: \n",
      " Avg loss: 0.000114 \n",
      "\n",
      "[[-0.00056065 -0.00515748 -0.00403557 ...  0.01395776  0.0032577\n",
      "  -0.00596588]\n",
      " [-0.00198363 -0.01152889 -0.00488533 ...  0.00798282  0.00332679\n",
      "  -0.011597  ]\n",
      " [-0.00185614 -0.00365593 -0.01224805 ...  0.0064858   0.00370077\n",
      "  -0.00065778]\n",
      " ...\n",
      " [ 0.01730165 -0.01267288  0.00515844 ...  0.01508365 -0.00495811\n",
      "  -0.00509773]\n",
      " [ 0.00960788 -0.01199029 -0.0072107  ...  0.01006927 -0.00541023\n",
      "  -0.01074359]\n",
      " [ 0.00343833 -0.01249748 -0.01052896 ...  0.00448333 -0.00856077\n",
      "  -0.00631255]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Figure(1000x600)\n",
      "Using mps device\n",
      "Epoch 1, Train loss: 0.041422, Validation loss: 0.012148\n",
      "Epoch 2, Train loss: 0.017905, Validation loss: 0.004747\n",
      "Epoch 3, Train loss: 0.011029, Validation loss: 0.002338\n",
      "Epoch 4, Train loss: 0.007727, Validation loss: 0.001120\n",
      "Epoch 5, Train loss: 0.005836, Validation loss: 0.000617\n",
      "Epoch 6, Train loss: 0.004715, Validation loss: 0.000502\n",
      "Epoch 7, Train loss: 0.003995, Validation loss: 0.000574\n",
      "Epoch 8, Train loss: 0.003543, Validation loss: 0.000634\n",
      "Epoch 9, Train loss: 0.003251, Validation loss: 0.000705\n",
      "Epoch 10, Train loss: 0.003062, Validation loss: 0.000669\n",
      "Epoch 11, Train loss: 0.002944, Validation loss: 0.000625\n",
      "Epoch 12, Train loss: 0.002868, Validation loss: 0.000537\n",
      "Epoch 13, Train loss: 0.002811, Validation loss: 0.000509\n",
      "Epoch 14, Train loss: 0.002770, Validation loss: 0.000457\n",
      "Epoch 15, Train loss: 0.002738, Validation loss: 0.000425\n",
      "Epoch 16, Train loss: 0.002710, Validation loss: 0.000396\n",
      "Epoch 17, Train loss: 0.002687, Validation loss: 0.000375\n",
      "Epoch 18, Train loss: 0.002666, Validation loss: 0.000357\n",
      "Epoch 19, Train loss: 0.002649, Validation loss: 0.000342\n",
      "Epoch 20, Train loss: 0.002630, Validation loss: 0.000328\n",
      "Epoch 21, Train loss: 0.002616, Validation loss: 0.000316\n",
      "Epoch 22, Train loss: 0.002597, Validation loss: 0.000305\n",
      "Epoch 23, Train loss: 0.002585, Validation loss: 0.000294\n",
      "Epoch 24, Train loss: 0.002568, Validation loss: 0.000285\n",
      "Epoch 25, Train loss: 0.002555, Validation loss: 0.000275\n",
      "Epoch 26, Train loss: 0.002539, Validation loss: 0.000267\n",
      "Epoch 27, Train loss: 0.002529, Validation loss: 0.000259\n",
      "Epoch 28, Train loss: 0.002518, Validation loss: 0.000253\n",
      "Epoch 29, Train loss: 0.002503, Validation loss: 0.000245\n",
      "Epoch 30, Train loss: 0.002492, Validation loss: 0.000239\n",
      "Epoch 31, Train loss: 0.002480, Validation loss: 0.000234\n",
      "Epoch 32, Train loss: 0.002470, Validation loss: 0.000228\n",
      "Epoch 33, Train loss: 0.002458, Validation loss: 0.000223\n",
      "Epoch 34, Train loss: 0.002449, Validation loss: 0.000218\n",
      "Epoch 35, Train loss: 0.002440, Validation loss: 0.000213\n",
      "Epoch 36, Train loss: 0.002429, Validation loss: 0.000208\n",
      "Epoch 37, Train loss: 0.002420, Validation loss: 0.000204\n",
      "Epoch 38, Train loss: 0.002410, Validation loss: 0.000200\n",
      "Epoch 39, Train loss: 0.002401, Validation loss: 0.000197\n",
      "Epoch 40, Train loss: 0.002391, Validation loss: 0.000193\n",
      "Epoch 41, Train loss: 0.002382, Validation loss: 0.000189\n",
      "Epoch 42, Train loss: 0.002377, Validation loss: 0.000186\n",
      "Epoch 43, Train loss: 0.002362, Validation loss: 0.000183\n",
      "Epoch 44, Train loss: 0.002355, Validation loss: 0.000180\n",
      "Epoch 45, Train loss: 0.002347, Validation loss: 0.000176\n",
      "Epoch 46, Train loss: 0.002337, Validation loss: 0.000175\n",
      "Epoch 47, Train loss: 0.002331, Validation loss: 0.000172\n",
      "Epoch 48, Train loss: 0.002320, Validation loss: 0.000170\n",
      "Epoch 49, Train loss: 0.002309, Validation loss: 0.000167\n",
      "Epoch 50, Train loss: 0.002303, Validation loss: 0.000165\n",
      "Epoch 51, Train loss: 0.002295, Validation loss: 0.000163\n",
      "Epoch 52, Train loss: 0.002284, Validation loss: 0.000160\n",
      "Epoch 53, Train loss: 0.002278, Validation loss: 0.000159\n",
      "Epoch 54, Train loss: 0.002268, Validation loss: 0.000158\n",
      "Epoch 55, Train loss: 0.002261, Validation loss: 0.000155\n",
      "Epoch 56, Train loss: 0.002250, Validation loss: 0.000155\n",
      "Epoch 57, Train loss: 0.002243, Validation loss: 0.000153\n",
      "Epoch 58, Train loss: 0.002237, Validation loss: 0.000152\n",
      "Epoch 59, Train loss: 0.002227, Validation loss: 0.000150\n",
      "Epoch 60, Train loss: 0.002217, Validation loss: 0.000148\n",
      "Epoch 61, Train loss: 0.002207, Validation loss: 0.000146\n",
      "Epoch 62, Train loss: 0.002200, Validation loss: 0.000145\n",
      "Epoch 63, Train loss: 0.002191, Validation loss: 0.000144\n",
      "Epoch 64, Train loss: 0.002183, Validation loss: 0.000142\n",
      "Epoch 65, Train loss: 0.002174, Validation loss: 0.000142\n",
      "Epoch 66, Train loss: 0.002164, Validation loss: 0.000140\n",
      "Epoch 67, Train loss: 0.002158, Validation loss: 0.000139\n",
      "Epoch 68, Train loss: 0.002148, Validation loss: 0.000138\n",
      "Epoch 69, Train loss: 0.002141, Validation loss: 0.000137\n",
      "Epoch 70, Train loss: 0.002128, Validation loss: 0.000136\n",
      "Epoch 71, Train loss: 0.002119, Validation loss: 0.000135\n",
      "Epoch 72, Train loss: 0.002107, Validation loss: 0.000134\n",
      "Epoch 73, Train loss: 0.002099, Validation loss: 0.000134\n",
      "Epoch 74, Train loss: 0.002088, Validation loss: 0.000132\n",
      "Epoch 75, Train loss: 0.002079, Validation loss: 0.000132\n",
      "Epoch 76, Train loss: 0.002070, Validation loss: 0.000130\n",
      "Epoch 77, Train loss: 0.002061, Validation loss: 0.000130\n",
      "Epoch 78, Train loss: 0.002052, Validation loss: 0.000129\n",
      "Epoch 79, Train loss: 0.002043, Validation loss: 0.000128\n",
      "Epoch 80, Train loss: 0.002033, Validation loss: 0.000128\n",
      "Epoch 81, Train loss: 0.002021, Validation loss: 0.000127\n",
      "Epoch 82, Train loss: 0.002013, Validation loss: 0.000127\n",
      "Epoch 83, Train loss: 0.002003, Validation loss: 0.000126\n",
      "Epoch 84, Train loss: 0.001994, Validation loss: 0.000125\n",
      "Epoch 85, Train loss: 0.001984, Validation loss: 0.000123\n",
      "Epoch 86, Train loss: 0.001975, Validation loss: 0.000122\n",
      "Epoch 87, Train loss: 0.001966, Validation loss: 0.000122\n",
      "Epoch 88, Train loss: 0.001955, Validation loss: 0.000121\n",
      "Epoch 89, Train loss: 0.001945, Validation loss: 0.000121\n",
      "Epoch 90, Train loss: 0.001936, Validation loss: 0.000120\n",
      "Epoch 91, Train loss: 0.001926, Validation loss: 0.000120\n",
      "Epoch 92, Train loss: 0.001916, Validation loss: 0.000119\n",
      "Epoch 93, Train loss: 0.001906, Validation loss: 0.000119\n",
      "Epoch 94, Train loss: 0.001896, Validation loss: 0.000118\n",
      "Epoch 95, Train loss: 0.001887, Validation loss: 0.000118\n",
      "Epoch 96, Train loss: 0.001877, Validation loss: 0.000117\n",
      "Epoch 97, Train loss: 0.001870, Validation loss: 0.000116\n",
      "Epoch 98, Train loss: 0.001856, Validation loss: 0.000115\n",
      "Epoch 99, Train loss: 0.001846, Validation loss: 0.000115\n",
      "Epoch 100, Train loss: 0.001838, Validation loss: 0.000114\n",
      "Epoch 101, Train loss: 0.001832, Validation loss: 0.000114\n",
      "Epoch 102, Train loss: 0.001820, Validation loss: 0.000113\n",
      "Epoch 103, Train loss: 0.001812, Validation loss: 0.000114\n",
      "Epoch 104, Train loss: 0.001800, Validation loss: 0.000113\n",
      "Epoch 105, Train loss: 0.001793, Validation loss: 0.000113\n",
      "Epoch 106, Train loss: 0.001784, Validation loss: 0.000112\n",
      "Epoch 107, Train loss: 0.001772, Validation loss: 0.000112\n",
      "Epoch 108, Train loss: 0.001764, Validation loss: 0.000111\n",
      "Epoch 109, Train loss: 0.001755, Validation loss: 0.000110\n",
      "Epoch 110, Train loss: 0.001747, Validation loss: 0.000109\n",
      "Epoch 111, Train loss: 0.001738, Validation loss: 0.000110\n",
      "Epoch 112, Train loss: 0.001730, Validation loss: 0.000108\n",
      "Epoch 113, Train loss: 0.001718, Validation loss: 0.000110\n",
      "Epoch 114, Train loss: 0.001709, Validation loss: 0.000109\n",
      "Epoch 115, Train loss: 0.001700, Validation loss: 0.000108\n",
      "Epoch 116, Train loss: 0.001695, Validation loss: 0.000108\n",
      "Epoch 117, Train loss: 0.001683, Validation loss: 0.000108\n",
      "Epoch 118, Train loss: 0.001675, Validation loss: 0.000109\n",
      "Epoch 119, Train loss: 0.001667, Validation loss: 0.000108\n",
      "Epoch 120, Train loss: 0.001658, Validation loss: 0.000108\n",
      "Epoch 121, Train loss: 0.001649, Validation loss: 0.000107\n",
      "Epoch 122, Train loss: 0.001641, Validation loss: 0.000108\n",
      "Epoch 123, Train loss: 0.001634, Validation loss: 0.000107\n",
      "Epoch 124, Train loss: 0.001623, Validation loss: 0.000107\n",
      "Epoch 125, Train loss: 0.001617, Validation loss: 0.000108\n",
      "Epoch 126, Train loss: 0.001607, Validation loss: 0.000109\n",
      "Epoch 127, Train loss: 0.001600, Validation loss: 0.000107\n",
      "Epoch 128, Train loss: 0.001594, Validation loss: 0.000108\n",
      "Epoch 129, Train loss: 0.001587, Validation loss: 0.000109\n",
      "Epoch 130, Train loss: 0.001577, Validation loss: 0.000109\n",
      "Epoch 131, Train loss: 0.001571, Validation loss: 0.000110\n",
      "Epoch 132, Train loss: 0.001563, Validation loss: 0.000110\n",
      "Epoch 133, Train loss: 0.001553, Validation loss: 0.000110\n",
      "Epoch 134, Train loss: 0.001546, Validation loss: 0.000111\n",
      "Epoch 135, Train loss: 0.001537, Validation loss: 0.000112\n",
      "Epoch 136, Train loss: 0.001531, Validation loss: 0.000113\n",
      "Epoch 137, Train loss: 0.001524, Validation loss: 0.000113\n",
      "Epoch 138, Train loss: 0.001516, Validation loss: 0.000114\n",
      "Epoch 139, Train loss: 0.001509, Validation loss: 0.000113\n",
      "Epoch 140, Train loss: 0.001502, Validation loss: 0.000113\n",
      "Epoch 141, Train loss: 0.001493, Validation loss: 0.000114\n",
      "Epoch 142, Train loss: 0.001486, Validation loss: 0.000114\n",
      "Epoch 143, Train loss: 0.001477, Validation loss: 0.000116\n",
      "Epoch 144, Train loss: 0.001471, Validation loss: 0.000117\n",
      "Epoch 145, Train loss: 0.001462, Validation loss: 0.000117\n",
      "Epoch 146, Train loss: 0.001457, Validation loss: 0.000120\n",
      "Epoch 147, Train loss: 0.001446, Validation loss: 0.000118\n",
      "Epoch 148, Train loss: 0.001442, Validation loss: 0.000120\n",
      "Epoch 149, Train loss: 0.001434, Validation loss: 0.000121\n",
      "Epoch 150, Train loss: 0.001424, Validation loss: 0.000122\n",
      "Epoch 151, Train loss: 0.001418, Validation loss: 0.000124\n",
      "Epoch 152, Train loss: 0.001411, Validation loss: 0.000125\n",
      "Epoch 153, Train loss: 0.001403, Validation loss: 0.000127\n",
      "Epoch 154, Train loss: 0.001396, Validation loss: 0.000126\n",
      "Epoch 155, Train loss: 0.001388, Validation loss: 0.000130\n",
      "Epoch 156, Train loss: 0.001381, Validation loss: 0.000133\n",
      "Epoch 157, Train loss: 0.001372, Validation loss: 0.000133\n",
      "Epoch 158, Train loss: 0.001368, Validation loss: 0.000135\n",
      "Epoch 159, Train loss: 0.001358, Validation loss: 0.000140\n",
      "Epoch 160, Train loss: 0.001350, Validation loss: 0.000137\n",
      "Epoch 161, Train loss: 0.001341, Validation loss: 0.000141\n",
      "Epoch 162, Train loss: 0.001334, Validation loss: 0.000142\n",
      "Epoch 163, Train loss: 0.001326, Validation loss: 0.000144\n",
      "Epoch 164, Train loss: 0.001320, Validation loss: 0.000149\n",
      "Epoch 165, Train loss: 0.001309, Validation loss: 0.000152\n",
      "Epoch 166, Train loss: 0.001303, Validation loss: 0.000153\n",
      "Epoch 167, Train loss: 0.001294, Validation loss: 0.000158\n",
      "Epoch 168, Train loss: 0.001285, Validation loss: 0.000159\n",
      "Epoch 169, Train loss: 0.001276, Validation loss: 0.000158\n",
      "Epoch 170, Train loss: 0.001270, Validation loss: 0.000164\n",
      "Epoch 171, Train loss: 0.001261, Validation loss: 0.000167\n",
      "Epoch 172, Train loss: 0.001252, Validation loss: 0.000169\n",
      "Epoch 173, Train loss: 0.001245, Validation loss: 0.000170\n",
      "Epoch 174, Train loss: 0.001236, Validation loss: 0.000174\n",
      "Epoch 175, Train loss: 0.001227, Validation loss: 0.000174\n",
      "Epoch 176, Train loss: 0.001216, Validation loss: 0.000178\n",
      "Epoch 177, Train loss: 0.001209, Validation loss: 0.000178\n",
      "Epoch 178, Train loss: 0.001201, Validation loss: 0.000185\n",
      "Epoch 179, Train loss: 0.001192, Validation loss: 0.000184\n",
      "Epoch 180, Train loss: 0.001183, Validation loss: 0.000189\n",
      "Epoch 181, Train loss: 0.001172, Validation loss: 0.000189\n",
      "Epoch 182, Train loss: 0.001165, Validation loss: 0.000189\n",
      "Epoch 183, Train loss: 0.001156, Validation loss: 0.000189\n",
      "Epoch 184, Train loss: 0.001146, Validation loss: 0.000196\n",
      "Epoch 185, Train loss: 0.001138, Validation loss: 0.000196\n",
      "Epoch 186, Train loss: 0.001129, Validation loss: 0.000195\n",
      "Epoch 187, Train loss: 0.001122, Validation loss: 0.000201\n",
      "Epoch 188, Train loss: 0.001111, Validation loss: 0.000198\n",
      "Epoch 189, Train loss: 0.001103, Validation loss: 0.000200\n",
      "Epoch 190, Train loss: 0.001092, Validation loss: 0.000204\n",
      "Epoch 191, Train loss: 0.001084, Validation loss: 0.000205\n",
      "Epoch 192, Train loss: 0.001074, Validation loss: 0.000206\n",
      "Epoch 193, Train loss: 0.001064, Validation loss: 0.000203\n",
      "Epoch 194, Train loss: 0.001053, Validation loss: 0.000204\n",
      "Epoch 195, Train loss: 0.001046, Validation loss: 0.000207\n",
      "Epoch 196, Train loss: 0.001037, Validation loss: 0.000207\n",
      "Epoch 197, Train loss: 0.001029, Validation loss: 0.000208\n",
      "Epoch 198, Train loss: 0.001018, Validation loss: 0.000204\n",
      "Epoch 199, Train loss: 0.001009, Validation loss: 0.000208\n",
      "Epoch 200, Train loss: 0.001003, Validation loss: 0.000207\n",
      "Epoch 201, Train loss: 0.000992, Validation loss: 0.000205\n",
      "Epoch 202, Train loss: 0.000983, Validation loss: 0.000204\n",
      "Epoch 203, Train loss: 0.000974, Validation loss: 0.000208\n",
      "Epoch 204, Train loss: 0.000966, Validation loss: 0.000208\n",
      "Epoch 205, Train loss: 0.000956, Validation loss: 0.000206\n",
      "Epoch 206, Train loss: 0.000949, Validation loss: 0.000207\n",
      "Epoch 207, Train loss: 0.000940, Validation loss: 0.000207\n",
      "Epoch 208, Train loss: 0.000933, Validation loss: 0.000206\n",
      "Epoch 209, Train loss: 0.000925, Validation loss: 0.000210\n",
      "Epoch 210, Train loss: 0.000919, Validation loss: 0.000210\n",
      "Epoch 211, Train loss: 0.000909, Validation loss: 0.000212\n",
      "Epoch 212, Train loss: 0.000901, Validation loss: 0.000213\n",
      "Epoch 213, Train loss: 0.000893, Validation loss: 0.000212\n",
      "Epoch 214, Train loss: 0.000886, Validation loss: 0.000210\n",
      "Epoch 215, Train loss: 0.000878, Validation loss: 0.000206\n",
      "Epoch 216, Train loss: 0.000871, Validation loss: 0.000210\n",
      "Epoch 217, Train loss: 0.000866, Validation loss: 0.000209\n",
      "Epoch 218, Train loss: 0.000856, Validation loss: 0.000208\n",
      "Epoch 219, Train loss: 0.000849, Validation loss: 0.000209\n",
      "Epoch 220, Train loss: 0.000842, Validation loss: 0.000209\n",
      "Epoch 221, Train loss: 0.000836, Validation loss: 0.000208\n",
      "Epoch 222, Train loss: 0.000825, Validation loss: 0.000213\n",
      "Epoch 223, Train loss: 0.000818, Validation loss: 0.000208\n",
      "Epoch 224, Train loss: 0.000812, Validation loss: 0.000209\n",
      "Early stopping on epoch 224\n",
      "Test Error: \n",
      " Avg loss: 0.000209 \n",
      "\n",
      "[[ 0.00574853 -0.01068635  0.01771488 ... -0.00958708 -0.00899614\n",
      "  -0.0076218 ]\n",
      " [-0.0060545  -0.01336727  0.01416986 ... -0.00619709 -0.00807139\n",
      "  -0.0086096 ]\n",
      " [-0.0096008  -0.00786307  0.00909599 ... -0.00318475 -0.01303645\n",
      "  -0.01964048]\n",
      " ...\n",
      " [ 0.01161939 -0.0087538   0.00281272 ... -0.01979861 -0.01561393\n",
      "  -0.00233144]\n",
      " [-0.00799451 -0.01924941  0.01009566 ... -0.00689523 -0.00061694\n",
      "  -0.00261041]\n",
      " [-0.00810092 -0.01610709  0.00239245 ... -0.00742731 -0.013355\n",
      "  -0.00068265]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Figure(1000x600)\n",
      "Using mps device\n",
      "Epoch 1, Train loss: 0.041998, Validation loss: 0.011878\n",
      "Epoch 2, Train loss: 0.018785, Validation loss: 0.004597\n",
      "Epoch 3, Train loss: 0.011676, Validation loss: 0.002273\n",
      "Epoch 4, Train loss: 0.008218, Validation loss: 0.001093\n",
      "Epoch 5, Train loss: 0.006282, Validation loss: 0.000569\n",
      "Epoch 6, Train loss: 0.005231, Validation loss: 0.000414\n",
      "Epoch 7, Train loss: 0.004658, Validation loss: 0.000401\n",
      "Epoch 8, Train loss: 0.004328, Validation loss: 0.000452\n",
      "Epoch 9, Train loss: 0.004134, Validation loss: 0.000498\n",
      "Epoch 10, Train loss: 0.004009, Validation loss: 0.000532\n",
      "Epoch 11, Train loss: 0.003929, Validation loss: 0.000531\n",
      "Epoch 12, Train loss: 0.003864, Validation loss: 0.000513\n",
      "Epoch 13, Train loss: 0.003822, Validation loss: 0.000488\n",
      "Epoch 14, Train loss: 0.003782, Validation loss: 0.000459\n",
      "Epoch 15, Train loss: 0.003747, Validation loss: 0.000436\n",
      "Epoch 16, Train loss: 0.003719, Validation loss: 0.000412\n",
      "Epoch 17, Train loss: 0.003690, Validation loss: 0.000394\n",
      "Epoch 18, Train loss: 0.003661, Validation loss: 0.000376\n",
      "Epoch 19, Train loss: 0.003639, Validation loss: 0.000360\n",
      "Epoch 20, Train loss: 0.003610, Validation loss: 0.000346\n",
      "Epoch 21, Train loss: 0.003590, Validation loss: 0.000334\n",
      "Epoch 22, Train loss: 0.003567, Validation loss: 0.000321\n",
      "Epoch 23, Train loss: 0.003548, Validation loss: 0.000311\n",
      "Epoch 24, Train loss: 0.003526, Validation loss: 0.000302\n",
      "Epoch 25, Train loss: 0.003507, Validation loss: 0.000293\n",
      "Epoch 26, Train loss: 0.003489, Validation loss: 0.000285\n",
      "Epoch 27, Train loss: 0.003470, Validation loss: 0.000276\n",
      "Epoch 28, Train loss: 0.003453, Validation loss: 0.000270\n",
      "Epoch 29, Train loss: 0.003432, Validation loss: 0.000264\n",
      "Epoch 30, Train loss: 0.003412, Validation loss: 0.000258\n",
      "Epoch 31, Train loss: 0.003397, Validation loss: 0.000252\n",
      "Epoch 32, Train loss: 0.003377, Validation loss: 0.000248\n",
      "Epoch 33, Train loss: 0.003359, Validation loss: 0.000242\n",
      "Epoch 34, Train loss: 0.003342, Validation loss: 0.000237\n",
      "Epoch 35, Train loss: 0.003323, Validation loss: 0.000233\n",
      "Epoch 36, Train loss: 0.003304, Validation loss: 0.000229\n",
      "Epoch 37, Train loss: 0.003287, Validation loss: 0.000225\n",
      "Epoch 38, Train loss: 0.003268, Validation loss: 0.000221\n",
      "Epoch 39, Train loss: 0.003251, Validation loss: 0.000218\n",
      "Epoch 40, Train loss: 0.003229, Validation loss: 0.000215\n",
      "Epoch 41, Train loss: 0.003213, Validation loss: 0.000212\n",
      "Epoch 42, Train loss: 0.003195, Validation loss: 0.000209\n",
      "Epoch 43, Train loss: 0.003178, Validation loss: 0.000206\n",
      "Epoch 44, Train loss: 0.003158, Validation loss: 0.000203\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/DannyPang/Desktop/bioinfmsc/diss/model_demo_dropout.py\", line 197, in <module>\n",
      "    main()\n",
      "  File \"/Users/DannyPang/Desktop/bioinfmsc/diss/model_demo_dropout.py\", line 129, in main\n",
      "    model.fit(train_loader, validation_loader, epochs=500)\n",
      "  File \"/Users/DannyPang/Desktop/bioinfmsc/diss/model_sigmoid_dropout.py\", line 71, in fit\n",
      "    train_loss += loss.item()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 model_demo_dropout.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
