{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176d54d3-1ccc-400b-9ff1-69f8f9924859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, random_split, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a325f7-df36-492e-b717-c15cf63e6208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from init_model_lstm import DeconvolutionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a55871-f7bc-4bc6-a42a-551f7f37dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(tensor, device, mean=0, stddev=0.1):\n",
    "    noise=(torch.randn_like(tensor)*stddev+mean).to(device)\n",
    "    noised_tensor=tensor+noise\n",
    "    return noised_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46fae64f-a401-45b8-92fe-8c42c78bc3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "n = 70000\n",
    "known_freqs_file = f'known_freqs_{n}.npy'\n",
    "snv_freqs_file = f'snv_freqs_{n}.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41fda830-dc08-4793-82ee-f5da9e9e8ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_freqs=np.load(snv_freqs_file).astype('float32')\n",
    "known_freqs=np.load(known_freqs_file).astype('float32')\n",
    "\n",
    "snv_freqs=torch.from_numpy(snv_freqs).to(device)\n",
    "known_freqs=torch.from_numpy(known_freqs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b5da6ce-ae51-44b4-b22e-57ea0d0bb851",
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_freqs_splits=torch.split(snv_freqs, [10000, 10000, 10000,10000, 10000, 10000, 10000])\n",
    "known_freqs_splits=torch.split(known_freqs, [10000, 10000, 10000,10000, 10000, 10000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23251674-c2a8-4a82-b319-0eeaccdd8ceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "Epoch 1, Train loss: 0.0071597964, Validation loss: 0.0066729988, LR: 0.0001\n",
      "Epoch 2, Train loss: 0.0063867158, Validation loss: 0.0062565760, LR: 0.0001\n",
      "Epoch 3, Train loss: 0.0060818139, Validation loss: 0.0060446976, LR: 0.0001\n",
      "Epoch 4, Train loss: 0.0059114454, Validation loss: 0.0059155438, LR: 0.0001\n",
      "Epoch 5, Train loss: 0.0058003667, Validation loss: 0.0058241730, LR: 0.0001\n",
      "Epoch 6, Train loss: 0.0057223613, Validation loss: 0.0057613902, LR: 0.0001\n",
      "Epoch 7, Train loss: 0.0056659513, Validation loss: 0.0057072858, LR: 0.0001\n",
      "Epoch 8, Train loss: 0.0056202202, Validation loss: 0.0056628941, LR: 0.0001\n",
      "Epoch 9, Train loss: 0.0055833321, Validation loss: 0.0056272617, LR: 0.0001\n",
      "Epoch 10, Train loss: 0.0055532290, Validation loss: 0.0055998625, LR: 0.0001\n",
      "Epoch 11, Train loss: 0.0055285574, Validation loss: 0.0055779978, LR: 0.0001\n",
      "Epoch 12, Train loss: 0.0055067299, Validation loss: 0.0055573266, LR: 0.0001\n",
      "Epoch 13, Train loss: 0.0054882604, Validation loss: 0.0055390765, LR: 0.0001\n",
      "Epoch 14, Train loss: 0.0054722998, Validation loss: 0.0055207322, LR: 0.0001\n",
      "Epoch 15, Train loss: 0.0054567721, Validation loss: 0.0055081802, LR: 0.0001\n",
      "Epoch 16, Train loss: 0.0054449529, Validation loss: 0.0054961060, LR: 0.0001\n",
      "Epoch 17, Train loss: 0.0054351611, Validation loss: 0.0054855896, LR: 0.0001\n",
      "Epoch 18, Train loss: 0.0054246075, Validation loss: 0.0054751734, LR: 0.0001\n",
      "Epoch 19, Train loss: 0.0054160965, Validation loss: 0.0054657189, LR: 0.0001\n",
      "Epoch 20, Train loss: 0.0054080929, Validation loss: 0.0054580745, LR: 0.0001\n",
      "Epoch 21, Train loss: 0.0054006726, Validation loss: 0.0054513938, LR: 0.0001\n",
      "Epoch 22, Train loss: 0.0053952445, Validation loss: 0.0054444741, LR: 0.0001\n",
      "Epoch 23, Train loss: 0.0053886674, Validation loss: 0.0054385842, LR: 0.0001\n",
      "Epoch 24, Train loss: 0.0053834688, Validation loss: 0.0054336742, LR: 0.0001\n",
      "Epoch 25, Train loss: 0.0053792801, Validation loss: 0.0054266060, LR: 0.0001\n",
      "Epoch 26, Train loss: 0.0053748486, Validation loss: 0.0054236409, LR: 0.0001\n",
      "Epoch 27, Train loss: 0.0053716243, Validation loss: 0.0054192866, LR: 0.0001\n",
      "Epoch 28, Train loss: 0.0053677964, Validation loss: 0.0054170501, LR: 0.0001\n",
      "Epoch 29, Train loss: 0.0053644298, Validation loss: 0.0054123902, LR: 0.0001\n",
      "Epoch 30, Train loss: 0.0053614495, Validation loss: 0.0054095995, LR: 0.0001\n",
      "Epoch 31, Train loss: 0.0053586986, Validation loss: 0.0054065383, LR: 0.0001\n",
      "Epoch 32, Train loss: 0.0053558255, Validation loss: 0.0054033249, LR: 0.0001\n",
      "Epoch 33, Train loss: 0.0053541053, Validation loss: 0.0054002665, LR: 0.0001\n",
      "Epoch 34, Train loss: 0.0053506800, Validation loss: 0.0053969431, LR: 0.0001\n",
      "Epoch 35, Train loss: 0.0053487893, Validation loss: 0.0053949495, LR: 0.0001\n",
      "Epoch 36, Train loss: 0.0053451438, Validation loss: 0.0053918590, LR: 0.0001\n",
      "Epoch 37, Train loss: 0.0053422255, Validation loss: 0.0053893141, LR: 0.0001\n",
      "Epoch 38, Train loss: 0.0053410246, Validation loss: 0.0053863487, LR: 0.0001\n",
      "Epoch 39, Train loss: 0.0053392083, Validation loss: 0.0053844307, LR: 0.0001\n",
      "Epoch 40, Train loss: 0.0053370649, Validation loss: 0.0053826001, LR: 0.0001\n",
      "Epoch 41, Train loss: 0.0053361644, Validation loss: 0.0053820939, LR: 0.0001\n",
      "Epoch 42, Train loss: 0.0053346914, Validation loss: 0.0053803581, LR: 0.0001\n",
      "Epoch 43, Train loss: 0.0053336135, Validation loss: 0.0053787936, LR: 0.0001\n",
      "Epoch 44, Train loss: 0.0053321064, Validation loss: 0.0053759982, LR: 0.0001\n",
      "Epoch 45, Train loss: 0.0053309211, Validation loss: 0.0053760622, LR: 0.0001\n",
      "Epoch 46, Train loss: 0.0053302080, Validation loss: 0.0053737638, LR: 0.0001\n",
      "Epoch 47, Train loss: 0.0053288322, Validation loss: 0.0053734616, LR: 0.0001\n",
      "Epoch 48, Train loss: 0.0053278389, Validation loss: 0.0053711813, LR: 0.0001\n",
      "Epoch 49, Train loss: 0.0053259505, Validation loss: 0.0053712116, LR: 0.0001\n",
      "Epoch 50, Train loss: 0.0053248647, Validation loss: 0.0053701800, LR: 0.0001\n",
      "Epoch 51, Train loss: 0.0053249347, Validation loss: 0.0053699546, LR: 0.0001\n",
      "Epoch 52, Train loss: 0.0053238129, Validation loss: 0.0053680135, LR: 0.0001\n",
      "Epoch 53, Train loss: 0.0053231305, Validation loss: 0.0053666873, LR: 0.0001\n",
      "Epoch 54, Train loss: 0.0053223084, Validation loss: 0.0053668245, LR: 0.0001\n",
      "Epoch 55, Train loss: 0.0053217736, Validation loss: 0.0053654968, LR: 0.0001\n",
      "Epoch 56, Train loss: 0.0053216377, Validation loss: 0.0053653549, LR: 0.0001\n",
      "Epoch 57, Train loss: 0.0053196157, Validation loss: 0.0053653660, LR: 0.0001\n",
      "Epoch 58, Train loss: 0.0053194998, Validation loss: 0.0053635549, LR: 0.0001\n",
      "Epoch 59, Train loss: 0.0053184228, Validation loss: 0.0053624665, LR: 0.0001\n",
      "Epoch 60, Train loss: 0.0053183148, Validation loss: 0.0053627700, LR: 0.0001\n",
      "Epoch 61, Train loss: 0.0053174157, Validation loss: 0.0053621667, LR: 0.0001\n",
      "Epoch 62, Train loss: 0.0053170519, Validation loss: 0.0053615216, LR: 0.0001\n",
      "Epoch 63, Train loss: 0.0053165661, Validation loss: 0.0053606867, LR: 0.0001\n",
      "Epoch 64, Train loss: 0.0053149771, Validation loss: 0.0053596167, LR: 0.0001\n",
      "Epoch 65, Train loss: 0.0053150830, Validation loss: 0.0053591229, LR: 0.0001\n",
      "Epoch 66, Train loss: 0.0053138635, Validation loss: 0.0053597580, LR: 0.0001\n",
      "Epoch 67, Train loss: 0.0053144642, Validation loss: 0.0053584240, LR: 0.0001\n",
      "Epoch 68, Train loss: 0.0053141770, Validation loss: 0.0053583432, LR: 0.0001\n",
      "Epoch 69, Train loss: 0.0053134083, Validation loss: 0.0053573320, LR: 0.0001\n",
      "Epoch 70, Train loss: 0.0053125767, Validation loss: 0.0053568424, LR: 0.0001\n",
      "Epoch 71, Train loss: 0.0053118486, Validation loss: 0.0053563862, LR: 0.0001\n",
      "Epoch 72, Train loss: 0.0053122030, Validation loss: 0.0053562443, LR: 0.0001\n",
      "Epoch 73, Train loss: 0.0053105312, Validation loss: 0.0053549968, LR: 0.0001\n",
      "Epoch 74, Train loss: 0.0053108030, Validation loss: 0.0053551782, LR: 0.0001\n",
      "Epoch 75, Train loss: 0.0053098907, Validation loss: 0.0053546467, LR: 0.0001\n",
      "Epoch 76, Train loss: 0.0053096372, Validation loss: 0.0053552110, LR: 0.0001\n",
      "Epoch 77, Train loss: 0.0053103144, Validation loss: 0.0053544585, LR: 0.0001\n",
      "Epoch 78, Train loss: 0.0053094672, Validation loss: 0.0053542745, LR: 0.0001\n",
      "Epoch 79, Train loss: 0.0053095911, Validation loss: 0.0053540297, LR: 0.0001\n",
      "Epoch 80, Train loss: 0.0053085896, Validation loss: 0.0053530374, LR: 0.0001\n",
      "Epoch 81, Train loss: 0.0053083126, Validation loss: 0.0053530759, LR: 0.0001\n",
      "Epoch 82, Train loss: 0.0053078589, Validation loss: 0.0053528376, LR: 0.0001\n",
      "Epoch 83, Train loss: 0.0053076279, Validation loss: 0.0053521563, LR: 0.0001\n",
      "Epoch 84, Train loss: 0.0053070038, Validation loss: 0.0053524302, LR: 0.0001\n",
      "Epoch 85, Train loss: 0.0053060931, Validation loss: 0.0053516857, LR: 0.0001\n",
      "Epoch 86, Train loss: 0.0053066947, Validation loss: 0.0053513612, LR: 0.0001\n",
      "Epoch 87, Train loss: 0.0053066308, Validation loss: 0.0053513623, LR: 0.0001\n",
      "Epoch 88, Train loss: 0.0053056134, Validation loss: 0.0053507006, LR: 0.0001\n",
      "Epoch 89, Train loss: 0.0053064732, Validation loss: 0.0053501191, LR: 0.0001\n",
      "Epoch 90, Train loss: 0.0053051862, Validation loss: 0.0053510661, LR: 0.0001\n",
      "Epoch 91, Train loss: 0.0053044365, Validation loss: 0.0053499893, LR: 0.0001\n",
      "Epoch 92, Train loss: 0.0053044348, Validation loss: 0.0053498499, LR: 0.0001\n",
      "Epoch 93, Train loss: 0.0053042435, Validation loss: 0.0053496640, LR: 0.0001\n",
      "Epoch 94, Train loss: 0.0053037673, Validation loss: 0.0053489051, LR: 0.0001\n",
      "Epoch 95, Train loss: 0.0053039521, Validation loss: 0.0053490048, LR: 0.0001\n",
      "Epoch 96, Train loss: 0.0053024511, Validation loss: 0.0053485862, LR: 0.0001\n",
      "Epoch 97, Train loss: 0.0053041005, Validation loss: 0.0053482892, LR: 0.0001\n",
      "Epoch 98, Train loss: 0.0053031260, Validation loss: 0.0053479614, LR: 0.0001\n",
      "Epoch 99, Train loss: 0.0053022461, Validation loss: 0.0053481481, LR: 0.0001\n",
      "Epoch 100, Train loss: 0.0053023749, Validation loss: 0.0053475067, LR: 0.0001\n",
      "Epoch 101, Train loss: 0.0053020575, Validation loss: 0.0053475093, LR: 0.0001\n",
      "Epoch 102, Train loss: 0.0053022903, Validation loss: 0.0053475589, LR: 0.0001\n",
      "Epoch 103, Train loss: 0.0053019852, Validation loss: 0.0053470880, LR: 0.0001\n",
      "Epoch 104, Train loss: 0.0053011129, Validation loss: 0.0053475540, LR: 0.0001\n",
      "Epoch 105, Train loss: 0.0053010057, Validation loss: 0.0053466613, LR: 0.0001\n",
      "Epoch 106, Train loss: 0.0053007136, Validation loss: 0.0053466570, LR: 0.0001\n",
      "Epoch 107, Train loss: 0.0053003190, Validation loss: 0.0053458060, LR: 0.0001\n",
      "Epoch 108, Train loss: 0.0053014667, Validation loss: 0.0053457313, LR: 0.0001\n",
      "Epoch 109, Train loss: 0.0053008073, Validation loss: 0.0053456982, LR: 0.0001\n",
      "Epoch 110, Train loss: 0.0053007097, Validation loss: 0.0053459638, LR: 0.0001\n",
      "Epoch 111, Train loss: 0.0052998162, Validation loss: 0.0053448844, LR: 0.0001\n",
      "Epoch 112, Train loss: 0.0052998333, Validation loss: 0.0053451968, LR: 0.0001\n",
      "Epoch 113, Train loss: 0.0053001187, Validation loss: 0.0053448259, LR: 0.0001\n",
      "Epoch 114, Train loss: 0.0052994474, Validation loss: 0.0053446329, LR: 0.0001\n",
      "Epoch 115, Train loss: 0.0052990275, Validation loss: 0.0053450381, LR: 0.0001\n",
      "Epoch 116, Train loss: 0.0052994479, Validation loss: 0.0053455069, LR: 0.0001\n",
      "Epoch 117, Train loss: 0.0052987475, Validation loss: 0.0053445782, LR: 0.0001\n",
      "Epoch 118, Train loss: 0.0052994670, Validation loss: 0.0053442356, LR: 0.0001\n",
      "Epoch 119, Train loss: 0.0052994434, Validation loss: 0.0053441485, LR: 0.0001\n",
      "Epoch 120, Train loss: 0.0052989452, Validation loss: 0.0053434483, LR: 0.0001\n",
      "Epoch 121, Train loss: 0.0052976513, Validation loss: 0.0053438653, LR: 0.0001\n",
      "Epoch 122, Train loss: 0.0052983802, Validation loss: 0.0053435442, LR: 0.0001\n",
      "Epoch 123, Train loss: 0.0052981644, Validation loss: 0.0053440867, LR: 0.0001\n",
      "Epoch 124, Train loss: 0.0052984382, Validation loss: 0.0053432565, LR: 0.0001\n",
      "Epoch 125, Train loss: 0.0052982470, Validation loss: 0.0053428658, LR: 0.0001\n",
      "Epoch 126, Train loss: 0.0052975687, Validation loss: 0.0053427913, LR: 0.0001\n",
      "Epoch 127, Train loss: 0.0052966638, Validation loss: 0.0053424280, LR: 0.0001\n",
      "Epoch 128, Train loss: 0.0052968749, Validation loss: 0.0053424016, LR: 0.0001\n",
      "Epoch 129, Train loss: 0.0052964862, Validation loss: 0.0053419642, LR: 0.0001\n",
      "Epoch 130, Train loss: 0.0052973160, Validation loss: 0.0053419898, LR: 0.0001\n",
      "Epoch 131, Train loss: 0.0052970425, Validation loss: 0.0053421287, LR: 0.0001\n",
      "Epoch 132, Train loss: 0.0052968995, Validation loss: 0.0053410624, LR: 0.0001\n",
      "Epoch 133, Train loss: 0.0052967840, Validation loss: 0.0053413765, LR: 0.0001\n",
      "Epoch 134, Train loss: 0.0052957180, Validation loss: 0.0053415717, LR: 0.0001\n",
      "Epoch 135, Train loss: 0.0052966730, Validation loss: 0.0053411103, LR: 0.0001\n",
      "Epoch 136, Train loss: 0.0052962715, Validation loss: 0.0053410231, LR: 0.0001\n",
      "Epoch 137, Train loss: 0.0052966664, Validation loss: 0.0053414029, LR: 0.0001\n",
      "Epoch 138, Train loss: 0.0052951570, Validation loss: 0.0053404501, LR: 0.0001\n",
      "Epoch 139, Train loss: 0.0052956544, Validation loss: 0.0053407158, LR: 0.0001\n",
      "Epoch 140, Train loss: 0.0052955859, Validation loss: 0.0053406546, LR: 0.0001\n",
      "Epoch 141, Train loss: 0.0052945281, Validation loss: 0.0053400588, LR: 0.0001\n",
      "Epoch 142, Train loss: 0.0052954424, Validation loss: 0.0053401528, LR: 0.0001\n",
      "Epoch 143, Train loss: 0.0052945775, Validation loss: 0.0053403951, LR: 0.0001\n",
      "Epoch 144, Train loss: 0.0052946032, Validation loss: 0.0053404818, LR: 0.0001\n",
      "Epoch 145, Train loss: 0.0052950120, Validation loss: 0.0053398653, LR: 0.0001\n",
      "Epoch 146, Train loss: 0.0052946166, Validation loss: 0.0053396157, LR: 0.0001\n",
      "Epoch 147, Train loss: 0.0052940077, Validation loss: 0.0053395524, LR: 0.0001\n",
      "Epoch 148, Train loss: 0.0052942439, Validation loss: 0.0053392326, LR: 0.0001\n",
      "Epoch 149, Train loss: 0.0052936015, Validation loss: 0.0053394313, LR: 0.0001\n",
      "Epoch 150, Train loss: 0.0052945555, Validation loss: 0.0053394449, LR: 0.0001\n",
      "Epoch 151, Train loss: 0.0052950138, Validation loss: 0.0053392227, LR: 0.0001\n",
      "Epoch 152, Train loss: 0.0052940694, Validation loss: 0.0053386885, LR: 0.0001\n",
      "Epoch 153, Train loss: 0.0052931580, Validation loss: 0.0053387264, LR: 0.0001\n",
      "Epoch 154, Train loss: 0.0052936451, Validation loss: 0.0053386767, LR: 0.0001\n",
      "Epoch 155, Train loss: 0.0052933243, Validation loss: 0.0053388049, LR: 0.0001\n",
      "Epoch 156, Train loss: 0.0052942339, Validation loss: 0.0053387266, LR: 0.0001\n",
      "Epoch 157, Train loss: 0.0052936700, Validation loss: 0.0053384477, LR: 0.0001\n",
      "Epoch 158, Train loss: 0.0052935906, Validation loss: 0.0053385656, LR: 0.0001\n",
      "Epoch 159, Train loss: 0.0052933068, Validation loss: 0.0053380287, LR: 0.0001\n",
      "Epoch 160, Train loss: 0.0052931641, Validation loss: 0.0053381483, LR: 0.0001\n",
      "Epoch 161, Train loss: 0.0052924178, Validation loss: 0.0053380546, LR: 0.0001\n",
      "Epoch 162, Train loss: 0.0052918730, Validation loss: 0.0053377940, LR: 0.0001\n",
      "Epoch 163, Train loss: 0.0052927193, Validation loss: 0.0053377167, LR: 0.0001\n",
      "Epoch 164, Train loss: 0.0052923061, Validation loss: 0.0053378982, LR: 0.0001\n",
      "Epoch 165, Train loss: 0.0052923625, Validation loss: 0.0053375179, LR: 0.0001\n",
      "Epoch 166, Train loss: 0.0052925459, Validation loss: 0.0053375940, LR: 0.0001\n",
      "Epoch 167, Train loss: 0.0052921940, Validation loss: 0.0053373805, LR: 0.0001\n",
      "Epoch 168, Train loss: 0.0052919104, Validation loss: 0.0053372317, LR: 0.0001\n",
      "Epoch 169, Train loss: 0.0052919498, Validation loss: 0.0053370470, LR: 0.0001\n",
      "Epoch 170, Train loss: 0.0052915423, Validation loss: 0.0053372927, LR: 0.0001\n",
      "Epoch 171, Train loss: 0.0052921198, Validation loss: 0.0053366359, LR: 0.0001\n",
      "Epoch 172, Train loss: 0.0052916999, Validation loss: 0.0053366559, LR: 0.0001\n",
      "Epoch 173, Train loss: 0.0052915962, Validation loss: 0.0053366939, LR: 0.0001\n",
      "Epoch 174, Train loss: 0.0052919157, Validation loss: 0.0053368516, LR: 0.0001\n",
      "Epoch 175, Train loss: 0.0052920118, Validation loss: 0.0053374466, LR: 0.0001\n",
      "Epoch 176, Train loss: 0.0052919328, Validation loss: 0.0053366089, LR: 0.0001\n",
      "Epoch 177, Train loss: 0.0052911390, Validation loss: 0.0053360198, LR: 0.0001\n",
      "Epoch 178, Train loss: 0.0052910918, Validation loss: 0.0053359779, LR: 0.0001\n",
      "Epoch 179, Train loss: 0.0052906438, Validation loss: 0.0053356160, LR: 0.0001\n",
      "Epoch 180, Train loss: 0.0052917654, Validation loss: 0.0053358375, LR: 0.0001\n",
      "Epoch 181, Train loss: 0.0052912594, Validation loss: 0.0053353957, LR: 0.0001\n",
      "Epoch 182, Train loss: 0.0052908432, Validation loss: 0.0053354728, LR: 0.0001\n",
      "Epoch 183, Train loss: 0.0052909049, Validation loss: 0.0053354125, LR: 0.0001\n",
      "Epoch 184, Train loss: 0.0052907866, Validation loss: 0.0053361767, LR: 0.0001\n",
      "Epoch 185, Train loss: 0.0052909108, Validation loss: 0.0053348780, LR: 0.0001\n",
      "Epoch 186, Train loss: 0.0052903770, Validation loss: 0.0053352382, LR: 0.0001\n",
      "Epoch 187, Train loss: 0.0052906899, Validation loss: 0.0053352214, LR: 0.0001\n",
      "Epoch 188, Train loss: 0.0052906929, Validation loss: 0.0053346794, LR: 0.0001\n",
      "Epoch 189, Train loss: 0.0052900997, Validation loss: 0.0053342246, LR: 0.0001\n",
      "Epoch 190, Train loss: 0.0052900876, Validation loss: 0.0053350099, LR: 0.0001\n",
      "Epoch 191, Train loss: 0.0052901566, Validation loss: 0.0053347830, LR: 0.0001\n",
      "Epoch 192, Train loss: 0.0052902157, Validation loss: 0.0053345706, LR: 0.0001\n",
      "Epoch 193, Train loss: 0.0052900812, Validation loss: 0.0053347996, LR: 0.0001\n",
      "Epoch 194, Train loss: 0.0052903292, Validation loss: 0.0053345096, LR: 0.0001\n",
      "Epoch 195, Train loss: 0.0052900754, Validation loss: 0.0053339621, LR: 0.0001\n",
      "Epoch 196, Train loss: 0.0052900803, Validation loss: 0.0053336681, LR: 0.0001\n",
      "Epoch 197, Train loss: 0.0052901007, Validation loss: 0.0053341587, LR: 0.0001\n",
      "Epoch 198, Train loss: 0.0052897732, Validation loss: 0.0053338586, LR: 0.0001\n",
      "Epoch 199, Train loss: 0.0052900284, Validation loss: 0.0053342721, LR: 0.0001\n",
      "Epoch 200, Train loss: 0.0052898642, Validation loss: 0.0053336248, LR: 0.0001\n",
      "Epoch 201, Train loss: 0.0052892252, Validation loss: 0.0053337962, LR: 0.0001\n",
      "Epoch 202, Train loss: 0.0052890880, Validation loss: 0.0053336093, LR: 0.0001\n",
      "Epoch 203, Train loss: 0.0052895242, Validation loss: 0.0053334794, LR: 0.0001\n",
      "Epoch 204, Train loss: 0.0052882453, Validation loss: 0.0053332890, LR: 0.0001\n",
      "Epoch 205, Train loss: 0.0052894058, Validation loss: 0.0053327348, LR: 0.0001\n",
      "Epoch 206, Train loss: 0.0052894585, Validation loss: 0.0053334387, LR: 0.0001\n",
      "Epoch 207, Train loss: 0.0052893110, Validation loss: 0.0053331006, LR: 0.0001\n",
      "Epoch 208, Train loss: 0.0052882878, Validation loss: 0.0053332872, LR: 0.0001\n",
      "Epoch 209, Train loss: 0.0052887968, Validation loss: 0.0053327437, LR: 0.0001\n",
      "Epoch 210, Train loss: 0.0052882141, Validation loss: 0.0053326287, LR: 0.0001\n",
      "Epoch 211, Train loss: 0.0052884117, Validation loss: 0.0053326007, LR: 0.0001\n",
      "Epoch 212, Train loss: 0.0052883124, Validation loss: 0.0053323380, LR: 0.0001\n",
      "Epoch 213, Train loss: 0.0052889958, Validation loss: 0.0053328344, LR: 0.0001\n",
      "Epoch 214, Train loss: 0.0052893704, Validation loss: 0.0053326721, LR: 0.0001\n",
      "Epoch 215, Train loss: 0.0052889925, Validation loss: 0.0053325586, LR: 0.0001\n",
      "Epoch 216, Train loss: 0.0052883622, Validation loss: 0.0053318490, LR: 0.0001\n",
      "Epoch 217, Train loss: 0.0052883163, Validation loss: 0.0053321504, LR: 0.0001\n",
      "Epoch 218, Train loss: 0.0052880834, Validation loss: 0.0053320976, LR: 0.0001\n",
      "Epoch 219, Train loss: 0.0052876761, Validation loss: 0.0053318743, LR: 0.0001\n",
      "Epoch 220, Train loss: 0.0052880091, Validation loss: 0.0053319456, LR: 0.0001\n",
      "Epoch 221, Train loss: 0.0052879869, Validation loss: 0.0053313244, LR: 0.0001\n",
      "Epoch 222, Train loss: 0.0052878288, Validation loss: 0.0053318278, LR: 0.0001\n",
      "Epoch 223, Train loss: 0.0052872953, Validation loss: 0.0053312956, LR: 0.0001\n",
      "Epoch 224, Train loss: 0.0052873724, Validation loss: 0.0053314859, LR: 0.0001\n",
      "Epoch 225, Train loss: 0.0052878728, Validation loss: 0.0053310060, LR: 0.0001\n",
      "Epoch 226, Train loss: 0.0052881728, Validation loss: 0.0053309339, LR: 0.0001\n",
      "Epoch 227, Train loss: 0.0052873522, Validation loss: 0.0053312262, LR: 0.0001\n",
      "Epoch 228, Train loss: 0.0052877309, Validation loss: 0.0053313101, LR: 0.0001\n",
      "Epoch 229, Train loss: 0.0052878310, Validation loss: 0.0053306922, LR: 0.0001\n",
      "Epoch 230, Train loss: 0.0052876099, Validation loss: 0.0053302879, LR: 0.0001\n",
      "Epoch 231, Train loss: 0.0052872838, Validation loss: 0.0053313107, LR: 0.0001\n",
      "Epoch 232, Train loss: 0.0052869124, Validation loss: 0.0053302076, LR: 0.0001\n",
      "Epoch 233, Train loss: 0.0052862610, Validation loss: 0.0053309450, LR: 0.0001\n",
      "Epoch 234, Train loss: 0.0052867367, Validation loss: 0.0053305200, LR: 0.0001\n",
      "Epoch 235, Train loss: 0.0052873362, Validation loss: 0.0053304726, LR: 0.0001\n",
      "Epoch 236, Train loss: 0.0052876700, Validation loss: 0.0053300171, LR: 0.0001\n",
      "Epoch 237, Train loss: 0.0052865485, Validation loss: 0.0053305268, LR: 0.0001\n",
      "Epoch 238, Train loss: 0.0052866763, Validation loss: 0.0053302985, LR: 0.0001\n",
      "Epoch 239, Train loss: 0.0052875138, Validation loss: 0.0053300878, LR: 0.0001\n",
      "Epoch 240, Train loss: 0.0052862874, Validation loss: 0.0053305893, LR: 0.0001\n",
      "Epoch 241, Train loss: 0.0052867097, Validation loss: 0.0053300327, LR: 0.0001\n",
      "Epoch 242, Train loss: 0.0052867233, Validation loss: 0.0053293931, LR: 0.0001\n",
      "Epoch 243, Train loss: 0.0052866068, Validation loss: 0.0053296532, LR: 0.0001\n",
      "Epoch 244, Train loss: 0.0052865877, Validation loss: 0.0053294695, LR: 0.0001\n",
      "Epoch 245, Train loss: 0.0052866269, Validation loss: 0.0053295169, LR: 0.0001\n",
      "Epoch 246, Train loss: 0.0052869177, Validation loss: 0.0053296743, LR: 0.0001\n",
      "Epoch 247, Train loss: 0.0052865194, Validation loss: 0.0053294223, LR: 0.0001\n",
      "Epoch 248, Train loss: 0.0052864419, Validation loss: 0.0053293898, LR: 0.0001\n",
      "Epoch 249, Train loss: 0.0052863987, Validation loss: 0.0053291055, LR: 0.0001\n",
      "Epoch 250, Train loss: 0.0052866771, Validation loss: 0.0053290834, LR: 0.0001\n",
      "Epoch 251, Train loss: 0.0052862057, Validation loss: 0.0053291244, LR: 0.0001\n",
      "Epoch 252, Train loss: 0.0052870177, Validation loss: 0.0053289513, LR: 0.0001\n",
      "Epoch 253, Train loss: 0.0052864831, Validation loss: 0.0053291878, LR: 0.0001\n",
      "Epoch 254, Train loss: 0.0052862277, Validation loss: 0.0053290963, LR: 0.0001\n",
      "Epoch 255, Train loss: 0.0052866792, Validation loss: 0.0053287299, LR: 0.0001\n",
      "Epoch 256, Train loss: 0.0052861712, Validation loss: 0.0053288624, LR: 0.0001\n",
      "Epoch 257, Train loss: 0.0052861229, Validation loss: 0.0053283247, LR: 0.0001\n",
      "Epoch 258, Train loss: 0.0052856507, Validation loss: 0.0053284600, LR: 0.0001\n",
      "Epoch 259, Train loss: 0.0052863883, Validation loss: 0.0053286825, LR: 0.0001\n",
      "Epoch 260, Train loss: 0.0052854327, Validation loss: 0.0053286207, LR: 0.0001\n",
      "Epoch 261, Train loss: 0.0052853702, Validation loss: 0.0053284755, LR: 0.0001\n",
      "Epoch 262, Train loss: 0.0052856449, Validation loss: 0.0053282839, LR: 0.0001\n",
      "Epoch 263, Train loss: 0.0052856777, Validation loss: 0.0053276777, LR: 0.0001\n",
      "Epoch 264, Train loss: 0.0052850638, Validation loss: 0.0053280577, LR: 0.0001\n",
      "Epoch 265, Train loss: 0.0052854440, Validation loss: 0.0053277247, LR: 0.0001\n",
      "Epoch 266, Train loss: 0.0052857928, Validation loss: 0.0053278542, LR: 0.0001\n",
      "Epoch 267, Train loss: 0.0052854522, Validation loss: 0.0053278395, LR: 0.0001\n",
      "Epoch 268, Train loss: 0.0052851794, Validation loss: 0.0053279206, LR: 0.0001\n",
      "Epoch 269, Train loss: 0.0052850552, Validation loss: 0.0053282398, LR: 0.0001\n",
      "Epoch 270, Train loss: 0.0052857461, Validation loss: 0.0053281428, LR: 0.0001\n",
      "Epoch 271, Train loss: 0.0052855984, Validation loss: 0.0053276369, LR: 0.0001\n",
      "Epoch 272, Train loss: 0.0052852114, Validation loss: 0.0053274601, LR: 0.0001\n",
      "Epoch 273, Train loss: 0.0052853747, Validation loss: 0.0053278582, LR: 0.0001\n",
      "Epoch 274, Train loss: 0.0052861835, Validation loss: 0.0053274634, LR: 0.0001\n",
      "Epoch 275, Train loss: 0.0052850166, Validation loss: 0.0053271116, LR: 0.0001\n",
      "Epoch 276, Train loss: 0.0052861504, Validation loss: 0.0053270923, LR: 0.0001\n",
      "Epoch 277, Train loss: 0.0052853181, Validation loss: 0.0053274693, LR: 0.0001\n",
      "Epoch 278, Train loss: 0.0052852042, Validation loss: 0.0053269347, LR: 0.0001\n",
      "Epoch 279, Train loss: 0.0052852921, Validation loss: 0.0053271782, LR: 0.0001\n",
      "Epoch 280, Train loss: 0.0052849438, Validation loss: 0.0053267964, LR: 0.0001\n",
      "Epoch 281, Train loss: 0.0052848535, Validation loss: 0.0053267919, LR: 0.0001\n",
      "Epoch 282, Train loss: 0.0052851318, Validation loss: 0.0053266449, LR: 0.0001\n",
      "Epoch 283, Train loss: 0.0052851189, Validation loss: 0.0053265357, LR: 0.0001\n",
      "Epoch 284, Train loss: 0.0052849119, Validation loss: 0.0053271801, LR: 0.0001\n",
      "Epoch 285, Train loss: 0.0052850677, Validation loss: 0.0053271884, LR: 0.0001\n",
      "Epoch 286, Train loss: 0.0052845378, Validation loss: 0.0053263239, LR: 0.0001\n",
      "Epoch 287, Train loss: 0.0052848814, Validation loss: 0.0053261879, LR: 0.0001\n",
      "Epoch 288, Train loss: 0.0052852534, Validation loss: 0.0053261110, LR: 0.0001\n",
      "Epoch 289, Train loss: 0.0052851821, Validation loss: 0.0053264466, LR: 0.0001\n",
      "Epoch 290, Train loss: 0.0052852892, Validation loss: 0.0053266220, LR: 0.0001\n",
      "Epoch 291, Train loss: 0.0052851450, Validation loss: 0.0053262261, LR: 0.0001\n",
      "Epoch 292, Train loss: 0.0052841634, Validation loss: 0.0053258758, LR: 0.0001\n",
      "Epoch 293, Train loss: 0.0052850709, Validation loss: 0.0053262550, LR: 0.0001\n",
      "Epoch 294, Train loss: 0.0052855355, Validation loss: 0.0053257386, LR: 0.0001\n",
      "Epoch 295, Train loss: 0.0052844485, Validation loss: 0.0053261542, LR: 0.0001\n",
      "Epoch 296, Train loss: 0.0052848745, Validation loss: 0.0053261025, LR: 0.0001\n",
      "Epoch 297, Train loss: 0.0052845915, Validation loss: 0.0053256348, LR: 0.0001\n",
      "Epoch 298, Train loss: 0.0052846733, Validation loss: 0.0053256335, LR: 0.0001\n",
      "Epoch 299, Train loss: 0.0052847317, Validation loss: 0.0053255286, LR: 0.0001\n",
      "Epoch 300, Train loss: 0.0052842268, Validation loss: 0.0053254177, LR: 0.0001\n",
      "Epoch 301, Train loss: 0.0052843968, Validation loss: 0.0053255063, LR: 0.0001\n",
      "Epoch 302, Train loss: 0.0052846391, Validation loss: 0.0053255135, LR: 0.0001\n",
      "Epoch 303, Train loss: 0.0052846320, Validation loss: 0.0053255723, LR: 0.0001\n",
      "Epoch 304, Train loss: 0.0052846414, Validation loss: 0.0053255534, LR: 0.0001\n",
      "Epoch 305, Train loss: 0.0052833950, Validation loss: 0.0053253648, LR: 0.0001\n",
      "Epoch 306, Train loss: 0.0052841420, Validation loss: 0.0053252761, LR: 0.0001\n",
      "Epoch 307, Train loss: 0.0052842998, Validation loss: 0.0053247239, LR: 0.0001\n",
      "Epoch 308, Train loss: 0.0052843052, Validation loss: 0.0053251030, LR: 0.0001\n",
      "Epoch 309, Train loss: 0.0052833820, Validation loss: 0.0053254383, LR: 0.0001\n",
      "Epoch 310, Train loss: 0.0052842698, Validation loss: 0.0053251116, LR: 0.0001\n",
      "Epoch 311, Train loss: 0.0052838248, Validation loss: 0.0053251761, LR: 0.0001\n",
      "Epoch 312, Train loss: 0.0052837608, Validation loss: 0.0053248263, LR: 0.0001\n",
      "Epoch 313, Train loss: 0.0052843762, Validation loss: 0.0053247609, LR: 0.0001\n",
      "Epoch 314, Train loss: 0.0052842765, Validation loss: 0.0053248946, LR: 0.0001\n",
      "Epoch 315, Train loss: 0.0052837238, Validation loss: 0.0053252177, LR: 0.0001\n",
      "Epoch 316, Train loss: 0.0052834223, Validation loss: 0.0053248198, LR: 0.0001\n",
      "Epoch 317, Train loss: 0.0052841089, Validation loss: 0.0053246811, LR: 0.0001\n",
      "Epoch 318, Train loss: 0.0052835006, Validation loss: 0.0053249836, LR: 0.0001\n",
      "Epoch 319, Train loss: 0.0052836768, Validation loss: 0.0053245443, LR: 0.0001\n",
      "Epoch 320, Train loss: 0.0052832283, Validation loss: 0.0053242984, LR: 0.0001\n",
      "Epoch 321, Train loss: 0.0052837095, Validation loss: 0.0053243614, LR: 0.0001\n",
      "Epoch 322, Train loss: 0.0052831639, Validation loss: 0.0053242885, LR: 0.0001\n",
      "Epoch 323, Train loss: 0.0052842774, Validation loss: 0.0053244465, LR: 0.0001\n",
      "Epoch 324, Train loss: 0.0052833387, Validation loss: 0.0053239573, LR: 0.0001\n",
      "Epoch 325, Train loss: 0.0052832322, Validation loss: 0.0053244521, LR: 0.0001\n",
      "Epoch 326, Train loss: 0.0052832306, Validation loss: 0.0053245249, LR: 0.0001\n",
      "Epoch 327, Train loss: 0.0052833024, Validation loss: 0.0053243025, LR: 0.0001\n",
      "Epoch 328, Train loss: 0.0052838856, Validation loss: 0.0053242147, LR: 0.0001\n",
      "Epoch 329, Train loss: 0.0052831889, Validation loss: 0.0053238055, LR: 0.0001\n",
      "Epoch 330, Train loss: 0.0052831792, Validation loss: 0.0053235966, LR: 0.0001\n",
      "Epoch 331, Train loss: 0.0052828218, Validation loss: 0.0053241540, LR: 0.0001\n",
      "Epoch 332, Train loss: 0.0052828813, Validation loss: 0.0053239241, LR: 0.0001\n",
      "Epoch 333, Train loss: 0.0052829147, Validation loss: 0.0053241148, LR: 0.0001\n",
      "Epoch 334, Train loss: 0.0052835623, Validation loss: 0.0053238300, LR: 0.0001\n",
      "Epoch 335, Train loss: 0.0052825359, Validation loss: 0.0053238588, LR: 0.0001\n",
      "Epoch 336, Train loss: 0.0052834781, Validation loss: 0.0053236161, LR: 0.0001\n",
      "Epoch 337, Train loss: 0.0052829767, Validation loss: 0.0053236545, LR: 0.0001\n",
      "Epoch 338, Train loss: 0.0052828741, Validation loss: 0.0053235503, LR: 0.0001\n",
      "Epoch 339, Train loss: 0.0052825588, Validation loss: 0.0053235538, LR: 0.0001\n",
      "Epoch 340, Train loss: 0.0052840995, Validation loss: 0.0053235488, LR: 0.0001\n",
      "Epoch 341, Train loss: 0.0052826587, Validation loss: 0.0053233708, LR: 0.0001\n",
      "Epoch 342, Train loss: 0.0052833529, Validation loss: 0.0053236188, LR: 0.0001\n",
      "Epoch 343, Train loss: 0.0052831909, Validation loss: 0.0053229968, LR: 0.0001\n",
      "Epoch 344, Train loss: 0.0052834640, Validation loss: 0.0053235078, LR: 0.0001\n",
      "Epoch 345, Train loss: 0.0052826208, Validation loss: 0.0053231676, LR: 0.0001\n",
      "Epoch 346, Train loss: 0.0052825000, Validation loss: 0.0053231406, LR: 0.0001\n",
      "Epoch 347, Train loss: 0.0052832002, Validation loss: 0.0053229284, LR: 0.0001\n",
      "Epoch 348, Train loss: 0.0052831571, Validation loss: 0.0053229714, LR: 0.0001\n",
      "Epoch 349, Train loss: 0.0052827342, Validation loss: 0.0053230043, LR: 0.0001\n",
      "Epoch 350, Train loss: 0.0052826613, Validation loss: 0.0053227494, LR: 0.0001\n",
      "Epoch 351, Train loss: 0.0052818161, Validation loss: 0.0053231463, LR: 0.0001\n",
      "Epoch 352, Train loss: 0.0052828472, Validation loss: 0.0053227535, LR: 0.0001\n",
      "Epoch 353, Train loss: 0.0052820005, Validation loss: 0.0053233544, LR: 0.0001\n",
      "Epoch 354, Train loss: 0.0052822537, Validation loss: 0.0053226405, LR: 0.0001\n",
      "Epoch 355, Train loss: 0.0052828798, Validation loss: 0.0053228319, LR: 0.0001\n",
      "Epoch 356, Train loss: 0.0052827015, Validation loss: 0.0053223224, LR: 0.0001\n",
      "Epoch 357, Train loss: 0.0052820838, Validation loss: 0.0053226061, LR: 0.0001\n",
      "Epoch 358, Train loss: 0.0052834090, Validation loss: 0.0053227665, LR: 0.0001\n",
      "Epoch 359, Train loss: 0.0052819927, Validation loss: 0.0053225273, LR: 0.0001\n",
      "Epoch 360, Train loss: 0.0052831139, Validation loss: 0.0053227016, LR: 0.0001\n",
      "Epoch 361, Train loss: 0.0052829690, Validation loss: 0.0053224169, LR: 0.0001\n",
      "Epoch 362, Train loss: 0.0052827646, Validation loss: 0.0053224505, LR: 0.0001\n",
      "Epoch 363, Train loss: 0.0052832104, Validation loss: 0.0053222857, LR: 0.0001\n",
      "Epoch 364, Train loss: 0.0052817193, Validation loss: 0.0053223955, LR: 0.0001\n",
      "Epoch 365, Train loss: 0.0052822960, Validation loss: 0.0053224593, LR: 0.0001\n",
      "Epoch 366, Train loss: 0.0052826146, Validation loss: 0.0053223140, LR: 0.0001\n",
      "Epoch 367, Train loss: 0.0052815624, Validation loss: 0.0053220234, LR: 0.0001\n",
      "Epoch 368, Train loss: 0.0052822427, Validation loss: 0.0053223741, LR: 0.0001\n",
      "Epoch 369, Train loss: 0.0052824269, Validation loss: 0.0053222875, LR: 0.0001\n",
      "Epoch 370, Train loss: 0.0052822540, Validation loss: 0.0053220080, LR: 0.0001\n",
      "Epoch 371, Train loss: 0.0052822422, Validation loss: 0.0053223305, LR: 0.0001\n",
      "Epoch 372, Train loss: 0.0052823081, Validation loss: 0.0053219557, LR: 0.0001\n",
      "Epoch 373, Train loss: 0.0052823158, Validation loss: 0.0053221055, LR: 0.0001\n",
      "Epoch 374, Train loss: 0.0052825607, Validation loss: 0.0053218390, LR: 0.0001\n",
      "Epoch 375, Train loss: 0.0052821522, Validation loss: 0.0053218860, LR: 0.0001\n",
      "Epoch 376, Train loss: 0.0052822796, Validation loss: 0.0053218589, LR: 0.0001\n",
      "Epoch 377, Train loss: 0.0052817599, Validation loss: 0.0053217554, LR: 0.0001\n",
      "Epoch 378, Train loss: 0.0052821731, Validation loss: 0.0053219352, LR: 0.0001\n",
      "Epoch 379, Train loss: 0.0052823405, Validation loss: 0.0053213373, LR: 0.0001\n",
      "Epoch 380, Train loss: 0.0052818798, Validation loss: 0.0053218302, LR: 0.0001\n",
      "Epoch 381, Train loss: 0.0052821179, Validation loss: 0.0053214439, LR: 0.0001\n",
      "Epoch 382, Train loss: 0.0052823234, Validation loss: 0.0053215973, LR: 0.0001\n",
      "Epoch 383, Train loss: 0.0052815641, Validation loss: 0.0053215975, LR: 0.0001\n",
      "Epoch 384, Train loss: 0.0052815261, Validation loss: 0.0053215441, LR: 0.0001\n",
      "Epoch 385, Train loss: 0.0052821169, Validation loss: 0.0053216048, LR: 0.0001\n",
      "Epoch 386, Train loss: 0.0052819207, Validation loss: 0.0053215293, LR: 0.0001\n",
      "Epoch 387, Train loss: 0.0052821196, Validation loss: 0.0053210585, LR: 0.0001\n",
      "Epoch 388, Train loss: 0.0052817350, Validation loss: 0.0053216145, LR: 0.0001\n",
      "Epoch 389, Train loss: 0.0052823302, Validation loss: 0.0053215312, LR: 0.0001\n",
      "Epoch 390, Train loss: 0.0052812793, Validation loss: 0.0053215227, LR: 0.0001\n",
      "Epoch 391, Train loss: 0.0052814038, Validation loss: 0.0053210647, LR: 0.0001\n",
      "Epoch 392, Train loss: 0.0052818944, Validation loss: 0.0053214166, LR: 0.0001\n",
      "Epoch 393, Train loss: 0.0052818621, Validation loss: 0.0053211257, LR: 0.0001\n",
      "Epoch 394, Train loss: 0.0052817460, Validation loss: 0.0053213434, LR: 0.0001\n",
      "Epoch 395, Train loss: 0.0052814431, Validation loss: 0.0053211757, LR: 0.0001\n",
      "Epoch 396, Train loss: 0.0052810962, Validation loss: 0.0053210943, LR: 0.0001\n",
      "Epoch 397, Train loss: 0.0052817088, Validation loss: 0.0053210195, LR: 0.0001\n",
      "Epoch 398, Train loss: 0.0052818332, Validation loss: 0.0053208145, LR: 0.0001\n",
      "Epoch 399, Train loss: 0.0052811670, Validation loss: 0.0053207996, LR: 0.0001\n",
      "Epoch 400, Train loss: 0.0052810165, Validation loss: 0.0053207266, LR: 0.0001\n",
      "Epoch 401, Train loss: 0.0052814452, Validation loss: 0.0053208310, LR: 0.0001\n",
      "Epoch 402, Train loss: 0.0052809700, Validation loss: 0.0053212118, LR: 0.0001\n",
      "Epoch 403, Train loss: 0.0052814025, Validation loss: 0.0053206381, LR: 0.0001\n",
      "Epoch 404, Train loss: 0.0052811429, Validation loss: 0.0053208148, LR: 0.0001\n",
      "Epoch 405, Train loss: 0.0052811798, Validation loss: 0.0053206022, LR: 0.0001\n",
      "Epoch 406, Train loss: 0.0052822043, Validation loss: 0.0053203901, LR: 0.0001\n",
      "Epoch 407, Train loss: 0.0052811676, Validation loss: 0.0053205559, LR: 0.0001\n",
      "Epoch 408, Train loss: 0.0052814231, Validation loss: 0.0053202772, LR: 0.0001\n",
      "Epoch 409, Train loss: 0.0052816591, Validation loss: 0.0053204671, LR: 0.0001\n",
      "Epoch 410, Train loss: 0.0052814781, Validation loss: 0.0053205760, LR: 0.0001\n",
      "Epoch 411, Train loss: 0.0052814719, Validation loss: 0.0053204292, LR: 0.0001\n",
      "Epoch 412, Train loss: 0.0052817967, Validation loss: 0.0053208328, LR: 0.0001\n",
      "Epoch 413, Train loss: 0.0052817594, Validation loss: 0.0053205044, LR: 0.0001\n",
      "Epoch 414, Train loss: 0.0052808479, Validation loss: 0.0053206437, LR: 0.0001\n",
      "Epoch 415, Train loss: 0.0052812362, Validation loss: 0.0053201915, LR: 0.0001\n",
      "Epoch 416, Train loss: 0.0052820080, Validation loss: 0.0053205790, LR: 0.0001\n",
      "Epoch 417, Train loss: 0.0052815682, Validation loss: 0.0053201824, LR: 0.0001\n",
      "Epoch 418, Train loss: 0.0052814736, Validation loss: 0.0053201014, LR: 0.0001\n",
      "Epoch 419, Train loss: 0.0052806979, Validation loss: 0.0053205304, LR: 0.0001\n",
      "Epoch 420, Train loss: 0.0052807768, Validation loss: 0.0053206669, LR: 0.0001\n",
      "Epoch 421, Train loss: 0.0052816129, Validation loss: 0.0053200239, LR: 0.0001\n",
      "Epoch 422, Train loss: 0.0052815846, Validation loss: 0.0053201068, LR: 0.0001\n",
      "Epoch 423, Train loss: 0.0052811335, Validation loss: 0.0053197239, LR: 0.0001\n",
      "Epoch 424, Train loss: 0.0052805076, Validation loss: 0.0053199478, LR: 0.0001\n",
      "Epoch 425, Train loss: 0.0052815539, Validation loss: 0.0053199833, LR: 0.0001\n",
      "Epoch 426, Train loss: 0.0052809131, Validation loss: 0.0053198877, LR: 0.0001\n",
      "Epoch 427, Train loss: 0.0052814205, Validation loss: 0.0053194989, LR: 0.0001\n",
      "Epoch 428, Train loss: 0.0052813909, Validation loss: 0.0053198778, LR: 0.0001\n",
      "Epoch 429, Train loss: 0.0052801603, Validation loss: 0.0053196646, LR: 0.0001\n",
      "Epoch 430, Train loss: 0.0052811578, Validation loss: 0.0053199092, LR: 0.0001\n",
      "Epoch 431, Train loss: 0.0052814220, Validation loss: 0.0053197755, LR: 0.0001\n",
      "Epoch 432, Train loss: 0.0052812059, Validation loss: 0.0053201147, LR: 0.0001\n",
      "Epoch 433, Train loss: 0.0052811832, Validation loss: 0.0053193979, LR: 0.0001\n",
      "Epoch 434, Train loss: 0.0052805992, Validation loss: 0.0053197913, LR: 0.0001\n",
      "Epoch 435, Train loss: 0.0052809738, Validation loss: 0.0053194617, LR: 0.0001\n",
      "Epoch 436, Train loss: 0.0052806835, Validation loss: 0.0053198882, LR: 0.0001\n",
      "Epoch 437, Train loss: 0.0052809970, Validation loss: 0.0053194969, LR: 0.0001\n",
      "Epoch 438, Train loss: 0.0052807860, Validation loss: 0.0053193096, LR: 0.0001\n",
      "Epoch 439, Train loss: 0.0052813038, Validation loss: 0.0053198874, LR: 0.0001\n",
      "Epoch 440, Train loss: 0.0052809593, Validation loss: 0.0053195979, LR: 0.0001\n",
      "Epoch 441, Train loss: 0.0052808022, Validation loss: 0.0053194564, LR: 0.0001\n",
      "Epoch 442, Train loss: 0.0052805499, Validation loss: 0.0053194441, LR: 0.0001\n",
      "Epoch 443, Train loss: 0.0052812814, Validation loss: 0.0053192187, LR: 0.0001\n",
      "Epoch 444, Train loss: 0.0052816172, Validation loss: 0.0053193178, LR: 0.0001\n",
      "Epoch 445, Train loss: 0.0052811927, Validation loss: 0.0053190836, LR: 0.0001\n",
      "Epoch 446, Train loss: 0.0052807992, Validation loss: 0.0053192221, LR: 0.0001\n",
      "Epoch 447, Train loss: 0.0052806467, Validation loss: 0.0053195513, LR: 0.0001\n",
      "Epoch 448, Train loss: 0.0052814810, Validation loss: 0.0053195099, LR: 0.0001\n",
      "Epoch 449, Train loss: 0.0052806561, Validation loss: 0.0053198670, LR: 0.0001\n",
      "Epoch 450, Train loss: 0.0052804394, Validation loss: 0.0053192966, LR: 0.0001\n",
      "Epoch 451, Train loss: 0.0052811022, Validation loss: 0.0053189127, LR: 0.0001\n",
      "Epoch 452, Train loss: 0.0052797501, Validation loss: 0.0053190637, LR: 0.0001\n",
      "Epoch 453, Train loss: 0.0052802673, Validation loss: 0.0053193556, LR: 0.0001\n",
      "Epoch 454, Train loss: 0.0052805175, Validation loss: 0.0053186027, LR: 0.0001\n",
      "Epoch 455, Train loss: 0.0052805004, Validation loss: 0.0053194409, LR: 0.0001\n",
      "Epoch 456, Train loss: 0.0052802197, Validation loss: 0.0053192528, LR: 0.0001\n",
      "Epoch 457, Train loss: 0.0052806260, Validation loss: 0.0053189622, LR: 0.0001\n",
      "Epoch 458, Train loss: 0.0052808762, Validation loss: 0.0053187633, LR: 0.0001\n",
      "Epoch 459, Train loss: 0.0052802683, Validation loss: 0.0053188434, LR: 0.0001\n",
      "Epoch 460, Train loss: 0.0052805623, Validation loss: 0.0053189746, LR: 0.0001\n",
      "Epoch 461, Train loss: 0.0052804308, Validation loss: 0.0053188282, LR: 0.0001\n",
      "Epoch 462, Train loss: 0.0052803064, Validation loss: 0.0053188910, LR: 0.0001\n",
      "Epoch 463, Train loss: 0.0052810779, Validation loss: 0.0053188485, LR: 0.0001\n",
      "Epoch 464, Train loss: 0.0052811774, Validation loss: 0.0053182654, LR: 0.0001\n",
      "Epoch 465, Train loss: 0.0052807917, Validation loss: 0.0053188181, LR: 0.0001\n",
      "Epoch 466, Train loss: 0.0052806781, Validation loss: 0.0053189748, LR: 0.0001\n",
      "Epoch 467, Train loss: 0.0052803950, Validation loss: 0.0053184340, LR: 0.0001\n",
      "Epoch 468, Train loss: 0.0052804240, Validation loss: 0.0053186542, LR: 0.0001\n",
      "Epoch 469, Train loss: 0.0052808388, Validation loss: 0.0053184683, LR: 0.0001\n",
      "Epoch 470, Train loss: 0.0052798831, Validation loss: 0.0053185973, LR: 0.0001\n",
      "Epoch 471, Train loss: 0.0052805115, Validation loss: 0.0053185179, LR: 0.0001\n",
      "Epoch 472, Train loss: 0.0052798989, Validation loss: 0.0053181906, LR: 0.0001\n",
      "Epoch 473, Train loss: 0.0052802552, Validation loss: 0.0053185452, LR: 0.0001\n",
      "Epoch 474, Train loss: 0.0052806670, Validation loss: 0.0053185522, LR: 0.0001\n",
      "Epoch 475, Train loss: 0.0052804533, Validation loss: 0.0053183945, LR: 0.0001\n",
      "Epoch 476, Train loss: 0.0052801282, Validation loss: 0.0053183750, LR: 0.0001\n",
      "Epoch 477, Train loss: 0.0052810880, Validation loss: 0.0053183805, LR: 0.0001\n",
      "Epoch 478, Train loss: 0.0052806645, Validation loss: 0.0053181106, LR: 0.0001\n",
      "Epoch 479, Train loss: 0.0052807560, Validation loss: 0.0053180771, LR: 0.0001\n",
      "Epoch 480, Train loss: 0.0052807816, Validation loss: 0.0053184717, LR: 0.0001\n",
      "Epoch 481, Train loss: 0.0052798687, Validation loss: 0.0053184775, LR: 0.0001\n",
      "Epoch 482, Train loss: 0.0052807398, Validation loss: 0.0053189335, LR: 0.0001\n",
      "Epoch 483, Train loss: 0.0052802090, Validation loss: 0.0053182410, LR: 0.0001\n",
      "Epoch 484, Train loss: 0.0052799180, Validation loss: 0.0053182577, LR: 0.0001\n",
      "Epoch 485, Train loss: 0.0052801706, Validation loss: 0.0053182327, LR: 0.0001\n",
      "Epoch 486, Train loss: 0.0052798108, Validation loss: 0.0053178210, LR: 0.0001\n",
      "Epoch 487, Train loss: 0.0052808522, Validation loss: 0.0053180088, LR: 0.0001\n",
      "Epoch 488, Train loss: 0.0052802612, Validation loss: 0.0053185376, LR: 0.0001\n",
      "Epoch 489, Train loss: 0.0052807579, Validation loss: 0.0053181234, LR: 0.0001\n",
      "Epoch 490, Train loss: 0.0052800015, Validation loss: 0.0053177928, LR: 0.0001\n",
      "Epoch 491, Train loss: 0.0052804152, Validation loss: 0.0053179215, LR: 0.0001\n",
      "Epoch 492, Train loss: 0.0052801693, Validation loss: 0.0053181356, LR: 0.0001\n",
      "Epoch 493, Train loss: 0.0052804990, Validation loss: 0.0053176884, LR: 0.0001\n",
      "Epoch 494, Train loss: 0.0052793290, Validation loss: 0.0053178424, LR: 0.0001\n",
      "Epoch 495, Train loss: 0.0052799188, Validation loss: 0.0053178330, LR: 0.0001\n",
      "Epoch 496, Train loss: 0.0052799691, Validation loss: 0.0053177621, LR: 0.0001\n",
      "Epoch 497, Train loss: 0.0052790547, Validation loss: 0.0053180218, LR: 0.0001\n",
      "Epoch 498, Train loss: 0.0052796984, Validation loss: 0.0053177493, LR: 0.0001\n",
      "Epoch 499, Train loss: 0.0052804520, Validation loss: 0.0053177648, LR: 0.0001\n",
      "Epoch 500, Train loss: 0.0052803151, Validation loss: 0.0053175191, LR: 0.0001\n",
      "Epoch 501, Train loss: 0.0052805601, Validation loss: 0.0053176574, LR: 0.0001\n",
      "Epoch 502, Train loss: 0.0052802831, Validation loss: 0.0053178358, LR: 0.0001\n",
      "Epoch 503, Train loss: 0.0052797897, Validation loss: 0.0053175426, LR: 0.0001\n",
      "Epoch 504, Train loss: 0.0052806464, Validation loss: 0.0053176605, LR: 0.0001\n",
      "Epoch 505, Train loss: 0.0052796999, Validation loss: 0.0053175634, LR: 0.0001\n",
      "Epoch 506, Train loss: 0.0052792810, Validation loss: 0.0053173696, LR: 0.0001\n",
      "Epoch 507, Train loss: 0.0052796615, Validation loss: 0.0053172679, LR: 0.0001\n",
      "Epoch 508, Train loss: 0.0052801506, Validation loss: 0.0053178468, LR: 0.0001\n",
      "Epoch 509, Train loss: 0.0052802169, Validation loss: 0.0053173024, LR: 0.0001\n",
      "Epoch 510, Train loss: 0.0052796084, Validation loss: 0.0053177218, LR: 0.0001\n",
      "Epoch 511, Train loss: 0.0052804534, Validation loss: 0.0053172695, LR: 0.0001\n",
      "Epoch 512, Train loss: 0.0052799866, Validation loss: 0.0053174321, LR: 0.0001\n",
      "Epoch 513, Train loss: 0.0052799147, Validation loss: 0.0053174901, LR: 0.0001\n",
      "Epoch 514, Train loss: 0.0052794156, Validation loss: 0.0053175224, LR: 0.0001\n",
      "Epoch 515, Train loss: 0.0052793577, Validation loss: 0.0053171564, LR: 0.0001\n",
      "Epoch 516, Train loss: 0.0052802658, Validation loss: 0.0053173465, LR: 0.0001\n",
      "Epoch 517, Train loss: 0.0052797681, Validation loss: 0.0053172569, LR: 0.0001\n",
      "Epoch 518, Train loss: 0.0052793498, Validation loss: 0.0053172758, LR: 0.0001\n",
      "Epoch 519, Train loss: 0.0052800545, Validation loss: 0.0053168425, LR: 0.0001\n",
      "Epoch 520, Train loss: 0.0052798982, Validation loss: 0.0053176397, LR: 0.0001\n",
      "Epoch 521, Train loss: 0.0052802595, Validation loss: 0.0053175637, LR: 0.0001\n",
      "Epoch 522, Train loss: 0.0052793166, Validation loss: 0.0053170539, LR: 0.0001\n",
      "Epoch 523, Train loss: 0.0052796188, Validation loss: 0.0053172645, LR: 0.0001\n",
      "Epoch 524, Train loss: 0.0052799343, Validation loss: 0.0053168602, LR: 0.0001\n",
      "Epoch 525, Train loss: 0.0052800001, Validation loss: 0.0053170189, LR: 0.0001\n",
      "Epoch 526, Train loss: 0.0052801212, Validation loss: 0.0053168124, LR: 0.0001\n",
      "Epoch 527, Train loss: 0.0052793522, Validation loss: 0.0053169625, LR: 0.0001\n",
      "Epoch 528, Train loss: 0.0052789962, Validation loss: 0.0053167269, LR: 0.0001\n",
      "Epoch 529, Train loss: 0.0052795027, Validation loss: 0.0053166720, LR: 0.0001\n",
      "Epoch 530, Train loss: 0.0052795068, Validation loss: 0.0053169039, LR: 0.0001\n",
      "Epoch 531, Train loss: 0.0052793633, Validation loss: 0.0053170400, LR: 0.0001\n",
      "Epoch 532, Train loss: 0.0052795804, Validation loss: 0.0053169147, LR: 0.0001\n",
      "Epoch 533, Train loss: 0.0052797993, Validation loss: 0.0053169563, LR: 0.0001\n",
      "Epoch 534, Train loss: 0.0052799361, Validation loss: 0.0053169372, LR: 0.0001\n",
      "Epoch 535, Train loss: 0.0052805591, Validation loss: 0.0053165624, LR: 0.0001\n",
      "Epoch 536, Train loss: 0.0052798495, Validation loss: 0.0053165578, LR: 0.0001\n",
      "Epoch 537, Train loss: 0.0052796526, Validation loss: 0.0053168286, LR: 0.0001\n",
      "Epoch 538, Train loss: 0.0052789568, Validation loss: 0.0053167048, LR: 0.0001\n",
      "Epoch 539, Train loss: 0.0052793982, Validation loss: 0.0053169201, LR: 0.0001\n",
      "Epoch 540, Train loss: 0.0052787578, Validation loss: 0.0053165456, LR: 0.0001\n",
      "Epoch 541, Train loss: 0.0052804151, Validation loss: 0.0053169526, LR: 0.0001\n",
      "Epoch 542, Train loss: 0.0052794922, Validation loss: 0.0053165961, LR: 0.0001\n",
      "Epoch 543, Train loss: 0.0052797369, Validation loss: 0.0053164988, LR: 0.0001\n",
      "Epoch 544, Train loss: 0.0052798463, Validation loss: 0.0053166971, LR: 0.0001\n",
      "Epoch 545, Train loss: 0.0052804303, Validation loss: 0.0053163503, LR: 0.0001\n",
      "Epoch 546, Train loss: 0.0052797212, Validation loss: 0.0053168727, LR: 0.0001\n",
      "Epoch 547, Train loss: 0.0052790902, Validation loss: 0.0053166391, LR: 0.0001\n",
      "Epoch 548, Train loss: 0.0052784681, Validation loss: 0.0053164645, LR: 0.0001\n",
      "Epoch 549, Train loss: 0.0052806390, Validation loss: 0.0053166256, LR: 0.0001\n",
      "Epoch 550, Train loss: 0.0052792671, Validation loss: 0.0053164226, LR: 0.0001\n",
      "Epoch 551, Train loss: 0.0052792736, Validation loss: 0.0053164340, LR: 0.0001\n",
      "Epoch 552, Train loss: 0.0052795088, Validation loss: 0.0053167082, LR: 0.0001\n",
      "Epoch 553, Train loss: 0.0052791770, Validation loss: 0.0053163031, LR: 0.0001\n",
      "Epoch 554, Train loss: 0.0052788277, Validation loss: 0.0053164489, LR: 0.0001\n",
      "Epoch 555, Train loss: 0.0052793226, Validation loss: 0.0053165268, LR: 0.0001\n",
      "Epoch 556, Train loss: 0.0052800079, Validation loss: 0.0053164104, LR: 0.0001\n",
      "Epoch 557, Train loss: 0.0052793515, Validation loss: 0.0053163354, LR: 0.0001\n",
      "Epoch 558, Train loss: 0.0052791741, Validation loss: 0.0053164731, LR: 0.0001\n",
      "Epoch 559, Train loss: 0.0052781422, Validation loss: 0.0053163520, LR: 0.0001\n",
      "Epoch 560, Train loss: 0.0052793790, Validation loss: 0.0053163619, LR: 0.0001\n",
      "Epoch 561, Train loss: 0.0052793273, Validation loss: 0.0053161903, LR: 0.0001\n",
      "Epoch 562, Train loss: 0.0052784441, Validation loss: 0.0053162621, LR: 0.0001\n",
      "Epoch 563, Train loss: 0.0052791126, Validation loss: 0.0053162622, LR: 0.0001\n",
      "Epoch 564, Train loss: 0.0052787548, Validation loss: 0.0053163172, LR: 0.0001\n",
      "Epoch 565, Train loss: 0.0052795684, Validation loss: 0.0053164879, LR: 0.0001\n",
      "Epoch 566, Train loss: 0.0052794798, Validation loss: 0.0053161774, LR: 0.0001\n",
      "Epoch 567, Train loss: 0.0052794356, Validation loss: 0.0053159032, LR: 0.0001\n",
      "Epoch 568, Train loss: 0.0052793464, Validation loss: 0.0053162677, LR: 0.0001\n",
      "Epoch 569, Train loss: 0.0052797785, Validation loss: 0.0053159711, LR: 0.0001\n",
      "Epoch 570, Train loss: 0.0052791376, Validation loss: 0.0053164564, LR: 0.0001\n",
      "Epoch 571, Train loss: 0.0052792598, Validation loss: 0.0053161289, LR: 0.0001\n",
      "Epoch 572, Train loss: 0.0052792315, Validation loss: 0.0053163184, LR: 0.0001\n",
      "Epoch 573, Train loss: 0.0052793239, Validation loss: 0.0053159772, LR: 0.0001\n",
      "Epoch 574, Train loss: 0.0052796953, Validation loss: 0.0053160413, LR: 0.0001\n",
      "Epoch 575, Train loss: 0.0052793804, Validation loss: 0.0053160603, LR: 0.0001\n",
      "Epoch 576, Train loss: 0.0052790390, Validation loss: 0.0053163219, LR: 0.0001\n",
      "Epoch 577, Train loss: 0.0052789493, Validation loss: 0.0053158070, LR: 0.0001\n",
      "Epoch 578, Train loss: 0.0052791661, Validation loss: 0.0053160948, LR: 0.0001\n",
      "Epoch 579, Train loss: 0.0052793241, Validation loss: 0.0053158659, LR: 0.0001\n",
      "Epoch 580, Train loss: 0.0052794304, Validation loss: 0.0053158757, LR: 0.0001\n",
      "Epoch 581, Train loss: 0.0052788583, Validation loss: 0.0053158149, LR: 0.0001\n",
      "Epoch 582, Train loss: 0.0052796839, Validation loss: 0.0053159726, LR: 0.0001\n",
      "Epoch 583, Train loss: 0.0052789034, Validation loss: 0.0053158260, LR: 0.0001\n",
      "Epoch 584, Train loss: 0.0052794793, Validation loss: 0.0053158613, LR: 0.0001\n",
      "Epoch 585, Train loss: 0.0052787903, Validation loss: 0.0053164589, LR: 0.0001\n",
      "Epoch 586, Train loss: 0.0052796445, Validation loss: 0.0053155601, LR: 0.0001\n",
      "Epoch 587, Train loss: 0.0052792414, Validation loss: 0.0053157959, LR: 0.0001\n",
      "Epoch 588, Train loss: 0.0052797448, Validation loss: 0.0053158461, LR: 0.0001\n",
      "Epoch 589, Train loss: 0.0052780907, Validation loss: 0.0053157594, LR: 0.0001\n",
      "Epoch 590, Train loss: 0.0052792336, Validation loss: 0.0053155604, LR: 0.0001\n",
      "Epoch 591, Train loss: 0.0052789225, Validation loss: 0.0053157595, LR: 0.0001\n",
      "Epoch 592, Train loss: 0.0052788257, Validation loss: 0.0053155758, LR: 0.0001\n",
      "Epoch 593, Train loss: 0.0052785701, Validation loss: 0.0053160040, LR: 0.0001\n",
      "Epoch 594, Train loss: 0.0052791581, Validation loss: 0.0053155498, LR: 0.0001\n",
      "Epoch 595, Train loss: 0.0052786273, Validation loss: 0.0053156060, LR: 0.0001\n",
      "Epoch 596, Train loss: 0.0052786407, Validation loss: 0.0053159870, LR: 0.0001\n",
      "Epoch 597, Train loss: 0.0052791866, Validation loss: 0.0053157977, LR: 0.0001\n",
      "Epoch 598, Train loss: 0.0052794272, Validation loss: 0.0053155553, LR: 0.0001\n",
      "Epoch 599, Train loss: 0.0052790992, Validation loss: 0.0053155216, LR: 0.0001\n",
      "Epoch 600, Train loss: 0.0052798000, Validation loss: 0.0053153247, LR: 0.0001\n",
      "Epoch 601, Train loss: 0.0052794913, Validation loss: 0.0053156397, LR: 0.0001\n",
      "Epoch 602, Train loss: 0.0052787245, Validation loss: 0.0053156237, LR: 0.0001\n",
      "Epoch 603, Train loss: 0.0052780257, Validation loss: 0.0053156526, LR: 0.0001\n",
      "Epoch 604, Train loss: 0.0052790990, Validation loss: 0.0053154246, LR: 0.0001\n",
      "Epoch 605, Train loss: 0.0052784272, Validation loss: 0.0053152808, LR: 0.0001\n",
      "Epoch 606, Train loss: 0.0052777531, Validation loss: 0.0053157692, LR: 0.0001\n",
      "Epoch 607, Train loss: 0.0052793463, Validation loss: 0.0053152299, LR: 0.0001\n",
      "Epoch 608, Train loss: 0.0052788360, Validation loss: 0.0053153431, LR: 0.0001\n",
      "Epoch 609, Train loss: 0.0052790835, Validation loss: 0.0053153912, LR: 0.0001\n",
      "Epoch 610, Train loss: 0.0052784231, Validation loss: 0.0053153245, LR: 0.0001\n",
      "Epoch 611, Train loss: 0.0052783774, Validation loss: 0.0053153236, LR: 0.0001\n",
      "Epoch 612, Train loss: 0.0052787777, Validation loss: 0.0053151417, LR: 0.0001\n",
      "Epoch 613, Train loss: 0.0052785848, Validation loss: 0.0053151118, LR: 0.0001\n",
      "Epoch 614, Train loss: 0.0052791178, Validation loss: 0.0053152535, LR: 0.0001\n",
      "Epoch 615, Train loss: 0.0052786433, Validation loss: 0.0053155046, LR: 0.0001\n",
      "Epoch 616, Train loss: 0.0052787943, Validation loss: 0.0053151051, LR: 0.0001\n",
      "Epoch 617, Train loss: 0.0052782950, Validation loss: 0.0053152575, LR: 0.0001\n",
      "Epoch 618, Train loss: 0.0052785899, Validation loss: 0.0053153342, LR: 0.0001\n",
      "Epoch 619, Train loss: 0.0052786824, Validation loss: 0.0053159180, LR: 0.0001\n",
      "Epoch 620, Train loss: 0.0052790869, Validation loss: 0.0053154728, LR: 0.0001\n",
      "Epoch 621, Train loss: 0.0052776696, Validation loss: 0.0053153347, LR: 0.0001\n",
      "Epoch 622, Train loss: 0.0052785531, Validation loss: 0.0053151824, LR: 0.0001\n",
      "Epoch 623, Train loss: 0.0052786500, Validation loss: 0.0053156089, LR: 0.0001\n",
      "Epoch 624, Train loss: 0.0052785242, Validation loss: 0.0053153238, LR: 0.0001\n",
      "Epoch 625, Train loss: 0.0052791608, Validation loss: 0.0053151427, LR: 0.0001\n",
      "Epoch 626, Train loss: 0.0052794306, Validation loss: 0.0053151775, LR: 0.0001\n",
      "Epoch 627, Train loss: 0.0052791151, Validation loss: 0.0053154534, LR: 0.0001\n",
      "Epoch 628, Train loss: 0.0052794679, Validation loss: 0.0053148523, LR: 0.0001\n",
      "Epoch 629, Train loss: 0.0052786384, Validation loss: 0.0053149027, LR: 0.0001\n",
      "Epoch 630, Train loss: 0.0052790851, Validation loss: 0.0053155164, LR: 0.0001\n",
      "Epoch 631, Train loss: 0.0052785313, Validation loss: 0.0053153064, LR: 0.0001\n",
      "Epoch 632, Train loss: 0.0052792325, Validation loss: 0.0053147963, LR: 0.0001\n",
      "Epoch 633, Train loss: 0.0052785792, Validation loss: 0.0053151323, LR: 0.0001\n",
      "Epoch 634, Train loss: 0.0052782517, Validation loss: 0.0053147233, LR: 0.0001\n",
      "Epoch 635, Train loss: 0.0052792283, Validation loss: 0.0053150868, LR: 0.0001\n",
      "Epoch 636, Train loss: 0.0052788279, Validation loss: 0.0053148106, LR: 0.0001\n",
      "Epoch 637, Train loss: 0.0052788492, Validation loss: 0.0053149874, LR: 0.0001\n",
      "Epoch 638, Train loss: 0.0052786730, Validation loss: 0.0053150269, LR: 0.0001\n",
      "Epoch 639, Train loss: 0.0052783302, Validation loss: 0.0053151621, LR: 0.0001\n",
      "Epoch 640, Train loss: 0.0052784107, Validation loss: 0.0053149410, LR: 0.0001\n",
      "Epoch 641, Train loss: 0.0052783591, Validation loss: 0.0053147142, LR: 0.0001\n",
      "Epoch 642, Train loss: 0.0052787993, Validation loss: 0.0053146669, LR: 0.0001\n",
      "Epoch 643, Train loss: 0.0052778957, Validation loss: 0.0053147008, LR: 0.0001\n",
      "Epoch 644, Train loss: 0.0052781831, Validation loss: 0.0053147214, LR: 0.0001\n",
      "Epoch 645, Train loss: 0.0052783145, Validation loss: 0.0053148577, LR: 0.0001\n",
      "Epoch 646, Train loss: 0.0052790785, Validation loss: 0.0053145801, LR: 0.0001\n",
      "Epoch 647, Train loss: 0.0052785638, Validation loss: 0.0053146655, LR: 0.0001\n",
      "Epoch 648, Train loss: 0.0052785765, Validation loss: 0.0053146149, LR: 0.0001\n",
      "Epoch 649, Train loss: 0.0052788772, Validation loss: 0.0053146103, LR: 0.0001\n",
      "Epoch 650, Train loss: 0.0052787457, Validation loss: 0.0053151078, LR: 0.0001\n",
      "Epoch 651, Train loss: 0.0052789020, Validation loss: 0.0053146589, LR: 0.0001\n",
      "Epoch 652, Train loss: 0.0052789303, Validation loss: 0.0053147414, LR: 0.0001\n",
      "Epoch 653, Train loss: 0.0052786021, Validation loss: 0.0053146016, LR: 0.0001\n",
      "Epoch 654, Train loss: 0.0052786896, Validation loss: 0.0053146255, LR: 0.0001\n",
      "Epoch 655, Train loss: 0.0052791412, Validation loss: 0.0053143058, LR: 0.0001\n",
      "Epoch 656, Train loss: 0.0052786167, Validation loss: 0.0053148477, LR: 0.0001\n",
      "Epoch 657, Train loss: 0.0052787419, Validation loss: 0.0053149194, LR: 0.0001\n",
      "Epoch 658, Train loss: 0.0052785873, Validation loss: 0.0053145171, LR: 0.0001\n",
      "Epoch 659, Train loss: 0.0052783023, Validation loss: 0.0053144419, LR: 0.0001\n",
      "Epoch 660, Train loss: 0.0052784415, Validation loss: 0.0053146305, LR: 0.0001\n",
      "Epoch 661, Train loss: 0.0052787891, Validation loss: 0.0053146453, LR: 0.0001\n",
      "Epoch 662, Train loss: 0.0052784404, Validation loss: 0.0053150134, LR: 0.0001\n",
      "Epoch 663, Train loss: 0.0052785826, Validation loss: 0.0053145358, LR: 0.0001\n",
      "Epoch 664, Train loss: 0.0052789245, Validation loss: 0.0053145088, LR: 0.0001\n",
      "Epoch 665, Train loss: 0.0052780548, Validation loss: 0.0053145285, LR: 0.0001\n",
      "Epoch 666, Train loss: 0.0052794285, Validation loss: 0.0053144534, LR: 0.0001\n",
      "Epoch 667, Train loss: 0.0052776543, Validation loss: 0.0053145760, LR: 0.0001\n",
      "Epoch 668, Train loss: 0.0052785109, Validation loss: 0.0053146384, LR: 0.0001\n",
      "Epoch 669, Train loss: 0.0052780307, Validation loss: 0.0053145603, LR: 0.0001\n",
      "Epoch 670, Train loss: 0.0052789425, Validation loss: 0.0053146096, LR: 0.0001\n",
      "Epoch 671, Train loss: 0.0052783604, Validation loss: 0.0053144333, LR: 0.0001\n",
      "Epoch 672, Train loss: 0.0052780184, Validation loss: 0.0053145360, LR: 0.0001\n",
      "Epoch 673, Train loss: 0.0052779038, Validation loss: 0.0053144195, LR: 0.0001\n",
      "Epoch 674, Train loss: 0.0052785730, Validation loss: 0.0053142455, LR: 0.0001\n",
      "Epoch 675, Train loss: 0.0052780747, Validation loss: 0.0053146274, LR: 0.0001\n",
      "Epoch 676, Train loss: 0.0052781866, Validation loss: 0.0053140776, LR: 0.0001\n",
      "Epoch 677, Train loss: 0.0052785923, Validation loss: 0.0053148872, LR: 0.0001\n",
      "Epoch 678, Train loss: 0.0052779825, Validation loss: 0.0053148690, LR: 0.0001\n",
      "Epoch 679, Train loss: 0.0052774946, Validation loss: 0.0053140745, LR: 0.0001\n",
      "Epoch 680, Train loss: 0.0052775843, Validation loss: 0.0053142478, LR: 0.0001\n",
      "Epoch 681, Train loss: 0.0052784031, Validation loss: 0.0053143501, LR: 0.0001\n",
      "Epoch 682, Train loss: 0.0052787410, Validation loss: 0.0053140639, LR: 0.0001\n",
      "Epoch 683, Train loss: 0.0052781902, Validation loss: 0.0053143759, LR: 0.0001\n",
      "Epoch 684, Train loss: 0.0052784215, Validation loss: 0.0053144921, LR: 0.0001\n",
      "Epoch 685, Train loss: 0.0052786526, Validation loss: 0.0053142812, LR: 0.0001\n",
      "Epoch 686, Train loss: 0.0052779390, Validation loss: 0.0053140744, LR: 0.0001\n",
      "Epoch 687, Train loss: 0.0052784776, Validation loss: 0.0053141293, LR: 0.0001\n",
      "Epoch 688, Train loss: 0.0052784297, Validation loss: 0.0053142241, LR: 0.0001\n",
      "Epoch 689, Train loss: 0.0052785247, Validation loss: 0.0053145193, LR: 0.0001\n",
      "Epoch 690, Train loss: 0.0052781570, Validation loss: 0.0053141635, LR: 0.0001\n",
      "Epoch 691, Train loss: 0.0052778978, Validation loss: 0.0053142169, LR: 0.0001\n",
      "Epoch 692, Train loss: 0.0052777731, Validation loss: 0.0053140536, LR: 0.0001\n",
      "Epoch 693, Train loss: 0.0052790862, Validation loss: 0.0053140168, LR: 0.0001\n",
      "Epoch 694, Train loss: 0.0052775626, Validation loss: 0.0053141444, LR: 0.0001\n",
      "Epoch 695, Train loss: 0.0052785937, Validation loss: 0.0053140331, LR: 0.0001\n",
      "Epoch 696, Train loss: 0.0052785354, Validation loss: 0.0053144891, LR: 0.0001\n",
      "Epoch 697, Train loss: 0.0052774054, Validation loss: 0.0053142438, LR: 0.0001\n",
      "Epoch 698, Train loss: 0.0052791815, Validation loss: 0.0053140679, LR: 0.0001\n",
      "Epoch 699, Train loss: 0.0052785517, Validation loss: 0.0053140259, LR: 0.0001\n",
      "Epoch 700, Train loss: 0.0052782173, Validation loss: 0.0053138580, LR: 0.0001\n",
      "Epoch 701, Train loss: 0.0052782839, Validation loss: 0.0053139311, LR: 0.0001\n",
      "Epoch 702, Train loss: 0.0052774550, Validation loss: 0.0053137988, LR: 0.0001\n",
      "Epoch 703, Train loss: 0.0052788043, Validation loss: 0.0053141009, LR: 0.0001\n",
      "Epoch 704, Train loss: 0.0052781799, Validation loss: 0.0053142742, LR: 0.0001\n",
      "Epoch 705, Train loss: 0.0052783978, Validation loss: 0.0053144119, LR: 0.0001\n",
      "Epoch 706, Train loss: 0.0052785073, Validation loss: 0.0053143437, LR: 0.0001\n",
      "Epoch 707, Train loss: 0.0052789056, Validation loss: 0.0053136077, LR: 0.0001\n",
      "Epoch 708, Train loss: 0.0052778137, Validation loss: 0.0053139900, LR: 0.0001\n",
      "Epoch 709, Train loss: 0.0052787353, Validation loss: 0.0053136874, LR: 0.0001\n",
      "Epoch 710, Train loss: 0.0052775248, Validation loss: 0.0053140726, LR: 0.0001\n",
      "Epoch 711, Train loss: 0.0052787620, Validation loss: 0.0053138955, LR: 0.0001\n",
      "Epoch 712, Train loss: 0.0052788870, Validation loss: 0.0053138921, LR: 0.0001\n",
      "Epoch 713, Train loss: 0.0052779036, Validation loss: 0.0053138001, LR: 0.0001\n",
      "Epoch 714, Train loss: 0.0052774624, Validation loss: 0.0053136117, LR: 0.0001\n",
      "Epoch 715, Train loss: 0.0052780275, Validation loss: 0.0053137932, LR: 0.0001\n",
      "Epoch 716, Train loss: 0.0052779438, Validation loss: 0.0053137781, LR: 0.0001\n",
      "Epoch 717, Train loss: 0.0052770460, Validation loss: 0.0053141314, LR: 0.0001\n",
      "Epoch 718, Train loss: 0.0052783858, Validation loss: 0.0053138272, LR: 0.0001\n",
      "Epoch 719, Train loss: 0.0052781005, Validation loss: 0.0053137630, LR: 0.0001\n",
      "Epoch 720, Train loss: 0.0052776772, Validation loss: 0.0053143215, LR: 0.0001\n",
      "Epoch 721, Train loss: 0.0052779283, Validation loss: 0.0053139385, LR: 0.0001\n",
      "Epoch 722, Train loss: 0.0052779113, Validation loss: 0.0053136022, LR: 0.0001\n",
      "Epoch 723, Train loss: 0.0052784001, Validation loss: 0.0053137384, LR: 0.0001\n",
      "Epoch 724, Train loss: 0.0052775991, Validation loss: 0.0053136527, LR: 0.0001\n",
      "Epoch 725, Train loss: 0.0052778564, Validation loss: 0.0053136652, LR: 0.0001\n",
      "Epoch 726, Train loss: 0.0052783099, Validation loss: 0.0053134318, LR: 0.0001\n",
      "Epoch 727, Train loss: 0.0052776862, Validation loss: 0.0053136922, LR: 0.0001\n",
      "Epoch 728, Train loss: 0.0052781479, Validation loss: 0.0053137505, LR: 0.0001\n",
      "Epoch 729, Train loss: 0.0052790494, Validation loss: 0.0053138179, LR: 0.0001\n",
      "Epoch 730, Train loss: 0.0052782917, Validation loss: 0.0053135145, LR: 0.0001\n",
      "Epoch 731, Train loss: 0.0052780346, Validation loss: 0.0053136876, LR: 0.0001\n",
      "Epoch 732, Train loss: 0.0052777356, Validation loss: 0.0053136148, LR: 0.0001\n",
      "Epoch 733, Train loss: 0.0052785100, Validation loss: 0.0053135733, LR: 0.0001\n",
      "Epoch 734, Train loss: 0.0052778570, Validation loss: 0.0053137958, LR: 0.0001\n",
      "Epoch 735, Train loss: 0.0052774844, Validation loss: 0.0053139293, LR: 0.0001\n",
      "Epoch 736, Train loss: 0.0052783503, Validation loss: 0.0053136933, LR: 0.0001\n",
      "Epoch 737, Train loss: 0.0052786942, Validation loss: 0.0053136513, LR: 0.0001\n",
      "Epoch 738, Train loss: 0.0052782735, Validation loss: 0.0053136536, LR: 0.0001\n",
      "Epoch 739, Train loss: 0.0052774901, Validation loss: 0.0053134799, LR: 0.0001\n",
      "Epoch 740, Train loss: 0.0052783315, Validation loss: 0.0053137419, LR: 0.0001\n",
      "Epoch 741, Train loss: 0.0052783708, Validation loss: 0.0053135724, LR: 0.0001\n",
      "Epoch 742, Train loss: 0.0052777355, Validation loss: 0.0053135913, LR: 0.0001\n",
      "Epoch 743, Train loss: 0.0052776141, Validation loss: 0.0053135090, LR: 0.0001\n",
      "Epoch 744, Train loss: 0.0052776930, Validation loss: 0.0053136304, LR: 0.0001\n",
      "Epoch 745, Train loss: 0.0052778012, Validation loss: 0.0053134690, LR: 0.0001\n",
      "Epoch 746, Train loss: 0.0052770363, Validation loss: 0.0053134140, LR: 0.0001\n",
      "Epoch 747, Train loss: 0.0052775945, Validation loss: 0.0053134356, LR: 0.0001\n",
      "Epoch 748, Train loss: 0.0052775462, Validation loss: 0.0053135587, LR: 0.0001\n",
      "Epoch 749, Train loss: 0.0052781653, Validation loss: 0.0053135592, LR: 0.0001\n",
      "Epoch 750, Train loss: 0.0052783377, Validation loss: 0.0053133359, LR: 0.0001\n",
      "Epoch 751, Train loss: 0.0052785885, Validation loss: 0.0053134402, LR: 0.0001\n",
      "Epoch 752, Train loss: 0.0052780571, Validation loss: 0.0053133453, LR: 0.0001\n",
      "Epoch 753, Train loss: 0.0052781327, Validation loss: 0.0053133070, LR: 0.0001\n",
      "Epoch 754, Train loss: 0.0052776265, Validation loss: 0.0053133107, LR: 0.0001\n",
      "Epoch 755, Train loss: 0.0052782197, Validation loss: 0.0053133024, LR: 0.0001\n",
      "Epoch 756, Train loss: 0.0052778967, Validation loss: 0.0053132983, LR: 0.0001\n",
      "Epoch 757, Train loss: 0.0052787382, Validation loss: 0.0053134613, LR: 0.0001\n",
      "Epoch 758, Train loss: 0.0052781717, Validation loss: 0.0053131376, LR: 0.0001\n",
      "Epoch 759, Train loss: 0.0052782487, Validation loss: 0.0053133857, LR: 0.0001\n",
      "Epoch 760, Train loss: 0.0052783714, Validation loss: 0.0053132979, LR: 0.0001\n",
      "Epoch 761, Train loss: 0.0052777762, Validation loss: 0.0053133135, LR: 0.0001\n",
      "Epoch 762, Train loss: 0.0052782087, Validation loss: 0.0053133407, LR: 0.0001\n",
      "Epoch 763, Train loss: 0.0052781295, Validation loss: 0.0053132772, LR: 0.0001\n",
      "Epoch 764, Train loss: 0.0052780102, Validation loss: 0.0053136227, LR: 0.0001\n",
      "Epoch 765, Train loss: 0.0052782214, Validation loss: 0.0053132823, LR: 0.0001\n",
      "Epoch 766, Train loss: 0.0052779449, Validation loss: 0.0053132421, LR: 0.0001\n",
      "Epoch 767, Train loss: 0.0052779773, Validation loss: 0.0053132068, LR: 0.0001\n",
      "Epoch 768, Train loss: 0.0052777734, Validation loss: 0.0053133775, LR: 0.0001\n",
      "Epoch 769, Train loss: 0.0052780640, Validation loss: 0.0053132563, LR: 0.0001\n",
      "Epoch 770, Train loss: 0.0052779258, Validation loss: 0.0053132836, LR: 0.0001\n",
      "Epoch 771, Train loss: 0.0052776816, Validation loss: 0.0053132312, LR: 0.0001\n",
      "Epoch 772, Train loss: 0.0052781884, Validation loss: 0.0053133263, LR: 0.0001\n",
      "Epoch 773, Train loss: 0.0052772921, Validation loss: 0.0053132160, LR: 0.0001\n",
      "Epoch 774, Train loss: 0.0052779568, Validation loss: 0.0053130988, LR: 0.0001\n",
      "Epoch 775, Train loss: 0.0052772341, Validation loss: 0.0053134150, LR: 0.0001\n",
      "Epoch 776, Train loss: 0.0052778537, Validation loss: 0.0053131014, LR: 0.0001\n",
      "Epoch 777, Train loss: 0.0052776994, Validation loss: 0.0053127784, LR: 0.0001\n",
      "Epoch 778, Train loss: 0.0052774554, Validation loss: 0.0053130261, LR: 0.0001\n",
      "Epoch 779, Train loss: 0.0052784630, Validation loss: 0.0053132293, LR: 0.0001\n",
      "Epoch 780, Train loss: 0.0052777355, Validation loss: 0.0053128712, LR: 0.0001\n",
      "Epoch 781, Train loss: 0.0052774705, Validation loss: 0.0053128391, LR: 0.0001\n",
      "Epoch 782, Train loss: 0.0052780962, Validation loss: 0.0053130655, LR: 0.0001\n",
      "Epoch 783, Train loss: 0.0052775895, Validation loss: 0.0053128809, LR: 0.0001\n",
      "Epoch 784, Train loss: 0.0052776614, Validation loss: 0.0053132605, LR: 0.0001\n",
      "Epoch 785, Train loss: 0.0052776528, Validation loss: 0.0053128483, LR: 0.0001\n",
      "Epoch 786, Train loss: 0.0052783828, Validation loss: 0.0053130765, LR: 0.0001\n",
      "Epoch 787, Train loss: 0.0052780621, Validation loss: 0.0053130939, LR: 0.0001\n",
      "Epoch 788, Train loss: 0.0052775609, Validation loss: 0.0053128785, LR: 0.0001\n",
      "Epoch 789, Train loss: 0.0052777769, Validation loss: 0.0053133056, LR: 0.0001\n",
      "Epoch 790, Train loss: 0.0052778577, Validation loss: 0.0053128529, LR: 0.0001\n",
      "Epoch 791, Train loss: 0.0052780748, Validation loss: 0.0053131240, LR: 0.0001\n",
      "Epoch 792, Train loss: 0.0052774290, Validation loss: 0.0053127398, LR: 0.0001\n",
      "Epoch 793, Train loss: 0.0052777913, Validation loss: 0.0053128319, LR: 0.0001\n",
      "Epoch 794, Train loss: 0.0052773134, Validation loss: 0.0053125961, LR: 0.0001\n",
      "Epoch 795, Train loss: 0.0052772236, Validation loss: 0.0053128763, LR: 0.0001\n",
      "Epoch 796, Train loss: 0.0052774612, Validation loss: 0.0053132419, LR: 0.0001\n",
      "Epoch 797, Train loss: 0.0052783805, Validation loss: 0.0053130180, LR: 0.0001\n",
      "Epoch 798, Train loss: 0.0052779975, Validation loss: 0.0053129623, LR: 0.0001\n",
      "Epoch 799, Train loss: 0.0052768674, Validation loss: 0.0053130181, LR: 0.0001\n",
      "Epoch 800, Train loss: 0.0052781877, Validation loss: 0.0053130043, LR: 0.0001\n",
      "Epoch 801, Train loss: 0.0052782590, Validation loss: 0.0053129290, LR: 0.0001\n",
      "Epoch 802, Train loss: 0.0052784054, Validation loss: 0.0053129194, LR: 0.0001\n",
      "Epoch 803, Train loss: 0.0052775287, Validation loss: 0.0053126588, LR: 0.0001\n",
      "Epoch 804, Train loss: 0.0052778294, Validation loss: 0.0053126777, LR: 0.0001\n",
      "Epoch 805, Train loss: 0.0052771168, Validation loss: 0.0053128953, LR: 0.0001\n",
      "Epoch 806, Train loss: 0.0052771639, Validation loss: 0.0053129395, LR: 0.0001\n",
      "Epoch 807, Train loss: 0.0052779433, Validation loss: 0.0053127472, LR: 0.0001\n",
      "Epoch 808, Train loss: 0.0052780946, Validation loss: 0.0053126615, LR: 0.0001\n",
      "Epoch 809, Train loss: 0.0052783194, Validation loss: 0.0053125507, LR: 0.0001\n",
      "Epoch 810, Train loss: 0.0052773805, Validation loss: 0.0053126459, LR: 0.0001\n",
      "Epoch 811, Train loss: 0.0052777937, Validation loss: 0.0053126807, LR: 0.0001\n",
      "Epoch 812, Train loss: 0.0052776092, Validation loss: 0.0053127589, LR: 0.0001\n",
      "Epoch 813, Train loss: 0.0052777495, Validation loss: 0.0053127371, LR: 0.0001\n",
      "Epoch 814, Train loss: 0.0052775303, Validation loss: 0.0053127756, LR: 0.0001\n",
      "Epoch 815, Train loss: 0.0052777515, Validation loss: 0.0053127186, LR: 0.0001\n",
      "Epoch 816, Train loss: 0.0052781333, Validation loss: 0.0053130861, LR: 0.0001\n",
      "Epoch 817, Train loss: 0.0052779297, Validation loss: 0.0053127106, LR: 0.0001\n",
      "Epoch 818, Train loss: 0.0052779853, Validation loss: 0.0053129341, LR: 0.0001\n",
      "Epoch 819, Train loss: 0.0052780602, Validation loss: 0.0053126439, LR: 0.0001\n",
      "Epoch 820, Train loss: 0.0052766356, Validation loss: 0.0053125916, LR: 0.0001\n",
      "Epoch 821, Train loss: 0.0052773574, Validation loss: 0.0053126090, LR: 0.0001\n",
      "Epoch 822, Train loss: 0.0052773425, Validation loss: 0.0053126775, LR: 0.0001\n",
      "Epoch 823, Train loss: 0.0052776522, Validation loss: 0.0053125115, LR: 0.0001\n",
      "Epoch 824, Train loss: 0.0052782044, Validation loss: 0.0053138560, LR: 0.0001\n",
      "Epoch 825, Train loss: 0.0052779571, Validation loss: 0.0053125857, LR: 0.0001\n",
      "Epoch 826, Train loss: 0.0052769635, Validation loss: 0.0053122918, LR: 0.0001\n",
      "Epoch 827, Train loss: 0.0052772409, Validation loss: 0.0053127687, LR: 0.0001\n",
      "Epoch 828, Train loss: 0.0052770997, Validation loss: 0.0053124930, LR: 0.0001\n",
      "Epoch 829, Train loss: 0.0052770814, Validation loss: 0.0053124902, LR: 0.0001\n",
      "Epoch 830, Train loss: 0.0052777168, Validation loss: 0.0053126028, LR: 0.0001\n",
      "Epoch 831, Train loss: 0.0052779082, Validation loss: 0.0053123860, LR: 0.0001\n",
      "Epoch 832, Train loss: 0.0052777842, Validation loss: 0.0053129334, LR: 0.0001\n",
      "Epoch 833, Train loss: 0.0052777268, Validation loss: 0.0053126416, LR: 0.0001\n",
      "Epoch 834, Train loss: 0.0052777775, Validation loss: 0.0053128726, LR: 0.0001\n",
      "Epoch 835, Train loss: 0.0052771234, Validation loss: 0.0053125561, LR: 0.0001\n",
      "Epoch 836, Train loss: 0.0052773527, Validation loss: 0.0053125871, LR: 0.0001\n",
      "Epoch 837, Train loss: 0.0052779344, Validation loss: 0.0053124269, LR: 0.0001\n",
      "Epoch 838, Train loss: 0.0052772261, Validation loss: 0.0053127740, LR: 0.0001\n",
      "Epoch 839, Train loss: 0.0052775725, Validation loss: 0.0053123222, LR: 0.0001\n",
      "Epoch 840, Train loss: 0.0052767465, Validation loss: 0.0053124660, LR: 0.0001\n",
      "Epoch 841, Train loss: 0.0052781404, Validation loss: 0.0053124019, LR: 0.0001\n",
      "Epoch 842, Train loss: 0.0052774165, Validation loss: 0.0053125123, LR: 0.0001\n",
      "Epoch 843, Train loss: 0.0052777082, Validation loss: 0.0053123104, LR: 0.0001\n",
      "Epoch 844, Train loss: 0.0052777904, Validation loss: 0.0053124038, LR: 0.0001\n",
      "Epoch 845, Train loss: 0.0052777720, Validation loss: 0.0053124133, LR: 0.0001\n",
      "Epoch 846, Train loss: 0.0052773126, Validation loss: 0.0053124778, LR: 0.0001\n",
      "Epoch 847, Train loss: 0.0052777960, Validation loss: 0.0053127136, LR: 0.0001\n",
      "Epoch 848, Train loss: 0.0052778833, Validation loss: 0.0053127730, LR: 0.0001\n",
      "Epoch 849, Train loss: 0.0052773073, Validation loss: 0.0053124109, LR: 0.0001\n",
      "Epoch 850, Train loss: 0.0052778403, Validation loss: 0.0053122996, LR: 0.0001\n",
      "Epoch 851, Train loss: 0.0052781716, Validation loss: 0.0053122643, LR: 0.0001\n",
      "Epoch 852, Train loss: 0.0052773725, Validation loss: 0.0053123986, LR: 0.0001\n",
      "Epoch 853, Train loss: 0.0052779947, Validation loss: 0.0053124591, LR: 0.0001\n",
      "Epoch 854, Train loss: 0.0052777199, Validation loss: 0.0053123970, LR: 0.0001\n",
      "Epoch 855, Train loss: 0.0052777244, Validation loss: 0.0053122287, LR: 0.0001\n",
      "Epoch 856, Train loss: 0.0052774392, Validation loss: 0.0053121166, LR: 0.0001\n",
      "Epoch 857, Train loss: 0.0052773028, Validation loss: 0.0053123898, LR: 0.0001\n",
      "Epoch 858, Train loss: 0.0052769254, Validation loss: 0.0053124503, LR: 0.0001\n",
      "Epoch 859, Train loss: 0.0052775568, Validation loss: 0.0053130261, LR: 0.0001\n",
      "Epoch 860, Train loss: 0.0052771185, Validation loss: 0.0053122382, LR: 0.0001\n",
      "Epoch 861, Train loss: 0.0052781944, Validation loss: 0.0053123895, LR: 0.0001\n",
      "Epoch 862, Train loss: 0.0052772154, Validation loss: 0.0053123058, LR: 0.0001\n",
      "Epoch 863, Train loss: 0.0052773046, Validation loss: 0.0053120003, LR: 0.0001\n",
      "Epoch 864, Train loss: 0.0052772684, Validation loss: 0.0053122588, LR: 0.0001\n",
      "Epoch 865, Train loss: 0.0052772957, Validation loss: 0.0053122679, LR: 0.0001\n",
      "Epoch 866, Train loss: 0.0052779033, Validation loss: 0.0053121631, LR: 0.0001\n",
      "Epoch 867, Train loss: 0.0052768856, Validation loss: 0.0053124245, LR: 0.0001\n",
      "Epoch 868, Train loss: 0.0052775920, Validation loss: 0.0053120889, LR: 0.0001\n",
      "Epoch 869, Train loss: 0.0052774230, Validation loss: 0.0053122433, LR: 0.0001\n",
      "Epoch 870, Train loss: 0.0052782982, Validation loss: 0.0053124323, LR: 0.0001\n",
      "Epoch 871, Train loss: 0.0052777340, Validation loss: 0.0053122003, LR: 0.0001\n",
      "Epoch 872, Train loss: 0.0052767854, Validation loss: 0.0053120655, LR: 0.0001\n",
      "Epoch 873, Train loss: 0.0052767887, Validation loss: 0.0053123887, LR: 0.0001\n",
      "Epoch 874, Train loss: 0.0052768063, Validation loss: 0.0053123168, LR: 0.0001\n",
      "Epoch 875, Train loss: 0.0052770951, Validation loss: 0.0053121839, LR: 0.0001\n",
      "Epoch 876, Train loss: 0.0052770440, Validation loss: 0.0053125184, LR: 0.0001\n",
      "Epoch 877, Train loss: 0.0052773601, Validation loss: 0.0053122159, LR: 0.0001\n",
      "Epoch 878, Train loss: 0.0052778858, Validation loss: 0.0053121818, LR: 0.0001\n",
      "Epoch 879, Train loss: 0.0052771111, Validation loss: 0.0053125270, LR: 0.0001\n",
      "Epoch 880, Train loss: 0.0052774289, Validation loss: 0.0053121617, LR: 0.0001\n",
      "Epoch 881, Train loss: 0.0052769774, Validation loss: 0.0053122117, LR: 0.0001\n",
      "Epoch 882, Train loss: 0.0052778442, Validation loss: 0.0053121053, LR: 0.0001\n",
      "Epoch 883, Train loss: 0.0052775465, Validation loss: 0.0053121177, LR: 0.0001\n",
      "Epoch 884, Train loss: 0.0052774710, Validation loss: 0.0053120892, LR: 0.0001\n",
      "Epoch 885, Train loss: 0.0052780529, Validation loss: 0.0053121263, LR: 0.0001\n",
      "Epoch 886, Train loss: 0.0052768761, Validation loss: 0.0053123319, LR: 0.0001\n",
      "Epoch 887, Train loss: 0.0052766272, Validation loss: 0.0053126004, LR: 0.0001\n",
      "Epoch 888, Train loss: 0.0052775643, Validation loss: 0.0053121708, LR: 0.0001\n",
      "Epoch 889, Train loss: 0.0052769026, Validation loss: 0.0053121219, LR: 0.0001\n",
      "Epoch 890, Train loss: 0.0052772370, Validation loss: 0.0053121682, LR: 0.0001\n",
      "Epoch 891, Train loss: 0.0052776251, Validation loss: 0.0053117841, LR: 0.0001\n",
      "Epoch 892, Train loss: 0.0052765473, Validation loss: 0.0053121235, LR: 0.0001\n",
      "Epoch 893, Train loss: 0.0052774823, Validation loss: 0.0053122814, LR: 0.0001\n",
      "Epoch 894, Train loss: 0.0052773057, Validation loss: 0.0053119769, LR: 0.0001\n",
      "Epoch 895, Train loss: 0.0052771213, Validation loss: 0.0053123538, LR: 0.0001\n",
      "Epoch 896, Train loss: 0.0052773411, Validation loss: 0.0053118926, LR: 0.0001\n",
      "Epoch 897, Train loss: 0.0052773874, Validation loss: 0.0053119294, LR: 0.0001\n",
      "Epoch 898, Train loss: 0.0052775862, Validation loss: 0.0053119810, LR: 0.0001\n",
      "Epoch 899, Train loss: 0.0052774903, Validation loss: 0.0053124391, LR: 0.0001\n",
      "Epoch 900, Train loss: 0.0052772907, Validation loss: 0.0053124554, LR: 0.0001\n",
      "Epoch 901, Train loss: 0.0052771368, Validation loss: 0.0053119308, LR: 0.0001\n",
      "Epoch 902, Train loss: 0.0052780068, Validation loss: 0.0053123822, LR: 0.0001\n",
      "Epoch 903, Train loss: 0.0052775134, Validation loss: 0.0053122369, LR: 0.0001\n",
      "Epoch 904, Train loss: 0.0052764518, Validation loss: 0.0053119763, LR: 0.0001\n",
      "Epoch 905, Train loss: 0.0052767755, Validation loss: 0.0053119572, LR: 0.0001\n",
      "Epoch 906, Train loss: 0.0052769255, Validation loss: 0.0053121250, LR: 0.0001\n",
      "Epoch 907, Train loss: 0.0052774508, Validation loss: 0.0053119211, LR: 0.0001\n",
      "Epoch 908, Train loss: 0.0052777923, Validation loss: 0.0053123062, LR: 0.0001\n",
      "Epoch 909, Train loss: 0.0052768710, Validation loss: 0.0053119349, LR: 0.0001\n",
      "Epoch 910, Train loss: 0.0052773042, Validation loss: 0.0053117620, LR: 0.0001\n",
      "Epoch 911, Train loss: 0.0052774683, Validation loss: 0.0053117823, LR: 0.0001\n",
      "Epoch 912, Train loss: 0.0052777488, Validation loss: 0.0053118006, LR: 0.0001\n",
      "Epoch 913, Train loss: 0.0052775595, Validation loss: 0.0053120062, LR: 0.0001\n",
      "Epoch 914, Train loss: 0.0052771102, Validation loss: 0.0053116456, LR: 0.0001\n",
      "Epoch 915, Train loss: 0.0052770625, Validation loss: 0.0053121482, LR: 0.0001\n",
      "Epoch 916, Train loss: 0.0052772948, Validation loss: 0.0053122186, LR: 0.0001\n",
      "Epoch 917, Train loss: 0.0052770266, Validation loss: 0.0053118801, LR: 0.0001\n",
      "Epoch 918, Train loss: 0.0052775604, Validation loss: 0.0053119189, LR: 0.0001\n",
      "Epoch 919, Train loss: 0.0052766884, Validation loss: 0.0053120155, LR: 0.0001\n",
      "Epoch 920, Train loss: 0.0052773021, Validation loss: 0.0053120035, LR: 0.0001\n",
      "Epoch 921, Train loss: 0.0052768864, Validation loss: 0.0053118001, LR: 0.0001\n",
      "Epoch 922, Train loss: 0.0052765727, Validation loss: 0.0053117694, LR: 0.0001\n",
      "Epoch 923, Train loss: 0.0052773611, Validation loss: 0.0053117020, LR: 0.0001\n",
      "Epoch 924, Train loss: 0.0052777720, Validation loss: 0.0053117989, LR: 0.0001\n",
      "Epoch 925, Train loss: 0.0052763236, Validation loss: 0.0053120514, LR: 0.0001\n",
      "Epoch 926, Train loss: 0.0052769157, Validation loss: 0.0053121191, LR: 0.0001\n",
      "Epoch 927, Train loss: 0.0052771294, Validation loss: 0.0053118686, LR: 0.0001\n",
      "Epoch 928, Train loss: 0.0052763182, Validation loss: 0.0053116849, LR: 0.0001\n",
      "Epoch 929, Train loss: 0.0052774266, Validation loss: 0.0053122510, LR: 0.0001\n",
      "Epoch 930, Train loss: 0.0052776741, Validation loss: 0.0053116779, LR: 0.0001\n",
      "Epoch 931, Train loss: 0.0052772358, Validation loss: 0.0053123224, LR: 0.0001\n",
      "Epoch 932, Train loss: 0.0052777917, Validation loss: 0.0053118992, LR: 0.0001\n",
      "Epoch 933, Train loss: 0.0052776050, Validation loss: 0.0053118972, LR: 0.0001\n",
      "Epoch 934, Train loss: 0.0052767836, Validation loss: 0.0053117006, LR: 0.0001\n",
      "Epoch 935, Train loss: 0.0052772663, Validation loss: 0.0053118232, LR: 0.0001\n",
      "Epoch 936, Train loss: 0.0052777553, Validation loss: 0.0053117572, LR: 0.0001\n",
      "Epoch 937, Train loss: 0.0052778826, Validation loss: 0.0053119489, LR: 0.0001\n",
      "Epoch 938, Train loss: 0.0052770149, Validation loss: 0.0053117539, LR: 0.0001\n",
      "Epoch 939, Train loss: 0.0052772781, Validation loss: 0.0053115722, LR: 0.0001\n",
      "Epoch 940, Train loss: 0.0052773306, Validation loss: 0.0053117332, LR: 0.0001\n",
      "Epoch 941, Train loss: 0.0052774126, Validation loss: 0.0053118959, LR: 0.0001\n",
      "Epoch 942, Train loss: 0.0052763224, Validation loss: 0.0053118854, LR: 0.0001\n",
      "Epoch 943, Train loss: 0.0052771172, Validation loss: 0.0053118626, LR: 0.0001\n",
      "Epoch 944, Train loss: 0.0052771488, Validation loss: 0.0053114110, LR: 0.0001\n",
      "Epoch 945, Train loss: 0.0052764771, Validation loss: 0.0053114955, LR: 0.0001\n",
      "Epoch 946, Train loss: 0.0052775178, Validation loss: 0.0053114658, LR: 0.0001\n",
      "Epoch 947, Train loss: 0.0052770475, Validation loss: 0.0053117839, LR: 0.0001\n",
      "Epoch 948, Train loss: 0.0052774176, Validation loss: 0.0053118884, LR: 0.0001\n",
      "Epoch 949, Train loss: 0.0052772872, Validation loss: 0.0053118058, LR: 0.0001\n",
      "Epoch 950, Train loss: 0.0052775983, Validation loss: 0.0053115620, LR: 0.0001\n",
      "Epoch 951, Train loss: 0.0052772810, Validation loss: 0.0053116705, LR: 0.0001\n",
      "Epoch 952, Train loss: 0.0052771389, Validation loss: 0.0053116459, LR: 0.0001\n",
      "Epoch 953, Train loss: 0.0052765702, Validation loss: 0.0053113783, LR: 0.0001\n",
      "Epoch 954, Train loss: 0.0052770332, Validation loss: 0.0053117538, LR: 0.0001\n",
      "Epoch 955, Train loss: 0.0052765710, Validation loss: 0.0053116005, LR: 0.0001\n",
      "Epoch 956, Train loss: 0.0052769070, Validation loss: 0.0053114237, LR: 0.0001\n",
      "Epoch 957, Train loss: 0.0052763548, Validation loss: 0.0053115348, LR: 0.0001\n",
      "Epoch 958, Train loss: 0.0052771164, Validation loss: 0.0053123665, LR: 0.0001\n",
      "Epoch 959, Train loss: 0.0052774566, Validation loss: 0.0053116505, LR: 0.0001\n",
      "Epoch 960, Train loss: 0.0052769559, Validation loss: 0.0053116752, LR: 0.0001\n",
      "Epoch 961, Train loss: 0.0052776673, Validation loss: 0.0053115241, LR: 0.0001\n",
      "Epoch 962, Train loss: 0.0052774347, Validation loss: 0.0053115725, LR: 0.0001\n",
      "Epoch 963, Train loss: 0.0052771086, Validation loss: 0.0053115443, LR: 0.0001\n",
      "Epoch 964, Train loss: 0.0052777912, Validation loss: 0.0053113030, LR: 0.0001\n",
      "Epoch 965, Train loss: 0.0052765706, Validation loss: 0.0053115563, LR: 0.0001\n",
      "Epoch 966, Train loss: 0.0052771427, Validation loss: 0.0053113892, LR: 0.0001\n",
      "Epoch 967, Train loss: 0.0052761712, Validation loss: 0.0053114790, LR: 0.0001\n",
      "Epoch 968, Train loss: 0.0052768569, Validation loss: 0.0053118800, LR: 0.0001\n",
      "Epoch 969, Train loss: 0.0052774931, Validation loss: 0.0053114078, LR: 0.0001\n",
      "Epoch 970, Train loss: 0.0052770332, Validation loss: 0.0053118446, LR: 0.0001\n",
      "Epoch 971, Train loss: 0.0052769143, Validation loss: 0.0053117095, LR: 0.0001\n",
      "Epoch 972, Train loss: 0.0052771317, Validation loss: 0.0053112456, LR: 0.0001\n",
      "Epoch 973, Train loss: 0.0052774582, Validation loss: 0.0053113616, LR: 0.0001\n",
      "Epoch 974, Train loss: 0.0052776154, Validation loss: 0.0053113683, LR: 0.0001\n",
      "Epoch 975, Train loss: 0.0052768150, Validation loss: 0.0053114567, LR: 0.0001\n",
      "Epoch 976, Train loss: 0.0052766649, Validation loss: 0.0053113151, LR: 0.0001\n",
      "Epoch 977, Train loss: 0.0052772360, Validation loss: 0.0053116250, LR: 0.0001\n",
      "Epoch 978, Train loss: 0.0052769747, Validation loss: 0.0053117221, LR: 0.0001\n",
      "Epoch 979, Train loss: 0.0052770497, Validation loss: 0.0053114020, LR: 0.0001\n",
      "Epoch 980, Train loss: 0.0052778957, Validation loss: 0.0053115574, LR: 0.0001\n",
      "Epoch 981, Train loss: 0.0052763231, Validation loss: 0.0053115663, LR: 0.0001\n",
      "Epoch 982, Train loss: 0.0052779988, Validation loss: 0.0053114301, LR: 0.0001\n",
      "Epoch 983, Train loss: 0.0052768567, Validation loss: 0.0053115100, LR: 0.0001\n",
      "Epoch 984, Train loss: 0.0052762245, Validation loss: 0.0053113088, LR: 0.0001\n",
      "Epoch 985, Train loss: 0.0052771177, Validation loss: 0.0053113422, LR: 0.0001\n",
      "Epoch 986, Train loss: 0.0052773274, Validation loss: 0.0053115314, LR: 0.0001\n",
      "Epoch 987, Train loss: 0.0052773642, Validation loss: 0.0053114194, LR: 0.0001\n",
      "Epoch 988, Train loss: 0.0052770440, Validation loss: 0.0053114276, LR: 0.0001\n",
      "Epoch 989, Train loss: 0.0052771056, Validation loss: 0.0053113391, LR: 0.0001\n",
      "Epoch 990, Train loss: 0.0052764543, Validation loss: 0.0053113220, LR: 0.0001\n",
      "Epoch 991, Train loss: 0.0052772695, Validation loss: 0.0053114247, LR: 0.0001\n",
      "Epoch 992, Train loss: 0.0052765887, Validation loss: 0.0053116207, LR: 0.0001\n",
      "Epoch 993, Train loss: 0.0052771998, Validation loss: 0.0053112864, LR: 0.0001\n",
      "Epoch 994, Train loss: 0.0052771656, Validation loss: 0.0053111083, LR: 0.0001\n",
      "Epoch 995, Train loss: 0.0052766584, Validation loss: 0.0053116452, LR: 0.0001\n",
      "Epoch 996, Train loss: 0.0052771277, Validation loss: 0.0053115170, LR: 0.0001\n",
      "Epoch 997, Train loss: 0.0052768537, Validation loss: 0.0053116650, LR: 0.0001\n",
      "Epoch 998, Train loss: 0.0052770306, Validation loss: 0.0053112281, LR: 0.0001\n",
      "Epoch 999, Train loss: 0.0052766502, Validation loss: 0.0053112255, LR: 0.0001\n",
      "Epoch 1000, Train loss: 0.0052768312, Validation loss: 0.0053113194, LR: 0.0001\n",
      "Epoch 1001, Train loss: 0.0052774728, Validation loss: 0.0053115483, LR: 0.0001\n",
      "Epoch 1002, Train loss: 0.0052771154, Validation loss: 0.0053113858, LR: 0.0001\n",
      "Epoch 1003, Train loss: 0.0052772653, Validation loss: 0.0053115159, LR: 0.0001\n",
      "Epoch 1004, Train loss: 0.0052769768, Validation loss: 0.0053113633, LR: 0.0001\n",
      "Epoch 1005, Train loss: 0.0052765917, Validation loss: 0.0053110994, LR: 0.0001\n",
      "Epoch 1006, Train loss: 0.0052770728, Validation loss: 0.0053114287, LR: 0.0001\n",
      "Epoch 1007, Train loss: 0.0052774160, Validation loss: 0.0053111370, LR: 0.0001\n",
      "Epoch 1008, Train loss: 0.0052767015, Validation loss: 0.0053116549, LR: 0.0001\n",
      "Epoch 1009, Train loss: 0.0052771954, Validation loss: 0.0053110710, LR: 0.0001\n",
      "Epoch 1010, Train loss: 0.0052767314, Validation loss: 0.0053114122, LR: 0.0001\n",
      "Epoch 1011, Train loss: 0.0052765550, Validation loss: 0.0053110976, LR: 0.0001\n",
      "Epoch 1012, Train loss: 0.0052770860, Validation loss: 0.0053113164, LR: 0.0001\n",
      "Epoch 1013, Train loss: 0.0052769797, Validation loss: 0.0053111517, LR: 0.0001\n",
      "Epoch 1014, Train loss: 0.0052762738, Validation loss: 0.0053115005, LR: 0.0001\n",
      "Epoch 1015, Train loss: 0.0052778705, Validation loss: 0.0053112311, LR: 0.0001\n",
      "Epoch 1016, Train loss: 0.0052767142, Validation loss: 0.0053112270, LR: 0.0001\n",
      "Epoch 1017, Train loss: 0.0052773451, Validation loss: 0.0053110086, LR: 0.0001\n",
      "Epoch 1018, Train loss: 0.0052761199, Validation loss: 0.0053110247, LR: 0.0001\n",
      "Epoch 1019, Train loss: 0.0052773001, Validation loss: 0.0053112701, LR: 0.0001\n",
      "Epoch 1020, Train loss: 0.0052758980, Validation loss: 0.0053109898, LR: 0.0001\n",
      "Epoch 1021, Train loss: 0.0052767192, Validation loss: 0.0053111554, LR: 0.0001\n",
      "Epoch 1022, Train loss: 0.0052770238, Validation loss: 0.0053114294, LR: 0.0001\n",
      "Epoch 1023, Train loss: 0.0052770187, Validation loss: 0.0053110391, LR: 0.0001\n",
      "Epoch 1024, Train loss: 0.0052773520, Validation loss: 0.0053110692, LR: 0.0001\n",
      "Epoch 1025, Train loss: 0.0052765318, Validation loss: 0.0053112458, LR: 0.0001\n",
      "Epoch 1026, Train loss: 0.0052774974, Validation loss: 0.0053111127, LR: 0.0001\n",
      "Epoch 1027, Train loss: 0.0052765940, Validation loss: 0.0053111048, LR: 0.0001\n",
      "Epoch 1028, Train loss: 0.0052763867, Validation loss: 0.0053111470, LR: 0.0001\n",
      "Epoch 1029, Train loss: 0.0052764759, Validation loss: 0.0053112958, LR: 0.0001\n",
      "Epoch 1030, Train loss: 0.0052772289, Validation loss: 0.0053111452, LR: 0.0001\n",
      "Epoch 1031, Train loss: 0.0052766433, Validation loss: 0.0053113097, LR: 0.0001\n",
      "Epoch 1032, Train loss: 0.0052768169, Validation loss: 0.0053110239, LR: 0.0001\n",
      "Epoch 1033, Train loss: 0.0052760862, Validation loss: 0.0053109878, LR: 0.0001\n",
      "Epoch 1034, Train loss: 0.0052767755, Validation loss: 0.0053112771, LR: 0.0001\n",
      "Epoch 1035, Train loss: 0.0052771843, Validation loss: 0.0053113542, LR: 0.0001\n",
      "Epoch 1036, Train loss: 0.0052769964, Validation loss: 0.0053111968, LR: 0.0001\n",
      "Epoch 1037, Train loss: 0.0052761654, Validation loss: 0.0053111477, LR: 0.0001\n",
      "Epoch 1038, Train loss: 0.0052763503, Validation loss: 0.0053114129, LR: 0.0001\n",
      "Epoch 1039, Train loss: 0.0052769087, Validation loss: 0.0053110737, LR: 0.0001\n",
      "Epoch 1040, Train loss: 0.0052765924, Validation loss: 0.0053110431, LR: 0.0001\n",
      "Epoch 1041, Train loss: 0.0052761559, Validation loss: 0.0053110946, LR: 0.0001\n",
      "Epoch 1042, Train loss: 0.0052766823, Validation loss: 0.0053108494, LR: 0.0001\n",
      "Epoch 1043, Train loss: 0.0052765739, Validation loss: 0.0053110644, LR: 0.0001\n",
      "Epoch 1044, Train loss: 0.0052773640, Validation loss: 0.0053110714, LR: 0.0001\n",
      "Epoch 1045, Train loss: 0.0052763061, Validation loss: 0.0053110194, LR: 0.0001\n",
      "Epoch 1046, Train loss: 0.0052771526, Validation loss: 0.0053110252, LR: 0.0001\n",
      "Epoch 1047, Train loss: 0.0052767948, Validation loss: 0.0053111252, LR: 0.0001\n",
      "Epoch 1048, Train loss: 0.0052769000, Validation loss: 0.0053112598, LR: 0.0001\n",
      "Epoch 1049, Train loss: 0.0052775048, Validation loss: 0.0053112139, LR: 0.0001\n",
      "Epoch 1050, Train loss: 0.0052772459, Validation loss: 0.0053108854, LR: 0.0001\n",
      "Epoch 1051, Train loss: 0.0052764641, Validation loss: 0.0053110858, LR: 0.0001\n",
      "Epoch 1052, Train loss: 0.0052774890, Validation loss: 0.0053111327, LR: 0.0001\n",
      "Epoch 1053, Train loss: 0.0052769408, Validation loss: 0.0053110071, LR: 0.0001\n",
      "Epoch 1054, Train loss: 0.0052771555, Validation loss: 0.0053111434, LR: 0.0001\n",
      "Epoch 1055, Train loss: 0.0052773742, Validation loss: 0.0053109324, LR: 0.0001\n",
      "Epoch 1056, Train loss: 0.0052771529, Validation loss: 0.0053108439, LR: 0.0001\n",
      "Epoch 1057, Train loss: 0.0052764960, Validation loss: 0.0053110794, LR: 0.0001\n",
      "Epoch 1058, Train loss: 0.0052767863, Validation loss: 0.0053110666, LR: 0.0001\n",
      "Epoch 1059, Train loss: 0.0052766534, Validation loss: 0.0053112507, LR: 0.0001\n",
      "Epoch 1060, Train loss: 0.0052767721, Validation loss: 0.0053108726, LR: 0.0001\n",
      "Epoch 1061, Train loss: 0.0052764057, Validation loss: 0.0053109307, LR: 0.0001\n",
      "Epoch 1062, Train loss: 0.0052766746, Validation loss: 0.0053109818, LR: 0.0001\n",
      "Epoch 1063, Train loss: 0.0052764611, Validation loss: 0.0053108892, LR: 0.0001\n",
      "Epoch 1064, Train loss: 0.0052772977, Validation loss: 0.0053110328, LR: 0.0001\n",
      "Epoch 1065, Train loss: 0.0052766738, Validation loss: 0.0053109682, LR: 0.0001\n",
      "Epoch 1066, Train loss: 0.0052765909, Validation loss: 0.0053110484, LR: 0.0001\n",
      "Epoch 1067, Train loss: 0.0052770385, Validation loss: 0.0053107750, LR: 0.0001\n",
      "Epoch 1068, Train loss: 0.0052760067, Validation loss: 0.0053110405, LR: 0.0001\n",
      "Epoch 1069, Train loss: 0.0052769113, Validation loss: 0.0053109592, LR: 0.0001\n",
      "Epoch 1070, Train loss: 0.0052762930, Validation loss: 0.0053109691, LR: 0.0001\n",
      "Epoch 1071, Train loss: 0.0052765565, Validation loss: 0.0053107867, LR: 0.0001\n",
      "Epoch 1072, Train loss: 0.0052768351, Validation loss: 0.0053108153, LR: 0.0001\n",
      "Epoch 1073, Train loss: 0.0052774120, Validation loss: 0.0053108169, LR: 0.0001\n",
      "Epoch 1074, Train loss: 0.0052766328, Validation loss: 0.0053110966, LR: 0.0001\n",
      "Epoch 1075, Train loss: 0.0052772905, Validation loss: 0.0053109048, LR: 0.0001\n",
      "Epoch 1076, Train loss: 0.0052772857, Validation loss: 0.0053109966, LR: 0.0001\n",
      "Epoch 1077, Train loss: 0.0052770901, Validation loss: 0.0053108764, LR: 0.0001\n",
      "Epoch 1078, Train loss: 0.0052765514, Validation loss: 0.0053107908, LR: 0.0001\n",
      "Epoch 1079, Train loss: 0.0052768728, Validation loss: 0.0053109054, LR: 0.0001\n",
      "Epoch 1080, Train loss: 0.0052760846, Validation loss: 0.0053109748, LR: 0.0001\n",
      "Epoch 1081, Train loss: 0.0052775867, Validation loss: 0.0053112333, LR: 0.0001\n",
      "Epoch 1082, Train loss: 0.0052777345, Validation loss: 0.0053107106, LR: 0.0001\n",
      "Epoch 1083, Train loss: 0.0052766754, Validation loss: 0.0053112220, LR: 0.0001\n",
      "Epoch 1084, Train loss: 0.0052770117, Validation loss: 0.0053110727, LR: 0.0001\n",
      "Epoch 1085, Train loss: 0.0052765412, Validation loss: 0.0053107860, LR: 0.0001\n",
      "Epoch 1086, Train loss: 0.0052774227, Validation loss: 0.0053106879, LR: 0.0001\n",
      "Epoch 1087, Train loss: 0.0052766512, Validation loss: 0.0053107112, LR: 0.0001\n",
      "Epoch 1088, Train loss: 0.0052767081, Validation loss: 0.0053112365, LR: 0.0001\n",
      "Epoch 1089, Train loss: 0.0052768931, Validation loss: 0.0053107947, LR: 0.0001\n",
      "Epoch 1090, Train loss: 0.0052772610, Validation loss: 0.0053109651, LR: 0.0001\n",
      "Epoch 1091, Train loss: 0.0052769323, Validation loss: 0.0053107591, LR: 0.0001\n",
      "Epoch 1092, Train loss: 0.0052764492, Validation loss: 0.0053108112, LR: 0.0001\n",
      "Epoch 1093, Train loss: 0.0052766067, Validation loss: 0.0053107628, LR: 0.0001\n",
      "Epoch 1094, Train loss: 0.0052769001, Validation loss: 0.0053109168, LR: 0.0001\n",
      "Epoch 1095, Train loss: 0.0052762297, Validation loss: 0.0053106376, LR: 0.0001\n",
      "Epoch 1096, Train loss: 0.0052770135, Validation loss: 0.0053109047, LR: 0.0001\n",
      "Epoch 1097, Train loss: 0.0052768247, Validation loss: 0.0053107956, LR: 0.0001\n",
      "Epoch 1098, Train loss: 0.0052767759, Validation loss: 0.0053108626, LR: 0.0001\n",
      "Epoch 1099, Train loss: 0.0052764632, Validation loss: 0.0053108347, LR: 0.0001\n",
      "Epoch 1100, Train loss: 0.0052768110, Validation loss: 0.0053108172, LR: 0.0001\n",
      "Epoch 1101, Train loss: 0.0052769853, Validation loss: 0.0053107891, LR: 0.0001\n",
      "Epoch 1102, Train loss: 0.0052769028, Validation loss: 0.0053107136, LR: 0.0001\n",
      "Epoch 1103, Train loss: 0.0052763031, Validation loss: 0.0053107342, LR: 0.0001\n",
      "Epoch 1104, Train loss: 0.0052770936, Validation loss: 0.0053106394, LR: 0.0001\n",
      "Epoch 1105, Train loss: 0.0052763943, Validation loss: 0.0053106545, LR: 0.0001\n",
      "Epoch 1106, Train loss: 0.0052765722, Validation loss: 0.0053106087, LR: 0.0001\n",
      "Epoch 1107, Train loss: 0.0052772246, Validation loss: 0.0053110007, LR: 0.0001\n",
      "Epoch 1108, Train loss: 0.0052767315, Validation loss: 0.0053108097, LR: 0.0001\n",
      "Epoch 1109, Train loss: 0.0052773584, Validation loss: 0.0053108481, LR: 0.0001\n",
      "Epoch 1110, Train loss: 0.0052763786, Validation loss: 0.0053110254, LR: 0.0001\n",
      "Epoch 1111, Train loss: 0.0052765283, Validation loss: 0.0053110161, LR: 0.0001\n",
      "Epoch 1112, Train loss: 0.0052766917, Validation loss: 0.0053106626, LR: 0.0001\n",
      "Epoch 1113, Train loss: 0.0052768251, Validation loss: 0.0053104902, LR: 0.0001\n",
      "Epoch 1114, Train loss: 0.0052761759, Validation loss: 0.0053109725, LR: 0.0001\n",
      "Epoch 1115, Train loss: 0.0052767605, Validation loss: 0.0053107948, LR: 0.0001\n",
      "Epoch 1116, Train loss: 0.0052764292, Validation loss: 0.0053108423, LR: 0.0001\n",
      "Epoch 1117, Train loss: 0.0052768355, Validation loss: 0.0053107160, LR: 0.0001\n",
      "Epoch 1118, Train loss: 0.0052767401, Validation loss: 0.0053105892, LR: 0.0001\n",
      "Epoch 1119, Train loss: 0.0052762798, Validation loss: 0.0053106607, LR: 0.0001\n",
      "Epoch 1120, Train loss: 0.0052761469, Validation loss: 0.0053107019, LR: 0.0001\n",
      "Epoch 1121, Train loss: 0.0052764776, Validation loss: 0.0053106820, LR: 0.0001\n",
      "Epoch 1122, Train loss: 0.0052756456, Validation loss: 0.0053109710, LR: 0.0001\n",
      "Epoch 1123, Train loss: 0.0052772050, Validation loss: 0.0053105506, LR: 0.0001\n",
      "Epoch 1124, Train loss: 0.0052771449, Validation loss: 0.0053107756, LR: 0.0001\n",
      "Epoch 1125, Train loss: 0.0052763483, Validation loss: 0.0053105092, LR: 0.0001\n",
      "Epoch 1126, Train loss: 0.0052769184, Validation loss: 0.0053108976, LR: 0.0001\n",
      "Epoch 1127, Train loss: 0.0052766983, Validation loss: 0.0053107514, LR: 0.0001\n",
      "Epoch 1128, Train loss: 0.0052771131, Validation loss: 0.0053105158, LR: 0.0001\n",
      "Epoch 1129, Train loss: 0.0052771090, Validation loss: 0.0053106540, LR: 0.0001\n",
      "Epoch 1130, Train loss: 0.0052759884, Validation loss: 0.0053105204, LR: 0.0001\n",
      "Epoch 1131, Train loss: 0.0052766957, Validation loss: 0.0053105429, LR: 0.0001\n",
      "Epoch 1132, Train loss: 0.0052762454, Validation loss: 0.0053107375, LR: 0.0001\n",
      "Epoch 1133, Train loss: 0.0052769834, Validation loss: 0.0053104549, LR: 0.0001\n",
      "Epoch 1134, Train loss: 0.0052772516, Validation loss: 0.0053106121, LR: 0.0001\n",
      "Epoch 1135, Train loss: 0.0052762000, Validation loss: 0.0053105574, LR: 0.0001\n",
      "Epoch 1136, Train loss: 0.0052762719, Validation loss: 0.0053107689, LR: 0.0001\n",
      "Epoch 1137, Train loss: 0.0052772169, Validation loss: 0.0053105442, LR: 0.0001\n",
      "Epoch 1138, Train loss: 0.0052770221, Validation loss: 0.0053105232, LR: 0.0001\n",
      "Epoch 1139, Train loss: 0.0052762778, Validation loss: 0.0053105788, LR: 0.0001\n",
      "Epoch 1140, Train loss: 0.0052764724, Validation loss: 0.0053104936, LR: 0.0001\n",
      "Epoch 1141, Train loss: 0.0052764735, Validation loss: 0.0053107198, LR: 0.0001\n",
      "Epoch 1142, Train loss: 0.0052765241, Validation loss: 0.0053104042, LR: 0.0001\n",
      "Epoch 1143, Train loss: 0.0052763479, Validation loss: 0.0053108841, LR: 0.0001\n",
      "Epoch 1144, Train loss: 0.0052771427, Validation loss: 0.0053104903, LR: 0.0001\n",
      "Epoch 1145, Train loss: 0.0052765848, Validation loss: 0.0053109890, LR: 0.0001\n",
      "Epoch 1146, Train loss: 0.0052770443, Validation loss: 0.0053103986, LR: 0.0001\n",
      "Epoch 1147, Train loss: 0.0052761538, Validation loss: 0.0053104061, LR: 0.0001\n",
      "Epoch 1148, Train loss: 0.0052762212, Validation loss: 0.0053106614, LR: 0.0001\n",
      "Epoch 1149, Train loss: 0.0052773635, Validation loss: 0.0053103520, LR: 0.0001\n",
      "Epoch 1150, Train loss: 0.0052768658, Validation loss: 0.0053103183, LR: 0.0001\n",
      "Epoch 1151, Train loss: 0.0052765704, Validation loss: 0.0053104639, LR: 0.0001\n",
      "Epoch 1152, Train loss: 0.0052766265, Validation loss: 0.0053107279, LR: 0.0001\n",
      "Epoch 1153, Train loss: 0.0052766370, Validation loss: 0.0053108021, LR: 0.0001\n",
      "Epoch 1154, Train loss: 0.0052758860, Validation loss: 0.0053104360, LR: 0.0001\n",
      "Epoch 1155, Train loss: 0.0052765666, Validation loss: 0.0053104734, LR: 0.0001\n",
      "Epoch 1156, Train loss: 0.0052763371, Validation loss: 0.0053108708, LR: 0.0001\n",
      "Epoch 1157, Train loss: 0.0052761836, Validation loss: 0.0053108443, LR: 0.0001\n",
      "Epoch 1158, Train loss: 0.0052761463, Validation loss: 0.0053104548, LR: 0.0001\n",
      "Epoch 1159, Train loss: 0.0052774071, Validation loss: 0.0053108557, LR: 0.0001\n",
      "Epoch 1160, Train loss: 0.0052769206, Validation loss: 0.0053104531, LR: 0.0001\n",
      "Epoch 1161, Train loss: 0.0052773614, Validation loss: 0.0053106373, LR: 0.0001\n",
      "Epoch 1162, Train loss: 0.0052766743, Validation loss: 0.0053103938, LR: 0.0001\n",
      "Epoch 1163, Train loss: 0.0052772068, Validation loss: 0.0053105144, LR: 0.0001\n",
      "Epoch 1164, Train loss: 0.0052763464, Validation loss: 0.0053105153, LR: 0.0001\n",
      "Epoch 1165, Train loss: 0.0052758864, Validation loss: 0.0053106208, LR: 0.0001\n",
      "Epoch 1166, Train loss: 0.0052767160, Validation loss: 0.0053106704, LR: 0.0001\n",
      "Epoch 1167, Train loss: 0.0052774730, Validation loss: 0.0053103033, LR: 0.0001\n",
      "Epoch 1168, Train loss: 0.0052763113, Validation loss: 0.0053103929, LR: 0.0001\n",
      "Epoch 1169, Train loss: 0.0052763811, Validation loss: 0.0053103828, LR: 0.0001\n",
      "Epoch 1170, Train loss: 0.0052762658, Validation loss: 0.0053106791, LR: 0.0001\n",
      "Epoch 1171, Train loss: 0.0052763928, Validation loss: 0.0053104620, LR: 0.0001\n",
      "Epoch 1172, Train loss: 0.0052772237, Validation loss: 0.0053106610, LR: 0.0001\n",
      "Epoch 1173, Train loss: 0.0052767068, Validation loss: 0.0053104958, LR: 0.0001\n",
      "Epoch 1174, Train loss: 0.0052768059, Validation loss: 0.0053104108, LR: 0.0001\n",
      "Epoch 1175, Train loss: 0.0052758964, Validation loss: 0.0053103783, LR: 0.0001\n",
      "Epoch 1176, Train loss: 0.0052770618, Validation loss: 0.0053105914, LR: 0.0001\n",
      "Epoch 1177, Train loss: 0.0052764258, Validation loss: 0.0053104998, LR: 0.0001\n",
      "Epoch 1178, Train loss: 0.0052761333, Validation loss: 0.0053104557, LR: 0.0001\n",
      "Epoch 1179, Train loss: 0.0052754387, Validation loss: 0.0053104823, LR: 0.0001\n",
      "Epoch 1180, Train loss: 0.0052760286, Validation loss: 0.0053104667, LR: 0.0001\n",
      "Epoch 1181, Train loss: 0.0052766988, Validation loss: 0.0053102193, LR: 0.0001\n",
      "Epoch 1182, Train loss: 0.0052766033, Validation loss: 0.0053103983, LR: 0.0001\n",
      "Epoch 1183, Train loss: 0.0052765513, Validation loss: 0.0053105704, LR: 0.0001\n",
      "Epoch 1184, Train loss: 0.0052767454, Validation loss: 0.0053105907, LR: 0.0001\n",
      "Epoch 1185, Train loss: 0.0052770654, Validation loss: 0.0053104229, LR: 0.0001\n",
      "Epoch 1186, Train loss: 0.0052759250, Validation loss: 0.0053101910, LR: 0.0001\n",
      "Epoch 1187, Train loss: 0.0052769207, Validation loss: 0.0053102971, LR: 0.0001\n",
      "Epoch 1188, Train loss: 0.0052766703, Validation loss: 0.0053103562, LR: 0.0001\n",
      "Epoch 1189, Train loss: 0.0052773651, Validation loss: 0.0053104244, LR: 0.0001\n",
      "Epoch 1190, Train loss: 0.0052760879, Validation loss: 0.0053102097, LR: 0.0001\n",
      "Epoch 1191, Train loss: 0.0052752338, Validation loss: 0.0053106592, LR: 0.0001\n",
      "Epoch 1192, Train loss: 0.0052764912, Validation loss: 0.0053106427, LR: 0.0001\n",
      "Epoch 1193, Train loss: 0.0052764015, Validation loss: 0.0053105250, LR: 0.0001\n",
      "Epoch 1194, Train loss: 0.0052767897, Validation loss: 0.0053102633, LR: 0.0001\n",
      "Epoch 1195, Train loss: 0.0052757790, Validation loss: 0.0053102929, LR: 0.0001\n",
      "Epoch 1196, Train loss: 0.0052763921, Validation loss: 0.0053102207, LR: 0.0001\n",
      "Epoch 1197, Train loss: 0.0052757136, Validation loss: 0.0053104876, LR: 0.0001\n",
      "Epoch 1198, Train loss: 0.0052758572, Validation loss: 0.0053102454, LR: 0.0001\n",
      "Epoch 1199, Train loss: 0.0052769433, Validation loss: 0.0053103520, LR: 0.0001\n",
      "Epoch 1200, Train loss: 0.0052766763, Validation loss: 0.0053103276, LR: 0.0001\n",
      "Epoch 1201, Train loss: 0.0052769220, Validation loss: 0.0053103102, LR: 0.0001\n",
      "Epoch 1202, Train loss: 0.0052765756, Validation loss: 0.0053102221, LR: 0.0001\n",
      "Epoch 1203, Train loss: 0.0052765287, Validation loss: 0.0053104665, LR: 0.0001\n",
      "Epoch 1204, Train loss: 0.0052769028, Validation loss: 0.0053103442, LR: 0.0001\n",
      "Epoch 1205, Train loss: 0.0052768233, Validation loss: 0.0053102956, LR: 0.0001\n",
      "Epoch 1206, Train loss: 0.0052767122, Validation loss: 0.0053105900, LR: 0.0001\n",
      "Epoch 1207, Train loss: 0.0052765571, Validation loss: 0.0053105165, LR: 0.0001\n",
      "Epoch 1208, Train loss: 0.0052772623, Validation loss: 0.0053102656, LR: 0.0001\n",
      "Epoch 1209, Train loss: 0.0052770056, Validation loss: 0.0053101360, LR: 0.0001\n",
      "Epoch 1210, Train loss: 0.0052768550, Validation loss: 0.0053102510, LR: 0.0001\n",
      "Epoch 1211, Train loss: 0.0052767978, Validation loss: 0.0053105309, LR: 0.0001\n",
      "Epoch 1212, Train loss: 0.0052762665, Validation loss: 0.0053108276, LR: 0.0001\n",
      "Epoch 1213, Train loss: 0.0052758059, Validation loss: 0.0053102017, LR: 0.0001\n",
      "Epoch 1214, Train loss: 0.0052766354, Validation loss: 0.0053103575, LR: 0.0001\n",
      "Epoch 1215, Train loss: 0.0052761068, Validation loss: 0.0053104362, LR: 0.0001\n",
      "Epoch 1216, Train loss: 0.0052770819, Validation loss: 0.0053103660, LR: 0.0001\n",
      "Epoch 1217, Train loss: 0.0052761769, Validation loss: 0.0053102132, LR: 0.0001\n",
      "Epoch 1218, Train loss: 0.0052767607, Validation loss: 0.0053102821, LR: 0.0001\n",
      "Epoch 1219, Train loss: 0.0052763438, Validation loss: 0.0053104550, LR: 0.0001\n",
      "Epoch 1220, Train loss: 0.0052760404, Validation loss: 0.0053102231, LR: 0.0001\n",
      "Epoch 1221, Train loss: 0.0052764660, Validation loss: 0.0053102190, LR: 0.0001\n",
      "Epoch 1222, Train loss: 0.0052766119, Validation loss: 0.0053101465, LR: 0.0001\n",
      "Epoch 1223, Train loss: 0.0052757530, Validation loss: 0.0053103115, LR: 0.0001\n",
      "Epoch 1224, Train loss: 0.0052762651, Validation loss: 0.0053100923, LR: 0.0001\n",
      "Epoch 1225, Train loss: 0.0052757799, Validation loss: 0.0053101743, LR: 0.0001\n",
      "Epoch 1226, Train loss: 0.0052759746, Validation loss: 0.0053103852, LR: 0.0001\n",
      "Epoch 1227, Train loss: 0.0052753674, Validation loss: 0.0053100401, LR: 0.0001\n",
      "Epoch 1228, Train loss: 0.0052758167, Validation loss: 0.0053102376, LR: 0.0001\n",
      "Epoch 1229, Train loss: 0.0052764361, Validation loss: 0.0053104429, LR: 0.0001\n",
      "Epoch 1230, Train loss: 0.0052767200, Validation loss: 0.0053101221, LR: 0.0001\n",
      "Epoch 1231, Train loss: 0.0052766076, Validation loss: 0.0053101479, LR: 0.0001\n",
      "Epoch 1232, Train loss: 0.0052764973, Validation loss: 0.0053102429, LR: 0.0001\n",
      "Epoch 1233, Train loss: 0.0052760323, Validation loss: 0.0053101031, LR: 0.0001\n",
      "Epoch 1234, Train loss: 0.0052764664, Validation loss: 0.0053101717, LR: 0.0001\n",
      "Epoch 1235, Train loss: 0.0052762249, Validation loss: 0.0053100417, LR: 0.0001\n",
      "Epoch 1236, Train loss: 0.0052765041, Validation loss: 0.0053103385, LR: 0.0001\n",
      "Epoch 1237, Train loss: 0.0052758254, Validation loss: 0.0053103700, LR: 0.0001\n",
      "Epoch 1238, Train loss: 0.0052764190, Validation loss: 0.0053101324, LR: 0.0001\n",
      "Epoch 1239, Train loss: 0.0052764352, Validation loss: 0.0053103692, LR: 0.0001\n",
      "Epoch 1240, Train loss: 0.0052773686, Validation loss: 0.0053104125, LR: 0.0001\n",
      "Epoch 1241, Train loss: 0.0052764836, Validation loss: 0.0053101834, LR: 0.0001\n",
      "Epoch 1242, Train loss: 0.0052761491, Validation loss: 0.0053100453, LR: 0.0001\n",
      "Epoch 1243, Train loss: 0.0052769498, Validation loss: 0.0053102529, LR: 0.0001\n",
      "Epoch 1244, Train loss: 0.0052763798, Validation loss: 0.0053101396, LR: 0.0001\n",
      "Epoch 1245, Train loss: 0.0052772022, Validation loss: 0.0053102090, LR: 0.0001\n",
      "Epoch 1246, Train loss: 0.0052773006, Validation loss: 0.0053102525, LR: 0.0001\n",
      "Epoch 1247, Train loss: 0.0052766563, Validation loss: 0.0053101722, LR: 0.0001\n",
      "Epoch 1248, Train loss: 0.0052759256, Validation loss: 0.0053100417, LR: 0.0001\n",
      "Epoch 1249, Train loss: 0.0052765685, Validation loss: 0.0053101408, LR: 0.0001\n",
      "Epoch 1250, Train loss: 0.0052762686, Validation loss: 0.0053101228, LR: 0.0001\n",
      "Epoch 1251, Train loss: 0.0052761750, Validation loss: 0.0053102052, LR: 0.0001\n",
      "Epoch 1252, Train loss: 0.0052768952, Validation loss: 0.0053100191, LR: 0.0001\n",
      "Epoch 1253, Train loss: 0.0052761254, Validation loss: 0.0053101373, LR: 0.0001\n",
      "Epoch 1254, Train loss: 0.0052767383, Validation loss: 0.0053099403, LR: 0.0001\n",
      "Epoch 1255, Train loss: 0.0052761948, Validation loss: 0.0053103776, LR: 0.0001\n",
      "Epoch 1256, Train loss: 0.0052754442, Validation loss: 0.0053101909, LR: 0.0001\n",
      "Epoch 1257, Train loss: 0.0052758435, Validation loss: 0.0053101341, LR: 0.0001\n",
      "Epoch 1258, Train loss: 0.0052768666, Validation loss: 0.0053101064, LR: 0.0001\n",
      "Epoch 1259, Train loss: 0.0052766683, Validation loss: 0.0053101618, LR: 0.0001\n",
      "Epoch 1260, Train loss: 0.0052766069, Validation loss: 0.0053100949, LR: 0.0001\n",
      "Epoch 1261, Train loss: 0.0052757502, Validation loss: 0.0053102333, LR: 0.0001\n",
      "Epoch 1262, Train loss: 0.0052767627, Validation loss: 0.0053100553, LR: 0.0001\n",
      "Epoch 1263, Train loss: 0.0052762067, Validation loss: 0.0053101180, LR: 0.0001\n",
      "Epoch 1264, Train loss: 0.0052764648, Validation loss: 0.0053101233, LR: 0.0001\n",
      "Epoch 1265, Train loss: 0.0052767955, Validation loss: 0.0053101277, LR: 0.0001\n",
      "Epoch 1266, Train loss: 0.0052768577, Validation loss: 0.0053101567, LR: 0.0001\n",
      "Epoch 1267, Train loss: 0.0052758561, Validation loss: 0.0053101877, LR: 0.0001\n",
      "Epoch 1268, Train loss: 0.0052760680, Validation loss: 0.0053101368, LR: 0.0001\n",
      "Epoch 1269, Train loss: 0.0052764893, Validation loss: 0.0053107026, LR: 0.0001\n",
      "Epoch 1270, Train loss: 0.0052769115, Validation loss: 0.0053100331, LR: 0.0001\n",
      "Epoch 1271, Train loss: 0.0052758014, Validation loss: 0.0053102266, LR: 0.0001\n",
      "Epoch 1272, Train loss: 0.0052758912, Validation loss: 0.0053100075, LR: 0.0001\n",
      "Epoch 1273, Train loss: 0.0052760848, Validation loss: 0.0053105428, LR: 0.0001\n",
      "Epoch 1274, Train loss: 0.0052764673, Validation loss: 0.0053099048, LR: 0.0001\n",
      "Epoch 1275, Train loss: 0.0052760765, Validation loss: 0.0053098797, LR: 0.0001\n",
      "Epoch 1276, Train loss: 0.0052761740, Validation loss: 0.0053101109, LR: 0.0001\n",
      "Epoch 1277, Train loss: 0.0052764028, Validation loss: 0.0053099984, LR: 0.0001\n",
      "Epoch 1278, Train loss: 0.0052761721, Validation loss: 0.0053101768, LR: 0.0001\n",
      "Epoch 1279, Train loss: 0.0052770746, Validation loss: 0.0053098571, LR: 0.0001\n",
      "Epoch 1280, Train loss: 0.0052761388, Validation loss: 0.0053097849, LR: 0.0001\n",
      "Epoch 1281, Train loss: 0.0052766783, Validation loss: 0.0053100249, LR: 0.0001\n",
      "Epoch 1282, Train loss: 0.0052765998, Validation loss: 0.0053101671, LR: 0.0001\n",
      "Epoch 1283, Train loss: 0.0052765998, Validation loss: 0.0053100908, LR: 0.0001\n",
      "Epoch 1284, Train loss: 0.0052766559, Validation loss: 0.0053099064, LR: 0.0001\n",
      "Epoch 1285, Train loss: 0.0052765321, Validation loss: 0.0053102582, LR: 0.0001\n",
      "Epoch 1286, Train loss: 0.0052766595, Validation loss: 0.0053099826, LR: 0.0001\n",
      "Epoch 1287, Train loss: 0.0052768404, Validation loss: 0.0053102736, LR: 0.0001\n",
      "Epoch 1288, Train loss: 0.0052755619, Validation loss: 0.0053099561, LR: 0.0001\n",
      "Epoch 1289, Train loss: 0.0052761015, Validation loss: 0.0053101460, LR: 0.0001\n",
      "Epoch 1290, Train loss: 0.0052758533, Validation loss: 0.0053100399, LR: 0.0001\n",
      "Epoch 1291, Train loss: 0.0052762637, Validation loss: 0.0053099975, LR: 0.0001\n",
      "Epoch 1292, Train loss: 0.0052762682, Validation loss: 0.0053100546, LR: 0.0001\n",
      "Epoch 1293, Train loss: 0.0052761718, Validation loss: 0.0053099738, LR: 0.0001\n",
      "Epoch 1294, Train loss: 0.0052758043, Validation loss: 0.0053100423, LR: 0.0001\n",
      "Epoch 1295, Train loss: 0.0052763155, Validation loss: 0.0053103155, LR: 0.0001\n",
      "Epoch 1296, Train loss: 0.0052759872, Validation loss: 0.0053099564, LR: 0.0001\n",
      "Epoch 1297, Train loss: 0.0052757728, Validation loss: 0.0053099306, LR: 0.0001\n",
      "Epoch 1298, Train loss: 0.0052758002, Validation loss: 0.0053100810, LR: 0.0001\n",
      "Epoch 1299, Train loss: 0.0052761171, Validation loss: 0.0053101361, LR: 0.0001\n",
      "Epoch 1300, Train loss: 0.0052769640, Validation loss: 0.0053099045, LR: 0.0001\n",
      "Epoch 1301, Train loss: 0.0052756939, Validation loss: 0.0053098822, LR: 0.0001\n",
      "Epoch 1302, Train loss: 0.0052761224, Validation loss: 0.0053099431, LR: 0.0001\n",
      "Epoch 1303, Train loss: 0.0052766724, Validation loss: 0.0053097415, LR: 0.0001\n",
      "Epoch 1304, Train loss: 0.0052762273, Validation loss: 0.0053101278, LR: 0.0001\n",
      "Epoch 1305, Train loss: 0.0052764879, Validation loss: 0.0053099292, LR: 0.0001\n",
      "Epoch 1306, Train loss: 0.0052759708, Validation loss: 0.0053101024, LR: 0.0001\n",
      "Epoch 1307, Train loss: 0.0052755686, Validation loss: 0.0053098143, LR: 0.0001\n",
      "Epoch 1308, Train loss: 0.0052762728, Validation loss: 0.0053099125, LR: 0.0001\n",
      "Epoch 1309, Train loss: 0.0052767918, Validation loss: 0.0053099296, LR: 0.0001\n",
      "Epoch 1310, Train loss: 0.0052767457, Validation loss: 0.0053100698, LR: 0.0001\n",
      "Epoch 1311, Train loss: 0.0052760621, Validation loss: 0.0053098707, LR: 0.0001\n",
      "Epoch 1312, Train loss: 0.0052758432, Validation loss: 0.0053099286, LR: 0.0001\n",
      "Epoch 1313, Train loss: 0.0052756778, Validation loss: 0.0053100716, LR: 0.0001\n",
      "Epoch 1314, Train loss: 0.0052766938, Validation loss: 0.0053099921, LR: 0.0001\n",
      "Epoch 1315, Train loss: 0.0052761458, Validation loss: 0.0053100976, LR: 0.0001\n",
      "Epoch 1316, Train loss: 0.0052758712, Validation loss: 0.0053099318, LR: 0.0001\n",
      "Epoch 1317, Train loss: 0.0052763994, Validation loss: 0.0053099341, LR: 0.0001\n",
      "Epoch 1318, Train loss: 0.0052770162, Validation loss: 0.0053099834, LR: 0.0001\n",
      "Epoch 1319, Train loss: 0.0052754974, Validation loss: 0.0053098552, LR: 0.0001\n",
      "Epoch 1320, Train loss: 0.0052765355, Validation loss: 0.0053100711, LR: 0.0001\n",
      "Epoch 1321, Train loss: 0.0052769628, Validation loss: 0.0053097557, LR: 0.0001\n",
      "Epoch 1322, Train loss: 0.0052758365, Validation loss: 0.0053099533, LR: 0.0001\n",
      "Epoch 1323, Train loss: 0.0052762895, Validation loss: 0.0053097488, LR: 0.0001\n",
      "Epoch 1324, Train loss: 0.0052761140, Validation loss: 0.0053098385, LR: 0.0001\n",
      "Epoch 1325, Train loss: 0.0052762650, Validation loss: 0.0053098981, LR: 0.0001\n",
      "Epoch 1326, Train loss: 0.0052772053, Validation loss: 0.0053098698, LR: 0.0001\n",
      "Epoch 1327, Train loss: 0.0052754863, Validation loss: 0.0053100640, LR: 0.0001\n",
      "Epoch 1328, Train loss: 0.0052760805, Validation loss: 0.0053099571, LR: 0.0001\n",
      "Epoch 1329, Train loss: 0.0052754074, Validation loss: 0.0053099099, LR: 0.0001\n",
      "Epoch 1330, Train loss: 0.0052765865, Validation loss: 0.0053098176, LR: 0.0001\n",
      "Epoch 1331, Train loss: 0.0052760724, Validation loss: 0.0053101218, LR: 0.0001\n",
      "Epoch 1332, Train loss: 0.0052763696, Validation loss: 0.0053099376, LR: 0.0001\n",
      "Epoch 1333, Train loss: 0.0052761780, Validation loss: 0.0053097424, LR: 0.0001\n",
      "Epoch 1334, Train loss: 0.0052761441, Validation loss: 0.0053097059, LR: 0.0001\n",
      "Epoch 1335, Train loss: 0.0052761780, Validation loss: 0.0053099573, LR: 0.0001\n",
      "Epoch 1336, Train loss: 0.0052768384, Validation loss: 0.0053098701, LR: 0.0001\n",
      "Epoch 1337, Train loss: 0.0052761228, Validation loss: 0.0053099226, LR: 0.0001\n",
      "Epoch 1338, Train loss: 0.0052760942, Validation loss: 0.0053100662, LR: 0.0001\n",
      "Epoch 1339, Train loss: 0.0052763733, Validation loss: 0.0053102802, LR: 0.0001\n",
      "Epoch 1340, Train loss: 0.0052766852, Validation loss: 0.0053098945, LR: 0.0001\n",
      "Epoch 1341, Train loss: 0.0052754692, Validation loss: 0.0053098867, LR: 0.0001\n",
      "Epoch 1342, Train loss: 0.0052762976, Validation loss: 0.0053100675, LR: 0.0001\n",
      "Epoch 1343, Train loss: 0.0052764882, Validation loss: 0.0053098591, LR: 0.0001\n",
      "Epoch 1344, Train loss: 0.0052758087, Validation loss: 0.0053097608, LR: 0.0001\n",
      "Epoch 1345, Train loss: 0.0052764640, Validation loss: 0.0053102441, LR: 0.0001\n",
      "Epoch 1346, Train loss: 0.0052758815, Validation loss: 0.0053097982, LR: 0.0001\n",
      "Epoch 1347, Train loss: 0.0052760445, Validation loss: 0.0053099642, LR: 0.0001\n",
      "Epoch 1348, Train loss: 0.0052763582, Validation loss: 0.0053100964, LR: 0.0001\n",
      "Epoch 1349, Train loss: 0.0052763784, Validation loss: 0.0053097307, LR: 0.0001\n",
      "Epoch 1350, Train loss: 0.0052760655, Validation loss: 0.0053097695, LR: 0.0001\n",
      "Epoch 1351, Train loss: 0.0052757523, Validation loss: 0.0053103129, LR: 0.0001\n",
      "Epoch 1352, Train loss: 0.0052766131, Validation loss: 0.0053098844, LR: 0.0001\n",
      "Epoch 1353, Train loss: 0.0052761667, Validation loss: 0.0053097442, LR: 0.0001\n",
      "Epoch 1354, Train loss: 0.0052761418, Validation loss: 0.0053098411, LR: 0.0001\n",
      "Epoch 1355, Train loss: 0.0052768904, Validation loss: 0.0053099862, LR: 0.0001\n",
      "Epoch 1356, Train loss: 0.0052757177, Validation loss: 0.0053100550, LR: 0.0001\n",
      "Epoch 1357, Train loss: 0.0052763739, Validation loss: 0.0053099463, LR: 0.0001\n",
      "Epoch 1358, Train loss: 0.0052761423, Validation loss: 0.0053099448, LR: 0.0001\n",
      "Epoch 1359, Train loss: 0.0052759127, Validation loss: 0.0053099266, LR: 0.0001\n",
      "Epoch 1360, Train loss: 0.0052761548, Validation loss: 0.0053097176, LR: 0.0001\n",
      "Epoch 1361, Train loss: 0.0052762048, Validation loss: 0.0053096825, LR: 0.0001\n",
      "Epoch 1362, Train loss: 0.0052765991, Validation loss: 0.0053097350, LR: 0.0001\n",
      "Epoch 1363, Train loss: 0.0052759201, Validation loss: 0.0053100683, LR: 0.0001\n",
      "Epoch 1364, Train loss: 0.0052757145, Validation loss: 0.0053099753, LR: 0.0001\n",
      "Epoch 1365, Train loss: 0.0052764385, Validation loss: 0.0053098066, LR: 0.0001\n",
      "Epoch 1366, Train loss: 0.0052758191, Validation loss: 0.0053096677, LR: 0.0001\n",
      "Epoch 1367, Train loss: 0.0052759225, Validation loss: 0.0053101020, LR: 0.0001\n",
      "Epoch 1368, Train loss: 0.0052764903, Validation loss: 0.0053099106, LR: 0.0001\n",
      "Epoch 1369, Train loss: 0.0052758811, Validation loss: 0.0053097352, LR: 0.0001\n",
      "Epoch 1370, Train loss: 0.0052765607, Validation loss: 0.0053096515, LR: 0.0001\n",
      "Epoch 1371, Train loss: 0.0052764802, Validation loss: 0.0053095447, LR: 0.0001\n",
      "Epoch 1372, Train loss: 0.0052755283, Validation loss: 0.0053098023, LR: 0.0001\n",
      "Epoch 1373, Train loss: 0.0052764938, Validation loss: 0.0053097030, LR: 0.0001\n",
      "Epoch 1374, Train loss: 0.0052760506, Validation loss: 0.0053099187, LR: 0.0001\n",
      "Epoch 1375, Train loss: 0.0052760250, Validation loss: 0.0053096449, LR: 0.0001\n",
      "Epoch 1376, Train loss: 0.0052760457, Validation loss: 0.0053099018, LR: 0.0001\n",
      "Epoch 1377, Train loss: 0.0052763283, Validation loss: 0.0053098426, LR: 0.0001\n",
      "Epoch 1378, Train loss: 0.0052759533, Validation loss: 0.0053096244, LR: 0.0001\n",
      "Epoch 1379, Train loss: 0.0052763046, Validation loss: 0.0053096671, LR: 0.0001\n",
      "Epoch 1380, Train loss: 0.0052761253, Validation loss: 0.0053100796, LR: 0.0001\n",
      "Epoch 1381, Train loss: 0.0052756821, Validation loss: 0.0053101121, LR: 0.0001\n",
      "Epoch 1382, Train loss: 0.0052765966, Validation loss: 0.0053097347, LR: 0.0001\n",
      "Epoch 1383, Train loss: 0.0052755903, Validation loss: 0.0053097899, LR: 0.0001\n",
      "Epoch 1384, Train loss: 0.0052756435, Validation loss: 0.0053098078, LR: 0.0001\n",
      "Epoch 1385, Train loss: 0.0052766937, Validation loss: 0.0053097383, LR: 0.0001\n",
      "Epoch 1386, Train loss: 0.0052760658, Validation loss: 0.0053096458, LR: 0.0001\n",
      "Epoch 1387, Train loss: 0.0052758006, Validation loss: 0.0053095565, LR: 0.0001\n",
      "Epoch 1388, Train loss: 0.0052754593, Validation loss: 0.0053096733, LR: 0.0001\n",
      "Epoch 1389, Train loss: 0.0052761174, Validation loss: 0.0053096882, LR: 0.0001\n",
      "Epoch 1390, Train loss: 0.0052768556, Validation loss: 0.0053096755, LR: 0.0001\n",
      "Epoch 1391, Train loss: 0.0052755257, Validation loss: 0.0053102265, LR: 0.0001\n",
      "Epoch 1392, Train loss: 0.0052756930, Validation loss: 0.0053097940, LR: 0.0001\n",
      "Epoch 1393, Train loss: 0.0052761173, Validation loss: 0.0053096344, LR: 0.0001\n",
      "Epoch 1394, Train loss: 0.0052756201, Validation loss: 0.0053096685, LR: 0.0001\n",
      "Epoch 1395, Train loss: 0.0052763177, Validation loss: 0.0053095279, LR: 0.0001\n",
      "Epoch 1396, Train loss: 0.0052765264, Validation loss: 0.0053096658, LR: 0.0001\n",
      "Epoch 1397, Train loss: 0.0052769773, Validation loss: 0.0053099879, LR: 0.0001\n",
      "Epoch 1398, Train loss: 0.0052760542, Validation loss: 0.0053096151, LR: 0.0001\n",
      "Epoch 1399, Train loss: 0.0052756005, Validation loss: 0.0053095372, LR: 0.0001\n",
      "Epoch 1400, Train loss: 0.0052760856, Validation loss: 0.0053097934, LR: 0.0001\n",
      "Epoch 1401, Train loss: 0.0052762332, Validation loss: 0.0053096227, LR: 0.0001\n",
      "Epoch 1402, Train loss: 0.0052749546, Validation loss: 0.0053098950, LR: 0.0001\n",
      "Epoch 1403, Train loss: 0.0052754487, Validation loss: 0.0053095820, LR: 0.0001\n",
      "Epoch 1404, Train loss: 0.0052761649, Validation loss: 0.0053097499, LR: 0.0001\n",
      "Epoch 1405, Train loss: 0.0052760684, Validation loss: 0.0053096971, LR: 1e-05\n",
      "Epoch 1406, Train loss: 0.0052751084, Validation loss: 0.0053090192, LR: 1e-05\n",
      "Epoch 1407, Train loss: 0.0052754467, Validation loss: 0.0053089898, LR: 1e-05\n",
      "Epoch 1408, Train loss: 0.0052754202, Validation loss: 0.0053089890, LR: 1e-05\n",
      "Epoch 1409, Train loss: 0.0052756573, Validation loss: 0.0053089944, LR: 1e-05\n",
      "Epoch 1410, Train loss: 0.0052754345, Validation loss: 0.0053089956, LR: 1e-05\n",
      "Epoch 1411, Train loss: 0.0052755651, Validation loss: 0.0053089981, LR: 1e-05\n",
      "Epoch 1412, Train loss: 0.0052747279, Validation loss: 0.0053090200, LR: 1e-05\n",
      "Epoch 1413, Train loss: 0.0052751087, Validation loss: 0.0053090007, LR: 1e-05\n",
      "Epoch 1414, Train loss: 0.0052747041, Validation loss: 0.0053090064, LR: 1e-05\n",
      "Epoch 1415, Train loss: 0.0052755089, Validation loss: 0.0053089911, LR: 1e-05\n",
      "Epoch 1416, Train loss: 0.0052748305, Validation loss: 0.0053089914, LR: 1e-05\n",
      "Epoch 1417, Train loss: 0.0052755806, Validation loss: 0.0053090181, LR: 1e-05\n",
      "Epoch 1418, Train loss: 0.0052753718, Validation loss: 0.0053089896, LR: 1e-05\n",
      "Epoch 1419, Train loss: 0.0052749007, Validation loss: 0.0053090207, LR: 1e-05\n",
      "Epoch 1420, Train loss: 0.0052751267, Validation loss: 0.0053090316, LR: 1e-05\n",
      "Epoch 1421, Train loss: 0.0052752736, Validation loss: 0.0053090036, LR: 1e-05\n",
      "Epoch 1422, Train loss: 0.0052756009, Validation loss: 0.0053090219, LR: 1e-05\n",
      "Epoch 1423, Train loss: 0.0052749726, Validation loss: 0.0053090419, LR: 1e-05\n",
      "Epoch 1424, Train loss: 0.0052752614, Validation loss: 0.0053090095, LR: 1e-05\n",
      "Epoch 1425, Train loss: 0.0052750802, Validation loss: 0.0053090184, LR: 1e-05\n",
      "Epoch 1426, Train loss: 0.0052748324, Validation loss: 0.0053089991, LR: 1e-05\n",
      "Epoch 1427, Train loss: 0.0052747995, Validation loss: 0.0053090370, LR: 1e-05\n",
      "Epoch 1428, Train loss: 0.0052754964, Validation loss: 0.0053090353, LR: 1e-05\n",
      "Epoch 1429, Train loss: 0.0052751498, Validation loss: 0.0053090154, LR: 1e-05\n",
      "Epoch 1430, Train loss: 0.0052745196, Validation loss: 0.0053090479, LR: 1e-05\n",
      "Epoch 1431, Train loss: 0.0052755259, Validation loss: 0.0053090447, LR: 1e-05\n",
      "Epoch 1432, Train loss: 0.0052755530, Validation loss: 0.0053090674, LR: 1e-05\n",
      "Epoch 1433, Train loss: 0.0052752716, Validation loss: 0.0053090162, LR: 1e-05\n",
      "Epoch 1434, Train loss: 0.0052752986, Validation loss: 0.0053090958, LR: 1e-05\n",
      "Epoch 1435, Train loss: 0.0052749314, Validation loss: 0.0053090383, LR: 1e-05\n",
      "Epoch 1436, Train loss: 0.0052750961, Validation loss: 0.0053090246, LR: 1e-05\n",
      "Epoch 1437, Train loss: 0.0052745079, Validation loss: 0.0053090257, LR: 1e-05\n",
      "Epoch 1438, Train loss: 0.0052754677, Validation loss: 0.0053090522, LR: 1e-05\n",
      "Epoch 1439, Train loss: 0.0052752273, Validation loss: 0.0053090404, LR: 1e-05\n",
      "Epoch 1440, Train loss: 0.0052749428, Validation loss: 0.0053090469, LR: 1e-05\n",
      "Epoch 1441, Train loss: 0.0052753271, Validation loss: 0.0053090687, LR: 1e-05\n",
      "Epoch 1442, Train loss: 0.0052753953, Validation loss: 0.0053090463, LR: 1e-05\n",
      "Epoch 1443, Train loss: 0.0052752403, Validation loss: 0.0053090537, LR: 1e-05\n",
      "Epoch 1444, Train loss: 0.0052760395, Validation loss: 0.0053090528, LR: 1e-05\n",
      "Epoch 1445, Train loss: 0.0052752565, Validation loss: 0.0053090281, LR: 1e-05\n",
      "Epoch 1446, Train loss: 0.0052749098, Validation loss: 0.0053090348, LR: 1e-05\n",
      "Epoch 1447, Train loss: 0.0052752559, Validation loss: 0.0053090421, LR: 1e-05\n",
      "Epoch 1448, Train loss: 0.0052757713, Validation loss: 0.0053090520, LR: 1e-05\n",
      "Epoch 1449, Train loss: 0.0052751300, Validation loss: 0.0053090778, LR: 1e-05\n",
      "Epoch 1450, Train loss: 0.0052763471, Validation loss: 0.0053090613, LR: 1e-05\n",
      "Epoch 1451, Train loss: 0.0052754642, Validation loss: 0.0053090480, LR: 1e-05\n",
      "Epoch 1452, Train loss: 0.0052757120, Validation loss: 0.0053090419, LR: 1e-05\n",
      "Epoch 1453, Train loss: 0.0052752475, Validation loss: 0.0053090693, LR: 1e-05\n",
      "Epoch 1454, Train loss: 0.0052753624, Validation loss: 0.0053090743, LR: 1e-05\n",
      "Epoch 1455, Train loss: 0.0052750020, Validation loss: 0.0053090547, LR: 1e-05\n",
      "Epoch 1456, Train loss: 0.0052754519, Validation loss: 0.0053090686, LR: 1e-05\n",
      "Epoch 1457, Train loss: 0.0052755404, Validation loss: 0.0053090246, LR: 1e-05\n",
      "Epoch 1458, Train loss: 0.0052748849, Validation loss: 0.0053090573, LR: 1e-05\n",
      "Epoch 1459, Train loss: 0.0052750456, Validation loss: 0.0053090813, LR: 1e-05\n",
      "Epoch 1460, Train loss: 0.0052751946, Validation loss: 0.0053090670, LR: 1e-05\n",
      "Epoch 1461, Train loss: 0.0052761334, Validation loss: 0.0053090395, LR: 1e-05\n",
      "Epoch 1462, Train loss: 0.0052753751, Validation loss: 0.0053090731, LR: 1e-05\n",
      "Epoch 1463, Train loss: 0.0052757674, Validation loss: 0.0053090746, LR: 1e-05\n",
      "Epoch 1464, Train loss: 0.0052753245, Validation loss: 0.0053090620, LR: 1e-05\n",
      "Epoch 1465, Train loss: 0.0052747126, Validation loss: 0.0053090674, LR: 1e-05\n",
      "Epoch 1466, Train loss: 0.0052752072, Validation loss: 0.0053090369, LR: 1e-05\n",
      "Epoch 1467, Train loss: 0.0052742009, Validation loss: 0.0053090783, LR: 1e-05\n",
      "Epoch 1468, Train loss: 0.0052746369, Validation loss: 0.0053090333, LR: 1e-05\n",
      "Epoch 1469, Train loss: 0.0052748498, Validation loss: 0.0053090734, LR: 1e-05\n",
      "Epoch 1470, Train loss: 0.0052750524, Validation loss: 0.0053090623, LR: 1e-05\n",
      "Epoch 1471, Train loss: 0.0052757499, Validation loss: 0.0053091014, LR: 1e-05\n",
      "Epoch 1472, Train loss: 0.0052750751, Validation loss: 0.0053090826, LR: 1e-05\n",
      "Epoch 1473, Train loss: 0.0052754355, Validation loss: 0.0053090787, LR: 1e-05\n",
      "Epoch 1474, Train loss: 0.0052753305, Validation loss: 0.0053090898, LR: 1e-05\n",
      "Epoch 1475, Train loss: 0.0052755344, Validation loss: 0.0053090797, LR: 1e-05\n",
      "Epoch 1476, Train loss: 0.0052750386, Validation loss: 0.0053090783, LR: 1e-05\n",
      "Epoch 1477, Train loss: 0.0052755424, Validation loss: 0.0053090850, LR: 1e-05\n",
      "Epoch 1478, Train loss: 0.0052754609, Validation loss: 0.0053090614, LR: 1e-05\n",
      "Epoch 1479, Train loss: 0.0052751426, Validation loss: 0.0053090739, LR: 1e-05\n",
      "Epoch 1480, Train loss: 0.0052754369, Validation loss: 0.0053091049, LR: 1e-05\n",
      "Epoch 1481, Train loss: 0.0052753975, Validation loss: 0.0053091330, LR: 1e-05\n",
      "Epoch 1482, Train loss: 0.0052753831, Validation loss: 0.0053090766, LR: 1e-05\n",
      "Epoch 1483, Train loss: 0.0052745767, Validation loss: 0.0053090398, LR: 1e-05\n",
      "Epoch 1484, Train loss: 0.0052756852, Validation loss: 0.0053090550, LR: 1e-05\n",
      "Epoch 1485, Train loss: 0.0052758617, Validation loss: 0.0053090707, LR: 1e-05\n",
      "Epoch 1486, Train loss: 0.0052750254, Validation loss: 0.0053090854, LR: 1e-05\n",
      "Epoch 1487, Train loss: 0.0052755891, Validation loss: 0.0053090692, LR: 1e-05\n",
      "Epoch 1488, Train loss: 0.0052750221, Validation loss: 0.0053090661, LR: 1e-05\n",
      "Epoch 1489, Train loss: 0.0052746984, Validation loss: 0.0053090740, LR: 1e-05\n",
      "Epoch 1490, Train loss: 0.0052756097, Validation loss: 0.0053091318, LR: 1e-05\n",
      "Epoch 1491, Train loss: 0.0052755060, Validation loss: 0.0053090627, LR: 1e-05\n",
      "Epoch 1492, Train loss: 0.0052745345, Validation loss: 0.0053090587, LR: 1e-05\n",
      "Epoch 1493, Train loss: 0.0052747425, Validation loss: 0.0053090803, LR: 1e-05\n",
      "Epoch 1494, Train loss: 0.0052745972, Validation loss: 0.0053090514, LR: 1e-05\n",
      "Epoch 1495, Train loss: 0.0052759708, Validation loss: 0.0053090573, LR: 1e-05\n",
      "Epoch 1496, Train loss: 0.0052753423, Validation loss: 0.0053091314, LR: 1e-05\n",
      "Epoch 1497, Train loss: 0.0052749305, Validation loss: 0.0053090696, LR: 1e-05\n",
      "Epoch 1498, Train loss: 0.0052741439, Validation loss: 0.0053091249, LR: 1e-05\n",
      "Epoch 1499, Train loss: 0.0052753604, Validation loss: 0.0053090580, LR: 1e-05\n",
      "Epoch 1500, Train loss: 0.0052755744, Validation loss: 0.0053090669, LR: 1e-05\n",
      "Epoch 1501, Train loss: 0.0052755556, Validation loss: 0.0053090864, LR: 1e-05\n",
      "Epoch 1502, Train loss: 0.0052753118, Validation loss: 0.0053090790, LR: 1e-05\n",
      "Epoch 1503, Train loss: 0.0052752536, Validation loss: 0.0053090662, LR: 1e-05\n",
      "Epoch 1504, Train loss: 0.0052753411, Validation loss: 0.0053090967, LR: 1e-05\n",
      "Epoch 1505, Train loss: 0.0052749656, Validation loss: 0.0053090607, LR: 1e-05\n",
      "Epoch 1506, Train loss: 0.0052753795, Validation loss: 0.0053090923, LR: 1e-05\n",
      "Epoch 1507, Train loss: 0.0052749097, Validation loss: 0.0053090910, LR: 1e-05\n",
      "Epoch 1508, Train loss: 0.0052758062, Validation loss: 0.0053090864, LR: 1e-05\n",
      "Early stopping on epoch 1508\n",
      "Test Error: \n",
      " Avg loss: 0.005309 \n",
      "\n",
      "Epoch 1, Train loss: 0.0052980695, Validation loss: 0.0053177949, LR: 1e-05\n",
      "Epoch 2, Train loss: 0.0052971816, Validation loss: 0.0053172523, LR: 1e-05\n",
      "Epoch 3, Train loss: 0.0052965211, Validation loss: 0.0053169381, LR: 1e-05\n",
      "Epoch 4, Train loss: 0.0052951268, Validation loss: 0.0053165126, LR: 1e-05\n",
      "Epoch 5, Train loss: 0.0052948863, Validation loss: 0.0053163185, LR: 1e-05\n",
      "Epoch 6, Train loss: 0.0052934812, Validation loss: 0.0053162453, LR: 1e-05\n",
      "Epoch 7, Train loss: 0.0052937446, Validation loss: 0.0053161646, LR: 1e-05\n",
      "Epoch 8, Train loss: 0.0052935446, Validation loss: 0.0053160641, LR: 1e-05\n",
      "Epoch 9, Train loss: 0.0052927465, Validation loss: 0.0053159140, LR: 1e-05\n",
      "Epoch 10, Train loss: 0.0052927935, Validation loss: 0.0053158962, LR: 1e-05\n",
      "Epoch 11, Train loss: 0.0052932006, Validation loss: 0.0053158455, LR: 1e-05\n",
      "Epoch 12, Train loss: 0.0052919125, Validation loss: 0.0053155831, LR: 1e-05\n",
      "Epoch 13, Train loss: 0.0052919845, Validation loss: 0.0053155409, LR: 1e-05\n",
      "Epoch 14, Train loss: 0.0052917408, Validation loss: 0.0053155915, LR: 1e-05\n",
      "Epoch 15, Train loss: 0.0052914735, Validation loss: 0.0053154911, LR: 1e-05\n",
      "Epoch 16, Train loss: 0.0052919490, Validation loss: 0.0053153955, LR: 1e-05\n",
      "Epoch 17, Train loss: 0.0052913503, Validation loss: 0.0053153848, LR: 1e-05\n",
      "Epoch 18, Train loss: 0.0052911540, Validation loss: 0.0053153478, LR: 1e-05\n",
      "Epoch 19, Train loss: 0.0052905134, Validation loss: 0.0053152496, LR: 1e-05\n",
      "Epoch 20, Train loss: 0.0052909988, Validation loss: 0.0053150972, LR: 1e-05\n",
      "Epoch 21, Train loss: 0.0052912338, Validation loss: 0.0053151199, LR: 1e-05\n",
      "Epoch 22, Train loss: 0.0052905639, Validation loss: 0.0053151336, LR: 1e-05\n",
      "Epoch 23, Train loss: 0.0052892670, Validation loss: 0.0053151805, LR: 1e-05\n",
      "Epoch 24, Train loss: 0.0052904629, Validation loss: 0.0053150576, LR: 1e-05\n",
      "Epoch 25, Train loss: 0.0052897220, Validation loss: 0.0053149287, LR: 1e-05\n",
      "Epoch 26, Train loss: 0.0052905045, Validation loss: 0.0053149593, LR: 1e-05\n",
      "Epoch 27, Train loss: 0.0052892304, Validation loss: 0.0053148862, LR: 1e-05\n",
      "Epoch 28, Train loss: 0.0052892179, Validation loss: 0.0053149350, LR: 1e-05\n",
      "Epoch 29, Train loss: 0.0052897593, Validation loss: 0.0053149524, LR: 1e-05\n",
      "Epoch 30, Train loss: 0.0052898248, Validation loss: 0.0053149377, LR: 1e-05\n",
      "Epoch 31, Train loss: 0.0052892751, Validation loss: 0.0053147823, LR: 1e-05\n",
      "Epoch 32, Train loss: 0.0052891943, Validation loss: 0.0053148027, LR: 1e-05\n",
      "Epoch 33, Train loss: 0.0052894661, Validation loss: 0.0053147909, LR: 1e-05\n",
      "Epoch 34, Train loss: 0.0052883077, Validation loss: 0.0053148190, LR: 1e-05\n",
      "Epoch 35, Train loss: 0.0052886007, Validation loss: 0.0053147432, LR: 1e-05\n",
      "Epoch 36, Train loss: 0.0052886000, Validation loss: 0.0053146829, LR: 1e-05\n",
      "Epoch 37, Train loss: 0.0052882462, Validation loss: 0.0053146188, LR: 1e-05\n",
      "Epoch 38, Train loss: 0.0052893505, Validation loss: 0.0053146138, LR: 1e-05\n",
      "Epoch 39, Train loss: 0.0052892241, Validation loss: 0.0053145698, LR: 1e-05\n",
      "Epoch 40, Train loss: 0.0052880029, Validation loss: 0.0053145769, LR: 1e-05\n",
      "Epoch 41, Train loss: 0.0052880447, Validation loss: 0.0053145713, LR: 1e-05\n",
      "Epoch 42, Train loss: 0.0052882265, Validation loss: 0.0053145021, LR: 1e-05\n",
      "Epoch 43, Train loss: 0.0052882823, Validation loss: 0.0053145677, LR: 1e-05\n",
      "Epoch 44, Train loss: 0.0052885983, Validation loss: 0.0053144723, LR: 1e-05\n",
      "Epoch 45, Train loss: 0.0052877816, Validation loss: 0.0053145089, LR: 1e-05\n",
      "Epoch 46, Train loss: 0.0052884386, Validation loss: 0.0053144239, LR: 1e-05\n",
      "Epoch 47, Train loss: 0.0052878686, Validation loss: 0.0053144187, LR: 1e-05\n",
      "Epoch 48, Train loss: 0.0052875771, Validation loss: 0.0053144331, LR: 1e-05\n",
      "Epoch 49, Train loss: 0.0052875036, Validation loss: 0.0053145290, LR: 1.0000000000000002e-06\n",
      "Epoch 50, Train loss: 0.0052880048, Validation loss: 0.0053141980, LR: 1.0000000000000002e-06\n",
      "Epoch 51, Train loss: 0.0052881659, Validation loss: 0.0053141965, LR: 1.0000000000000002e-06\n",
      "Epoch 52, Train loss: 0.0052880583, Validation loss: 0.0053142153, LR: 1.0000000000000002e-06\n",
      "Epoch 53, Train loss: 0.0052874327, Validation loss: 0.0053142004, LR: 1.0000000000000002e-06\n",
      "Epoch 54, Train loss: 0.0052877833, Validation loss: 0.0053141993, LR: 1.0000000000000002e-06\n",
      "Epoch 55, Train loss: 0.0052873435, Validation loss: 0.0053141969, LR: 1.0000000000000002e-06\n",
      "Epoch 56, Train loss: 0.0052879298, Validation loss: 0.0053141967, LR: 1.0000000000000002e-06\n",
      "Epoch 57, Train loss: 0.0052871473, Validation loss: 0.0053141988, LR: 1.0000000000000002e-06\n",
      "Epoch 58, Train loss: 0.0052879014, Validation loss: 0.0053141858, LR: 1.0000000000000002e-06\n",
      "Epoch 59, Train loss: 0.0052870386, Validation loss: 0.0053141838, LR: 1.0000000000000002e-06\n",
      "Epoch 60, Train loss: 0.0052866881, Validation loss: 0.0053141762, LR: 1.0000000000000002e-06\n",
      "Epoch 61, Train loss: 0.0052876690, Validation loss: 0.0053141891, LR: 1.0000000000000002e-06\n",
      "Epoch 62, Train loss: 0.0052874529, Validation loss: 0.0053141719, LR: 1.0000000000000002e-06\n",
      "Epoch 63, Train loss: 0.0052879890, Validation loss: 0.0053141860, LR: 1.0000000000000002e-06\n",
      "Epoch 64, Train loss: 0.0052869059, Validation loss: 0.0053141794, LR: 1.0000000000000002e-06\n",
      "Epoch 65, Train loss: 0.0052873007, Validation loss: 0.0053141744, LR: 1.0000000000000002e-06\n",
      "Epoch 66, Train loss: 0.0052871615, Validation loss: 0.0053141682, LR: 1.0000000000000002e-06\n",
      "Epoch 67, Train loss: 0.0052872078, Validation loss: 0.0053141779, LR: 1.0000000000000002e-06\n",
      "Epoch 68, Train loss: 0.0052874631, Validation loss: 0.0053141915, LR: 1.0000000000000002e-06\n",
      "Epoch 69, Train loss: 0.0052875247, Validation loss: 0.0053141753, LR: 1.0000000000000002e-06\n",
      "Epoch 70, Train loss: 0.0052876915, Validation loss: 0.0053141622, LR: 1.0000000000000002e-06\n",
      "Epoch 71, Train loss: 0.0052878263, Validation loss: 0.0053141668, LR: 1.0000000000000002e-06\n",
      "Epoch 72, Train loss: 0.0052880041, Validation loss: 0.0053141718, LR: 1.0000000000000002e-06\n",
      "Epoch 73, Train loss: 0.0052877630, Validation loss: 0.0053141632, LR: 1.0000000000000002e-06\n",
      "Epoch 74, Train loss: 0.0052877032, Validation loss: 0.0053141652, LR: 1.0000000000000002e-06\n",
      "Epoch 75, Train loss: 0.0052873938, Validation loss: 0.0053141685, LR: 1.0000000000000002e-06\n",
      "Epoch 76, Train loss: 0.0052871438, Validation loss: 0.0053141730, LR: 1.0000000000000002e-06\n",
      "Epoch 77, Train loss: 0.0052870349, Validation loss: 0.0053141609, LR: 1.0000000000000002e-06\n",
      "Epoch 78, Train loss: 0.0052876792, Validation loss: 0.0053141504, LR: 1.0000000000000002e-06\n",
      "Epoch 79, Train loss: 0.0052872840, Validation loss: 0.0053141557, LR: 1.0000000000000002e-06\n",
      "Epoch 80, Train loss: 0.0052874750, Validation loss: 0.0053141463, LR: 1.0000000000000002e-06\n",
      "Epoch 81, Train loss: 0.0052865209, Validation loss: 0.0053141459, LR: 1.0000000000000002e-06\n",
      "Epoch 82, Train loss: 0.0052863838, Validation loss: 0.0053141442, LR: 1.0000000000000002e-06\n",
      "Epoch 83, Train loss: 0.0052867328, Validation loss: 0.0053141475, LR: 1.0000000000000002e-06\n",
      "Epoch 84, Train loss: 0.0052873224, Validation loss: 0.0053141552, LR: 1.0000000000000002e-06\n",
      "Epoch 85, Train loss: 0.0052871577, Validation loss: 0.0053141461, LR: 1.0000000000000002e-06\n",
      "Epoch 86, Train loss: 0.0052867379, Validation loss: 0.0053141380, LR: 1.0000000000000002e-06\n",
      "Epoch 87, Train loss: 0.0052871740, Validation loss: 0.0053141578, LR: 1.0000000000000002e-06\n",
      "Epoch 88, Train loss: 0.0052867657, Validation loss: 0.0053141280, LR: 1.0000000000000002e-06\n",
      "Epoch 89, Train loss: 0.0052862621, Validation loss: 0.0053141637, LR: 1.0000000000000002e-06\n",
      "Epoch 90, Train loss: 0.0052874306, Validation loss: 0.0053141432, LR: 1.0000000000000002e-06\n",
      "Epoch 91, Train loss: 0.0052870687, Validation loss: 0.0053141332, LR: 1.0000000000000002e-06\n",
      "Epoch 92, Train loss: 0.0052871475, Validation loss: 0.0053141247, LR: 1.0000000000000002e-06\n",
      "Epoch 93, Train loss: 0.0052868277, Validation loss: 0.0053141474, LR: 1.0000000000000002e-06\n",
      "Epoch 94, Train loss: 0.0052868181, Validation loss: 0.0053141131, LR: 1.0000000000000002e-06\n",
      "Epoch 95, Train loss: 0.0052864123, Validation loss: 0.0053141301, LR: 1.0000000000000002e-06\n",
      "Epoch 96, Train loss: 0.0052867161, Validation loss: 0.0053141258, LR: 1.0000000000000002e-06\n",
      "Epoch 97, Train loss: 0.0052880062, Validation loss: 0.0053141390, LR: 1.0000000000000002e-06\n",
      "Epoch 98, Train loss: 0.0052876787, Validation loss: 0.0053141206, LR: 1.0000000000000002e-06\n",
      "Epoch 99, Train loss: 0.0052872441, Validation loss: 0.0053141230, LR: 1.0000000000000002e-06\n",
      "Epoch 100, Train loss: 0.0052877133, Validation loss: 0.0053141264, LR: 1.0000000000000002e-06\n",
      "Epoch 101, Train loss: 0.0052876912, Validation loss: 0.0053141227, LR: 1.0000000000000002e-06\n",
      "Epoch 102, Train loss: 0.0052872037, Validation loss: 0.0053141293, LR: 1.0000000000000002e-06\n",
      "Epoch 103, Train loss: 0.0052875258, Validation loss: 0.0053141257, LR: 1.0000000000000002e-06\n",
      "Epoch 104, Train loss: 0.0052875394, Validation loss: 0.0053141166, LR: 1.0000000000000002e-06\n",
      "Epoch 105, Train loss: 0.0052874473, Validation loss: 0.0053141427, LR: 1.0000000000000002e-06\n",
      "Epoch 106, Train loss: 0.0052863268, Validation loss: 0.0053141105, LR: 1.0000000000000002e-06\n",
      "Epoch 107, Train loss: 0.0052874796, Validation loss: 0.0053141011, LR: 1.0000000000000002e-06\n",
      "Epoch 108, Train loss: 0.0052871899, Validation loss: 0.0053141229, LR: 1.0000000000000002e-06\n",
      "Epoch 109, Train loss: 0.0052870005, Validation loss: 0.0053141217, LR: 1.0000000000000002e-06\n",
      "Epoch 110, Train loss: 0.0052867817, Validation loss: 0.0053141131, LR: 1.0000000000000002e-06\n",
      "Epoch 111, Train loss: 0.0052862842, Validation loss: 0.0053140954, LR: 1.0000000000000002e-06\n",
      "Epoch 112, Train loss: 0.0052866739, Validation loss: 0.0053140974, LR: 1.0000000000000002e-06\n",
      "Epoch 113, Train loss: 0.0052861026, Validation loss: 0.0053140869, LR: 1.0000000000000002e-06\n",
      "Epoch 114, Train loss: 0.0052871520, Validation loss: 0.0053141113, LR: 1.0000000000000002e-06\n",
      "Epoch 115, Train loss: 0.0052869652, Validation loss: 0.0053140985, LR: 1.0000000000000002e-06\n",
      "Epoch 116, Train loss: 0.0052865980, Validation loss: 0.0053140821, LR: 1.0000000000000002e-06\n",
      "Epoch 117, Train loss: 0.0052866809, Validation loss: 0.0053140834, LR: 1.0000000000000002e-06\n",
      "Epoch 118, Train loss: 0.0052862696, Validation loss: 0.0053140830, LR: 1.0000000000000002e-06\n",
      "Epoch 119, Train loss: 0.0052872871, Validation loss: 0.0053140881, LR: 1.0000000000000002e-06\n",
      "Epoch 120, Train loss: 0.0052877553, Validation loss: 0.0053140708, LR: 1.0000000000000002e-06\n",
      "Epoch 121, Train loss: 0.0052876301, Validation loss: 0.0053140899, LR: 1.0000000000000002e-06\n",
      "Epoch 122, Train loss: 0.0052864288, Validation loss: 0.0053140725, LR: 1.0000000000000002e-06\n",
      "Epoch 123, Train loss: 0.0052877038, Validation loss: 0.0053140649, LR: 1.0000000000000002e-06\n",
      "Epoch 124, Train loss: 0.0052876660, Validation loss: 0.0053140827, LR: 1.0000000000000002e-06\n",
      "Epoch 125, Train loss: 0.0052875361, Validation loss: 0.0053140744, LR: 1.0000000000000002e-06\n",
      "Epoch 126, Train loss: 0.0052875856, Validation loss: 0.0053140699, LR: 1.0000000000000002e-06\n",
      "Epoch 127, Train loss: 0.0052866844, Validation loss: 0.0053140754, LR: 1.0000000000000002e-06\n",
      "Epoch 128, Train loss: 0.0052875933, Validation loss: 0.0053140645, LR: 1.0000000000000002e-06\n",
      "Epoch 129, Train loss: 0.0052868395, Validation loss: 0.0053140697, LR: 1.0000000000000002e-06\n",
      "Epoch 130, Train loss: 0.0052872475, Validation loss: 0.0053140648, LR: 1.0000000000000002e-06\n",
      "Epoch 131, Train loss: 0.0052863300, Validation loss: 0.0053140738, LR: 1.0000000000000002e-06\n",
      "Epoch 132, Train loss: 0.0052878189, Validation loss: 0.0053140776, LR: 1.0000000000000002e-06\n",
      "Epoch 133, Train loss: 0.0052867190, Validation loss: 0.0053140851, LR: 1.0000000000000002e-06\n",
      "Epoch 134, Train loss: 0.0052867683, Validation loss: 0.0053140654, LR: 1.0000000000000002e-06\n",
      "Epoch 135, Train loss: 0.0052865369, Validation loss: 0.0053140780, LR: 1.0000000000000002e-06\n",
      "Epoch 136, Train loss: 0.0052859135, Validation loss: 0.0053140740, LR: 1.0000000000000002e-06\n",
      "Epoch 137, Train loss: 0.0052875202, Validation loss: 0.0053140666, LR: 1.0000000000000002e-06\n",
      "Epoch 138, Train loss: 0.0052870580, Validation loss: 0.0053140783, LR: 1.0000000000000002e-06\n",
      "Epoch 139, Train loss: 0.0052867246, Validation loss: 0.0053140529, LR: 1.0000000000000002e-06\n",
      "Epoch 140, Train loss: 0.0052867844, Validation loss: 0.0053140452, LR: 1.0000000000000002e-06\n",
      "Epoch 141, Train loss: 0.0052865625, Validation loss: 0.0053140697, LR: 1.0000000000000002e-06\n",
      "Epoch 142, Train loss: 0.0052868733, Validation loss: 0.0053140430, LR: 1.0000000000000002e-06\n",
      "Epoch 143, Train loss: 0.0052875634, Validation loss: 0.0053140413, LR: 1.0000000000000002e-06\n",
      "Epoch 144, Train loss: 0.0052876707, Validation loss: 0.0053140462, LR: 1.0000000000000002e-06\n",
      "Epoch 145, Train loss: 0.0052864929, Validation loss: 0.0053140480, LR: 1.0000000000000002e-06\n",
      "Epoch 146, Train loss: 0.0052870596, Validation loss: 0.0053140582, LR: 1.0000000000000002e-06\n",
      "Epoch 147, Train loss: 0.0052871656, Validation loss: 0.0053140287, LR: 1.0000000000000002e-06\n",
      "Epoch 148, Train loss: 0.0052869295, Validation loss: 0.0053140215, LR: 1.0000000000000002e-06\n",
      "Epoch 149, Train loss: 0.0052859951, Validation loss: 0.0053140456, LR: 1.0000000000000002e-06\n",
      "Epoch 150, Train loss: 0.0052867433, Validation loss: 0.0053140386, LR: 1.0000000000000002e-06\n",
      "Epoch 151, Train loss: 0.0052866817, Validation loss: 0.0053140261, LR: 1.0000000000000002e-06\n",
      "Epoch 152, Train loss: 0.0052865440, Validation loss: 0.0053140399, LR: 1.0000000000000002e-06\n",
      "Epoch 153, Train loss: 0.0052871269, Validation loss: 0.0053140318, LR: 1.0000000000000002e-06\n",
      "Epoch 154, Train loss: 0.0052872817, Validation loss: 0.0053140345, LR: 1.0000000000000002e-06\n",
      "Epoch 155, Train loss: 0.0052870839, Validation loss: 0.0053140218, LR: 1.0000000000000002e-06\n",
      "Epoch 156, Train loss: 0.0052877498, Validation loss: 0.0053140303, LR: 1.0000000000000002e-06\n",
      "Epoch 157, Train loss: 0.0052858399, Validation loss: 0.0053140300, LR: 1.0000000000000002e-06\n",
      "Epoch 158, Train loss: 0.0052867323, Validation loss: 0.0053140115, LR: 1.0000000000000002e-06\n",
      "Epoch 159, Train loss: 0.0052868774, Validation loss: 0.0053140375, LR: 1.0000000000000002e-06\n",
      "Epoch 160, Train loss: 0.0052874407, Validation loss: 0.0053140213, LR: 1.0000000000000002e-06\n",
      "Epoch 161, Train loss: 0.0052878245, Validation loss: 0.0053140129, LR: 1.0000000000000002e-06\n",
      "Epoch 162, Train loss: 0.0052867258, Validation loss: 0.0053140252, LR: 1.0000000000000002e-06\n",
      "Epoch 163, Train loss: 0.0052864792, Validation loss: 0.0053140070, LR: 1.0000000000000002e-06\n",
      "Epoch 164, Train loss: 0.0052872850, Validation loss: 0.0053140009, LR: 1.0000000000000002e-06\n",
      "Epoch 165, Train loss: 0.0052868379, Validation loss: 0.0053140043, LR: 1.0000000000000002e-06\n",
      "Epoch 166, Train loss: 0.0052870542, Validation loss: 0.0053140103, LR: 1.0000000000000002e-06\n",
      "Epoch 167, Train loss: 0.0052864556, Validation loss: 0.0053140207, LR: 1.0000000000000002e-06\n",
      "Epoch 168, Train loss: 0.0052863329, Validation loss: 0.0053140272, LR: 1.0000000000000002e-06\n",
      "Epoch 169, Train loss: 0.0052866399, Validation loss: 0.0053140255, LR: 1.0000000000000002e-06\n",
      "Epoch 170, Train loss: 0.0052864637, Validation loss: 0.0053140265, LR: 1.0000000000000002e-06\n",
      "Epoch 171, Train loss: 0.0052871824, Validation loss: 0.0053140045, LR: 1.0000000000000002e-06\n",
      "Epoch 172, Train loss: 0.0052864911, Validation loss: 0.0053140367, LR: 1.0000000000000002e-06\n",
      "Epoch 173, Train loss: 0.0052868560, Validation loss: 0.0053139943, LR: 1.0000000000000002e-06\n",
      "Epoch 174, Train loss: 0.0052868406, Validation loss: 0.0053139985, LR: 1.0000000000000002e-06\n",
      "Epoch 175, Train loss: 0.0052868073, Validation loss: 0.0053140047, LR: 1.0000000000000002e-06\n",
      "Epoch 176, Train loss: 0.0052873963, Validation loss: 0.0053139975, LR: 1.0000000000000002e-06\n",
      "Epoch 177, Train loss: 0.0052857694, Validation loss: 0.0053139747, LR: 1.0000000000000002e-06\n",
      "Epoch 178, Train loss: 0.0052870868, Validation loss: 0.0053139912, LR: 1.0000000000000002e-06\n",
      "Epoch 179, Train loss: 0.0052867577, Validation loss: 0.0053139837, LR: 1.0000000000000002e-06\n",
      "Epoch 180, Train loss: 0.0052858494, Validation loss: 0.0053139913, LR: 1.0000000000000002e-06\n",
      "Epoch 181, Train loss: 0.0052871229, Validation loss: 0.0053139770, LR: 1.0000000000000002e-06\n",
      "Epoch 182, Train loss: 0.0052870867, Validation loss: 0.0053139808, LR: 1.0000000000000002e-06\n",
      "Epoch 183, Train loss: 0.0052869655, Validation loss: 0.0053139710, LR: 1.0000000000000002e-06\n",
      "Epoch 184, Train loss: 0.0052860297, Validation loss: 0.0053139756, LR: 1.0000000000000002e-06\n",
      "Epoch 185, Train loss: 0.0052862619, Validation loss: 0.0053139668, LR: 1.0000000000000002e-06\n",
      "Epoch 186, Train loss: 0.0052863543, Validation loss: 0.0053139746, LR: 1.0000000000000002e-06\n",
      "Epoch 187, Train loss: 0.0052873493, Validation loss: 0.0053139732, LR: 1.0000000000000002e-06\n",
      "Epoch 188, Train loss: 0.0052869176, Validation loss: 0.0053139656, LR: 1.0000000000000002e-06\n",
      "Epoch 189, Train loss: 0.0052865389, Validation loss: 0.0053139696, LR: 1.0000000000000002e-06\n",
      "Epoch 190, Train loss: 0.0052875358, Validation loss: 0.0053139827, LR: 1.0000000000000002e-06\n",
      "Epoch 191, Train loss: 0.0052861871, Validation loss: 0.0053139661, LR: 1.0000000000000002e-06\n",
      "Epoch 192, Train loss: 0.0052864870, Validation loss: 0.0053139681, LR: 1.0000000000000002e-06\n",
      "Epoch 193, Train loss: 0.0052866131, Validation loss: 0.0053139635, LR: 1.0000000000000002e-06\n",
      "Epoch 194, Train loss: 0.0052861968, Validation loss: 0.0053139774, LR: 1.0000000000000002e-06\n",
      "Epoch 195, Train loss: 0.0052863976, Validation loss: 0.0053139541, LR: 1.0000000000000002e-06\n",
      "Epoch 196, Train loss: 0.0052864901, Validation loss: 0.0053139559, LR: 1.0000000000000002e-06\n",
      "Epoch 197, Train loss: 0.0052866806, Validation loss: 0.0053139619, LR: 1.0000000000000002e-06\n",
      "Epoch 198, Train loss: 0.0052865106, Validation loss: 0.0053139581, LR: 1.0000000000000002e-06\n",
      "Epoch 199, Train loss: 0.0052866576, Validation loss: 0.0053139604, LR: 1.0000000000000002e-06\n",
      "Epoch 200, Train loss: 0.0052867378, Validation loss: 0.0053139587, LR: 1.0000000000000002e-07\n",
      "Epoch 201, Train loss: 0.0052862890, Validation loss: 0.0053139354, LR: 1.0000000000000002e-07\n",
      "Epoch 202, Train loss: 0.0052868374, Validation loss: 0.0053139331, LR: 1.0000000000000002e-07\n",
      "Epoch 203, Train loss: 0.0052864773, Validation loss: 0.0053139349, LR: 1.0000000000000002e-07\n",
      "Epoch 204, Train loss: 0.0052869360, Validation loss: 0.0053139323, LR: 1.0000000000000002e-07\n",
      "Epoch 205, Train loss: 0.0052864891, Validation loss: 0.0053139310, LR: 1.0000000000000002e-07\n",
      "Epoch 206, Train loss: 0.0052866051, Validation loss: 0.0053139360, LR: 1.0000000000000002e-07\n",
      "Epoch 207, Train loss: 0.0052871119, Validation loss: 0.0053139347, LR: 1.0000000000000002e-07\n",
      "Epoch 208, Train loss: 0.0052856220, Validation loss: 0.0053139323, LR: 1.0000000000000002e-07\n",
      "Epoch 209, Train loss: 0.0052863343, Validation loss: 0.0053139338, LR: 1.0000000000000002e-07\n",
      "Epoch 210, Train loss: 0.0052861192, Validation loss: 0.0053139298, LR: 1.0000000000000002e-07\n",
      "Epoch 211, Train loss: 0.0052863988, Validation loss: 0.0053139318, LR: 1.0000000000000002e-07\n",
      "Epoch 212, Train loss: 0.0052864308, Validation loss: 0.0053139277, LR: 1.0000000000000002e-07\n",
      "Epoch 213, Train loss: 0.0052867340, Validation loss: 0.0053139300, LR: 1.0000000000000002e-07\n",
      "Epoch 214, Train loss: 0.0052869629, Validation loss: 0.0053139291, LR: 1.0000000000000002e-07\n",
      "Epoch 215, Train loss: 0.0052863714, Validation loss: 0.0053139281, LR: 1.0000000000000002e-07\n",
      "Epoch 216, Train loss: 0.0052869815, Validation loss: 0.0053139338, LR: 1.0000000000000002e-07\n",
      "Epoch 217, Train loss: 0.0052867227, Validation loss: 0.0053139298, LR: 1.0000000000000002e-07\n",
      "Epoch 218, Train loss: 0.0052866165, Validation loss: 0.0053139300, LR: 1.0000000000000002e-07\n",
      "Epoch 219, Train loss: 0.0052865078, Validation loss: 0.0053139298, LR: 1.0000000000000002e-07\n",
      "Epoch 220, Train loss: 0.0052862411, Validation loss: 0.0053139306, LR: 1.0000000000000002e-07\n",
      "Epoch 221, Train loss: 0.0052868494, Validation loss: 0.0053139295, LR: 1.0000000000000002e-07\n",
      "Epoch 222, Train loss: 0.0052861553, Validation loss: 0.0053139283, LR: 1.0000000000000002e-07\n",
      "Epoch 223, Train loss: 0.0052864006, Validation loss: 0.0053139284, LR: 1.0000000000000002e-07\n",
      "Epoch 224, Train loss: 0.0052869406, Validation loss: 0.0053139303, LR: 1.0000000000000002e-07\n",
      "Epoch 225, Train loss: 0.0052868819, Validation loss: 0.0053139312, LR: 1.0000000000000002e-07\n",
      "Epoch 226, Train loss: 0.0052867122, Validation loss: 0.0053139312, LR: 1.0000000000000002e-07\n",
      "Epoch 227, Train loss: 0.0052869674, Validation loss: 0.0053139293, LR: 1.0000000000000002e-07\n",
      "Epoch 228, Train loss: 0.0052868873, Validation loss: 0.0053139298, LR: 1.0000000000000002e-07\n",
      "Epoch 229, Train loss: 0.0052867423, Validation loss: 0.0053139302, LR: 1.0000000000000002e-07\n",
      "Epoch 230, Train loss: 0.0052867882, Validation loss: 0.0053139298, LR: 1.0000000000000002e-07\n",
      "Epoch 231, Train loss: 0.0052865439, Validation loss: 0.0053139285, LR: 1.0000000000000002e-07\n",
      "Epoch 232, Train loss: 0.0052862160, Validation loss: 0.0053139268, LR: 1.0000000000000002e-07\n",
      "Epoch 233, Train loss: 0.0052863853, Validation loss: 0.0053139286, LR: 1.0000000000000002e-07\n",
      "Epoch 234, Train loss: 0.0052866789, Validation loss: 0.0053139282, LR: 1.0000000000000002e-07\n",
      "Epoch 235, Train loss: 0.0052868218, Validation loss: 0.0053139272, LR: 1.0000000000000002e-07\n",
      "Epoch 236, Train loss: 0.0052859480, Validation loss: 0.0053139281, LR: 1.0000000000000002e-07\n",
      "Epoch 237, Train loss: 0.0052864789, Validation loss: 0.0053139283, LR: 1.0000000000000002e-07\n",
      "Epoch 238, Train loss: 0.0052865691, Validation loss: 0.0053139266, LR: 1.0000000000000002e-07\n",
      "Epoch 239, Train loss: 0.0052868429, Validation loss: 0.0053139269, LR: 1.0000000000000002e-07\n",
      "Epoch 240, Train loss: 0.0052856107, Validation loss: 0.0053139268, LR: 1.0000000000000002e-07\n",
      "Epoch 241, Train loss: 0.0052866560, Validation loss: 0.0053139272, LR: 1.0000000000000002e-07\n",
      "Epoch 242, Train loss: 0.0052863222, Validation loss: 0.0053139303, LR: 1.0000000000000002e-07\n",
      "Epoch 243, Train loss: 0.0052855819, Validation loss: 0.0053139254, LR: 1.0000000000000002e-07\n",
      "Epoch 244, Train loss: 0.0052867938, Validation loss: 0.0053139279, LR: 1.0000000000000002e-07\n",
      "Epoch 245, Train loss: 0.0052860300, Validation loss: 0.0053139264, LR: 1.0000000000000002e-07\n",
      "Epoch 246, Train loss: 0.0052862824, Validation loss: 0.0053139258, LR: 1.0000000000000002e-07\n",
      "Epoch 247, Train loss: 0.0052866831, Validation loss: 0.0053139238, LR: 1.0000000000000002e-07\n",
      "Epoch 248, Train loss: 0.0052868149, Validation loss: 0.0053139263, LR: 1.0000000000000002e-07\n",
      "Epoch 249, Train loss: 0.0052859881, Validation loss: 0.0053139227, LR: 1.0000000000000002e-07\n",
      "Epoch 250, Train loss: 0.0052862117, Validation loss: 0.0053139271, LR: 1.0000000000000002e-07\n",
      "Epoch 251, Train loss: 0.0052861963, Validation loss: 0.0053139247, LR: 1.0000000000000002e-07\n",
      "Epoch 252, Train loss: 0.0052863481, Validation loss: 0.0053139250, LR: 1.0000000000000002e-07\n",
      "Epoch 253, Train loss: 0.0052865307, Validation loss: 0.0053139251, LR: 1.0000000000000002e-07\n",
      "Epoch 254, Train loss: 0.0052857742, Validation loss: 0.0053139218, LR: 1.0000000000000002e-07\n",
      "Epoch 255, Train loss: 0.0052862632, Validation loss: 0.0053139277, LR: 1.0000000000000002e-07\n",
      "Epoch 256, Train loss: 0.0052864876, Validation loss: 0.0053139256, LR: 1.0000000000000002e-07\n",
      "Epoch 257, Train loss: 0.0052870500, Validation loss: 0.0053139233, LR: 1.0000000000000002e-07\n",
      "Epoch 258, Train loss: 0.0052865843, Validation loss: 0.0053139274, LR: 1.0000000000000002e-07\n",
      "Epoch 259, Train loss: 0.0052870567, Validation loss: 0.0053139235, LR: 1.0000000000000002e-07\n",
      "Epoch 260, Train loss: 0.0052863001, Validation loss: 0.0053139205, LR: 1.0000000000000002e-07\n",
      "Epoch 261, Train loss: 0.0052872617, Validation loss: 0.0053139227, LR: 1.0000000000000002e-07\n",
      "Epoch 262, Train loss: 0.0052867481, Validation loss: 0.0053139234, LR: 1.0000000000000002e-07\n",
      "Epoch 263, Train loss: 0.0052867088, Validation loss: 0.0053139261, LR: 1.0000000000000002e-07\n",
      "Epoch 264, Train loss: 0.0052860609, Validation loss: 0.0053139221, LR: 1.0000000000000002e-07\n",
      "Epoch 265, Train loss: 0.0052860772, Validation loss: 0.0053139202, LR: 1.0000000000000002e-07\n",
      "Epoch 266, Train loss: 0.0052867808, Validation loss: 0.0053139245, LR: 1.0000000000000002e-07\n",
      "Epoch 267, Train loss: 0.0052869726, Validation loss: 0.0053139231, LR: 1.0000000000000002e-07\n",
      "Epoch 268, Train loss: 0.0052868906, Validation loss: 0.0053139216, LR: 1.0000000000000002e-07\n",
      "Epoch 269, Train loss: 0.0052864180, Validation loss: 0.0053139208, LR: 1.0000000000000002e-07\n",
      "Epoch 270, Train loss: 0.0052858264, Validation loss: 0.0053139197, LR: 1.0000000000000002e-07\n",
      "Epoch 271, Train loss: 0.0052871158, Validation loss: 0.0053139229, LR: 1.0000000000000002e-07\n",
      "Epoch 272, Train loss: 0.0052861865, Validation loss: 0.0053139213, LR: 1.0000000000000002e-07\n",
      "Epoch 273, Train loss: 0.0052858743, Validation loss: 0.0053139218, LR: 1.0000000000000002e-07\n",
      "Epoch 274, Train loss: 0.0052862094, Validation loss: 0.0053139229, LR: 1.0000000000000002e-07\n",
      "Epoch 275, Train loss: 0.0052862401, Validation loss: 0.0053139172, LR: 1.0000000000000002e-07\n",
      "Epoch 276, Train loss: 0.0052863599, Validation loss: 0.0053139228, LR: 1.0000000000000002e-07\n",
      "Epoch 277, Train loss: 0.0052869650, Validation loss: 0.0053139222, LR: 1.0000000000000002e-07\n",
      "Epoch 278, Train loss: 0.0052868772, Validation loss: 0.0053139220, LR: 1.0000000000000002e-07\n",
      "Epoch 279, Train loss: 0.0052860551, Validation loss: 0.0053139226, LR: 1.0000000000000002e-07\n",
      "Epoch 280, Train loss: 0.0052867411, Validation loss: 0.0053139221, LR: 1.0000000000000002e-07\n",
      "Epoch 281, Train loss: 0.0052868578, Validation loss: 0.0053139202, LR: 1.0000000000000002e-07\n",
      "Epoch 282, Train loss: 0.0052857702, Validation loss: 0.0053139245, LR: 1.0000000000000002e-07\n",
      "Epoch 283, Train loss: 0.0052866818, Validation loss: 0.0053139191, LR: 1.0000000000000002e-07\n",
      "Epoch 284, Train loss: 0.0052871202, Validation loss: 0.0053139184, LR: 1.0000000000000002e-07\n",
      "Epoch 285, Train loss: 0.0052853391, Validation loss: 0.0053139211, LR: 1.0000000000000002e-07\n",
      "Epoch 286, Train loss: 0.0052865510, Validation loss: 0.0053139193, LR: 1.0000000000000002e-07\n",
      "Epoch 287, Train loss: 0.0052862627, Validation loss: 0.0053139196, LR: 1.0000000000000002e-07\n",
      "Epoch 288, Train loss: 0.0052864845, Validation loss: 0.0053139204, LR: 1.0000000000000002e-07\n",
      "Epoch 289, Train loss: 0.0052864037, Validation loss: 0.0053139184, LR: 1.0000000000000002e-07\n",
      "Epoch 290, Train loss: 0.0052866493, Validation loss: 0.0053139190, LR: 1.0000000000000002e-07\n",
      "Epoch 291, Train loss: 0.0052863079, Validation loss: 0.0053139190, LR: 1.0000000000000002e-07\n",
      "Epoch 292, Train loss: 0.0052862948, Validation loss: 0.0053139201, LR: 1.0000000000000002e-07\n",
      "Epoch 293, Train loss: 0.0052863479, Validation loss: 0.0053139170, LR: 1.0000000000000002e-07\n",
      "Epoch 294, Train loss: 0.0052867554, Validation loss: 0.0053139188, LR: 1.0000000000000002e-07\n",
      "Epoch 295, Train loss: 0.0052869219, Validation loss: 0.0053139190, LR: 1.0000000000000002e-07\n",
      "Epoch 296, Train loss: 0.0052871576, Validation loss: 0.0053139182, LR: 1.0000000000000002e-07\n",
      "Epoch 297, Train loss: 0.0052870957, Validation loss: 0.0053139153, LR: 1.0000000000000002e-07\n",
      "Epoch 298, Train loss: 0.0052860369, Validation loss: 0.0053139220, LR: 1.0000000000000002e-07\n",
      "Epoch 299, Train loss: 0.0052867891, Validation loss: 0.0053139207, LR: 1.0000000000000002e-07\n",
      "Epoch 300, Train loss: 0.0052864168, Validation loss: 0.0053139218, LR: 1.0000000000000002e-07\n",
      "Epoch 301, Train loss: 0.0052867801, Validation loss: 0.0053139144, LR: 1.0000000000000002e-07\n",
      "Epoch 302, Train loss: 0.0052865540, Validation loss: 0.0053139172, LR: 1.0000000000000002e-07\n",
      "Epoch 303, Train loss: 0.0052861713, Validation loss: 0.0053139189, LR: 1.0000000000000002e-07\n",
      "Epoch 304, Train loss: 0.0052867806, Validation loss: 0.0053139175, LR: 1.0000000000000002e-07\n",
      "Epoch 305, Train loss: 0.0052860720, Validation loss: 0.0053139162, LR: 1.0000000000000002e-07\n",
      "Epoch 306, Train loss: 0.0052864112, Validation loss: 0.0053139123, LR: 1.0000000000000002e-07\n",
      "Epoch 307, Train loss: 0.0052863695, Validation loss: 0.0053139164, LR: 1.0000000000000002e-07\n",
      "Epoch 308, Train loss: 0.0052865048, Validation loss: 0.0053139178, LR: 1.0000000000000002e-07\n",
      "Epoch 309, Train loss: 0.0052861700, Validation loss: 0.0053139160, LR: 1.0000000000000002e-07\n",
      "Epoch 310, Train loss: 0.0052869838, Validation loss: 0.0053139180, LR: 1.0000000000000002e-07\n",
      "Epoch 311, Train loss: 0.0052855009, Validation loss: 0.0053139187, LR: 1.0000000000000002e-07\n",
      "Epoch 312, Train loss: 0.0052863372, Validation loss: 0.0053139170, LR: 1.0000000000000002e-07\n",
      "Epoch 313, Train loss: 0.0052866437, Validation loss: 0.0053139132, LR: 1.0000000000000002e-07\n",
      "Epoch 314, Train loss: 0.0052869092, Validation loss: 0.0053139145, LR: 1.0000000000000002e-07\n",
      "Epoch 315, Train loss: 0.0052862155, Validation loss: 0.0053139196, LR: 1.0000000000000002e-07\n",
      "Epoch 316, Train loss: 0.0052863552, Validation loss: 0.0053139168, LR: 1.0000000000000002e-07\n",
      "Epoch 317, Train loss: 0.0052862808, Validation loss: 0.0053139149, LR: 1.0000000000000002e-07\n",
      "Epoch 318, Train loss: 0.0052859887, Validation loss: 0.0053139152, LR: 1.0000000000000002e-07\n",
      "Epoch 319, Train loss: 0.0052861459, Validation loss: 0.0053139130, LR: 1.0000000000000002e-07\n",
      "Epoch 320, Train loss: 0.0052867412, Validation loss: 0.0053139162, LR: 1.0000000000000002e-07\n",
      "Epoch 321, Train loss: 0.0052869240, Validation loss: 0.0053139153, LR: 1.0000000000000002e-07\n",
      "Epoch 322, Train loss: 0.0052860878, Validation loss: 0.0053139140, LR: 1.0000000000000002e-07\n",
      "Epoch 323, Train loss: 0.0052865869, Validation loss: 0.0053139116, LR: 1.0000000000000002e-07\n",
      "Epoch 324, Train loss: 0.0052866580, Validation loss: 0.0053139138, LR: 1.0000000000000002e-07\n",
      "Epoch 325, Train loss: 0.0052855016, Validation loss: 0.0053139129, LR: 1.0000000000000002e-07\n",
      "Epoch 326, Train loss: 0.0052857793, Validation loss: 0.0053139167, LR: 1.0000000000000002e-07\n",
      "Epoch 327, Train loss: 0.0052865307, Validation loss: 0.0053139160, LR: 1.0000000000000002e-07\n",
      "Epoch 328, Train loss: 0.0052863168, Validation loss: 0.0053139141, LR: 1.0000000000000002e-07\n",
      "Epoch 329, Train loss: 0.0052862393, Validation loss: 0.0053139149, LR: 1.0000000000000002e-07\n",
      "Epoch 330, Train loss: 0.0052866512, Validation loss: 0.0053139142, LR: 1.0000000000000002e-07\n",
      "Epoch 331, Train loss: 0.0052863950, Validation loss: 0.0053139112, LR: 1.0000000000000002e-07\n",
      "Epoch 332, Train loss: 0.0052859607, Validation loss: 0.0053139150, LR: 1.0000000000000002e-07\n",
      "Epoch 333, Train loss: 0.0052868534, Validation loss: 0.0053139116, LR: 1.0000000000000002e-07\n",
      "Epoch 334, Train loss: 0.0052865308, Validation loss: 0.0053139150, LR: 1.0000000000000002e-07\n",
      "Epoch 335, Train loss: 0.0052858335, Validation loss: 0.0053139132, LR: 1.0000000000000002e-07\n",
      "Epoch 336, Train loss: 0.0052862223, Validation loss: 0.0053139123, LR: 1.0000000000000002e-07\n",
      "Epoch 337, Train loss: 0.0052866217, Validation loss: 0.0053139155, LR: 1.0000000000000002e-07\n",
      "Epoch 338, Train loss: 0.0052866132, Validation loss: 0.0053139134, LR: 1.0000000000000002e-07\n",
      "Epoch 339, Train loss: 0.0052869893, Validation loss: 0.0053139134, LR: 1.0000000000000002e-07\n",
      "Epoch 340, Train loss: 0.0052864322, Validation loss: 0.0053139115, LR: 1.0000000000000002e-07\n",
      "Epoch 341, Train loss: 0.0052864663, Validation loss: 0.0053139133, LR: 1.0000000000000002e-07\n",
      "Epoch 342, Train loss: 0.0052867313, Validation loss: 0.0053139127, LR: 1.0000000000000002e-07\n",
      "Epoch 343, Train loss: 0.0052862130, Validation loss: 0.0053139130, LR: 1.0000000000000002e-07\n",
      "Epoch 344, Train loss: 0.0052861297, Validation loss: 0.0053139117, LR: 1.0000000000000002e-07\n",
      "Epoch 345, Train loss: 0.0052863154, Validation loss: 0.0053139132, LR: 1.0000000000000002e-07\n",
      "Epoch 346, Train loss: 0.0052861561, Validation loss: 0.0053139133, LR: 1.0000000000000002e-07\n",
      "Epoch 347, Train loss: 0.0052868242, Validation loss: 0.0053139125, LR: 1.0000000000000002e-07\n",
      "Epoch 348, Train loss: 0.0052864811, Validation loss: 0.0053139111, LR: 1.0000000000000002e-07\n",
      "Epoch 349, Train loss: 0.0052859982, Validation loss: 0.0053139135, LR: 1.0000000000000002e-07\n",
      "Epoch 350, Train loss: 0.0052865221, Validation loss: 0.0053139130, LR: 1.0000000000000002e-07\n",
      "Epoch 351, Train loss: 0.0052864308, Validation loss: 0.0053139108, LR: 1.0000000000000004e-08\n",
      "Epoch 352, Train loss: 0.0052866408, Validation loss: 0.0053139096, LR: 1.0000000000000004e-08\n",
      "Epoch 353, Train loss: 0.0052860239, Validation loss: 0.0053139090, LR: 1.0000000000000004e-08\n",
      "Epoch 354, Train loss: 0.0052862650, Validation loss: 0.0053139088, LR: 1.0000000000000004e-08\n",
      "Epoch 355, Train loss: 0.0052861972, Validation loss: 0.0053139088, LR: 1.0000000000000004e-08\n",
      "Epoch 356, Train loss: 0.0052868346, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 357, Train loss: 0.0052861111, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 358, Train loss: 0.0052863436, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 359, Train loss: 0.0052865199, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 360, Train loss: 0.0052864296, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 361, Train loss: 0.0052858761, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 362, Train loss: 0.0052863893, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 363, Train loss: 0.0052859428, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 364, Train loss: 0.0052859422, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 365, Train loss: 0.0052862808, Validation loss: 0.0053139088, LR: 1.0000000000000004e-08\n",
      "Epoch 366, Train loss: 0.0052861043, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 367, Train loss: 0.0052870820, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 368, Train loss: 0.0052867717, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 369, Train loss: 0.0052862311, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 370, Train loss: 0.0052860644, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 371, Train loss: 0.0052856448, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 372, Train loss: 0.0052859707, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 373, Train loss: 0.0052869482, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 374, Train loss: 0.0052872257, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 375, Train loss: 0.0052873715, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 376, Train loss: 0.0052858969, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 377, Train loss: 0.0052865847, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 378, Train loss: 0.0052855347, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 379, Train loss: 0.0052871681, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 380, Train loss: 0.0052868538, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 381, Train loss: 0.0052867028, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 382, Train loss: 0.0052859791, Validation loss: 0.0053139088, LR: 1.0000000000000004e-08\n",
      "Epoch 383, Train loss: 0.0052865092, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 384, Train loss: 0.0052861410, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 385, Train loss: 0.0052863793, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 386, Train loss: 0.0052862230, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 387, Train loss: 0.0052868284, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 388, Train loss: 0.0052861300, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 389, Train loss: 0.0052869081, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 390, Train loss: 0.0052861464, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 391, Train loss: 0.0052869394, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 392, Train loss: 0.0052865067, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 393, Train loss: 0.0052867028, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 394, Train loss: 0.0052862182, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 395, Train loss: 0.0052866762, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 396, Train loss: 0.0052858386, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 397, Train loss: 0.0052866260, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 398, Train loss: 0.0052867906, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 399, Train loss: 0.0052869235, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 400, Train loss: 0.0052865023, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 401, Train loss: 0.0052862235, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 402, Train loss: 0.0052864154, Validation loss: 0.0053139088, LR: 1.0000000000000004e-08\n",
      "Epoch 403, Train loss: 0.0052869310, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 404, Train loss: 0.0052867811, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 405, Train loss: 0.0052858457, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 406, Train loss: 0.0052866258, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 407, Train loss: 0.0052865031, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 408, Train loss: 0.0052862829, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 409, Train loss: 0.0052861660, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 410, Train loss: 0.0052865273, Validation loss: 0.0053139089, LR: 1.0000000000000004e-08\n",
      "Epoch 411, Train loss: 0.0052864548, Validation loss: 0.0053139088, LR: 1.0000000000000004e-08\n",
      "Epoch 412, Train loss: 0.0052871563, Validation loss: 0.0053139088, LR: 1.0000000000000004e-08\n",
      "Epoch 413, Train loss: 0.0052854106, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 414, Train loss: 0.0052861498, Validation loss: 0.0053139088, LR: 1.0000000000000004e-08\n",
      "Epoch 415, Train loss: 0.0052864317, Validation loss: 0.0053139088, LR: 1.0000000000000004e-08\n",
      "Epoch 416, Train loss: 0.0052862261, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 417, Train loss: 0.0052863225, Validation loss: 0.0053139088, LR: 1.0000000000000004e-08\n",
      "Epoch 418, Train loss: 0.0052859364, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 419, Train loss: 0.0052863850, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 420, Train loss: 0.0052866632, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 421, Train loss: 0.0052860230, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 422, Train loss: 0.0052864242, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 423, Train loss: 0.0052865109, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 424, Train loss: 0.0052861870, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 425, Train loss: 0.0052868160, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 426, Train loss: 0.0052867187, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 427, Train loss: 0.0052858918, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 428, Train loss: 0.0052865394, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 429, Train loss: 0.0052862258, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 430, Train loss: 0.0052867025, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 431, Train loss: 0.0052852063, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 432, Train loss: 0.0052874830, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 433, Train loss: 0.0052864135, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 434, Train loss: 0.0052859986, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 435, Train loss: 0.0052866682, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 436, Train loss: 0.0052867387, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 437, Train loss: 0.0052858835, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 438, Train loss: 0.0052866442, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 439, Train loss: 0.0052861059, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 440, Train loss: 0.0052867287, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 441, Train loss: 0.0052865539, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 442, Train loss: 0.0052861271, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 443, Train loss: 0.0052865447, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 444, Train loss: 0.0052860419, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 445, Train loss: 0.0052864769, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 446, Train loss: 0.0052859975, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 447, Train loss: 0.0052866040, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 448, Train loss: 0.0052856064, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 449, Train loss: 0.0052861628, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 450, Train loss: 0.0052866279, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 451, Train loss: 0.0052861341, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 452, Train loss: 0.0052870431, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 453, Train loss: 0.0052869378, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 454, Train loss: 0.0052868798, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 455, Train loss: 0.0052863043, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 456, Train loss: 0.0052857474, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 457, Train loss: 0.0052865790, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 458, Train loss: 0.0052859292, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 459, Train loss: 0.0052868379, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 460, Train loss: 0.0052868626, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 461, Train loss: 0.0052860988, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 462, Train loss: 0.0052859382, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 463, Train loss: 0.0052863382, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 464, Train loss: 0.0052860183, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 465, Train loss: 0.0052863983, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 466, Train loss: 0.0052869021, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 467, Train loss: 0.0052858499, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 468, Train loss: 0.0052865248, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 469, Train loss: 0.0052870239, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 470, Train loss: 0.0052866535, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 471, Train loss: 0.0052866373, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 472, Train loss: 0.0052860285, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 473, Train loss: 0.0052856988, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 474, Train loss: 0.0052861787, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 475, Train loss: 0.0052859672, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 476, Train loss: 0.0052866601, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 477, Train loss: 0.0052864425, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 478, Train loss: 0.0052864770, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 479, Train loss: 0.0052867547, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 480, Train loss: 0.0052865244, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 481, Train loss: 0.0052865685, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 482, Train loss: 0.0052859015, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 483, Train loss: 0.0052863731, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 484, Train loss: 0.0052859656, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 485, Train loss: 0.0052863910, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 486, Train loss: 0.0052871188, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 487, Train loss: 0.0052862400, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 488, Train loss: 0.0052862925, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 489, Train loss: 0.0052862400, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 490, Train loss: 0.0052871424, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 491, Train loss: 0.0052867339, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 492, Train loss: 0.0052865796, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 493, Train loss: 0.0052865208, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 494, Train loss: 0.0052871084, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 495, Train loss: 0.0052859298, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 496, Train loss: 0.0052866170, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 497, Train loss: 0.0052863366, Validation loss: 0.0053139086, LR: 1.0000000000000004e-08\n",
      "Epoch 498, Train loss: 0.0052870535, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 499, Train loss: 0.0052861123, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 500, Train loss: 0.0052870956, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 501, Train loss: 0.0052855718, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 502, Train loss: 0.0052860531, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 503, Train loss: 0.0052874330, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 504, Train loss: 0.0052868558, Validation loss: 0.0053139087, LR: 1.0000000000000004e-08\n",
      "Epoch 505, Train loss: 0.0052863849, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 506, Train loss: 0.0052874158, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 507, Train loss: 0.0052862962, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 508, Train loss: 0.0052861223, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 509, Train loss: 0.0052865066, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 510, Train loss: 0.0052864632, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 511, Train loss: 0.0052868237, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 512, Train loss: 0.0052862277, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 513, Train loss: 0.0052869001, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 514, Train loss: 0.0052858891, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 515, Train loss: 0.0052869339, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 516, Train loss: 0.0052860320, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 517, Train loss: 0.0052860165, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 518, Train loss: 0.0052867838, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 519, Train loss: 0.0052868244, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 520, Train loss: 0.0052865318, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 521, Train loss: 0.0052866941, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 522, Train loss: 0.0052865360, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 523, Train loss: 0.0052864559, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 524, Train loss: 0.0052865631, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 525, Train loss: 0.0052868154, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 526, Train loss: 0.0052865344, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 527, Train loss: 0.0052864803, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 528, Train loss: 0.0052866492, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 529, Train loss: 0.0052866413, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 530, Train loss: 0.0052860677, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 531, Train loss: 0.0052863694, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 532, Train loss: 0.0052866949, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 533, Train loss: 0.0052867193, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 534, Train loss: 0.0052860849, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 535, Train loss: 0.0052853774, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 536, Train loss: 0.0052867174, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 537, Train loss: 0.0052867086, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 538, Train loss: 0.0052866152, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 539, Train loss: 0.0052858080, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 540, Train loss: 0.0052868269, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 541, Train loss: 0.0052863973, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 542, Train loss: 0.0052862925, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 543, Train loss: 0.0052865566, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 544, Train loss: 0.0052866633, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 545, Train loss: 0.0052867898, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 546, Train loss: 0.0052863582, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 547, Train loss: 0.0052859872, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 548, Train loss: 0.0052868151, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 549, Train loss: 0.0052861035, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 550, Train loss: 0.0052866894, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 551, Train loss: 0.0052868697, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 552, Train loss: 0.0052862048, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 553, Train loss: 0.0052859608, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 554, Train loss: 0.0052857025, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 555, Train loss: 0.0052862239, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 556, Train loss: 0.0052861566, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 557, Train loss: 0.0052864237, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 558, Train loss: 0.0052864220, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 559, Train loss: 0.0052863174, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 560, Train loss: 0.0052859519, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 561, Train loss: 0.0052865070, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 562, Train loss: 0.0052864743, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 563, Train loss: 0.0052867063, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 564, Train loss: 0.0052872644, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 565, Train loss: 0.0052870483, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 566, Train loss: 0.0052863003, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 567, Train loss: 0.0052867100, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 568, Train loss: 0.0052865802, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 569, Train loss: 0.0052868992, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 570, Train loss: 0.0052868887, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 571, Train loss: 0.0052869772, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 572, Train loss: 0.0052857772, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 573, Train loss: 0.0052864505, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 574, Train loss: 0.0052858855, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 575, Train loss: 0.0052859303, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 576, Train loss: 0.0052858953, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 577, Train loss: 0.0052862309, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 578, Train loss: 0.0052859609, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 579, Train loss: 0.0052864264, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 580, Train loss: 0.0052867571, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 581, Train loss: 0.0052860621, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 582, Train loss: 0.0052867309, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 583, Train loss: 0.0052870194, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 584, Train loss: 0.0052868222, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 585, Train loss: 0.0052862264, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 586, Train loss: 0.0052869606, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 587, Train loss: 0.0052859165, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 588, Train loss: 0.0052869596, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 589, Train loss: 0.0052864173, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 590, Train loss: 0.0052859300, Validation loss: 0.0053139085, LR: 1.0000000000000004e-08\n",
      "Epoch 591, Train loss: 0.0052858998, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 592, Train loss: 0.0052857564, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 593, Train loss: 0.0052866183, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 594, Train loss: 0.0052859524, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 595, Train loss: 0.0052862853, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 596, Train loss: 0.0052865411, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 597, Train loss: 0.0052865653, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 598, Train loss: 0.0052863300, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 599, Train loss: 0.0052863232, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 600, Train loss: 0.0052857348, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 601, Train loss: 0.0052864274, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 602, Train loss: 0.0052864465, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 603, Train loss: 0.0052866285, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 604, Train loss: 0.0052854975, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 605, Train loss: 0.0052863917, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 606, Train loss: 0.0052860820, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 607, Train loss: 0.0052859173, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 608, Train loss: 0.0052860914, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 609, Train loss: 0.0052859735, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 610, Train loss: 0.0052866654, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 611, Train loss: 0.0052873521, Validation loss: 0.0053139084, LR: 1.0000000000000004e-08\n",
      "Epoch 612, Train loss: 0.0052867693, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 613, Train loss: 0.0052855559, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 614, Train loss: 0.0052873718, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 615, Train loss: 0.0052864139, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 616, Train loss: 0.0052858824, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 617, Train loss: 0.0052858204, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 618, Train loss: 0.0052862482, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 619, Train loss: 0.0052865417, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 620, Train loss: 0.0052866463, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 621, Train loss: 0.0052863943, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 622, Train loss: 0.0052862039, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 623, Train loss: 0.0052865524, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 624, Train loss: 0.0052863044, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 625, Train loss: 0.0052860069, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 626, Train loss: 0.0052864841, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 627, Train loss: 0.0052864516, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 628, Train loss: 0.0052867093, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 629, Train loss: 0.0052867801, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 630, Train loss: 0.0052861529, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 631, Train loss: 0.0052862208, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 632, Train loss: 0.0052863774, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 633, Train loss: 0.0052859107, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 634, Train loss: 0.0052858807, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 635, Train loss: 0.0052870453, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 636, Train loss: 0.0052861944, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 637, Train loss: 0.0052860628, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 638, Train loss: 0.0052866091, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 639, Train loss: 0.0052861691, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 640, Train loss: 0.0052866846, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 641, Train loss: 0.0052868788, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 642, Train loss: 0.0052862576, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 643, Train loss: 0.0052856516, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 644, Train loss: 0.0052866934, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 645, Train loss: 0.0052869474, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 646, Train loss: 0.0052865858, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 647, Train loss: 0.0052861908, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 648, Train loss: 0.0052862608, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 649, Train loss: 0.0052860264, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 650, Train loss: 0.0052862632, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 651, Train loss: 0.0052870394, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 652, Train loss: 0.0052862402, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 653, Train loss: 0.0052869926, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 654, Train loss: 0.0052863059, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 655, Train loss: 0.0052867151, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 656, Train loss: 0.0052867160, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 657, Train loss: 0.0052859411, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 658, Train loss: 0.0052864724, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 659, Train loss: 0.0052862393, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 660, Train loss: 0.0052859695, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 661, Train loss: 0.0052863140, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 662, Train loss: 0.0052863027, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 663, Train loss: 0.0052871217, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 664, Train loss: 0.0052862960, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 665, Train loss: 0.0052869988, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 666, Train loss: 0.0052863705, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 667, Train loss: 0.0052859708, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 668, Train loss: 0.0052869328, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 669, Train loss: 0.0052861368, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 670, Train loss: 0.0052864800, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 671, Train loss: 0.0052863298, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 672, Train loss: 0.0052868088, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 673, Train loss: 0.0052865007, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 674, Train loss: 0.0052866897, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 675, Train loss: 0.0052867248, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 676, Train loss: 0.0052862621, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 677, Train loss: 0.0052866231, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 678, Train loss: 0.0052864949, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 679, Train loss: 0.0052858648, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 680, Train loss: 0.0052863117, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 681, Train loss: 0.0052863544, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 682, Train loss: 0.0052864770, Validation loss: 0.0053139083, LR: 1.0000000000000004e-08\n",
      "Epoch 683, Train loss: 0.0052871928, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 684, Train loss: 0.0052861287, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 685, Train loss: 0.0052865531, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 686, Train loss: 0.0052864215, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 687, Train loss: 0.0052857040, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 688, Train loss: 0.0052865730, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 689, Train loss: 0.0052865175, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 690, Train loss: 0.0052864936, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 691, Train loss: 0.0052864477, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 692, Train loss: 0.0052862164, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 693, Train loss: 0.0052871900, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 694, Train loss: 0.0052868630, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 695, Train loss: 0.0052870468, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 696, Train loss: 0.0052855070, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 697, Train loss: 0.0052857275, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 698, Train loss: 0.0052866889, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 699, Train loss: 0.0052865918, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 700, Train loss: 0.0052863217, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 701, Train loss: 0.0052867924, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 702, Train loss: 0.0052865738, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 703, Train loss: 0.0052862877, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 704, Train loss: 0.0052865727, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 705, Train loss: 0.0052870473, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 706, Train loss: 0.0052867407, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 707, Train loss: 0.0052865841, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 708, Train loss: 0.0052865452, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 709, Train loss: 0.0052871746, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 710, Train loss: 0.0052868897, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 711, Train loss: 0.0052866573, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 712, Train loss: 0.0052868646, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 713, Train loss: 0.0052856525, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 714, Train loss: 0.0052859248, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 715, Train loss: 0.0052863422, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 716, Train loss: 0.0052867127, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 717, Train loss: 0.0052868095, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 718, Train loss: 0.0052864103, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 719, Train loss: 0.0052859209, Validation loss: 0.0053139082, LR: 1.0000000000000004e-08\n",
      "Epoch 720, Train loss: 0.0052863507, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 721, Train loss: 0.0052866936, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 722, Train loss: 0.0052865648, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 723, Train loss: 0.0052859532, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 724, Train loss: 0.0052864438, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 725, Train loss: 0.0052863435, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 726, Train loss: 0.0052867835, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 727, Train loss: 0.0052858319, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 728, Train loss: 0.0052862185, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 729, Train loss: 0.0052851132, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 730, Train loss: 0.0052860335, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 731, Train loss: 0.0052868220, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 732, Train loss: 0.0052870209, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 733, Train loss: 0.0052869043, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 734, Train loss: 0.0052864620, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 735, Train loss: 0.0052868721, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 736, Train loss: 0.0052869476, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 737, Train loss: 0.0052871239, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 738, Train loss: 0.0052857928, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 739, Train loss: 0.0052868614, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 740, Train loss: 0.0052861987, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 741, Train loss: 0.0052860277, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 742, Train loss: 0.0052868363, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 743, Train loss: 0.0052864374, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 744, Train loss: 0.0052867835, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 745, Train loss: 0.0052869857, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 746, Train loss: 0.0052858467, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 747, Train loss: 0.0052863107, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 748, Train loss: 0.0052864249, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 749, Train loss: 0.0052864849, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 750, Train loss: 0.0052871434, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 751, Train loss: 0.0052868252, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 752, Train loss: 0.0052866324, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 753, Train loss: 0.0052866486, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 754, Train loss: 0.0052862408, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 755, Train loss: 0.0052859665, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 756, Train loss: 0.0052868044, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 757, Train loss: 0.0052867589, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 758, Train loss: 0.0052857459, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 759, Train loss: 0.0052864158, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 760, Train loss: 0.0052865243, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 761, Train loss: 0.0052865738, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 762, Train loss: 0.0052866919, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 763, Train loss: 0.0052861908, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 764, Train loss: 0.0052866861, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 765, Train loss: 0.0052864851, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 766, Train loss: 0.0052866297, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 767, Train loss: 0.0052859869, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 768, Train loss: 0.0052865144, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 769, Train loss: 0.0052869410, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 770, Train loss: 0.0052860919, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 771, Train loss: 0.0052867026, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 772, Train loss: 0.0052869023, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 773, Train loss: 0.0052858115, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 774, Train loss: 0.0052870419, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 775, Train loss: 0.0052872037, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 776, Train loss: 0.0052863051, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 777, Train loss: 0.0052853649, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 778, Train loss: 0.0052866382, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 779, Train loss: 0.0052868860, Validation loss: 0.0053139081, LR: 1.0000000000000004e-08\n",
      "Epoch 780, Train loss: 0.0052863423, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 781, Train loss: 0.0052865376, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 782, Train loss: 0.0052871552, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 783, Train loss: 0.0052858149, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 784, Train loss: 0.0052864767, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 785, Train loss: 0.0052865635, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 786, Train loss: 0.0052868033, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 787, Train loss: 0.0052862851, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 788, Train loss: 0.0052855620, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 789, Train loss: 0.0052870831, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 790, Train loss: 0.0052869354, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 791, Train loss: 0.0052861444, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 792, Train loss: 0.0052857377, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 793, Train loss: 0.0052869791, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 794, Train loss: 0.0052865979, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 795, Train loss: 0.0052860241, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 796, Train loss: 0.0052864607, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 797, Train loss: 0.0052863292, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 798, Train loss: 0.0052868296, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 799, Train loss: 0.0052868171, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 800, Train loss: 0.0052870625, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 801, Train loss: 0.0052871985, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 802, Train loss: 0.0052853909, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 803, Train loss: 0.0052866786, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 804, Train loss: 0.0052862364, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 805, Train loss: 0.0052867987, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 806, Train loss: 0.0052863794, Validation loss: 0.0053139080, LR: 1.0000000000000004e-08\n",
      "Epoch 807, Train loss: 0.0052859216, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 808, Train loss: 0.0052867385, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 809, Train loss: 0.0052861855, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 810, Train loss: 0.0052867156, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 811, Train loss: 0.0052870051, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 812, Train loss: 0.0052869385, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 813, Train loss: 0.0052864298, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 814, Train loss: 0.0052861584, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 815, Train loss: 0.0052861183, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 816, Train loss: 0.0052856708, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 817, Train loss: 0.0052866831, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 818, Train loss: 0.0052866980, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 819, Train loss: 0.0052872525, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 820, Train loss: 0.0052865586, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 821, Train loss: 0.0052864025, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 822, Train loss: 0.0052862997, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 823, Train loss: 0.0052863782, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 824, Train loss: 0.0052867565, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 825, Train loss: 0.0052866133, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 826, Train loss: 0.0052858402, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 827, Train loss: 0.0052860362, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 828, Train loss: 0.0052869807, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 829, Train loss: 0.0052871519, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 830, Train loss: 0.0052865676, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 831, Train loss: 0.0052867795, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 832, Train loss: 0.0052875558, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 833, Train loss: 0.0052859016, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 834, Train loss: 0.0052854767, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 835, Train loss: 0.0052868919, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 836, Train loss: 0.0052865026, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 837, Train loss: 0.0052865865, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 838, Train loss: 0.0052861084, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 839, Train loss: 0.0052855404, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 840, Train loss: 0.0052864375, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 841, Train loss: 0.0052864365, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 842, Train loss: 0.0052862725, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 843, Train loss: 0.0052863386, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 844, Train loss: 0.0052861534, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 845, Train loss: 0.0052867697, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 846, Train loss: 0.0052867596, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 847, Train loss: 0.0052858360, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 848, Train loss: 0.0052857843, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 849, Train loss: 0.0052863290, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 850, Train loss: 0.0052863717, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 851, Train loss: 0.0052868447, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 852, Train loss: 0.0052861560, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 853, Train loss: 0.0052866182, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 854, Train loss: 0.0052863102, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 855, Train loss: 0.0052864682, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 856, Train loss: 0.0052867408, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 857, Train loss: 0.0052863160, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 858, Train loss: 0.0052863432, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 859, Train loss: 0.0052860297, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 860, Train loss: 0.0052866279, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 861, Train loss: 0.0052862203, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 862, Train loss: 0.0052870459, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 863, Train loss: 0.0052859701, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 864, Train loss: 0.0052858382, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 865, Train loss: 0.0052864036, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 866, Train loss: 0.0052871251, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 867, Train loss: 0.0052867877, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 868, Train loss: 0.0052861806, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 869, Train loss: 0.0052870134, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 870, Train loss: 0.0052865517, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 871, Train loss: 0.0052866702, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 872, Train loss: 0.0052868549, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 873, Train loss: 0.0052867362, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 874, Train loss: 0.0052868732, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 875, Train loss: 0.0052864422, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 876, Train loss: 0.0052861326, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 877, Train loss: 0.0052865943, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 878, Train loss: 0.0052861106, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 879, Train loss: 0.0052870511, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 880, Train loss: 0.0052864475, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 881, Train loss: 0.0052858970, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 882, Train loss: 0.0052865481, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 883, Train loss: 0.0052867553, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 884, Train loss: 0.0052858724, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 885, Train loss: 0.0052862095, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 886, Train loss: 0.0052868394, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 887, Train loss: 0.0052861012, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 888, Train loss: 0.0052864450, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 889, Train loss: 0.0052856011, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 890, Train loss: 0.0052865195, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 891, Train loss: 0.0052865245, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 892, Train loss: 0.0052865179, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 893, Train loss: 0.0052859130, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 894, Train loss: 0.0052862789, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 895, Train loss: 0.0052867622, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 896, Train loss: 0.0052871796, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 897, Train loss: 0.0052865382, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 898, Train loss: 0.0052869678, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 899, Train loss: 0.0052855727, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 900, Train loss: 0.0052866369, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 901, Train loss: 0.0052861476, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 902, Train loss: 0.0052872880, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 903, Train loss: 0.0052866760, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 904, Train loss: 0.0052860100, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 905, Train loss: 0.0052861657, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 906, Train loss: 0.0052864493, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 907, Train loss: 0.0052862477, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 908, Train loss: 0.0052867012, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 909, Train loss: 0.0052869712, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 910, Train loss: 0.0052866429, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 911, Train loss: 0.0052865963, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 912, Train loss: 0.0052863521, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 913, Train loss: 0.0052871753, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 914, Train loss: 0.0052863442, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 915, Train loss: 0.0052864606, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 916, Train loss: 0.0052864433, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 917, Train loss: 0.0052861350, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 918, Train loss: 0.0052861828, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 919, Train loss: 0.0052870469, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 920, Train loss: 0.0052851991, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 921, Train loss: 0.0052860419, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 922, Train loss: 0.0052866575, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 923, Train loss: 0.0052869919, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 924, Train loss: 0.0052866963, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 925, Train loss: 0.0052864898, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 926, Train loss: 0.0052868613, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 927, Train loss: 0.0052868168, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 928, Train loss: 0.0052865249, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 929, Train loss: 0.0052857158, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 930, Train loss: 0.0052861343, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 931, Train loss: 0.0052864906, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 932, Train loss: 0.0052870802, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 933, Train loss: 0.0052867732, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 934, Train loss: 0.0052859158, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 935, Train loss: 0.0052857354, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 936, Train loss: 0.0052866912, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 937, Train loss: 0.0052866899, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 938, Train loss: 0.0052870339, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 939, Train loss: 0.0052867481, Validation loss: 0.0053139079, LR: 1.0000000000000004e-08\n",
      "Epoch 940, Train loss: 0.0052871379, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 941, Train loss: 0.0052868354, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 942, Train loss: 0.0052863830, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 943, Train loss: 0.0052856925, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 944, Train loss: 0.0052858510, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 945, Train loss: 0.0052865679, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 946, Train loss: 0.0052858646, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 947, Train loss: 0.0052863372, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 948, Train loss: 0.0052870937, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 949, Train loss: 0.0052866073, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 950, Train loss: 0.0052864275, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 951, Train loss: 0.0052860580, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 952, Train loss: 0.0052862189, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 953, Train loss: 0.0052862397, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 954, Train loss: 0.0052858386, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 955, Train loss: 0.0052869708, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 956, Train loss: 0.0052861556, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 957, Train loss: 0.0052866197, Validation loss: 0.0053139078, LR: 1.0000000000000004e-08\n",
      "Epoch 958, Train loss: 0.0052863010, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 959, Train loss: 0.0052867260, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 960, Train loss: 0.0052866345, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 961, Train loss: 0.0052869406, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 962, Train loss: 0.0052869461, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 963, Train loss: 0.0052859372, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 964, Train loss: 0.0052863158, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 965, Train loss: 0.0052859441, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 966, Train loss: 0.0052866953, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 967, Train loss: 0.0052862035, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 968, Train loss: 0.0052864768, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 969, Train loss: 0.0052869077, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 970, Train loss: 0.0052868044, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 971, Train loss: 0.0052864610, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 972, Train loss: 0.0052869390, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 973, Train loss: 0.0052868093, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 974, Train loss: 0.0052861211, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 975, Train loss: 0.0052857682, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 976, Train loss: 0.0052860798, Validation loss: 0.0053139077, LR: 1.0000000000000004e-08\n",
      "Epoch 977, Train loss: 0.0052867909, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 978, Train loss: 0.0052863857, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 979, Train loss: 0.0052865501, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 980, Train loss: 0.0052862852, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 981, Train loss: 0.0052864268, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 982, Train loss: 0.0052868295, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 983, Train loss: 0.0052863820, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 984, Train loss: 0.0052863492, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 985, Train loss: 0.0052866182, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 986, Train loss: 0.0052862672, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 987, Train loss: 0.0052858171, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 988, Train loss: 0.0052866118, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 989, Train loss: 0.0052864198, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 990, Train loss: 0.0052863814, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 991, Train loss: 0.0052866008, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 992, Train loss: 0.0052866346, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 993, Train loss: 0.0052861845, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 994, Train loss: 0.0052862930, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 995, Train loss: 0.0052862061, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 996, Train loss: 0.0052863424, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 997, Train loss: 0.0052864922, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 998, Train loss: 0.0052871297, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 999, Train loss: 0.0052860418, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1000, Train loss: 0.0052868633, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 1001, Train loss: 0.0052868358, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 1002, Train loss: 0.0052863247, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1003, Train loss: 0.0052867862, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 1004, Train loss: 0.0052866042, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 1005, Train loss: 0.0052864532, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 1006, Train loss: 0.0052868838, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1007, Train loss: 0.0052869231, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1008, Train loss: 0.0052861758, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1009, Train loss: 0.0052870205, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 1010, Train loss: 0.0052863707, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1011, Train loss: 0.0052864521, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1012, Train loss: 0.0052865428, Validation loss: 0.0053139076, LR: 1.0000000000000004e-08\n",
      "Epoch 1013, Train loss: 0.0052848731, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1014, Train loss: 0.0052867941, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 1015, Train loss: 0.0052868492, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1016, Train loss: 0.0052863391, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 1017, Train loss: 0.0052863854, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1018, Train loss: 0.0052870543, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1019, Train loss: 0.0052870987, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1020, Train loss: 0.0052864381, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1021, Train loss: 0.0052863200, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1022, Train loss: 0.0052869298, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1023, Train loss: 0.0052870368, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1024, Train loss: 0.0052864338, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1025, Train loss: 0.0052869892, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1026, Train loss: 0.0052873101, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1027, Train loss: 0.0052859675, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 1028, Train loss: 0.0052863228, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1029, Train loss: 0.0052859258, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1030, Train loss: 0.0052869104, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1031, Train loss: 0.0052865017, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1032, Train loss: 0.0052865772, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1033, Train loss: 0.0052863756, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1034, Train loss: 0.0052863380, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1035, Train loss: 0.0052865204, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1036, Train loss: 0.0052871812, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1037, Train loss: 0.0052864969, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1038, Train loss: 0.0052868237, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1039, Train loss: 0.0052866093, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1040, Train loss: 0.0052865838, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1041, Train loss: 0.0052861665, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1042, Train loss: 0.0052861265, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1043, Train loss: 0.0052863901, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1044, Train loss: 0.0052863387, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1045, Train loss: 0.0052860595, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1046, Train loss: 0.0052867136, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1047, Train loss: 0.0052859262, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1048, Train loss: 0.0052866534, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 1049, Train loss: 0.0052863734, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1050, Train loss: 0.0052861942, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1051, Train loss: 0.0052858328, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 1052, Train loss: 0.0052860352, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1053, Train loss: 0.0052859906, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1054, Train loss: 0.0052865998, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1055, Train loss: 0.0052858884, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1056, Train loss: 0.0052863655, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1057, Train loss: 0.0052856408, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1058, Train loss: 0.0052863458, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 1059, Train loss: 0.0052863493, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1060, Train loss: 0.0052866804, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 1061, Train loss: 0.0052866295, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 1062, Train loss: 0.0052854962, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 1063, Train loss: 0.0052865413, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1064, Train loss: 0.0052856255, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1065, Train loss: 0.0052866245, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1066, Train loss: 0.0052870674, Validation loss: 0.0053139075, LR: 1.0000000000000004e-08\n",
      "Epoch 1067, Train loss: 0.0052864043, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1068, Train loss: 0.0052866812, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1069, Train loss: 0.0052862834, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1070, Train loss: 0.0052860725, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1071, Train loss: 0.0052864753, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1072, Train loss: 0.0052863375, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1073, Train loss: 0.0052864927, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1074, Train loss: 0.0052866086, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1075, Train loss: 0.0052856203, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1076, Train loss: 0.0052866614, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1077, Train loss: 0.0052869643, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1078, Train loss: 0.0052859739, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1079, Train loss: 0.0052863595, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1080, Train loss: 0.0052860615, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1081, Train loss: 0.0052867566, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1082, Train loss: 0.0052859605, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1083, Train loss: 0.0052865320, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1084, Train loss: 0.0052866448, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1085, Train loss: 0.0052863348, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1086, Train loss: 0.0052868067, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1087, Train loss: 0.0052860493, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1088, Train loss: 0.0052865017, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1089, Train loss: 0.0052866441, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1090, Train loss: 0.0052865646, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1091, Train loss: 0.0052871954, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1092, Train loss: 0.0052863618, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1093, Train loss: 0.0052859021, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1094, Train loss: 0.0052864579, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1095, Train loss: 0.0052862901, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1096, Train loss: 0.0052864455, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1097, Train loss: 0.0052873811, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1098, Train loss: 0.0052865361, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1099, Train loss: 0.0052869994, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1100, Train loss: 0.0052860443, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1101, Train loss: 0.0052867277, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1102, Train loss: 0.0052864908, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1103, Train loss: 0.0052865773, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1104, Train loss: 0.0052870919, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1105, Train loss: 0.0052867522, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1106, Train loss: 0.0052869389, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1107, Train loss: 0.0052859416, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1108, Train loss: 0.0052860098, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1109, Train loss: 0.0052862508, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1110, Train loss: 0.0052871100, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1111, Train loss: 0.0052853978, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1112, Train loss: 0.0052873103, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1113, Train loss: 0.0052863014, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1114, Train loss: 0.0052851048, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1115, Train loss: 0.0052865791, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1116, Train loss: 0.0052854559, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1117, Train loss: 0.0052870320, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1118, Train loss: 0.0052864107, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1119, Train loss: 0.0052870371, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1120, Train loss: 0.0052864383, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1121, Train loss: 0.0052867939, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1122, Train loss: 0.0052867607, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1123, Train loss: 0.0052866279, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1124, Train loss: 0.0052866724, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1125, Train loss: 0.0052860309, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1126, Train loss: 0.0052869951, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1127, Train loss: 0.0052861380, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1128, Train loss: 0.0052865493, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1129, Train loss: 0.0052859789, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1130, Train loss: 0.0052862632, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1131, Train loss: 0.0052861412, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1132, Train loss: 0.0052869715, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1133, Train loss: 0.0052868864, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1134, Train loss: 0.0052858023, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1135, Train loss: 0.0052867051, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1136, Train loss: 0.0052863903, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1137, Train loss: 0.0052864839, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1138, Train loss: 0.0052857611, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1139, Train loss: 0.0052869208, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1140, Train loss: 0.0052862387, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1141, Train loss: 0.0052865308, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1142, Train loss: 0.0052862218, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1143, Train loss: 0.0052873938, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1144, Train loss: 0.0052865047, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1145, Train loss: 0.0052867590, Validation loss: 0.0053139074, LR: 1.0000000000000004e-08\n",
      "Epoch 1146, Train loss: 0.0052868058, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1147, Train loss: 0.0052866754, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1148, Train loss: 0.0052868290, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1149, Train loss: 0.0052872428, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1150, Train loss: 0.0052863123, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1151, Train loss: 0.0052861754, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1152, Train loss: 0.0052862849, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1153, Train loss: 0.0052859102, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1154, Train loss: 0.0052861214, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1155, Train loss: 0.0052866294, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1156, Train loss: 0.0052868895, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1157, Train loss: 0.0052856185, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1158, Train loss: 0.0052859411, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1159, Train loss: 0.0052867271, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1160, Train loss: 0.0052868847, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1161, Train loss: 0.0052866543, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1162, Train loss: 0.0052865873, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1163, Train loss: 0.0052865785, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1164, Train loss: 0.0052864478, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1165, Train loss: 0.0052858819, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1166, Train loss: 0.0052861350, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1167, Train loss: 0.0052859724, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1168, Train loss: 0.0052865528, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1169, Train loss: 0.0052864170, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1170, Train loss: 0.0052856204, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1171, Train loss: 0.0052859133, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1172, Train loss: 0.0052858203, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1173, Train loss: 0.0052863893, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1174, Train loss: 0.0052862364, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1175, Train loss: 0.0052853914, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1176, Train loss: 0.0052863732, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1177, Train loss: 0.0052867587, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1178, Train loss: 0.0052871241, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1179, Train loss: 0.0052868804, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1180, Train loss: 0.0052868992, Validation loss: 0.0053139073, LR: 1.0000000000000004e-08\n",
      "Epoch 1181, Train loss: 0.0052867203, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1182, Train loss: 0.0052868013, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1183, Train loss: 0.0052860121, Validation loss: 0.0053139072, LR: 1.0000000000000004e-08\n",
      "Epoch 1184, Train loss: 0.0052861796, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1185, Train loss: 0.0052870240, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1186, Train loss: 0.0052856158, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1187, Train loss: 0.0052864509, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1188, Train loss: 0.0052869657, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1189, Train loss: 0.0052861826, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1190, Train loss: 0.0052873377, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1191, Train loss: 0.0052868467, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1192, Train loss: 0.0052859701, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1193, Train loss: 0.0052863173, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1194, Train loss: 0.0052871222, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1195, Train loss: 0.0052865557, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1196, Train loss: 0.0052863955, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1197, Train loss: 0.0052868810, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1198, Train loss: 0.0052861637, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1199, Train loss: 0.0052870036, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1200, Train loss: 0.0052863386, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1201, Train loss: 0.0052862026, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1202, Train loss: 0.0052863656, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1203, Train loss: 0.0052870506, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1204, Train loss: 0.0052862515, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1205, Train loss: 0.0052868839, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1206, Train loss: 0.0052864162, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1207, Train loss: 0.0052865988, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1208, Train loss: 0.0052869004, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1209, Train loss: 0.0052870351, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1210, Train loss: 0.0052868102, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1211, Train loss: 0.0052861192, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1212, Train loss: 0.0052859039, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1213, Train loss: 0.0052866978, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1214, Train loss: 0.0052864629, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1215, Train loss: 0.0052866605, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1216, Train loss: 0.0052857593, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1217, Train loss: 0.0052862457, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1218, Train loss: 0.0052863334, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1219, Train loss: 0.0052862590, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1220, Train loss: 0.0052861498, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1221, Train loss: 0.0052865421, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1222, Train loss: 0.0052868465, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1223, Train loss: 0.0052859854, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1224, Train loss: 0.0052858793, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1225, Train loss: 0.0052856526, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1226, Train loss: 0.0052859710, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1227, Train loss: 0.0052869519, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1228, Train loss: 0.0052858532, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1229, Train loss: 0.0052864928, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1230, Train loss: 0.0052863836, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1231, Train loss: 0.0052860169, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1232, Train loss: 0.0052867898, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1233, Train loss: 0.0052862779, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1234, Train loss: 0.0052870679, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1235, Train loss: 0.0052860728, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1236, Train loss: 0.0052865909, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1237, Train loss: 0.0052868174, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1238, Train loss: 0.0052868652, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1239, Train loss: 0.0052868462, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1240, Train loss: 0.0052871592, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1241, Train loss: 0.0052865392, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1242, Train loss: 0.0052860866, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1243, Train loss: 0.0052856273, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1244, Train loss: 0.0052862899, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1245, Train loss: 0.0052857558, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1246, Train loss: 0.0052868474, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1247, Train loss: 0.0052868144, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1248, Train loss: 0.0052868686, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1249, Train loss: 0.0052864064, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1250, Train loss: 0.0052857647, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1251, Train loss: 0.0052866883, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1252, Train loss: 0.0052867491, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1253, Train loss: 0.0052869103, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1254, Train loss: 0.0052862394, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1255, Train loss: 0.0052859412, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1256, Train loss: 0.0052853392, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1257, Train loss: 0.0052867331, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1258, Train loss: 0.0052858649, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1259, Train loss: 0.0052860534, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1260, Train loss: 0.0052862809, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1261, Train loss: 0.0052864614, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1262, Train loss: 0.0052862004, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1263, Train loss: 0.0052872540, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1264, Train loss: 0.0052857831, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1265, Train loss: 0.0052853988, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1266, Train loss: 0.0052862463, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1267, Train loss: 0.0052856464, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1268, Train loss: 0.0052868616, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1269, Train loss: 0.0052867798, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1270, Train loss: 0.0052857420, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1271, Train loss: 0.0052867890, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1272, Train loss: 0.0052864111, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1273, Train loss: 0.0052862873, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1274, Train loss: 0.0052870215, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1275, Train loss: 0.0052862435, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1276, Train loss: 0.0052864911, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1277, Train loss: 0.0052864639, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1278, Train loss: 0.0052865075, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1279, Train loss: 0.0052862528, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1280, Train loss: 0.0052868281, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1281, Train loss: 0.0052860899, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1282, Train loss: 0.0052868762, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1283, Train loss: 0.0052866504, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1284, Train loss: 0.0052868897, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1285, Train loss: 0.0052867331, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1286, Train loss: 0.0052860881, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1287, Train loss: 0.0052860230, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1288, Train loss: 0.0052860484, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1289, Train loss: 0.0052862423, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1290, Train loss: 0.0052866156, Validation loss: 0.0053139071, LR: 1.0000000000000004e-08\n",
      "Epoch 1291, Train loss: 0.0052865268, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1292, Train loss: 0.0052868112, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1293, Train loss: 0.0052869078, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1294, Train loss: 0.0052862077, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1295, Train loss: 0.0052863713, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1296, Train loss: 0.0052868903, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1297, Train loss: 0.0052859777, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1298, Train loss: 0.0052858932, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1299, Train loss: 0.0052867530, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1300, Train loss: 0.0052866715, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1301, Train loss: 0.0052865286, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1302, Train loss: 0.0052868372, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1303, Train loss: 0.0052863619, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1304, Train loss: 0.0052864203, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1305, Train loss: 0.0052857234, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1306, Train loss: 0.0052863589, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1307, Train loss: 0.0052861610, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1308, Train loss: 0.0052864906, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1309, Train loss: 0.0052867719, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1310, Train loss: 0.0052862023, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1311, Train loss: 0.0052867146, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1312, Train loss: 0.0052866912, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1313, Train loss: 0.0052862994, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1314, Train loss: 0.0052869257, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1315, Train loss: 0.0052860326, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1316, Train loss: 0.0052861723, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1317, Train loss: 0.0052862191, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1318, Train loss: 0.0052862422, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1319, Train loss: 0.0052867004, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1320, Train loss: 0.0052862350, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1321, Train loss: 0.0052871478, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1322, Train loss: 0.0052863789, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1323, Train loss: 0.0052865997, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1324, Train loss: 0.0052849869, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1325, Train loss: 0.0052864035, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1326, Train loss: 0.0052868290, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1327, Train loss: 0.0052870560, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1328, Train loss: 0.0052868882, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1329, Train loss: 0.0052867804, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1330, Train loss: 0.0052870312, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1331, Train loss: 0.0052858150, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1332, Train loss: 0.0052868277, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1333, Train loss: 0.0052867818, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1334, Train loss: 0.0052860809, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1335, Train loss: 0.0052862876, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1336, Train loss: 0.0052868460, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1337, Train loss: 0.0052864348, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1338, Train loss: 0.0052873947, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1339, Train loss: 0.0052862900, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1340, Train loss: 0.0052860757, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1341, Train loss: 0.0052863920, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1342, Train loss: 0.0052864206, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1343, Train loss: 0.0052857590, Validation loss: 0.0053139070, LR: 1.0000000000000004e-08\n",
      "Epoch 1344, Train loss: 0.0052864004, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1345, Train loss: 0.0052869295, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1346, Train loss: 0.0052866256, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1347, Train loss: 0.0052868124, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1348, Train loss: 0.0052868400, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1349, Train loss: 0.0052871916, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1350, Train loss: 0.0052865151, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1351, Train loss: 0.0052867591, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1352, Train loss: 0.0052861864, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1353, Train loss: 0.0052867586, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1354, Train loss: 0.0052870179, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1355, Train loss: 0.0052859300, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1356, Train loss: 0.0052868592, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1357, Train loss: 0.0052868745, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1358, Train loss: 0.0052864890, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1359, Train loss: 0.0052864438, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1360, Train loss: 0.0052870511, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1361, Train loss: 0.0052868073, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1362, Train loss: 0.0052866708, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1363, Train loss: 0.0052862251, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1364, Train loss: 0.0052866735, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1365, Train loss: 0.0052866258, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1366, Train loss: 0.0052860398, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1367, Train loss: 0.0052865246, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1368, Train loss: 0.0052856683, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1369, Train loss: 0.0052861323, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1370, Train loss: 0.0052860426, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1371, Train loss: 0.0052860145, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1372, Train loss: 0.0052866143, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1373, Train loss: 0.0052864336, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1374, Train loss: 0.0052872817, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1375, Train loss: 0.0052867235, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1376, Train loss: 0.0052864974, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1377, Train loss: 0.0052870546, Validation loss: 0.0053139069, LR: 1.0000000000000004e-08\n",
      "Epoch 1378, Train loss: 0.0052866901, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1379, Train loss: 0.0052858689, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1380, Train loss: 0.0052857342, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1381, Train loss: 0.0052857222, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1382, Train loss: 0.0052864906, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1383, Train loss: 0.0052865142, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1384, Train loss: 0.0052865674, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1385, Train loss: 0.0052869032, Validation loss: 0.0053139068, LR: 1.0000000000000004e-08\n",
      "Epoch 1386, Train loss: 0.0052863616, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1387, Train loss: 0.0052868773, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1388, Train loss: 0.0052862536, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1389, Train loss: 0.0052862940, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1390, Train loss: 0.0052853486, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1391, Train loss: 0.0052862857, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1392, Train loss: 0.0052865585, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1393, Train loss: 0.0052866688, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1394, Train loss: 0.0052868774, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1395, Train loss: 0.0052870409, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1396, Train loss: 0.0052860375, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1397, Train loss: 0.0052866980, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1398, Train loss: 0.0052861458, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1399, Train loss: 0.0052863971, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1400, Train loss: 0.0052861972, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1401, Train loss: 0.0052861261, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1402, Train loss: 0.0052865189, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1403, Train loss: 0.0052864641, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1404, Train loss: 0.0052863168, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1405, Train loss: 0.0052861501, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1406, Train loss: 0.0052862063, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1407, Train loss: 0.0052863162, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1408, Train loss: 0.0052868733, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1409, Train loss: 0.0052859395, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1410, Train loss: 0.0052865291, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1411, Train loss: 0.0052862992, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1412, Train loss: 0.0052858921, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1413, Train loss: 0.0052860320, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1414, Train loss: 0.0052866786, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1415, Train loss: 0.0052858201, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1416, Train loss: 0.0052868349, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1417, Train loss: 0.0052868932, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1418, Train loss: 0.0052862184, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1419, Train loss: 0.0052862578, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1420, Train loss: 0.0052869697, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1421, Train loss: 0.0052856759, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1422, Train loss: 0.0052864869, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1423, Train loss: 0.0052862784, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1424, Train loss: 0.0052863064, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1425, Train loss: 0.0052864165, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1426, Train loss: 0.0052862421, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1427, Train loss: 0.0052868461, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1428, Train loss: 0.0052857396, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1429, Train loss: 0.0052866366, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1430, Train loss: 0.0052874421, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1431, Train loss: 0.0052863727, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1432, Train loss: 0.0052860881, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1433, Train loss: 0.0052864573, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1434, Train loss: 0.0052857837, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1435, Train loss: 0.0052860239, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1436, Train loss: 0.0052867884, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1437, Train loss: 0.0052856580, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1438, Train loss: 0.0052858883, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1439, Train loss: 0.0052865638, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1440, Train loss: 0.0052859975, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1441, Train loss: 0.0052866946, Validation loss: 0.0053139067, LR: 1.0000000000000004e-08\n",
      "Epoch 1442, Train loss: 0.0052870337, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1443, Train loss: 0.0052860035, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1444, Train loss: 0.0052863337, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1445, Train loss: 0.0052865339, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1446, Train loss: 0.0052868867, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1447, Train loss: 0.0052864775, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1448, Train loss: 0.0052861876, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1449, Train loss: 0.0052860052, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1450, Train loss: 0.0052867929, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1451, Train loss: 0.0052859959, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1452, Train loss: 0.0052868455, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1453, Train loss: 0.0052867287, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1454, Train loss: 0.0052865285, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1455, Train loss: 0.0052865414, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1456, Train loss: 0.0052865369, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1457, Train loss: 0.0052865800, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1458, Train loss: 0.0052860776, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1459, Train loss: 0.0052860119, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1460, Train loss: 0.0052865260, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1461, Train loss: 0.0052859377, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1462, Train loss: 0.0052866420, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1463, Train loss: 0.0052866413, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1464, Train loss: 0.0052871110, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1465, Train loss: 0.0052861832, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1466, Train loss: 0.0052860722, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1467, Train loss: 0.0052865565, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1468, Train loss: 0.0052864223, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1469, Train loss: 0.0052863585, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1470, Train loss: 0.0052871477, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1471, Train loss: 0.0052869062, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1472, Train loss: 0.0052862506, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1473, Train loss: 0.0052865923, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1474, Train loss: 0.0052870133, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1475, Train loss: 0.0052865160, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1476, Train loss: 0.0052866643, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1477, Train loss: 0.0052859341, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1478, Train loss: 0.0052858277, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1479, Train loss: 0.0052859361, Validation loss: 0.0053139066, LR: 1.0000000000000004e-08\n",
      "Epoch 1480, Train loss: 0.0052862987, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1481, Train loss: 0.0052863959, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1482, Train loss: 0.0052859618, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1483, Train loss: 0.0052850845, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1484, Train loss: 0.0052866862, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1485, Train loss: 0.0052871179, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1486, Train loss: 0.0052861360, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1487, Train loss: 0.0052859737, Validation loss: 0.0053139065, LR: 1.0000000000000004e-08\n",
      "Epoch 1488, Train loss: 0.0052868734, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1489, Train loss: 0.0052863324, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1490, Train loss: 0.0052867856, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1491, Train loss: 0.0052872217, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1492, Train loss: 0.0052852226, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1493, Train loss: 0.0052866295, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1494, Train loss: 0.0052864762, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1495, Train loss: 0.0052860257, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1496, Train loss: 0.0052861933, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1497, Train loss: 0.0052863520, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1498, Train loss: 0.0052867307, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1499, Train loss: 0.0052862188, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1500, Train loss: 0.0052859688, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1501, Train loss: 0.0052870530, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1502, Train loss: 0.0052866844, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1503, Train loss: 0.0052868779, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1504, Train loss: 0.0052870844, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1505, Train loss: 0.0052862516, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1506, Train loss: 0.0052863777, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1507, Train loss: 0.0052859354, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1508, Train loss: 0.0052868371, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1509, Train loss: 0.0052850308, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1510, Train loss: 0.0052870720, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1511, Train loss: 0.0052864290, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1512, Train loss: 0.0052872999, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1513, Train loss: 0.0052863452, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1514, Train loss: 0.0052867661, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1515, Train loss: 0.0052862011, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1516, Train loss: 0.0052872792, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1517, Train loss: 0.0052864092, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1518, Train loss: 0.0052864492, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1519, Train loss: 0.0052866178, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1520, Train loss: 0.0052864113, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1521, Train loss: 0.0052863479, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1522, Train loss: 0.0052865475, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1523, Train loss: 0.0052868013, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1524, Train loss: 0.0052863111, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1525, Train loss: 0.0052864827, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1526, Train loss: 0.0052859874, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1527, Train loss: 0.0052870105, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1528, Train loss: 0.0052865347, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1529, Train loss: 0.0052870404, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1530, Train loss: 0.0052856736, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1531, Train loss: 0.0052858084, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1532, Train loss: 0.0052865320, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1533, Train loss: 0.0052869675, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1534, Train loss: 0.0052865892, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1535, Train loss: 0.0052862908, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1536, Train loss: 0.0052859439, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1537, Train loss: 0.0052872005, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1538, Train loss: 0.0052861820, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1539, Train loss: 0.0052861702, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1540, Train loss: 0.0052863135, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1541, Train loss: 0.0052865201, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1542, Train loss: 0.0052865654, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1543, Train loss: 0.0052863783, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1544, Train loss: 0.0052865832, Validation loss: 0.0053139064, LR: 1.0000000000000004e-08\n",
      "Epoch 1545, Train loss: 0.0052865953, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1546, Train loss: 0.0052863828, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1547, Train loss: 0.0052864040, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1548, Train loss: 0.0052867946, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1549, Train loss: 0.0052857305, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1550, Train loss: 0.0052863134, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1551, Train loss: 0.0052871265, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1552, Train loss: 0.0052856721, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1553, Train loss: 0.0052868015, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1554, Train loss: 0.0052859244, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1555, Train loss: 0.0052864217, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1556, Train loss: 0.0052867088, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1557, Train loss: 0.0052864457, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1558, Train loss: 0.0052867389, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1559, Train loss: 0.0052861316, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1560, Train loss: 0.0052862336, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1561, Train loss: 0.0052864191, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1562, Train loss: 0.0052869632, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1563, Train loss: 0.0052863142, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1564, Train loss: 0.0052861045, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1565, Train loss: 0.0052864398, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1566, Train loss: 0.0052859813, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1567, Train loss: 0.0052861407, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1568, Train loss: 0.0052866584, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1569, Train loss: 0.0052869153, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1570, Train loss: 0.0052860777, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1571, Train loss: 0.0052864336, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1572, Train loss: 0.0052864890, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1573, Train loss: 0.0052865478, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1574, Train loss: 0.0052862565, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1575, Train loss: 0.0052859799, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1576, Train loss: 0.0052862663, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1577, Train loss: 0.0052865978, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1578, Train loss: 0.0052862965, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1579, Train loss: 0.0052866924, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1580, Train loss: 0.0052856276, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1581, Train loss: 0.0052863112, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1582, Train loss: 0.0052871221, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1583, Train loss: 0.0052861887, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1584, Train loss: 0.0052857295, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1585, Train loss: 0.0052859681, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1586, Train loss: 0.0052862681, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1587, Train loss: 0.0052862992, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1588, Train loss: 0.0052864763, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1589, Train loss: 0.0052872361, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1590, Train loss: 0.0052867271, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1591, Train loss: 0.0052865646, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1592, Train loss: 0.0052863287, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1593, Train loss: 0.0052868030, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1594, Train loss: 0.0052860580, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1595, Train loss: 0.0052862857, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1596, Train loss: 0.0052865272, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1597, Train loss: 0.0052863255, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1598, Train loss: 0.0052860271, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1599, Train loss: 0.0052862142, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1600, Train loss: 0.0052866890, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1601, Train loss: 0.0052863974, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1602, Train loss: 0.0052864000, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1603, Train loss: 0.0052867259, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1604, Train loss: 0.0052865178, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1605, Train loss: 0.0052857678, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1606, Train loss: 0.0052862965, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1607, Train loss: 0.0052871589, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1608, Train loss: 0.0052863520, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1609, Train loss: 0.0052867527, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1610, Train loss: 0.0052866292, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1611, Train loss: 0.0052860870, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1612, Train loss: 0.0052868512, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1613, Train loss: 0.0052871150, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1614, Train loss: 0.0052865345, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1615, Train loss: 0.0052856695, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1616, Train loss: 0.0052870656, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1617, Train loss: 0.0052865864, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1618, Train loss: 0.0052862355, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1619, Train loss: 0.0052861995, Validation loss: 0.0053139062, LR: 1.0000000000000004e-08\n",
      "Epoch 1620, Train loss: 0.0052868173, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1621, Train loss: 0.0052868267, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1622, Train loss: 0.0052867715, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1623, Train loss: 0.0052856501, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1624, Train loss: 0.0052872997, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1625, Train loss: 0.0052863178, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1626, Train loss: 0.0052865248, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1627, Train loss: 0.0052868584, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1628, Train loss: 0.0052864080, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1629, Train loss: 0.0052863678, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1630, Train loss: 0.0052863758, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1631, Train loss: 0.0052857134, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1632, Train loss: 0.0052864015, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1633, Train loss: 0.0052863970, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1634, Train loss: 0.0052866751, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1635, Train loss: 0.0052857540, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1636, Train loss: 0.0052860986, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1637, Train loss: 0.0052873884, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1638, Train loss: 0.0052859374, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1639, Train loss: 0.0052858116, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1640, Train loss: 0.0052866058, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1641, Train loss: 0.0052862049, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1642, Train loss: 0.0052867489, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1643, Train loss: 0.0052863618, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1644, Train loss: 0.0052868399, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1645, Train loss: 0.0052870599, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1646, Train loss: 0.0052865426, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1647, Train loss: 0.0052868897, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1648, Train loss: 0.0052861180, Validation loss: 0.0053139063, LR: 1.0000000000000004e-08\n",
      "Epoch 1649, Train loss: 0.0052866353, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1650, Train loss: 0.0052859411, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1651, Train loss: 0.0052866518, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1652, Train loss: 0.0052866009, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1653, Train loss: 0.0052866759, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1654, Train loss: 0.0052859152, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1655, Train loss: 0.0052860090, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1656, Train loss: 0.0052863541, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1657, Train loss: 0.0052865595, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1658, Train loss: 0.0052862224, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1659, Train loss: 0.0052864491, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1660, Train loss: 0.0052862307, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1661, Train loss: 0.0052855977, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1662, Train loss: 0.0052859350, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1663, Train loss: 0.0052862953, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1664, Train loss: 0.0052864502, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1665, Train loss: 0.0052866384, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1666, Train loss: 0.0052864684, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1667, Train loss: 0.0052859287, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1668, Train loss: 0.0052870249, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1669, Train loss: 0.0052864762, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1670, Train loss: 0.0052865674, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1671, Train loss: 0.0052861859, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1672, Train loss: 0.0052863962, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1673, Train loss: 0.0052864154, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1674, Train loss: 0.0052865092, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1675, Train loss: 0.0052872268, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1676, Train loss: 0.0052866617, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1677, Train loss: 0.0052853844, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1678, Train loss: 0.0052866201, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1679, Train loss: 0.0052866091, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1680, Train loss: 0.0052872033, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1681, Train loss: 0.0052864589, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1682, Train loss: 0.0052864302, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1683, Train loss: 0.0052861969, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1684, Train loss: 0.0052865926, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1685, Train loss: 0.0052868087, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1686, Train loss: 0.0052857003, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1687, Train loss: 0.0052866528, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1688, Train loss: 0.0052858235, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1689, Train loss: 0.0052867431, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1690, Train loss: 0.0052860979, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1691, Train loss: 0.0052872815, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1692, Train loss: 0.0052870775, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1693, Train loss: 0.0052866738, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1694, Train loss: 0.0052861331, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1695, Train loss: 0.0052866818, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1696, Train loss: 0.0052861220, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1697, Train loss: 0.0052862562, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1698, Train loss: 0.0052869538, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1699, Train loss: 0.0052863728, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1700, Train loss: 0.0052853098, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1701, Train loss: 0.0052868177, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1702, Train loss: 0.0052868090, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1703, Train loss: 0.0052868589, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1704, Train loss: 0.0052865565, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1705, Train loss: 0.0052865601, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1706, Train loss: 0.0052863904, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1707, Train loss: 0.0052861926, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1708, Train loss: 0.0052866063, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1709, Train loss: 0.0052867258, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1710, Train loss: 0.0052866329, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1711, Train loss: 0.0052857735, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1712, Train loss: 0.0052860946, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1713, Train loss: 0.0052865754, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1714, Train loss: 0.0052868919, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1715, Train loss: 0.0052867457, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1716, Train loss: 0.0052860961, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1717, Train loss: 0.0052864331, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1718, Train loss: 0.0052859077, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1719, Train loss: 0.0052864935, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1720, Train loss: 0.0052861845, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1721, Train loss: 0.0052859781, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1722, Train loss: 0.0052870696, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1723, Train loss: 0.0052858316, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1724, Train loss: 0.0052874356, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1725, Train loss: 0.0052864970, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1726, Train loss: 0.0052857907, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1727, Train loss: 0.0052858867, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1728, Train loss: 0.0052860063, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1729, Train loss: 0.0052867384, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1730, Train loss: 0.0052872949, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1731, Train loss: 0.0052864822, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1732, Train loss: 0.0052859771, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1733, Train loss: 0.0052862886, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1734, Train loss: 0.0052861816, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1735, Train loss: 0.0052861187, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1736, Train loss: 0.0052860797, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1737, Train loss: 0.0052864983, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1738, Train loss: 0.0052860032, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1739, Train loss: 0.0052869694, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1740, Train loss: 0.0052866115, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1741, Train loss: 0.0052865901, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1742, Train loss: 0.0052870745, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1743, Train loss: 0.0052864690, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1744, Train loss: 0.0052865466, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1745, Train loss: 0.0052858096, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1746, Train loss: 0.0052867481, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1747, Train loss: 0.0052864270, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1748, Train loss: 0.0052862502, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1749, Train loss: 0.0052863947, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1750, Train loss: 0.0052858985, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1751, Train loss: 0.0052861631, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1752, Train loss: 0.0052861235, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1753, Train loss: 0.0052863137, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1754, Train loss: 0.0052855313, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1755, Train loss: 0.0052863288, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1756, Train loss: 0.0052864076, Validation loss: 0.0053139060, LR: 1.0000000000000004e-08\n",
      "Epoch 1757, Train loss: 0.0052871659, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1758, Train loss: 0.0052862802, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1759, Train loss: 0.0052864251, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1760, Train loss: 0.0052871520, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1761, Train loss: 0.0052862149, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1762, Train loss: 0.0052866867, Validation loss: 0.0053139061, LR: 1.0000000000000004e-08\n",
      "Epoch 1763, Train loss: 0.0052865137, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1764, Train loss: 0.0052851212, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1765, Train loss: 0.0052869151, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1766, Train loss: 0.0052865327, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1767, Train loss: 0.0052865049, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1768, Train loss: 0.0052873705, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1769, Train loss: 0.0052861395, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1770, Train loss: 0.0052874504, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1771, Train loss: 0.0052869533, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1772, Train loss: 0.0052863738, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1773, Train loss: 0.0052858993, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1774, Train loss: 0.0052864654, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1775, Train loss: 0.0052852239, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1776, Train loss: 0.0052865402, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1777, Train loss: 0.0052861343, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1778, Train loss: 0.0052859505, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1779, Train loss: 0.0052861125, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1780, Train loss: 0.0052858149, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1781, Train loss: 0.0052865436, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1782, Train loss: 0.0052863083, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1783, Train loss: 0.0052871567, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1784, Train loss: 0.0052863522, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1785, Train loss: 0.0052862588, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1786, Train loss: 0.0052859969, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1787, Train loss: 0.0052864652, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1788, Train loss: 0.0052869297, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1789, Train loss: 0.0052872675, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1790, Train loss: 0.0052863015, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1791, Train loss: 0.0052870649, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1792, Train loss: 0.0052866186, Validation loss: 0.0053139059, LR: 1.0000000000000004e-08\n",
      "Epoch 1793, Train loss: 0.0052862350, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1794, Train loss: 0.0052863359, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1795, Train loss: 0.0052865236, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1796, Train loss: 0.0052860784, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1797, Train loss: 0.0052865568, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1798, Train loss: 0.0052860361, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1799, Train loss: 0.0052863680, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1800, Train loss: 0.0052856225, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1801, Train loss: 0.0052861326, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1802, Train loss: 0.0052865553, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1803, Train loss: 0.0052863843, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1804, Train loss: 0.0052869085, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1805, Train loss: 0.0052858124, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1806, Train loss: 0.0052865223, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1807, Train loss: 0.0052862617, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1808, Train loss: 0.0052864251, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1809, Train loss: 0.0052858860, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1810, Train loss: 0.0052862363, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1811, Train loss: 0.0052866626, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1812, Train loss: 0.0052868801, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1813, Train loss: 0.0052858692, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1814, Train loss: 0.0052866941, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1815, Train loss: 0.0052867429, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1816, Train loss: 0.0052859877, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1817, Train loss: 0.0052864655, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1818, Train loss: 0.0052862532, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1819, Train loss: 0.0052869768, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1820, Train loss: 0.0052865248, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1821, Train loss: 0.0052870190, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1822, Train loss: 0.0052867185, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1823, Train loss: 0.0052873726, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1824, Train loss: 0.0052858517, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1825, Train loss: 0.0052861201, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1826, Train loss: 0.0052868238, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1827, Train loss: 0.0052863398, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1828, Train loss: 0.0052863480, Validation loss: 0.0053139058, LR: 1.0000000000000004e-08\n",
      "Epoch 1829, Train loss: 0.0052856367, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1830, Train loss: 0.0052873770, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1831, Train loss: 0.0052859365, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1832, Train loss: 0.0052871934, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1833, Train loss: 0.0052866151, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1834, Train loss: 0.0052867471, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1835, Train loss: 0.0052862573, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1836, Train loss: 0.0052865581, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1837, Train loss: 0.0052861644, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1838, Train loss: 0.0052869249, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1839, Train loss: 0.0052859854, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1840, Train loss: 0.0052859438, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1841, Train loss: 0.0052858263, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1842, Train loss: 0.0052870156, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1843, Train loss: 0.0052867246, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1844, Train loss: 0.0052862671, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1845, Train loss: 0.0052863321, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1846, Train loss: 0.0052861073, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1847, Train loss: 0.0052864019, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1848, Train loss: 0.0052867412, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1849, Train loss: 0.0052864004, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1850, Train loss: 0.0052863380, Validation loss: 0.0053139057, LR: 1.0000000000000004e-08\n",
      "Epoch 1851, Train loss: 0.0052863393, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1852, Train loss: 0.0052864479, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1853, Train loss: 0.0052866939, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1854, Train loss: 0.0052863817, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1855, Train loss: 0.0052861967, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1856, Train loss: 0.0052858950, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1857, Train loss: 0.0052860242, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1858, Train loss: 0.0052868505, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1859, Train loss: 0.0052862356, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1860, Train loss: 0.0052863555, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1861, Train loss: 0.0052860940, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1862, Train loss: 0.0052866259, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1863, Train loss: 0.0052868251, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1864, Train loss: 0.0052867210, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1865, Train loss: 0.0052859561, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1866, Train loss: 0.0052860813, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1867, Train loss: 0.0052862731, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1868, Train loss: 0.0052870582, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1869, Train loss: 0.0052868361, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1870, Train loss: 0.0052863856, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1871, Train loss: 0.0052856274, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1872, Train loss: 0.0052867653, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1873, Train loss: 0.0052869357, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1874, Train loss: 0.0052865040, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1875, Train loss: 0.0052862446, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1876, Train loss: 0.0052863506, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1877, Train loss: 0.0052860508, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1878, Train loss: 0.0052862258, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1879, Train loss: 0.0052867990, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1880, Train loss: 0.0052855539, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1881, Train loss: 0.0052868838, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1882, Train loss: 0.0052864516, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1883, Train loss: 0.0052869120, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1884, Train loss: 0.0052865861, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1885, Train loss: 0.0052864329, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1886, Train loss: 0.0052862380, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1887, Train loss: 0.0052865728, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1888, Train loss: 0.0052856849, Validation loss: 0.0053139056, LR: 1.0000000000000004e-08\n",
      "Epoch 1889, Train loss: 0.0052860654, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1890, Train loss: 0.0052869364, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1891, Train loss: 0.0052858607, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1892, Train loss: 0.0052859249, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1893, Train loss: 0.0052866438, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1894, Train loss: 0.0052856376, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1895, Train loss: 0.0052858532, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1896, Train loss: 0.0052865620, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1897, Train loss: 0.0052867272, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1898, Train loss: 0.0052865648, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1899, Train loss: 0.0052862446, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1900, Train loss: 0.0052861203, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1901, Train loss: 0.0052869698, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1902, Train loss: 0.0052864350, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1903, Train loss: 0.0052863463, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1904, Train loss: 0.0052862975, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1905, Train loss: 0.0052860837, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1906, Train loss: 0.0052864198, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1907, Train loss: 0.0052863016, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1908, Train loss: 0.0052860508, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1909, Train loss: 0.0052860873, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1910, Train loss: 0.0052863663, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1911, Train loss: 0.0052870547, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1912, Train loss: 0.0052869185, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1913, Train loss: 0.0052860437, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1914, Train loss: 0.0052858333, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1915, Train loss: 0.0052862767, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1916, Train loss: 0.0052858601, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1917, Train loss: 0.0052869450, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1918, Train loss: 0.0052864363, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1919, Train loss: 0.0052869644, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1920, Train loss: 0.0052862485, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1921, Train loss: 0.0052865753, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1922, Train loss: 0.0052867547, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1923, Train loss: 0.0052867707, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1924, Train loss: 0.0052861731, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1925, Train loss: 0.0052871369, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1926, Train loss: 0.0052865708, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1927, Train loss: 0.0052858447, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1928, Train loss: 0.0052861379, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1929, Train loss: 0.0052865281, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1930, Train loss: 0.0052859507, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1931, Train loss: 0.0052867347, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1932, Train loss: 0.0052861107, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1933, Train loss: 0.0052868082, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1934, Train loss: 0.0052864044, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 1935, Train loss: 0.0052862017, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1936, Train loss: 0.0052859885, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1937, Train loss: 0.0052867852, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1938, Train loss: 0.0052868147, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1939, Train loss: 0.0052860613, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1940, Train loss: 0.0052863528, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1941, Train loss: 0.0052861526, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1942, Train loss: 0.0052872058, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1943, Train loss: 0.0052868035, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1944, Train loss: 0.0052868545, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1945, Train loss: 0.0052856028, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1946, Train loss: 0.0052860871, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1947, Train loss: 0.0052861987, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1948, Train loss: 0.0052863520, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1949, Train loss: 0.0052858338, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1950, Train loss: 0.0052866408, Validation loss: 0.0053139055, LR: 1.0000000000000004e-08\n",
      "Epoch 1951, Train loss: 0.0052864775, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1952, Train loss: 0.0052860543, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1953, Train loss: 0.0052861354, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1954, Train loss: 0.0052868147, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1955, Train loss: 0.0052867057, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1956, Train loss: 0.0052863063, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 1957, Train loss: 0.0052858354, Validation loss: 0.0053139054, LR: 1.0000000000000004e-08\n",
      "Epoch 1958, Train loss: 0.0052864919, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1959, Train loss: 0.0052868914, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1960, Train loss: 0.0052867612, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 1961, Train loss: 0.0052864276, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1962, Train loss: 0.0052861630, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1963, Train loss: 0.0052870592, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1964, Train loss: 0.0052862573, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1965, Train loss: 0.0052871334, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1966, Train loss: 0.0052866639, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1967, Train loss: 0.0052860988, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1968, Train loss: 0.0052856815, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1969, Train loss: 0.0052863703, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1970, Train loss: 0.0052859366, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1971, Train loss: 0.0052849712, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1972, Train loss: 0.0052854359, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1973, Train loss: 0.0052867204, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 1974, Train loss: 0.0052863483, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1975, Train loss: 0.0052864365, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1976, Train loss: 0.0052866996, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 1977, Train loss: 0.0052855506, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1978, Train loss: 0.0052863402, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 1979, Train loss: 0.0052862148, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1980, Train loss: 0.0052871740, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 1981, Train loss: 0.0052858856, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 1982, Train loss: 0.0052864015, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 1983, Train loss: 0.0052863711, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1984, Train loss: 0.0052863078, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 1985, Train loss: 0.0052867210, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1986, Train loss: 0.0052869350, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1987, Train loss: 0.0052860102, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1988, Train loss: 0.0052865950, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1989, Train loss: 0.0052866618, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1990, Train loss: 0.0052870355, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1991, Train loss: 0.0052862772, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1992, Train loss: 0.0052871981, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1993, Train loss: 0.0052859126, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1994, Train loss: 0.0052862439, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1995, Train loss: 0.0052862964, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1996, Train loss: 0.0052872861, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 1997, Train loss: 0.0052858834, Validation loss: 0.0053139053, LR: 1.0000000000000004e-08\n",
      "Epoch 1998, Train loss: 0.0052858976, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 1999, Train loss: 0.0052864759, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2000, Train loss: 0.0052864065, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2001, Train loss: 0.0052872190, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2002, Train loss: 0.0052861319, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2003, Train loss: 0.0052862535, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2004, Train loss: 0.0052858272, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2005, Train loss: 0.0052869302, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2006, Train loss: 0.0052865413, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2007, Train loss: 0.0052857981, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2008, Train loss: 0.0052858520, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2009, Train loss: 0.0052860159, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2010, Train loss: 0.0052865280, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2011, Train loss: 0.0052869709, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2012, Train loss: 0.0052866633, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2013, Train loss: 0.0052872802, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2014, Train loss: 0.0052866035, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2015, Train loss: 0.0052860569, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2016, Train loss: 0.0052866589, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2017, Train loss: 0.0052867937, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2018, Train loss: 0.0052869548, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2019, Train loss: 0.0052862141, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2020, Train loss: 0.0052859635, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2021, Train loss: 0.0052859361, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2022, Train loss: 0.0052858710, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2023, Train loss: 0.0052863818, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2024, Train loss: 0.0052863955, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2025, Train loss: 0.0052864206, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2026, Train loss: 0.0052866006, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2027, Train loss: 0.0052860541, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2028, Train loss: 0.0052868834, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2029, Train loss: 0.0052871397, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2030, Train loss: 0.0052863308, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2031, Train loss: 0.0052866751, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2032, Train loss: 0.0052866690, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2033, Train loss: 0.0052859265, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2034, Train loss: 0.0052860620, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2035, Train loss: 0.0052861553, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2036, Train loss: 0.0052858561, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2037, Train loss: 0.0052869248, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2038, Train loss: 0.0052865868, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2039, Train loss: 0.0052868350, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2040, Train loss: 0.0052866251, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2041, Train loss: 0.0052867704, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2042, Train loss: 0.0052859776, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2043, Train loss: 0.0052867522, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2044, Train loss: 0.0052855307, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2045, Train loss: 0.0052862505, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2046, Train loss: 0.0052862644, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2047, Train loss: 0.0052863716, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2048, Train loss: 0.0052872139, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2049, Train loss: 0.0052866030, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2050, Train loss: 0.0052861840, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2051, Train loss: 0.0052865138, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2052, Train loss: 0.0052872818, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2053, Train loss: 0.0052865151, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2054, Train loss: 0.0052858494, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2055, Train loss: 0.0052868958, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2056, Train loss: 0.0052865235, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2057, Train loss: 0.0052866288, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2058, Train loss: 0.0052863565, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2059, Train loss: 0.0052860387, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2060, Train loss: 0.0052862628, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2061, Train loss: 0.0052866598, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2062, Train loss: 0.0052867861, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2063, Train loss: 0.0052862624, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2064, Train loss: 0.0052865736, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2065, Train loss: 0.0052859344, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2066, Train loss: 0.0052868078, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2067, Train loss: 0.0052859934, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2068, Train loss: 0.0052857792, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2069, Train loss: 0.0052862754, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2070, Train loss: 0.0052867705, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2071, Train loss: 0.0052862347, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2072, Train loss: 0.0052866233, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2073, Train loss: 0.0052867680, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2074, Train loss: 0.0052873073, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2075, Train loss: 0.0052869274, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2076, Train loss: 0.0052865363, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2077, Train loss: 0.0052861899, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2078, Train loss: 0.0052860979, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2079, Train loss: 0.0052849193, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2080, Train loss: 0.0052864730, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2081, Train loss: 0.0052864852, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2082, Train loss: 0.0052865017, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2083, Train loss: 0.0052868658, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2084, Train loss: 0.0052858624, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2085, Train loss: 0.0052867840, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2086, Train loss: 0.0052866715, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2087, Train loss: 0.0052864631, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2088, Train loss: 0.0052865861, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2089, Train loss: 0.0052865183, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2090, Train loss: 0.0052859143, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2091, Train loss: 0.0052866717, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2092, Train loss: 0.0052865386, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2093, Train loss: 0.0052868471, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2094, Train loss: 0.0052866389, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2095, Train loss: 0.0052852394, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2096, Train loss: 0.0052855345, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2097, Train loss: 0.0052863604, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2098, Train loss: 0.0052864334, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2099, Train loss: 0.0052862813, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2100, Train loss: 0.0052862692, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2101, Train loss: 0.0052862294, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2102, Train loss: 0.0052872089, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2103, Train loss: 0.0052868624, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2104, Train loss: 0.0052864045, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2105, Train loss: 0.0052868235, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2106, Train loss: 0.0052864693, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2107, Train loss: 0.0052862690, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2108, Train loss: 0.0052867024, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2109, Train loss: 0.0052863581, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2110, Train loss: 0.0052870809, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2111, Train loss: 0.0052875094, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2112, Train loss: 0.0052862008, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2113, Train loss: 0.0052857064, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2114, Train loss: 0.0052865040, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2115, Train loss: 0.0052867018, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2116, Train loss: 0.0052867827, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2117, Train loss: 0.0052861077, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2118, Train loss: 0.0052861660, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2119, Train loss: 0.0052868179, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2120, Train loss: 0.0052870090, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2121, Train loss: 0.0052863452, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2122, Train loss: 0.0052865503, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2123, Train loss: 0.0052853315, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2124, Train loss: 0.0052867275, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2125, Train loss: 0.0052867804, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2126, Train loss: 0.0052869707, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2127, Train loss: 0.0052867232, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2128, Train loss: 0.0052864748, Validation loss: 0.0053139046, LR: 1.0000000000000004e-08\n",
      "Epoch 2129, Train loss: 0.0052865931, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2130, Train loss: 0.0052864861, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2131, Train loss: 0.0052864793, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2132, Train loss: 0.0052857554, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2133, Train loss: 0.0052861363, Validation loss: 0.0053139052, LR: 1.0000000000000004e-08\n",
      "Epoch 2134, Train loss: 0.0052865264, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2135, Train loss: 0.0052870089, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2136, Train loss: 0.0052864590, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2137, Train loss: 0.0052868799, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2138, Train loss: 0.0052863008, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2139, Train loss: 0.0052858166, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2140, Train loss: 0.0052865444, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2141, Train loss: 0.0052865496, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2142, Train loss: 0.0052866325, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2143, Train loss: 0.0052871684, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2144, Train loss: 0.0052862679, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2145, Train loss: 0.0052863886, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2146, Train loss: 0.0052867562, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2147, Train loss: 0.0052858856, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2148, Train loss: 0.0052865768, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2149, Train loss: 0.0052856101, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2150, Train loss: 0.0052867080, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2151, Train loss: 0.0052863289, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2152, Train loss: 0.0052862350, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2153, Train loss: 0.0052861427, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2154, Train loss: 0.0052861511, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2155, Train loss: 0.0052861077, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2156, Train loss: 0.0052863119, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2157, Train loss: 0.0052867108, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2158, Train loss: 0.0052858868, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2159, Train loss: 0.0052867412, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2160, Train loss: 0.0052867840, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2161, Train loss: 0.0052866027, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2162, Train loss: 0.0052852816, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2163, Train loss: 0.0052867078, Validation loss: 0.0053139046, LR: 1.0000000000000004e-08\n",
      "Epoch 2164, Train loss: 0.0052859274, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2165, Train loss: 0.0052864524, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2166, Train loss: 0.0052865903, Validation loss: 0.0053139051, LR: 1.0000000000000004e-08\n",
      "Epoch 2167, Train loss: 0.0052864588, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2168, Train loss: 0.0052857885, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2169, Train loss: 0.0052866168, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2170, Train loss: 0.0052858173, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2171, Train loss: 0.0052861863, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2172, Train loss: 0.0052867686, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2173, Train loss: 0.0052862620, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2174, Train loss: 0.0052867123, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2175, Train loss: 0.0052864927, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2176, Train loss: 0.0052862721, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2177, Train loss: 0.0052868683, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2178, Train loss: 0.0052863827, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2179, Train loss: 0.0052864363, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2180, Train loss: 0.0052863179, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2181, Train loss: 0.0052855500, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2182, Train loss: 0.0052870861, Validation loss: 0.0053139046, LR: 1.0000000000000004e-08\n",
      "Epoch 2183, Train loss: 0.0052868990, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2184, Train loss: 0.0052856212, Validation loss: 0.0053139046, LR: 1.0000000000000004e-08\n",
      "Epoch 2185, Train loss: 0.0052862596, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2186, Train loss: 0.0052866742, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2187, Train loss: 0.0052865697, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2188, Train loss: 0.0052863443, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2189, Train loss: 0.0052864428, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2190, Train loss: 0.0052863633, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2191, Train loss: 0.0052862051, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2192, Train loss: 0.0052855003, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2193, Train loss: 0.0052861608, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2194, Train loss: 0.0052864158, Validation loss: 0.0053139046, LR: 1.0000000000000004e-08\n",
      "Epoch 2195, Train loss: 0.0052864705, Validation loss: 0.0053139046, LR: 1.0000000000000004e-08\n",
      "Epoch 2196, Train loss: 0.0052866268, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2197, Train loss: 0.0052861657, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2198, Train loss: 0.0052862847, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2199, Train loss: 0.0052864892, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2200, Train loss: 0.0052868674, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2201, Train loss: 0.0052869670, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2202, Train loss: 0.0052868007, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2203, Train loss: 0.0052868883, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2204, Train loss: 0.0052863366, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2205, Train loss: 0.0052860054, Validation loss: 0.0053139049, LR: 1.0000000000000004e-08\n",
      "Epoch 2206, Train loss: 0.0052863144, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2207, Train loss: 0.0052864812, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2208, Train loss: 0.0052862316, Validation loss: 0.0053139050, LR: 1.0000000000000004e-08\n",
      "Epoch 2209, Train loss: 0.0052862282, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2210, Train loss: 0.0052862933, Validation loss: 0.0053139046, LR: 1.0000000000000004e-08\n",
      "Epoch 2211, Train loss: 0.0052867201, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2212, Train loss: 0.0052865036, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2213, Train loss: 0.0052870023, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2214, Train loss: 0.0052859159, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2215, Train loss: 0.0052858052, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2216, Train loss: 0.0052863414, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2217, Train loss: 0.0052854105, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2218, Train loss: 0.0052862607, Validation loss: 0.0053139046, LR: 1.0000000000000004e-08\n",
      "Epoch 2219, Train loss: 0.0052863776, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2220, Train loss: 0.0052862844, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2221, Train loss: 0.0052866478, Validation loss: 0.0053139046, LR: 1.0000000000000004e-08\n",
      "Epoch 2222, Train loss: 0.0052869393, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2223, Train loss: 0.0052858961, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2224, Train loss: 0.0052861760, Validation loss: 0.0053139046, LR: 1.0000000000000004e-08\n",
      "Epoch 2225, Train loss: 0.0052868602, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2226, Train loss: 0.0052867068, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2227, Train loss: 0.0052863553, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2228, Train loss: 0.0052864001, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2229, Train loss: 0.0052866049, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2230, Train loss: 0.0052867004, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2231, Train loss: 0.0052865511, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2232, Train loss: 0.0052862375, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2233, Train loss: 0.0052870074, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2234, Train loss: 0.0052863703, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2235, Train loss: 0.0052860533, Validation loss: 0.0053139046, LR: 1.0000000000000004e-08\n",
      "Epoch 2236, Train loss: 0.0052862578, Validation loss: 0.0053139046, LR: 1.0000000000000004e-08\n",
      "Epoch 2237, Train loss: 0.0052870478, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2238, Train loss: 0.0052854550, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2239, Train loss: 0.0052865110, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2240, Train loss: 0.0052866379, Validation loss: 0.0053139046, LR: 1.0000000000000004e-08\n",
      "Epoch 2241, Train loss: 0.0052859864, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2242, Train loss: 0.0052865511, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2243, Train loss: 0.0052867954, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2244, Train loss: 0.0052870524, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2245, Train loss: 0.0052871903, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2246, Train loss: 0.0052865225, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2247, Train loss: 0.0052861778, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2248, Train loss: 0.0052865245, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2249, Train loss: 0.0052854788, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2250, Train loss: 0.0052864221, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2251, Train loss: 0.0052864634, Validation loss: 0.0053139046, LR: 1.0000000000000004e-08\n",
      "Epoch 2252, Train loss: 0.0052866720, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2253, Train loss: 0.0052866638, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2254, Train loss: 0.0052862707, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2255, Train loss: 0.0052858995, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2256, Train loss: 0.0052865209, Validation loss: 0.0053139047, LR: 1.0000000000000004e-08\n",
      "Epoch 2257, Train loss: 0.0052865950, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2258, Train loss: 0.0052864508, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2259, Train loss: 0.0052867960, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2260, Train loss: 0.0052867614, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2261, Train loss: 0.0052861468, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2262, Train loss: 0.0052865790, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2263, Train loss: 0.0052868616, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2264, Train loss: 0.0052863658, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2265, Train loss: 0.0052868374, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2266, Train loss: 0.0052860914, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2267, Train loss: 0.0052862129, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2268, Train loss: 0.0052868037, Validation loss: 0.0053139048, LR: 1.0000000000000004e-08\n",
      "Epoch 2269, Train loss: 0.0052871738, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2270, Train loss: 0.0052863746, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2271, Train loss: 0.0052860721, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2272, Train loss: 0.0052863849, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2273, Train loss: 0.0052867768, Validation loss: 0.0053139046, LR: 1.0000000000000004e-08\n",
      "Epoch 2274, Train loss: 0.0052867806, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2275, Train loss: 0.0052865247, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2276, Train loss: 0.0052869945, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2277, Train loss: 0.0052867177, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2278, Train loss: 0.0052863591, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2279, Train loss: 0.0052865759, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2280, Train loss: 0.0052860399, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2281, Train loss: 0.0052864504, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2282, Train loss: 0.0052859272, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2283, Train loss: 0.0052859844, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2284, Train loss: 0.0052869634, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2285, Train loss: 0.0052860934, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2286, Train loss: 0.0052865600, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2287, Train loss: 0.0052865526, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2288, Train loss: 0.0052862654, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2289, Train loss: 0.0052868249, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2290, Train loss: 0.0052862083, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2291, Train loss: 0.0052860448, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2292, Train loss: 0.0052862279, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2293, Train loss: 0.0052863321, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2294, Train loss: 0.0052858929, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2295, Train loss: 0.0052858592, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2296, Train loss: 0.0052866176, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2297, Train loss: 0.0052865298, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2298, Train loss: 0.0052863178, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2299, Train loss: 0.0052870622, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2300, Train loss: 0.0052862072, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2301, Train loss: 0.0052858877, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2302, Train loss: 0.0052861898, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2303, Train loss: 0.0052863620, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2304, Train loss: 0.0052859519, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2305, Train loss: 0.0052863066, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2306, Train loss: 0.0052867366, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2307, Train loss: 0.0052864541, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2308, Train loss: 0.0052867807, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2309, Train loss: 0.0052858918, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2310, Train loss: 0.0052866888, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2311, Train loss: 0.0052868250, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2312, Train loss: 0.0052863505, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2313, Train loss: 0.0052859306, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2314, Train loss: 0.0052871255, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2315, Train loss: 0.0052864956, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2316, Train loss: 0.0052852979, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2317, Train loss: 0.0052857601, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2318, Train loss: 0.0052869032, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2319, Train loss: 0.0052859657, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2320, Train loss: 0.0052867476, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2321, Train loss: 0.0052857895, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2322, Train loss: 0.0052862516, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2323, Train loss: 0.0052865658, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2324, Train loss: 0.0052864499, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2325, Train loss: 0.0052861059, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2326, Train loss: 0.0052860595, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2327, Train loss: 0.0052865305, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2328, Train loss: 0.0052871787, Validation loss: 0.0053139044, LR: 1.0000000000000004e-08\n",
      "Epoch 2329, Train loss: 0.0052857902, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2330, Train loss: 0.0052860010, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2331, Train loss: 0.0052863403, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2332, Train loss: 0.0052868179, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2333, Train loss: 0.0052861838, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2334, Train loss: 0.0052863107, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2335, Train loss: 0.0052866100, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2336, Train loss: 0.0052865301, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2337, Train loss: 0.0052862733, Validation loss: 0.0053139046, LR: 1.0000000000000004e-08\n",
      "Epoch 2338, Train loss: 0.0052863198, Validation loss: 0.0053139045, LR: 1.0000000000000004e-08\n",
      "Epoch 2339, Train loss: 0.0052866174, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2340, Train loss: 0.0052868017, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2341, Train loss: 0.0052862302, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2342, Train loss: 0.0052865518, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2343, Train loss: 0.0052866535, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2344, Train loss: 0.0052867438, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2345, Train loss: 0.0052870608, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2346, Train loss: 0.0052869007, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2347, Train loss: 0.0052860609, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2348, Train loss: 0.0052859898, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2349, Train loss: 0.0052863740, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2350, Train loss: 0.0052859353, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2351, Train loss: 0.0052862861, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2352, Train loss: 0.0052871188, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2353, Train loss: 0.0052859582, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2354, Train loss: 0.0052869122, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2355, Train loss: 0.0052867270, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2356, Train loss: 0.0052859186, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2357, Train loss: 0.0052861756, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2358, Train loss: 0.0052856192, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2359, Train loss: 0.0052863019, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2360, Train loss: 0.0052863034, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2361, Train loss: 0.0052866558, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2362, Train loss: 0.0052853981, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2363, Train loss: 0.0052860305, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2364, Train loss: 0.0052860660, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2365, Train loss: 0.0052855928, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2366, Train loss: 0.0052853364, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2367, Train loss: 0.0052860768, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2368, Train loss: 0.0052860195, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2369, Train loss: 0.0052860214, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2370, Train loss: 0.0052860979, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2371, Train loss: 0.0052852161, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2372, Train loss: 0.0052862459, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2373, Train loss: 0.0052866193, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2374, Train loss: 0.0052851883, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2375, Train loss: 0.0052863628, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2376, Train loss: 0.0052864389, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2377, Train loss: 0.0052868474, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2378, Train loss: 0.0052865673, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2379, Train loss: 0.0052868260, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2380, Train loss: 0.0052857596, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2381, Train loss: 0.0052866087, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2382, Train loss: 0.0052862808, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2383, Train loss: 0.0052854265, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2384, Train loss: 0.0052868874, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2385, Train loss: 0.0052865415, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2386, Train loss: 0.0052857875, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2387, Train loss: 0.0052868481, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2388, Train loss: 0.0052863254, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2389, Train loss: 0.0052867777, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2390, Train loss: 0.0052872884, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2391, Train loss: 0.0052858163, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2392, Train loss: 0.0052859752, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2393, Train loss: 0.0052862619, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2394, Train loss: 0.0052867012, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2395, Train loss: 0.0052863775, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2396, Train loss: 0.0052854918, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2397, Train loss: 0.0052865676, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2398, Train loss: 0.0052855697, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2399, Train loss: 0.0052866249, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2400, Train loss: 0.0052864171, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2401, Train loss: 0.0052864080, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2402, Train loss: 0.0052864045, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2403, Train loss: 0.0052862662, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2404, Train loss: 0.0052866692, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2405, Train loss: 0.0052866363, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2406, Train loss: 0.0052860005, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2407, Train loss: 0.0052858871, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2408, Train loss: 0.0052868850, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2409, Train loss: 0.0052858892, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2410, Train loss: 0.0052861820, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2411, Train loss: 0.0052864210, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2412, Train loss: 0.0052862056, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2413, Train loss: 0.0052860811, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2414, Train loss: 0.0052863041, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2415, Train loss: 0.0052868094, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2416, Train loss: 0.0052865451, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2417, Train loss: 0.0052865296, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2418, Train loss: 0.0052868535, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2419, Train loss: 0.0052866067, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2420, Train loss: 0.0052867953, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2421, Train loss: 0.0052859676, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2422, Train loss: 0.0052860906, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2423, Train loss: 0.0052866062, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2424, Train loss: 0.0052866296, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2425, Train loss: 0.0052859818, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2426, Train loss: 0.0052863823, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2427, Train loss: 0.0052870678, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2428, Train loss: 0.0052868835, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2429, Train loss: 0.0052865800, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2430, Train loss: 0.0052863665, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2431, Train loss: 0.0052859057, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2432, Train loss: 0.0052866328, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2433, Train loss: 0.0052866641, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2434, Train loss: 0.0052867028, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2435, Train loss: 0.0052861586, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2436, Train loss: 0.0052862048, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2437, Train loss: 0.0052866770, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2438, Train loss: 0.0052859483, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2439, Train loss: 0.0052865051, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2440, Train loss: 0.0052864221, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2441, Train loss: 0.0052867315, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2442, Train loss: 0.0052866084, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2443, Train loss: 0.0052858248, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2444, Train loss: 0.0052856582, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2445, Train loss: 0.0052863164, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2446, Train loss: 0.0052861944, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2447, Train loss: 0.0052858107, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2448, Train loss: 0.0052865617, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2449, Train loss: 0.0052868631, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2450, Train loss: 0.0052867408, Validation loss: 0.0053139042, LR: 1.0000000000000004e-08\n",
      "Epoch 2451, Train loss: 0.0052860966, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2452, Train loss: 0.0052869966, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2453, Train loss: 0.0052859218, Validation loss: 0.0053139043, LR: 1.0000000000000004e-08\n",
      "Epoch 2454, Train loss: 0.0052861657, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2455, Train loss: 0.0052868528, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2456, Train loss: 0.0052862648, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2457, Train loss: 0.0052863811, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2458, Train loss: 0.0052865824, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2459, Train loss: 0.0052862743, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2460, Train loss: 0.0052861421, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2461, Train loss: 0.0052869374, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2462, Train loss: 0.0052863300, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2463, Train loss: 0.0052860238, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2464, Train loss: 0.0052871879, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2465, Train loss: 0.0052866309, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2466, Train loss: 0.0052863381, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2467, Train loss: 0.0052863910, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2468, Train loss: 0.0052864002, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2469, Train loss: 0.0052864283, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2470, Train loss: 0.0052866423, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2471, Train loss: 0.0052863893, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2472, Train loss: 0.0052876361, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2473, Train loss: 0.0052863850, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2474, Train loss: 0.0052865583, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2475, Train loss: 0.0052860472, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2476, Train loss: 0.0052870683, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2477, Train loss: 0.0052869024, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2478, Train loss: 0.0052858861, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2479, Train loss: 0.0052864310, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2480, Train loss: 0.0052866635, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2481, Train loss: 0.0052864851, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2482, Train loss: 0.0052867561, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2483, Train loss: 0.0052870007, Validation loss: 0.0053139040, LR: 1.0000000000000004e-08\n",
      "Epoch 2484, Train loss: 0.0052858960, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2485, Train loss: 0.0052859014, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2486, Train loss: 0.0052869120, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2487, Train loss: 0.0052857079, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2488, Train loss: 0.0052867392, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2489, Train loss: 0.0052866097, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2490, Train loss: 0.0052857821, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2491, Train loss: 0.0052868889, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2492, Train loss: 0.0052867116, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2493, Train loss: 0.0052867317, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2494, Train loss: 0.0052869265, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2495, Train loss: 0.0052863719, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2496, Train loss: 0.0052865489, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2497, Train loss: 0.0052866224, Validation loss: 0.0053139041, LR: 1.0000000000000004e-08\n",
      "Epoch 2498, Train loss: 0.0052862208, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2499, Train loss: 0.0052865513, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2500, Train loss: 0.0052858001, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2501, Train loss: 0.0052862355, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2502, Train loss: 0.0052855499, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2503, Train loss: 0.0052868630, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2504, Train loss: 0.0052869232, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2505, Train loss: 0.0052859981, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2506, Train loss: 0.0052865202, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2507, Train loss: 0.0052864905, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2508, Train loss: 0.0052858130, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2509, Train loss: 0.0052850082, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2510, Train loss: 0.0052860123, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2511, Train loss: 0.0052864284, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2512, Train loss: 0.0052869097, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2513, Train loss: 0.0052865823, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2514, Train loss: 0.0052858432, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2515, Train loss: 0.0052865470, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2516, Train loss: 0.0052861195, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2517, Train loss: 0.0052864250, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2518, Train loss: 0.0052861389, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2519, Train loss: 0.0052859993, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2520, Train loss: 0.0052860969, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2521, Train loss: 0.0052864292, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2522, Train loss: 0.0052867352, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2523, Train loss: 0.0052866077, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2524, Train loss: 0.0052862856, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2525, Train loss: 0.0052860886, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2526, Train loss: 0.0052867063, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2527, Train loss: 0.0052862977, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2528, Train loss: 0.0052860612, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2529, Train loss: 0.0052863150, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2530, Train loss: 0.0052857687, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2531, Train loss: 0.0052863797, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2532, Train loss: 0.0052863291, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2533, Train loss: 0.0052860663, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2534, Train loss: 0.0052866300, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2535, Train loss: 0.0052866270, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2536, Train loss: 0.0052865491, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2537, Train loss: 0.0052859319, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2538, Train loss: 0.0052866805, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2539, Train loss: 0.0052862848, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2540, Train loss: 0.0052869027, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2541, Train loss: 0.0052862101, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2542, Train loss: 0.0052869458, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2543, Train loss: 0.0052865424, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2544, Train loss: 0.0052862898, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2545, Train loss: 0.0052866911, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2546, Train loss: 0.0052861334, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2547, Train loss: 0.0052860561, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2548, Train loss: 0.0052870430, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2549, Train loss: 0.0052861412, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2550, Train loss: 0.0052869608, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2551, Train loss: 0.0052862069, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2552, Train loss: 0.0052859857, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2553, Train loss: 0.0052858071, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2554, Train loss: 0.0052857760, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2555, Train loss: 0.0052864693, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2556, Train loss: 0.0052872288, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2557, Train loss: 0.0052862291, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2558, Train loss: 0.0052869511, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2559, Train loss: 0.0052854283, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2560, Train loss: 0.0052858785, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2561, Train loss: 0.0052864420, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2562, Train loss: 0.0052856146, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2563, Train loss: 0.0052856098, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2564, Train loss: 0.0052860922, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2565, Train loss: 0.0052865183, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2566, Train loss: 0.0052858797, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2567, Train loss: 0.0052868269, Validation loss: 0.0053139039, LR: 1.0000000000000004e-08\n",
      "Epoch 2568, Train loss: 0.0052861135, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2569, Train loss: 0.0052859063, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2570, Train loss: 0.0052856828, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2571, Train loss: 0.0052865117, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2572, Train loss: 0.0052868039, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2573, Train loss: 0.0052857174, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2574, Train loss: 0.0052861882, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2575, Train loss: 0.0052863437, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2576, Train loss: 0.0052865759, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2577, Train loss: 0.0052865458, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2578, Train loss: 0.0052869872, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2579, Train loss: 0.0052863412, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2580, Train loss: 0.0052858986, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2581, Train loss: 0.0052866009, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2582, Train loss: 0.0052867838, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2583, Train loss: 0.0052856933, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2584, Train loss: 0.0052870656, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2585, Train loss: 0.0052859374, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2586, Train loss: 0.0052866526, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2587, Train loss: 0.0052867006, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2588, Train loss: 0.0052862982, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2589, Train loss: 0.0052861827, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2590, Train loss: 0.0052864240, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2591, Train loss: 0.0052867260, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2592, Train loss: 0.0052867519, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2593, Train loss: 0.0052860728, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2594, Train loss: 0.0052860419, Validation loss: 0.0053139038, LR: 1.0000000000000004e-08\n",
      "Epoch 2595, Train loss: 0.0052858862, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2596, Train loss: 0.0052857180, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2597, Train loss: 0.0052861205, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2598, Train loss: 0.0052861026, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2599, Train loss: 0.0052866704, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2600, Train loss: 0.0052861736, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2601, Train loss: 0.0052866395, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2602, Train loss: 0.0052866801, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2603, Train loss: 0.0052859185, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2604, Train loss: 0.0052863762, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2605, Train loss: 0.0052861111, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2606, Train loss: 0.0052860183, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2607, Train loss: 0.0052869226, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2608, Train loss: 0.0052870436, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2609, Train loss: 0.0052851600, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2610, Train loss: 0.0052866790, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2611, Train loss: 0.0052869147, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2612, Train loss: 0.0052865689, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2613, Train loss: 0.0052861565, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2614, Train loss: 0.0052862934, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2615, Train loss: 0.0052855611, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2616, Train loss: 0.0052868777, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2617, Train loss: 0.0052869089, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2618, Train loss: 0.0052860453, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2619, Train loss: 0.0052858279, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2620, Train loss: 0.0052871927, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2621, Train loss: 0.0052865737, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2622, Train loss: 0.0052868504, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2623, Train loss: 0.0052858171, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2624, Train loss: 0.0052862272, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2625, Train loss: 0.0052860156, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2626, Train loss: 0.0052859501, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2627, Train loss: 0.0052871333, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2628, Train loss: 0.0052861670, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2629, Train loss: 0.0052861201, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2630, Train loss: 0.0052868961, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2631, Train loss: 0.0052861868, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2632, Train loss: 0.0052863571, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2633, Train loss: 0.0052856742, Validation loss: 0.0053139037, LR: 1.0000000000000004e-08\n",
      "Epoch 2634, Train loss: 0.0052865020, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2635, Train loss: 0.0052866072, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2636, Train loss: 0.0052862204, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2637, Train loss: 0.0052855454, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2638, Train loss: 0.0052864453, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2639, Train loss: 0.0052863390, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2640, Train loss: 0.0052861562, Validation loss: 0.0053139036, LR: 1.0000000000000004e-08\n",
      "Epoch 2641, Train loss: 0.0052865984, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2642, Train loss: 0.0052867610, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2643, Train loss: 0.0052864497, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2644, Train loss: 0.0052861242, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2645, Train loss: 0.0052859732, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2646, Train loss: 0.0052865940, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2647, Train loss: 0.0052862305, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2648, Train loss: 0.0052864942, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2649, Train loss: 0.0052864683, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2650, Train loss: 0.0052859682, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2651, Train loss: 0.0052865083, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2652, Train loss: 0.0052866835, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2653, Train loss: 0.0052854471, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2654, Train loss: 0.0052869726, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2655, Train loss: 0.0052855164, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2656, Train loss: 0.0052860756, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2657, Train loss: 0.0052870723, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2658, Train loss: 0.0052860939, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2659, Train loss: 0.0052868137, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2660, Train loss: 0.0052858916, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2661, Train loss: 0.0052867400, Validation loss: 0.0053139035, LR: 1.0000000000000004e-08\n",
      "Epoch 2662, Train loss: 0.0052866000, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2663, Train loss: 0.0052865547, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2664, Train loss: 0.0052868110, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2665, Train loss: 0.0052867016, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2666, Train loss: 0.0052861986, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2667, Train loss: 0.0052868331, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2668, Train loss: 0.0052856723, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2669, Train loss: 0.0052852115, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2670, Train loss: 0.0052855396, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2671, Train loss: 0.0052863426, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2672, Train loss: 0.0052858385, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2673, Train loss: 0.0052869155, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2674, Train loss: 0.0052867122, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2675, Train loss: 0.0052858928, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2676, Train loss: 0.0052862547, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2677, Train loss: 0.0052855825, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2678, Train loss: 0.0052863496, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2679, Train loss: 0.0052854642, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2680, Train loss: 0.0052874156, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2681, Train loss: 0.0052866947, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2682, Train loss: 0.0052854756, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2683, Train loss: 0.0052866505, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2684, Train loss: 0.0052865937, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2685, Train loss: 0.0052871261, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2686, Train loss: 0.0052867959, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2687, Train loss: 0.0052867323, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2688, Train loss: 0.0052867370, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2689, Train loss: 0.0052872710, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2690, Train loss: 0.0052863692, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2691, Train loss: 0.0052861951, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2692, Train loss: 0.0052864656, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2693, Train loss: 0.0052863830, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2694, Train loss: 0.0052863623, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2695, Train loss: 0.0052865581, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2696, Train loss: 0.0052863917, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2697, Train loss: 0.0052863675, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2698, Train loss: 0.0052862359, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2699, Train loss: 0.0052863989, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2700, Train loss: 0.0052866089, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2701, Train loss: 0.0052859052, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2702, Train loss: 0.0052860827, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2703, Train loss: 0.0052865304, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2704, Train loss: 0.0052860175, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2705, Train loss: 0.0052868184, Validation loss: 0.0053139034, LR: 1.0000000000000004e-08\n",
      "Epoch 2706, Train loss: 0.0052859158, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2707, Train loss: 0.0052863640, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2708, Train loss: 0.0052865042, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2709, Train loss: 0.0052858860, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2710, Train loss: 0.0052860794, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2711, Train loss: 0.0052853203, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2712, Train loss: 0.0052859840, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2713, Train loss: 0.0052859176, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2714, Train loss: 0.0052865023, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2715, Train loss: 0.0052854791, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2716, Train loss: 0.0052868954, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2717, Train loss: 0.0052861068, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2718, Train loss: 0.0052863716, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2719, Train loss: 0.0052868073, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2720, Train loss: 0.0052869881, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2721, Train loss: 0.0052864963, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2722, Train loss: 0.0052865967, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2723, Train loss: 0.0052862040, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2724, Train loss: 0.0052862152, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2725, Train loss: 0.0052863359, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2726, Train loss: 0.0052861199, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2727, Train loss: 0.0052857248, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2728, Train loss: 0.0052861250, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2729, Train loss: 0.0052872449, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2730, Train loss: 0.0052864851, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2731, Train loss: 0.0052857577, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2732, Train loss: 0.0052863159, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2733, Train loss: 0.0052858110, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2734, Train loss: 0.0052865104, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2735, Train loss: 0.0052864766, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2736, Train loss: 0.0052858197, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2737, Train loss: 0.0052854580, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2738, Train loss: 0.0052867643, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2739, Train loss: 0.0052863796, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2740, Train loss: 0.0052863803, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2741, Train loss: 0.0052864006, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2742, Train loss: 0.0052867749, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2743, Train loss: 0.0052866504, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2744, Train loss: 0.0052867036, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2745, Train loss: 0.0052864563, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2746, Train loss: 0.0052867204, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2747, Train loss: 0.0052857476, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2748, Train loss: 0.0052867495, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2749, Train loss: 0.0052866268, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2750, Train loss: 0.0052857873, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2751, Train loss: 0.0052863013, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2752, Train loss: 0.0052865157, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2753, Train loss: 0.0052859237, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2754, Train loss: 0.0052861824, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2755, Train loss: 0.0052864472, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2756, Train loss: 0.0052865132, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2757, Train loss: 0.0052858006, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2758, Train loss: 0.0052865547, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2759, Train loss: 0.0052872927, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2760, Train loss: 0.0052864533, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2761, Train loss: 0.0052862416, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2762, Train loss: 0.0052851978, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2763, Train loss: 0.0052864026, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2764, Train loss: 0.0052863717, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2765, Train loss: 0.0052868089, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2766, Train loss: 0.0052861565, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2767, Train loss: 0.0052869295, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2768, Train loss: 0.0052865560, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2769, Train loss: 0.0052862829, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2770, Train loss: 0.0052860369, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2771, Train loss: 0.0052868150, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2772, Train loss: 0.0052869572, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2773, Train loss: 0.0052863583, Validation loss: 0.0053139033, LR: 1.0000000000000004e-08\n",
      "Epoch 2774, Train loss: 0.0052861872, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2775, Train loss: 0.0052865530, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2776, Train loss: 0.0052863032, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2777, Train loss: 0.0052862994, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2778, Train loss: 0.0052863102, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2779, Train loss: 0.0052865025, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2780, Train loss: 0.0052858700, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2781, Train loss: 0.0052860118, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2782, Train loss: 0.0052853385, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2783, Train loss: 0.0052860993, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2784, Train loss: 0.0052859664, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2785, Train loss: 0.0052862424, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2786, Train loss: 0.0052863118, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2787, Train loss: 0.0052862621, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2788, Train loss: 0.0052863086, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2789, Train loss: 0.0052864301, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2790, Train loss: 0.0052864085, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2791, Train loss: 0.0052864142, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2792, Train loss: 0.0052865812, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2793, Train loss: 0.0052862468, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2794, Train loss: 0.0052858368, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2795, Train loss: 0.0052864495, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2796, Train loss: 0.0052859447, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2797, Train loss: 0.0052858945, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2798, Train loss: 0.0052854674, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2799, Train loss: 0.0052859238, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2800, Train loss: 0.0052861983, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2801, Train loss: 0.0052863768, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2802, Train loss: 0.0052854128, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2803, Train loss: 0.0052866796, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2804, Train loss: 0.0052865151, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2805, Train loss: 0.0052864080, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2806, Train loss: 0.0052860921, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2807, Train loss: 0.0052859923, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2808, Train loss: 0.0052858063, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2809, Train loss: 0.0052865224, Validation loss: 0.0053139031, LR: 1.0000000000000004e-08\n",
      "Epoch 2810, Train loss: 0.0052866918, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2811, Train loss: 0.0052871376, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2812, Train loss: 0.0052869769, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2813, Train loss: 0.0052865984, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2814, Train loss: 0.0052862750, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2815, Train loss: 0.0052864024, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2816, Train loss: 0.0052865462, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2817, Train loss: 0.0052862407, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2818, Train loss: 0.0052869597, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2819, Train loss: 0.0052870617, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2820, Train loss: 0.0052865676, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2821, Train loss: 0.0052865816, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2822, Train loss: 0.0052869395, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2823, Train loss: 0.0052870258, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2824, Train loss: 0.0052857266, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2825, Train loss: 0.0052857735, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2826, Train loss: 0.0052866885, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2827, Train loss: 0.0052861381, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2828, Train loss: 0.0052863682, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2829, Train loss: 0.0052861877, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2830, Train loss: 0.0052866260, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2831, Train loss: 0.0052866044, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2832, Train loss: 0.0052862964, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2833, Train loss: 0.0052865448, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2834, Train loss: 0.0052865390, Validation loss: 0.0053139032, LR: 1.0000000000000004e-08\n",
      "Epoch 2835, Train loss: 0.0052859122, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2836, Train loss: 0.0052864432, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2837, Train loss: 0.0052857054, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2838, Train loss: 0.0052865719, Validation loss: 0.0053139030, LR: 1.0000000000000004e-08\n",
      "Epoch 2839, Train loss: 0.0052866499, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2840, Train loss: 0.0052862523, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2841, Train loss: 0.0052864814, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2842, Train loss: 0.0052856893, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2843, Train loss: 0.0052861342, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2844, Train loss: 0.0052865972, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2845, Train loss: 0.0052862216, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2846, Train loss: 0.0052866050, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2847, Train loss: 0.0052871090, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2848, Train loss: 0.0052861599, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2849, Train loss: 0.0052869544, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2850, Train loss: 0.0052862551, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2851, Train loss: 0.0052861565, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2852, Train loss: 0.0052866724, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2853, Train loss: 0.0052860897, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2854, Train loss: 0.0052866510, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2855, Train loss: 0.0052870610, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2856, Train loss: 0.0052865039, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2857, Train loss: 0.0052855734, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2858, Train loss: 0.0052867705, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2859, Train loss: 0.0052865029, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2860, Train loss: 0.0052866001, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2861, Train loss: 0.0052865073, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2862, Train loss: 0.0052873601, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2863, Train loss: 0.0052862537, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2864, Train loss: 0.0052866589, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2865, Train loss: 0.0052869433, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2866, Train loss: 0.0052868614, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2867, Train loss: 0.0052863945, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2868, Train loss: 0.0052864446, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2869, Train loss: 0.0052863397, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2870, Train loss: 0.0052860350, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2871, Train loss: 0.0052861701, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2872, Train loss: 0.0052866300, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2873, Train loss: 0.0052861299, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2874, Train loss: 0.0052869042, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2875, Train loss: 0.0052862334, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2876, Train loss: 0.0052868474, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2877, Train loss: 0.0052860846, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2878, Train loss: 0.0052864805, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2879, Train loss: 0.0052864550, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2880, Train loss: 0.0052863038, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2881, Train loss: 0.0052860462, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2882, Train loss: 0.0052868624, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2883, Train loss: 0.0052857453, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2884, Train loss: 0.0052858897, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2885, Train loss: 0.0052863302, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2886, Train loss: 0.0052864037, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2887, Train loss: 0.0052863289, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2888, Train loss: 0.0052862565, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2889, Train loss: 0.0052866708, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2890, Train loss: 0.0052864710, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2891, Train loss: 0.0052862890, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2892, Train loss: 0.0052865062, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2893, Train loss: 0.0052865067, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2894, Train loss: 0.0052857213, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2895, Train loss: 0.0052857106, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2896, Train loss: 0.0052862195, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2897, Train loss: 0.0052863650, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2898, Train loss: 0.0052866713, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2899, Train loss: 0.0052866345, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2900, Train loss: 0.0052867650, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2901, Train loss: 0.0052864293, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2902, Train loss: 0.0052867973, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2903, Train loss: 0.0052861233, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2904, Train loss: 0.0052869132, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2905, Train loss: 0.0052862122, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2906, Train loss: 0.0052868292, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2907, Train loss: 0.0052858481, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2908, Train loss: 0.0052867235, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2909, Train loss: 0.0052866732, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2910, Train loss: 0.0052857806, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2911, Train loss: 0.0052867521, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2912, Train loss: 0.0052871784, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2913, Train loss: 0.0052866250, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2914, Train loss: 0.0052865527, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2915, Train loss: 0.0052861003, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2916, Train loss: 0.0052869651, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2917, Train loss: 0.0052870904, Validation loss: 0.0053139029, LR: 1.0000000000000004e-08\n",
      "Epoch 2918, Train loss: 0.0052868798, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2919, Train loss: 0.0052863011, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2920, Train loss: 0.0052871329, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2921, Train loss: 0.0052864498, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2922, Train loss: 0.0052867423, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2923, Train loss: 0.0052864667, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2924, Train loss: 0.0052858661, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2925, Train loss: 0.0052860872, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2926, Train loss: 0.0052861906, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2927, Train loss: 0.0052864557, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2928, Train loss: 0.0052866125, Validation loss: 0.0053139028, LR: 1.0000000000000004e-08\n",
      "Epoch 2929, Train loss: 0.0052865793, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2930, Train loss: 0.0052867435, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2931, Train loss: 0.0052862959, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2932, Train loss: 0.0052853209, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2933, Train loss: 0.0052860704, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2934, Train loss: 0.0052867606, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2935, Train loss: 0.0052867663, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2936, Train loss: 0.0052865578, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2937, Train loss: 0.0052857617, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2938, Train loss: 0.0052864094, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2939, Train loss: 0.0052861317, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2940, Train loss: 0.0052863513, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2941, Train loss: 0.0052861696, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2942, Train loss: 0.0052866304, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2943, Train loss: 0.0052874743, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 2944, Train loss: 0.0052861709, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2945, Train loss: 0.0052869809, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 2946, Train loss: 0.0052860510, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2947, Train loss: 0.0052864092, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2948, Train loss: 0.0052857968, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2949, Train loss: 0.0052863401, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2950, Train loss: 0.0052864733, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2951, Train loss: 0.0052864434, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2952, Train loss: 0.0052861985, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2953, Train loss: 0.0052865036, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2954, Train loss: 0.0052861030, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2955, Train loss: 0.0052860149, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2956, Train loss: 0.0052858147, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2957, Train loss: 0.0052866371, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2958, Train loss: 0.0052854826, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2959, Train loss: 0.0052861151, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 2960, Train loss: 0.0052851759, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2961, Train loss: 0.0052863731, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 2962, Train loss: 0.0052862944, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 2963, Train loss: 0.0052862790, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 2964, Train loss: 0.0052858178, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2965, Train loss: 0.0052865301, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2966, Train loss: 0.0052867121, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2967, Train loss: 0.0052860187, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2968, Train loss: 0.0052863105, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2969, Train loss: 0.0052868672, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2970, Train loss: 0.0052866600, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2971, Train loss: 0.0052865739, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2972, Train loss: 0.0052863238, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 2973, Train loss: 0.0052866022, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2974, Train loss: 0.0052871400, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2975, Train loss: 0.0052862855, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2976, Train loss: 0.0052868248, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 2977, Train loss: 0.0052871788, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2978, Train loss: 0.0052866348, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2979, Train loss: 0.0052865707, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2980, Train loss: 0.0052856483, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2981, Train loss: 0.0052865234, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2982, Train loss: 0.0052859260, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 2983, Train loss: 0.0052869645, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2984, Train loss: 0.0052861522, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2985, Train loss: 0.0052872173, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2986, Train loss: 0.0052865836, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2987, Train loss: 0.0052863392, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2988, Train loss: 0.0052869571, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2989, Train loss: 0.0052869670, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2990, Train loss: 0.0052867321, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2991, Train loss: 0.0052864355, Validation loss: 0.0053139026, LR: 1.0000000000000004e-08\n",
      "Epoch 2992, Train loss: 0.0052861089, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2993, Train loss: 0.0052856845, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2994, Train loss: 0.0052870058, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2995, Train loss: 0.0052865985, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2996, Train loss: 0.0052861633, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 2997, Train loss: 0.0052860999, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 2998, Train loss: 0.0052860660, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 2999, Train loss: 0.0052869262, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3000, Train loss: 0.0052864959, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 3001, Train loss: 0.0052860424, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 3002, Train loss: 0.0052854729, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3003, Train loss: 0.0052857528, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 3004, Train loss: 0.0052859264, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3005, Train loss: 0.0052865510, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3006, Train loss: 0.0052864825, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 3007, Train loss: 0.0052859730, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 3008, Train loss: 0.0052865455, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 3009, Train loss: 0.0052866326, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 3010, Train loss: 0.0052861517, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3011, Train loss: 0.0052866875, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3012, Train loss: 0.0052862606, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3013, Train loss: 0.0052866296, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3014, Train loss: 0.0052860352, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3015, Train loss: 0.0052866636, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3016, Train loss: 0.0052862060, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 3017, Train loss: 0.0052871615, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3018, Train loss: 0.0052865206, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3019, Train loss: 0.0052862677, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3020, Train loss: 0.0052867212, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 3021, Train loss: 0.0052867697, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3022, Train loss: 0.0052856416, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3023, Train loss: 0.0052866363, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 3024, Train loss: 0.0052869137, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3025, Train loss: 0.0052869276, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 3026, Train loss: 0.0052869560, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 3027, Train loss: 0.0052866137, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3028, Train loss: 0.0052865055, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3029, Train loss: 0.0052869672, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3030, Train loss: 0.0052865348, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3031, Train loss: 0.0052856371, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3032, Train loss: 0.0052861795, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3033, Train loss: 0.0052862722, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3034, Train loss: 0.0052866127, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 3035, Train loss: 0.0052863820, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3036, Train loss: 0.0052873052, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3037, Train loss: 0.0052859304, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3038, Train loss: 0.0052862230, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 3039, Train loss: 0.0052871277, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3040, Train loss: 0.0052864971, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3041, Train loss: 0.0052864910, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3042, Train loss: 0.0052867912, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3043, Train loss: 0.0052863810, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3044, Train loss: 0.0052860145, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3045, Train loss: 0.0052863542, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3046, Train loss: 0.0052867191, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3047, Train loss: 0.0052870620, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3048, Train loss: 0.0052854482, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3049, Train loss: 0.0052865984, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3050, Train loss: 0.0052856115, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3051, Train loss: 0.0052867029, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3052, Train loss: 0.0052865887, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3053, Train loss: 0.0052859069, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3054, Train loss: 0.0052867962, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3055, Train loss: 0.0052869480, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3056, Train loss: 0.0052862804, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3057, Train loss: 0.0052862735, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3058, Train loss: 0.0052866823, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3059, Train loss: 0.0052857306, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3060, Train loss: 0.0052860895, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3061, Train loss: 0.0052863975, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3062, Train loss: 0.0052856882, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3063, Train loss: 0.0052867708, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3064, Train loss: 0.0052868999, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3065, Train loss: 0.0052863070, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 3066, Train loss: 0.0052859680, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3067, Train loss: 0.0052856893, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3068, Train loss: 0.0052867083, Validation loss: 0.0053139025, LR: 1.0000000000000004e-08\n",
      "Epoch 3069, Train loss: 0.0052860669, Validation loss: 0.0053139027, LR: 1.0000000000000004e-08\n",
      "Epoch 3070, Train loss: 0.0052867839, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3071, Train loss: 0.0052858908, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3072, Train loss: 0.0052863395, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3073, Train loss: 0.0052869496, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3074, Train loss: 0.0052857918, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3075, Train loss: 0.0052865432, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3076, Train loss: 0.0052862402, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3077, Train loss: 0.0052869301, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3078, Train loss: 0.0052867002, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3079, Train loss: 0.0052865423, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3080, Train loss: 0.0052864626, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3081, Train loss: 0.0052861682, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3082, Train loss: 0.0052864858, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3083, Train loss: 0.0052864550, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3084, Train loss: 0.0052858752, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3085, Train loss: 0.0052868220, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3086, Train loss: 0.0052865659, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3087, Train loss: 0.0052862324, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3088, Train loss: 0.0052860745, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3089, Train loss: 0.0052866581, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3090, Train loss: 0.0052866843, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3091, Train loss: 0.0052860122, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3092, Train loss: 0.0052865687, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3093, Train loss: 0.0052864039, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3094, Train loss: 0.0052862265, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3095, Train loss: 0.0052865554, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3096, Train loss: 0.0052862448, Validation loss: 0.0053139024, LR: 1.0000000000000004e-08\n",
      "Epoch 3097, Train loss: 0.0052863582, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3098, Train loss: 0.0052865709, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3099, Train loss: 0.0052866862, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3100, Train loss: 0.0052866388, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3101, Train loss: 0.0052861393, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3102, Train loss: 0.0052870717, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3103, Train loss: 0.0052862688, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3104, Train loss: 0.0052865854, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3105, Train loss: 0.0052864464, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3106, Train loss: 0.0052869883, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3107, Train loss: 0.0052859003, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3108, Train loss: 0.0052867343, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3109, Train loss: 0.0052855454, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3110, Train loss: 0.0052866051, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3111, Train loss: 0.0052863372, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3112, Train loss: 0.0052860606, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3113, Train loss: 0.0052860859, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3114, Train loss: 0.0052857487, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3115, Train loss: 0.0052866515, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3116, Train loss: 0.0052869245, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3117, Train loss: 0.0052869718, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3118, Train loss: 0.0052870257, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3119, Train loss: 0.0052863660, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3120, Train loss: 0.0052866340, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3121, Train loss: 0.0052868542, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3122, Train loss: 0.0052860137, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3123, Train loss: 0.0052858287, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3124, Train loss: 0.0052865439, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3125, Train loss: 0.0052857376, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3126, Train loss: 0.0052854861, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3127, Train loss: 0.0052863045, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3128, Train loss: 0.0052861650, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3129, Train loss: 0.0052862365, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3130, Train loss: 0.0052861112, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3131, Train loss: 0.0052861960, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3132, Train loss: 0.0052862277, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3133, Train loss: 0.0052865226, Validation loss: 0.0053139022, LR: 1.0000000000000004e-08\n",
      "Epoch 3134, Train loss: 0.0052860922, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3135, Train loss: 0.0052866453, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3136, Train loss: 0.0052864404, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3137, Train loss: 0.0052859339, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3138, Train loss: 0.0052872714, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3139, Train loss: 0.0052859272, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3140, Train loss: 0.0052871181, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3141, Train loss: 0.0052867705, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3142, Train loss: 0.0052867266, Validation loss: 0.0053139023, LR: 1.0000000000000004e-08\n",
      "Epoch 3143, Train loss: 0.0052861424, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3144, Train loss: 0.0052867073, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3145, Train loss: 0.0052863106, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3146, Train loss: 0.0052862841, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3147, Train loss: 0.0052859874, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3148, Train loss: 0.0052868792, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3149, Train loss: 0.0052866060, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3150, Train loss: 0.0052864733, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3151, Train loss: 0.0052867731, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3152, Train loss: 0.0052858576, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3153, Train loss: 0.0052859148, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3154, Train loss: 0.0052866094, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3155, Train loss: 0.0052866761, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3156, Train loss: 0.0052860902, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3157, Train loss: 0.0052874647, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3158, Train loss: 0.0052868542, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3159, Train loss: 0.0052863762, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3160, Train loss: 0.0052855978, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3161, Train loss: 0.0052864990, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3162, Train loss: 0.0052861102, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3163, Train loss: 0.0052863864, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3164, Train loss: 0.0052866650, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3165, Train loss: 0.0052864778, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3166, Train loss: 0.0052868451, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3167, Train loss: 0.0052867833, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3168, Train loss: 0.0052858187, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3169, Train loss: 0.0052863021, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3170, Train loss: 0.0052864358, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3171, Train loss: 0.0052863357, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3172, Train loss: 0.0052859366, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3173, Train loss: 0.0052861700, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3174, Train loss: 0.0052858205, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3175, Train loss: 0.0052868308, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3176, Train loss: 0.0052848755, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3177, Train loss: 0.0052863043, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3178, Train loss: 0.0052858315, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3179, Train loss: 0.0052862277, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3180, Train loss: 0.0052857850, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3181, Train loss: 0.0052859511, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3182, Train loss: 0.0052866108, Validation loss: 0.0053139021, LR: 1.0000000000000004e-08\n",
      "Epoch 3183, Train loss: 0.0052869085, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3184, Train loss: 0.0052857878, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3185, Train loss: 0.0052860723, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3186, Train loss: 0.0052868551, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3187, Train loss: 0.0052855766, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3188, Train loss: 0.0052862070, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3189, Train loss: 0.0052862197, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3190, Train loss: 0.0052865171, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3191, Train loss: 0.0052855479, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3192, Train loss: 0.0052869664, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3193, Train loss: 0.0052869894, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3194, Train loss: 0.0052868177, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3195, Train loss: 0.0052864373, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3196, Train loss: 0.0052865504, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3197, Train loss: 0.0052863345, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3198, Train loss: 0.0052865993, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3199, Train loss: 0.0052860238, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3200, Train loss: 0.0052865833, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3201, Train loss: 0.0052858819, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3202, Train loss: 0.0052867312, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3203, Train loss: 0.0052866206, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3204, Train loss: 0.0052861232, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3205, Train loss: 0.0052862598, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3206, Train loss: 0.0052873325, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3207, Train loss: 0.0052872130, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3208, Train loss: 0.0052865799, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3209, Train loss: 0.0052866049, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3210, Train loss: 0.0052855069, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3211, Train loss: 0.0052863974, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3212, Train loss: 0.0052865382, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3213, Train loss: 0.0052863784, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3214, Train loss: 0.0052861635, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3215, Train loss: 0.0052860712, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3216, Train loss: 0.0052857650, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3217, Train loss: 0.0052868069, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3218, Train loss: 0.0052869098, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3219, Train loss: 0.0052863765, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3220, Train loss: 0.0052863054, Validation loss: 0.0053139020, LR: 1.0000000000000004e-08\n",
      "Epoch 3221, Train loss: 0.0052864777, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3222, Train loss: 0.0052866959, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3223, Train loss: 0.0052868487, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3224, Train loss: 0.0052863326, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3225, Train loss: 0.0052865865, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3226, Train loss: 0.0052865688, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3227, Train loss: 0.0052865268, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3228, Train loss: 0.0052867006, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3229, Train loss: 0.0052860913, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3230, Train loss: 0.0052861933, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3231, Train loss: 0.0052860836, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3232, Train loss: 0.0052857696, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3233, Train loss: 0.0052866680, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3234, Train loss: 0.0052874600, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3235, Train loss: 0.0052864407, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3236, Train loss: 0.0052862156, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3237, Train loss: 0.0052858660, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3238, Train loss: 0.0052865838, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3239, Train loss: 0.0052864994, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3240, Train loss: 0.0052861504, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3241, Train loss: 0.0052863085, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3242, Train loss: 0.0052871768, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3243, Train loss: 0.0052857226, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3244, Train loss: 0.0052862194, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3245, Train loss: 0.0052857571, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3246, Train loss: 0.0052868833, Validation loss: 0.0053139019, LR: 1.0000000000000004e-08\n",
      "Epoch 3247, Train loss: 0.0052872729, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3248, Train loss: 0.0052854473, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3249, Train loss: 0.0052853341, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3250, Train loss: 0.0052864704, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3251, Train loss: 0.0052861269, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3252, Train loss: 0.0052858871, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3253, Train loss: 0.0052867580, Validation loss: 0.0053139018, LR: 1.0000000000000004e-08\n",
      "Epoch 3254, Train loss: 0.0052863142, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3255, Train loss: 0.0052867821, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3256, Train loss: 0.0052862258, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3257, Train loss: 0.0052868158, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3258, Train loss: 0.0052859358, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3259, Train loss: 0.0052862122, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3260, Train loss: 0.0052860533, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3261, Train loss: 0.0052858941, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3262, Train loss: 0.0052865572, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3263, Train loss: 0.0052860580, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3264, Train loss: 0.0052870482, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3265, Train loss: 0.0052859859, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3266, Train loss: 0.0052863700, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3267, Train loss: 0.0052864240, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3268, Train loss: 0.0052864275, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3269, Train loss: 0.0052859076, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3270, Train loss: 0.0052868887, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3271, Train loss: 0.0052862592, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3272, Train loss: 0.0052862898, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3273, Train loss: 0.0052869687, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3274, Train loss: 0.0052869988, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3275, Train loss: 0.0052852998, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3276, Train loss: 0.0052866815, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3277, Train loss: 0.0052863269, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3278, Train loss: 0.0052855027, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3279, Train loss: 0.0052866694, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3280, Train loss: 0.0052867056, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3281, Train loss: 0.0052858204, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3282, Train loss: 0.0052867613, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3283, Train loss: 0.0052860356, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3284, Train loss: 0.0052866409, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3285, Train loss: 0.0052863762, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3286, Train loss: 0.0052857561, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3287, Train loss: 0.0052865597, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3288, Train loss: 0.0052854762, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3289, Train loss: 0.0052858309, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3290, Train loss: 0.0052862381, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3291, Train loss: 0.0052865388, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3292, Train loss: 0.0052860180, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3293, Train loss: 0.0052860013, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3294, Train loss: 0.0052862761, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3295, Train loss: 0.0052867486, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3296, Train loss: 0.0052857857, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3297, Train loss: 0.0052864187, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3298, Train loss: 0.0052865342, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3299, Train loss: 0.0052863143, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3300, Train loss: 0.0052859265, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3301, Train loss: 0.0052862388, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3302, Train loss: 0.0052861394, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3303, Train loss: 0.0052861415, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3304, Train loss: 0.0052875351, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3305, Train loss: 0.0052866310, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3306, Train loss: 0.0052860607, Validation loss: 0.0053139017, LR: 1.0000000000000004e-08\n",
      "Epoch 3307, Train loss: 0.0052860050, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3308, Train loss: 0.0052865214, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3309, Train loss: 0.0052868085, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3310, Train loss: 0.0052858322, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3311, Train loss: 0.0052871855, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3312, Train loss: 0.0052864733, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3313, Train loss: 0.0052857666, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3314, Train loss: 0.0052859300, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3315, Train loss: 0.0052863555, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3316, Train loss: 0.0052854442, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3317, Train loss: 0.0052862577, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3318, Train loss: 0.0052863261, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3319, Train loss: 0.0052862748, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3320, Train loss: 0.0052872117, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3321, Train loss: 0.0052863000, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3322, Train loss: 0.0052874781, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3323, Train loss: 0.0052867344, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3324, Train loss: 0.0052866291, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3325, Train loss: 0.0052860949, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3326, Train loss: 0.0052865568, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3327, Train loss: 0.0052869770, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3328, Train loss: 0.0052866041, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3329, Train loss: 0.0052864448, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3330, Train loss: 0.0052865021, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3331, Train loss: 0.0052865231, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3332, Train loss: 0.0052864413, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3333, Train loss: 0.0052858128, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3334, Train loss: 0.0052862833, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3335, Train loss: 0.0052859066, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3336, Train loss: 0.0052866151, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3337, Train loss: 0.0052864439, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3338, Train loss: 0.0052865205, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3339, Train loss: 0.0052858103, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3340, Train loss: 0.0052858957, Validation loss: 0.0053139015, LR: 1.0000000000000004e-08\n",
      "Epoch 3341, Train loss: 0.0052862077, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3342, Train loss: 0.0052867512, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3343, Train loss: 0.0052863152, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3344, Train loss: 0.0052858311, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3345, Train loss: 0.0052863939, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3346, Train loss: 0.0052864978, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3347, Train loss: 0.0052862577, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3348, Train loss: 0.0052863581, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3349, Train loss: 0.0052867549, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3350, Train loss: 0.0052864676, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3351, Train loss: 0.0052872366, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3352, Train loss: 0.0052863194, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3353, Train loss: 0.0052857521, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3354, Train loss: 0.0052869020, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3355, Train loss: 0.0052862392, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3356, Train loss: 0.0052864814, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3357, Train loss: 0.0052869473, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3358, Train loss: 0.0052863145, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3359, Train loss: 0.0052868464, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3360, Train loss: 0.0052855804, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3361, Train loss: 0.0052863436, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3362, Train loss: 0.0052854041, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3363, Train loss: 0.0052859682, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3364, Train loss: 0.0052864666, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3365, Train loss: 0.0052866201, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3366, Train loss: 0.0052867361, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3367, Train loss: 0.0052863484, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3368, Train loss: 0.0052867510, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3369, Train loss: 0.0052859610, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3370, Train loss: 0.0052861452, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3371, Train loss: 0.0052869592, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3372, Train loss: 0.0052860139, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3373, Train loss: 0.0052853742, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3374, Train loss: 0.0052854130, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3375, Train loss: 0.0052860384, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3376, Train loss: 0.0052865291, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3377, Train loss: 0.0052857337, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3378, Train loss: 0.0052860575, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3379, Train loss: 0.0052863571, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3380, Train loss: 0.0052866998, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3381, Train loss: 0.0052865772, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3382, Train loss: 0.0052864182, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3383, Train loss: 0.0052867825, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3384, Train loss: 0.0052864495, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3385, Train loss: 0.0052855382, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3386, Train loss: 0.0052864030, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3387, Train loss: 0.0052868001, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3388, Train loss: 0.0052867057, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3389, Train loss: 0.0052858797, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3390, Train loss: 0.0052863363, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3391, Train loss: 0.0052868249, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3392, Train loss: 0.0052856976, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3393, Train loss: 0.0052864950, Validation loss: 0.0053139014, LR: 1.0000000000000004e-08\n",
      "Epoch 3394, Train loss: 0.0052866625, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3395, Train loss: 0.0052861407, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3396, Train loss: 0.0052861516, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3397, Train loss: 0.0052863770, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3398, Train loss: 0.0052862532, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3399, Train loss: 0.0052865793, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3400, Train loss: 0.0052871036, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3401, Train loss: 0.0052858407, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3402, Train loss: 0.0052869576, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3403, Train loss: 0.0052860747, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3404, Train loss: 0.0052866310, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3405, Train loss: 0.0052862312, Validation loss: 0.0053139016, LR: 1.0000000000000004e-08\n",
      "Epoch 3406, Train loss: 0.0052858372, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3407, Train loss: 0.0052863386, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3408, Train loss: 0.0052867610, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3409, Train loss: 0.0052860567, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3410, Train loss: 0.0052871831, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3411, Train loss: 0.0052860975, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3412, Train loss: 0.0052862045, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3413, Train loss: 0.0052855834, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3414, Train loss: 0.0052865562, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3415, Train loss: 0.0052869536, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3416, Train loss: 0.0052853437, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3417, Train loss: 0.0052862958, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3418, Train loss: 0.0052857225, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3419, Train loss: 0.0052863636, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3420, Train loss: 0.0052857631, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3421, Train loss: 0.0052866737, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3422, Train loss: 0.0052857966, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3423, Train loss: 0.0052864083, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3424, Train loss: 0.0052859824, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3425, Train loss: 0.0052859386, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3426, Train loss: 0.0052859387, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3427, Train loss: 0.0052858219, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3428, Train loss: 0.0052869739, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3429, Train loss: 0.0052867303, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3430, Train loss: 0.0052859546, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3431, Train loss: 0.0052865534, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3432, Train loss: 0.0052859617, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3433, Train loss: 0.0052867910, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3434, Train loss: 0.0052862686, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3435, Train loss: 0.0052863831, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3436, Train loss: 0.0052865897, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3437, Train loss: 0.0052868316, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3438, Train loss: 0.0052870663, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3439, Train loss: 0.0052861718, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3440, Train loss: 0.0052859257, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3441, Train loss: 0.0052867764, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3442, Train loss: 0.0052857322, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3443, Train loss: 0.0052862314, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3444, Train loss: 0.0052852045, Validation loss: 0.0053139013, LR: 1.0000000000000004e-08\n",
      "Epoch 3445, Train loss: 0.0052859052, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3446, Train loss: 0.0052862925, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3447, Train loss: 0.0052866223, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3448, Train loss: 0.0052861930, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3449, Train loss: 0.0052867730, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3450, Train loss: 0.0052863779, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3451, Train loss: 0.0052866998, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3452, Train loss: 0.0052865759, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3453, Train loss: 0.0052853071, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3454, Train loss: 0.0052867854, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3455, Train loss: 0.0052863138, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3456, Train loss: 0.0052871748, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3457, Train loss: 0.0052865415, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3458, Train loss: 0.0052863478, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3459, Train loss: 0.0052868293, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3460, Train loss: 0.0052869901, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3461, Train loss: 0.0052864894, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3462, Train loss: 0.0052861602, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3463, Train loss: 0.0052848620, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3464, Train loss: 0.0052866244, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3465, Train loss: 0.0052858357, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3466, Train loss: 0.0052861457, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3467, Train loss: 0.0052863774, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3468, Train loss: 0.0052868479, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3469, Train loss: 0.0052863156, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3470, Train loss: 0.0052862811, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3471, Train loss: 0.0052869399, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3472, Train loss: 0.0052864476, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3473, Train loss: 0.0052864403, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3474, Train loss: 0.0052869075, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3475, Train loss: 0.0052867100, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3476, Train loss: 0.0052863071, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3477, Train loss: 0.0052869492, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3478, Train loss: 0.0052858589, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3479, Train loss: 0.0052859642, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3480, Train loss: 0.0052862628, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3481, Train loss: 0.0052857834, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3482, Train loss: 0.0052861697, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3483, Train loss: 0.0052861637, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3484, Train loss: 0.0052866980, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3485, Train loss: 0.0052856960, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3486, Train loss: 0.0052861407, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3487, Train loss: 0.0052865902, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3488, Train loss: 0.0052866143, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3489, Train loss: 0.0052858586, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3490, Train loss: 0.0052866350, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3491, Train loss: 0.0052862155, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3492, Train loss: 0.0052860289, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3493, Train loss: 0.0052872057, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3494, Train loss: 0.0052861774, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3495, Train loss: 0.0052862764, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3496, Train loss: 0.0052865807, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3497, Train loss: 0.0052855777, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3498, Train loss: 0.0052855406, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3499, Train loss: 0.0052856570, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3500, Train loss: 0.0052852685, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3501, Train loss: 0.0052860631, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3502, Train loss: 0.0052859209, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3503, Train loss: 0.0052856233, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3504, Train loss: 0.0052859400, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3505, Train loss: 0.0052866972, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3506, Train loss: 0.0052857500, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3507, Train loss: 0.0052854208, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3508, Train loss: 0.0052863933, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3509, Train loss: 0.0052863023, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3510, Train loss: 0.0052864740, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3511, Train loss: 0.0052862494, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3512, Train loss: 0.0052865517, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3513, Train loss: 0.0052861939, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3514, Train loss: 0.0052861859, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3515, Train loss: 0.0052866661, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3516, Train loss: 0.0052861857, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3517, Train loss: 0.0052868054, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3518, Train loss: 0.0052866151, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3519, Train loss: 0.0052865394, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3520, Train loss: 0.0052861093, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3521, Train loss: 0.0052853708, Validation loss: 0.0053139012, LR: 1.0000000000000004e-08\n",
      "Epoch 3522, Train loss: 0.0052862845, Validation loss: 0.0053139011, LR: 1.0000000000000004e-08\n",
      "Epoch 3523, Train loss: 0.0052862554, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3524, Train loss: 0.0052863948, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3525, Train loss: 0.0052866599, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3526, Train loss: 0.0052866412, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3527, Train loss: 0.0052862925, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3528, Train loss: 0.0052863908, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3529, Train loss: 0.0052851872, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3530, Train loss: 0.0052859463, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3531, Train loss: 0.0052862930, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3532, Train loss: 0.0052867073, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3533, Train loss: 0.0052858464, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3534, Train loss: 0.0052855770, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3535, Train loss: 0.0052869935, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3536, Train loss: 0.0052863407, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3537, Train loss: 0.0052865121, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3538, Train loss: 0.0052859232, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3539, Train loss: 0.0052860079, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3540, Train loss: 0.0052861735, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3541, Train loss: 0.0052868351, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3542, Train loss: 0.0052864982, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3543, Train loss: 0.0052867205, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3544, Train loss: 0.0052863695, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3545, Train loss: 0.0052854251, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3546, Train loss: 0.0052865690, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3547, Train loss: 0.0052863070, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3548, Train loss: 0.0052859792, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3549, Train loss: 0.0052862822, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3550, Train loss: 0.0052863892, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3551, Train loss: 0.0052864570, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3552, Train loss: 0.0052863282, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3553, Train loss: 0.0052865075, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3554, Train loss: 0.0052877565, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3555, Train loss: 0.0052865060, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3556, Train loss: 0.0052860031, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3557, Train loss: 0.0052861632, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3558, Train loss: 0.0052868191, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3559, Train loss: 0.0052868843, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3560, Train loss: 0.0052857789, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3561, Train loss: 0.0052864874, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3562, Train loss: 0.0052866377, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3563, Train loss: 0.0052864655, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3564, Train loss: 0.0052868288, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3565, Train loss: 0.0052863450, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3566, Train loss: 0.0052873618, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3567, Train loss: 0.0052862656, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3568, Train loss: 0.0052866111, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3569, Train loss: 0.0052862380, Validation loss: 0.0053139010, LR: 1.0000000000000004e-08\n",
      "Epoch 3570, Train loss: 0.0052855940, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3571, Train loss: 0.0052872393, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3572, Train loss: 0.0052863219, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3573, Train loss: 0.0052862808, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3574, Train loss: 0.0052868683, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3575, Train loss: 0.0052857398, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3576, Train loss: 0.0052864136, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3577, Train loss: 0.0052869323, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3578, Train loss: 0.0052869817, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3579, Train loss: 0.0052870356, Validation loss: 0.0053139009, LR: 1.0000000000000004e-08\n",
      "Epoch 3580, Train loss: 0.0052862780, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3581, Train loss: 0.0052855689, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3582, Train loss: 0.0052865125, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3583, Train loss: 0.0052859232, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3584, Train loss: 0.0052870031, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3585, Train loss: 0.0052857349, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3586, Train loss: 0.0052860785, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3587, Train loss: 0.0052868937, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3588, Train loss: 0.0052856686, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3589, Train loss: 0.0052867848, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3590, Train loss: 0.0052863975, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3591, Train loss: 0.0052867501, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3592, Train loss: 0.0052861925, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3593, Train loss: 0.0052859652, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3594, Train loss: 0.0052860021, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3595, Train loss: 0.0052866301, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3596, Train loss: 0.0052864999, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3597, Train loss: 0.0052859874, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3598, Train loss: 0.0052857209, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3599, Train loss: 0.0052863068, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3600, Train loss: 0.0052865427, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3601, Train loss: 0.0052861026, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3602, Train loss: 0.0052866895, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3603, Train loss: 0.0052861234, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3604, Train loss: 0.0052863497, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3605, Train loss: 0.0052865107, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3606, Train loss: 0.0052859840, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3607, Train loss: 0.0052864747, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3608, Train loss: 0.0052868071, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3609, Train loss: 0.0052864610, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3610, Train loss: 0.0052861917, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3611, Train loss: 0.0052858670, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3612, Train loss: 0.0052859925, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3613, Train loss: 0.0052863247, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3614, Train loss: 0.0052863699, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3615, Train loss: 0.0052862867, Validation loss: 0.0053139008, LR: 1.0000000000000004e-08\n",
      "Epoch 3616, Train loss: 0.0052861975, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3617, Train loss: 0.0052866914, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3618, Train loss: 0.0052861621, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3619, Train loss: 0.0052865769, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3620, Train loss: 0.0052865978, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3621, Train loss: 0.0052863936, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3622, Train loss: 0.0052857398, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3623, Train loss: 0.0052864385, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3624, Train loss: 0.0052860479, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3625, Train loss: 0.0052862219, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3626, Train loss: 0.0052866170, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3627, Train loss: 0.0052872059, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3628, Train loss: 0.0052864061, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3629, Train loss: 0.0052863441, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3630, Train loss: 0.0052857232, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3631, Train loss: 0.0052860716, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3632, Train loss: 0.0052870017, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3633, Train loss: 0.0052868302, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3634, Train loss: 0.0052864966, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3635, Train loss: 0.0052864206, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3636, Train loss: 0.0052870975, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3637, Train loss: 0.0052855982, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3638, Train loss: 0.0052866178, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3639, Train loss: 0.0052856006, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3640, Train loss: 0.0052861313, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3641, Train loss: 0.0052863818, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3642, Train loss: 0.0052867558, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3643, Train loss: 0.0052864208, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3644, Train loss: 0.0052867107, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3645, Train loss: 0.0052862423, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3646, Train loss: 0.0052855674, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3647, Train loss: 0.0052862229, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3648, Train loss: 0.0052870027, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3649, Train loss: 0.0052861389, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3650, Train loss: 0.0052863541, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3651, Train loss: 0.0052862160, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3652, Train loss: 0.0052867110, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3653, Train loss: 0.0052855704, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3654, Train loss: 0.0052866000, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3655, Train loss: 0.0052866574, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3656, Train loss: 0.0052859975, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3657, Train loss: 0.0052862815, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3658, Train loss: 0.0052864581, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3659, Train loss: 0.0052865002, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3660, Train loss: 0.0052868241, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3661, Train loss: 0.0052863059, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3662, Train loss: 0.0052868250, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3663, Train loss: 0.0052857734, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3664, Train loss: 0.0052864505, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3665, Train loss: 0.0052862994, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3666, Train loss: 0.0052867777, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3667, Train loss: 0.0052859080, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3668, Train loss: 0.0052861126, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3669, Train loss: 0.0052858512, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3670, Train loss: 0.0052861759, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3671, Train loss: 0.0052858941, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3672, Train loss: 0.0052863384, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3673, Train loss: 0.0052856893, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3674, Train loss: 0.0052864352, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3675, Train loss: 0.0052859803, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3676, Train loss: 0.0052863537, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3677, Train loss: 0.0052864270, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3678, Train loss: 0.0052859601, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3679, Train loss: 0.0052862092, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3680, Train loss: 0.0052858061, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3681, Train loss: 0.0052862454, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3682, Train loss: 0.0052864596, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3683, Train loss: 0.0052861934, Validation loss: 0.0053139006, LR: 1.0000000000000004e-08\n",
      "Epoch 3684, Train loss: 0.0052864603, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3685, Train loss: 0.0052867661, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3686, Train loss: 0.0052862473, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3687, Train loss: 0.0052857873, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3688, Train loss: 0.0052869310, Validation loss: 0.0053139007, LR: 1.0000000000000004e-08\n",
      "Epoch 3689, Train loss: 0.0052860580, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3690, Train loss: 0.0052868826, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3691, Train loss: 0.0052855630, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3692, Train loss: 0.0052865282, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3693, Train loss: 0.0052863415, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3694, Train loss: 0.0052860239, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3695, Train loss: 0.0052863214, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3696, Train loss: 0.0052860195, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3697, Train loss: 0.0052871002, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3698, Train loss: 0.0052869607, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3699, Train loss: 0.0052865452, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3700, Train loss: 0.0052868376, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3701, Train loss: 0.0052866253, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3702, Train loss: 0.0052860860, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3703, Train loss: 0.0052856316, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3704, Train loss: 0.0052861769, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3705, Train loss: 0.0052860437, Validation loss: 0.0053139005, LR: 1.0000000000000004e-08\n",
      "Epoch 3706, Train loss: 0.0052858442, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3707, Train loss: 0.0052872873, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3708, Train loss: 0.0052866060, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3709, Train loss: 0.0052856913, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3710, Train loss: 0.0052861978, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3711, Train loss: 0.0052868719, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3712, Train loss: 0.0052868690, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3713, Train loss: 0.0052863256, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3714, Train loss: 0.0052861113, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3715, Train loss: 0.0052860354, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3716, Train loss: 0.0052864034, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3717, Train loss: 0.0052860602, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3718, Train loss: 0.0052866125, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3719, Train loss: 0.0052868102, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3720, Train loss: 0.0052862186, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3721, Train loss: 0.0052864250, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3722, Train loss: 0.0052863015, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3723, Train loss: 0.0052859957, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3724, Train loss: 0.0052863385, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3725, Train loss: 0.0052865233, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3726, Train loss: 0.0052865292, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3727, Train loss: 0.0052864792, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3728, Train loss: 0.0052863804, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3729, Train loss: 0.0052860606, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3730, Train loss: 0.0052865882, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3731, Train loss: 0.0052867658, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3732, Train loss: 0.0052862549, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3733, Train loss: 0.0052866155, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3734, Train loss: 0.0052861508, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3735, Train loss: 0.0052855888, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3736, Train loss: 0.0052861605, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3737, Train loss: 0.0052859279, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3738, Train loss: 0.0052861610, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3739, Train loss: 0.0052862346, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3740, Train loss: 0.0052859810, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3741, Train loss: 0.0052859741, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3742, Train loss: 0.0052868651, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3743, Train loss: 0.0052857110, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3744, Train loss: 0.0052864020, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3745, Train loss: 0.0052858100, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3746, Train loss: 0.0052867386, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3747, Train loss: 0.0052873802, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3748, Train loss: 0.0052859576, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3749, Train loss: 0.0052859506, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3750, Train loss: 0.0052853868, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3751, Train loss: 0.0052868116, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3752, Train loss: 0.0052862685, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3753, Train loss: 0.0052862501, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3754, Train loss: 0.0052864216, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3755, Train loss: 0.0052866366, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3756, Train loss: 0.0052847517, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3757, Train loss: 0.0052857779, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3758, Train loss: 0.0052856221, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3759, Train loss: 0.0052868003, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3760, Train loss: 0.0052862462, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3761, Train loss: 0.0052861045, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3762, Train loss: 0.0052869010, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3763, Train loss: 0.0052864292, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3764, Train loss: 0.0052863543, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3765, Train loss: 0.0052863907, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3766, Train loss: 0.0052865016, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3767, Train loss: 0.0052868828, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3768, Train loss: 0.0052868506, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3769, Train loss: 0.0052859733, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3770, Train loss: 0.0052857350, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3771, Train loss: 0.0052866525, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3772, Train loss: 0.0052855548, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3773, Train loss: 0.0052862644, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3774, Train loss: 0.0052867112, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3775, Train loss: 0.0052863923, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3776, Train loss: 0.0052866345, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3777, Train loss: 0.0052860987, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3778, Train loss: 0.0052870537, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3779, Train loss: 0.0052863556, Validation loss: 0.0053139004, LR: 1.0000000000000004e-08\n",
      "Epoch 3780, Train loss: 0.0052860934, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3781, Train loss: 0.0052865577, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3782, Train loss: 0.0052868544, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3783, Train loss: 0.0052861921, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3784, Train loss: 0.0052860198, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3785, Train loss: 0.0052856434, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3786, Train loss: 0.0052870984, Validation loss: 0.0053139003, LR: 1.0000000000000004e-08\n",
      "Epoch 3787, Train loss: 0.0052869895, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3788, Train loss: 0.0052868439, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3789, Train loss: 0.0052865283, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3790, Train loss: 0.0052866439, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3791, Train loss: 0.0052862213, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3792, Train loss: 0.0052861814, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3793, Train loss: 0.0052863037, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3794, Train loss: 0.0052861613, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3795, Train loss: 0.0052865329, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3796, Train loss: 0.0052864256, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3797, Train loss: 0.0052865674, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3798, Train loss: 0.0052862796, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3799, Train loss: 0.0052865563, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3800, Train loss: 0.0052862474, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3801, Train loss: 0.0052868232, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3802, Train loss: 0.0052864489, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3803, Train loss: 0.0052862750, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3804, Train loss: 0.0052859861, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3805, Train loss: 0.0052854626, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3806, Train loss: 0.0052862390, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3807, Train loss: 0.0052866175, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3808, Train loss: 0.0052863042, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3809, Train loss: 0.0052865768, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3810, Train loss: 0.0052868460, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3811, Train loss: 0.0052860866, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3812, Train loss: 0.0052861666, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3813, Train loss: 0.0052861603, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3814, Train loss: 0.0052852684, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3815, Train loss: 0.0052869842, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3816, Train loss: 0.0052863975, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3817, Train loss: 0.0052873042, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3818, Train loss: 0.0052859510, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3819, Train loss: 0.0052857366, Validation loss: 0.0053139002, LR: 1.0000000000000004e-08\n",
      "Epoch 3820, Train loss: 0.0052866766, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3821, Train loss: 0.0052868628, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3822, Train loss: 0.0052861274, Validation loss: 0.0053139001, LR: 1.0000000000000004e-08\n",
      "Epoch 3823, Train loss: 0.0052861785, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3824, Train loss: 0.0052865397, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3825, Train loss: 0.0052859834, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3826, Train loss: 0.0052863667, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3827, Train loss: 0.0052871339, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3828, Train loss: 0.0052864003, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3829, Train loss: 0.0052867457, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3830, Train loss: 0.0052865652, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3831, Train loss: 0.0052860450, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3832, Train loss: 0.0052857387, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3833, Train loss: 0.0052868437, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3834, Train loss: 0.0052863584, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3835, Train loss: 0.0052866129, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3836, Train loss: 0.0052866014, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3837, Train loss: 0.0052864576, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3838, Train loss: 0.0052855723, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3839, Train loss: 0.0052865275, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3840, Train loss: 0.0052858265, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3841, Train loss: 0.0052865814, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3842, Train loss: 0.0052864771, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3843, Train loss: 0.0052861888, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3844, Train loss: 0.0052858222, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3845, Train loss: 0.0052856860, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3846, Train loss: 0.0052868608, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3847, Train loss: 0.0052860515, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3848, Train loss: 0.0052857180, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3849, Train loss: 0.0052860269, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3850, Train loss: 0.0052859093, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3851, Train loss: 0.0052871009, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3852, Train loss: 0.0052862442, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3853, Train loss: 0.0052872618, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3854, Train loss: 0.0052862242, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3855, Train loss: 0.0052858005, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3856, Train loss: 0.0052861561, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3857, Train loss: 0.0052861465, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3858, Train loss: 0.0052865811, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3859, Train loss: 0.0052859534, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3860, Train loss: 0.0052865039, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3861, Train loss: 0.0052863916, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3862, Train loss: 0.0052865282, Validation loss: 0.0053139000, LR: 1.0000000000000004e-08\n",
      "Epoch 3863, Train loss: 0.0052855919, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3864, Train loss: 0.0052856492, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3865, Train loss: 0.0052862227, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3866, Train loss: 0.0052858346, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3867, Train loss: 0.0052856004, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3868, Train loss: 0.0052865699, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3869, Train loss: 0.0052866221, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3870, Train loss: 0.0052861261, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3871, Train loss: 0.0052859871, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3872, Train loss: 0.0052862354, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3873, Train loss: 0.0052859281, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3874, Train loss: 0.0052860814, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3875, Train loss: 0.0052861844, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3876, Train loss: 0.0052862715, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3877, Train loss: 0.0052867067, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3878, Train loss: 0.0052855952, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3879, Train loss: 0.0052861671, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3880, Train loss: 0.0052862103, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3881, Train loss: 0.0052862875, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3882, Train loss: 0.0052866045, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3883, Train loss: 0.0052860364, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3884, Train loss: 0.0052862536, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3885, Train loss: 0.0052867561, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3886, Train loss: 0.0052869537, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3887, Train loss: 0.0052861286, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3888, Train loss: 0.0052865458, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3889, Train loss: 0.0052857967, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3890, Train loss: 0.0052864513, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3891, Train loss: 0.0052860416, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3892, Train loss: 0.0052854029, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3893, Train loss: 0.0052868582, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3894, Train loss: 0.0052863790, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3895, Train loss: 0.0052864490, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3896, Train loss: 0.0052864138, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3897, Train loss: 0.0052857131, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3898, Train loss: 0.0052867511, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3899, Train loss: 0.0052865005, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3900, Train loss: 0.0052857102, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3901, Train loss: 0.0052862496, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3902, Train loss: 0.0052864774, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3903, Train loss: 0.0052869185, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3904, Train loss: 0.0052868453, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3905, Train loss: 0.0052868596, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3906, Train loss: 0.0052859984, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3907, Train loss: 0.0052866075, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3908, Train loss: 0.0052850429, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3909, Train loss: 0.0052871035, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3910, Train loss: 0.0052861485, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3911, Train loss: 0.0052846019, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3912, Train loss: 0.0052863885, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3913, Train loss: 0.0052851429, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3914, Train loss: 0.0052863379, Validation loss: 0.0053138999, LR: 1.0000000000000004e-08\n",
      "Epoch 3915, Train loss: 0.0052861832, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3916, Train loss: 0.0052866752, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3917, Train loss: 0.0052864089, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3918, Train loss: 0.0052861580, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3919, Train loss: 0.0052866857, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3920, Train loss: 0.0052860088, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3921, Train loss: 0.0052860452, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3922, Train loss: 0.0052868867, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3923, Train loss: 0.0052858146, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3924, Train loss: 0.0052866774, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3925, Train loss: 0.0052861547, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3926, Train loss: 0.0052860920, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3927, Train loss: 0.0052863386, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3928, Train loss: 0.0052868513, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3929, Train loss: 0.0052862957, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3930, Train loss: 0.0052856021, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3931, Train loss: 0.0052860762, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3932, Train loss: 0.0052862543, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3933, Train loss: 0.0052858832, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3934, Train loss: 0.0052869293, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3935, Train loss: 0.0052858938, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3936, Train loss: 0.0052868351, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3937, Train loss: 0.0052868580, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3938, Train loss: 0.0052855403, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3939, Train loss: 0.0052863964, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 3940, Train loss: 0.0052864953, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3941, Train loss: 0.0052856570, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3942, Train loss: 0.0052851751, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3943, Train loss: 0.0052857033, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3944, Train loss: 0.0052863109, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3945, Train loss: 0.0052864683, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3946, Train loss: 0.0052861757, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3947, Train loss: 0.0052861269, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3948, Train loss: 0.0052863378, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3949, Train loss: 0.0052859791, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3950, Train loss: 0.0052863659, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3951, Train loss: 0.0052866811, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3952, Train loss: 0.0052864912, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3953, Train loss: 0.0052864139, Validation loss: 0.0053138998, LR: 1.0000000000000004e-08\n",
      "Epoch 3954, Train loss: 0.0052862878, Validation loss: 0.0053138996, LR: 1.0000000000000004e-08\n",
      "Epoch 3955, Train loss: 0.0052862650, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3956, Train loss: 0.0052863175, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3957, Train loss: 0.0052861473, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3958, Train loss: 0.0052858863, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3959, Train loss: 0.0052862389, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3960, Train loss: 0.0052862647, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3961, Train loss: 0.0052869221, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3962, Train loss: 0.0052870526, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 3963, Train loss: 0.0052855896, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3964, Train loss: 0.0052863890, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3965, Train loss: 0.0052867587, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 3966, Train loss: 0.0052865146, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3967, Train loss: 0.0052864878, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3968, Train loss: 0.0052867351, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 3969, Train loss: 0.0052864065, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3970, Train loss: 0.0052863454, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 3971, Train loss: 0.0052861830, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 3972, Train loss: 0.0052867833, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3973, Train loss: 0.0052869544, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 3974, Train loss: 0.0052865692, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3975, Train loss: 0.0052867044, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3976, Train loss: 0.0052866053, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3977, Train loss: 0.0052859395, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 3978, Train loss: 0.0052866386, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 3979, Train loss: 0.0052863482, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 3980, Train loss: 0.0052864170, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3981, Train loss: 0.0052866099, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 3982, Train loss: 0.0052867754, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 3983, Train loss: 0.0052861043, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3984, Train loss: 0.0052866107, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3985, Train loss: 0.0052859864, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 3986, Train loss: 0.0052866549, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3987, Train loss: 0.0052862471, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 3988, Train loss: 0.0052859280, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 3989, Train loss: 0.0052869173, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 3990, Train loss: 0.0052875642, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3991, Train loss: 0.0052869451, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 3992, Train loss: 0.0052859657, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 3993, Train loss: 0.0052868727, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3994, Train loss: 0.0052862210, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 3995, Train loss: 0.0052865109, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 3996, Train loss: 0.0052860466, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 3997, Train loss: 0.0052860533, Validation loss: 0.0053138997, LR: 1.0000000000000004e-08\n",
      "Epoch 3998, Train loss: 0.0052866582, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 3999, Train loss: 0.0052858339, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 4000, Train loss: 0.0052863128, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 4001, Train loss: 0.0052860005, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 4002, Train loss: 0.0052870430, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 4003, Train loss: 0.0052859228, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 4004, Train loss: 0.0052869125, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4005, Train loss: 0.0052862679, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4006, Train loss: 0.0052862915, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4007, Train loss: 0.0052860200, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 4008, Train loss: 0.0052865680, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4009, Train loss: 0.0052865481, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 4010, Train loss: 0.0052865474, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4011, Train loss: 0.0052857724, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4012, Train loss: 0.0052867524, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4013, Train loss: 0.0052865011, Validation loss: 0.0053138995, LR: 1.0000000000000004e-08\n",
      "Epoch 4014, Train loss: 0.0052865009, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4015, Train loss: 0.0052868241, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 4016, Train loss: 0.0052861580, Validation loss: 0.0053138994, LR: 1.0000000000000004e-08\n",
      "Epoch 4017, Train loss: 0.0052859606, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4018, Train loss: 0.0052860195, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4019, Train loss: 0.0052854345, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4020, Train loss: 0.0052861155, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4021, Train loss: 0.0052861929, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4022, Train loss: 0.0052853497, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4023, Train loss: 0.0052859298, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4024, Train loss: 0.0052865363, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4025, Train loss: 0.0052860894, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4026, Train loss: 0.0052864377, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 4027, Train loss: 0.0052856416, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4028, Train loss: 0.0052862312, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4029, Train loss: 0.0052857577, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4030, Train loss: 0.0052856281, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 4031, Train loss: 0.0052867508, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4032, Train loss: 0.0052856805, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4033, Train loss: 0.0052867927, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4034, Train loss: 0.0052861994, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4035, Train loss: 0.0052860533, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4036, Train loss: 0.0052861359, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4037, Train loss: 0.0052860447, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4038, Train loss: 0.0052869399, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4039, Train loss: 0.0052859319, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4040, Train loss: 0.0052854988, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4041, Train loss: 0.0052862592, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4042, Train loss: 0.0052864460, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4043, Train loss: 0.0052862050, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4044, Train loss: 0.0052865917, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4045, Train loss: 0.0052860728, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4046, Train loss: 0.0052864020, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4047, Train loss: 0.0052863559, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4048, Train loss: 0.0052863954, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4049, Train loss: 0.0052868319, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4050, Train loss: 0.0052867892, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4051, Train loss: 0.0052856552, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4052, Train loss: 0.0052863128, Validation loss: 0.0053138993, LR: 1.0000000000000004e-08\n",
      "Epoch 4053, Train loss: 0.0052858561, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4054, Train loss: 0.0052858261, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4055, Train loss: 0.0052866095, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4056, Train loss: 0.0052869730, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4057, Train loss: 0.0052862024, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4058, Train loss: 0.0052863027, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4059, Train loss: 0.0052862385, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4060, Train loss: 0.0052857740, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4061, Train loss: 0.0052865999, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4062, Train loss: 0.0052863148, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4063, Train loss: 0.0052866977, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4064, Train loss: 0.0052860943, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4065, Train loss: 0.0052864082, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4066, Train loss: 0.0052861761, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4067, Train loss: 0.0052853766, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4068, Train loss: 0.0052866343, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4069, Train loss: 0.0052862266, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4070, Train loss: 0.0052864130, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4071, Train loss: 0.0052861099, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4072, Train loss: 0.0052856460, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4073, Train loss: 0.0052860855, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4074, Train loss: 0.0052866734, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4075, Train loss: 0.0052865055, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4076, Train loss: 0.0052868553, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4077, Train loss: 0.0052866123, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4078, Train loss: 0.0052863958, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4079, Train loss: 0.0052854112, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4080, Train loss: 0.0052862177, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4081, Train loss: 0.0052862704, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4082, Train loss: 0.0052860569, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4083, Train loss: 0.0052855513, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4084, Train loss: 0.0052864476, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4085, Train loss: 0.0052865749, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4086, Train loss: 0.0052858940, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4087, Train loss: 0.0052859549, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4088, Train loss: 0.0052862875, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4089, Train loss: 0.0052862352, Validation loss: 0.0053138992, LR: 1.0000000000000004e-08\n",
      "Epoch 4090, Train loss: 0.0052857967, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4091, Train loss: 0.0052862060, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4092, Train loss: 0.0052858258, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4093, Train loss: 0.0052867072, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4094, Train loss: 0.0052858404, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4095, Train loss: 0.0052865736, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4096, Train loss: 0.0052861222, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4097, Train loss: 0.0052863602, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4098, Train loss: 0.0052860090, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4099, Train loss: 0.0052863442, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4100, Train loss: 0.0052862282, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4101, Train loss: 0.0052867929, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4102, Train loss: 0.0052863077, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4103, Train loss: 0.0052857518, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4104, Train loss: 0.0052857422, Validation loss: 0.0053138991, LR: 1.0000000000000004e-08\n",
      "Epoch 4105, Train loss: 0.0052858992, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4106, Train loss: 0.0052865972, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4107, Train loss: 0.0052865291, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4108, Train loss: 0.0052857242, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4109, Train loss: 0.0052864773, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4110, Train loss: 0.0052869352, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4111, Train loss: 0.0052870038, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4112, Train loss: 0.0052861863, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4113, Train loss: 0.0052863324, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4114, Train loss: 0.0052862429, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4115, Train loss: 0.0052868557, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4116, Train loss: 0.0052863921, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4117, Train loss: 0.0052863748, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4118, Train loss: 0.0052869696, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4119, Train loss: 0.0052852098, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4120, Train loss: 0.0052861768, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4121, Train loss: 0.0052863753, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4122, Train loss: 0.0052868537, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4123, Train loss: 0.0052863924, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4124, Train loss: 0.0052857910, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4125, Train loss: 0.0052860867, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4126, Train loss: 0.0052862467, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4127, Train loss: 0.0052857507, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4128, Train loss: 0.0052856540, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4129, Train loss: 0.0052854326, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4130, Train loss: 0.0052861084, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4131, Train loss: 0.0052856832, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4132, Train loss: 0.0052865646, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4133, Train loss: 0.0052855788, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4134, Train loss: 0.0052867874, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4135, Train loss: 0.0052859385, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4136, Train loss: 0.0052861523, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4137, Train loss: 0.0052856444, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4138, Train loss: 0.0052864538, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4139, Train loss: 0.0052861603, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4140, Train loss: 0.0052852246, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4141, Train loss: 0.0052862697, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4142, Train loss: 0.0052869925, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4143, Train loss: 0.0052862606, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4144, Train loss: 0.0052865453, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4145, Train loss: 0.0052868082, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4146, Train loss: 0.0052863779, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4147, Train loss: 0.0052860748, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4148, Train loss: 0.0052861055, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4149, Train loss: 0.0052861631, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4150, Train loss: 0.0052861160, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4151, Train loss: 0.0052865913, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4152, Train loss: 0.0052863550, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4153, Train loss: 0.0052859076, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4154, Train loss: 0.0052859524, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4155, Train loss: 0.0052862266, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4156, Train loss: 0.0052861586, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4157, Train loss: 0.0052867242, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4158, Train loss: 0.0052863547, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4159, Train loss: 0.0052869371, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4160, Train loss: 0.0052867915, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4161, Train loss: 0.0052867654, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4162, Train loss: 0.0052866073, Validation loss: 0.0053138989, LR: 1.0000000000000004e-08\n",
      "Epoch 4163, Train loss: 0.0052863699, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4164, Train loss: 0.0052864414, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4165, Train loss: 0.0052863223, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4166, Train loss: 0.0052861841, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4167, Train loss: 0.0052871040, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4168, Train loss: 0.0052863757, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4169, Train loss: 0.0052865840, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4170, Train loss: 0.0052852974, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4171, Train loss: 0.0052865819, Validation loss: 0.0053138990, LR: 1.0000000000000004e-08\n",
      "Epoch 4172, Train loss: 0.0052863727, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4173, Train loss: 0.0052859845, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4174, Train loss: 0.0052854245, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4175, Train loss: 0.0052855361, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4176, Train loss: 0.0052863829, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4177, Train loss: 0.0052864066, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4178, Train loss: 0.0052859414, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4179, Train loss: 0.0052862154, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4180, Train loss: 0.0052861534, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4181, Train loss: 0.0052870861, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4182, Train loss: 0.0052863065, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4183, Train loss: 0.0052866642, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4184, Train loss: 0.0052863766, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4185, Train loss: 0.0052870982, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4186, Train loss: 0.0052867895, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4187, Train loss: 0.0052863995, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4188, Train loss: 0.0052864559, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4189, Train loss: 0.0052863529, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4190, Train loss: 0.0052854182, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4191, Train loss: 0.0052853761, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4192, Train loss: 0.0052870206, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4193, Train loss: 0.0052861735, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4194, Train loss: 0.0052862745, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4195, Train loss: 0.0052867850, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4196, Train loss: 0.0052862213, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4197, Train loss: 0.0052857915, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4198, Train loss: 0.0052869774, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4199, Train loss: 0.0052861341, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4200, Train loss: 0.0052861670, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4201, Train loss: 0.0052868066, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4202, Train loss: 0.0052860303, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4203, Train loss: 0.0052857929, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4204, Train loss: 0.0052865636, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4205, Train loss: 0.0052867555, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4206, Train loss: 0.0052860901, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4207, Train loss: 0.0052862340, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4208, Train loss: 0.0052864765, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4209, Train loss: 0.0052862384, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4210, Train loss: 0.0052861674, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4211, Train loss: 0.0052852867, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4212, Train loss: 0.0052866727, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4213, Train loss: 0.0052863128, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4214, Train loss: 0.0052865806, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4215, Train loss: 0.0052870016, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4216, Train loss: 0.0052862545, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4217, Train loss: 0.0052857690, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4218, Train loss: 0.0052858142, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4219, Train loss: 0.0052861646, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4220, Train loss: 0.0052864650, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4221, Train loss: 0.0052859534, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4222, Train loss: 0.0052860818, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4223, Train loss: 0.0052857622, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4224, Train loss: 0.0052857598, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4225, Train loss: 0.0052865672, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4226, Train loss: 0.0052864877, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4227, Train loss: 0.0052859005, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4228, Train loss: 0.0052867115, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4229, Train loss: 0.0052857814, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4230, Train loss: 0.0052870971, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4231, Train loss: 0.0052864296, Validation loss: 0.0053138988, LR: 1.0000000000000004e-08\n",
      "Epoch 4232, Train loss: 0.0052863406, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4233, Train loss: 0.0052867609, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4234, Train loss: 0.0052863809, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4235, Train loss: 0.0052863289, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4236, Train loss: 0.0052860659, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4237, Train loss: 0.0052861263, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4238, Train loss: 0.0052865117, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4239, Train loss: 0.0052865313, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4240, Train loss: 0.0052854038, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4241, Train loss: 0.0052868511, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4242, Train loss: 0.0052862806, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4243, Train loss: 0.0052866933, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4244, Train loss: 0.0052867312, Validation loss: 0.0053138987, LR: 1.0000000000000004e-08\n",
      "Epoch 4245, Train loss: 0.0052860773, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4246, Train loss: 0.0052859392, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4247, Train loss: 0.0052867263, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4248, Train loss: 0.0052858502, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4249, Train loss: 0.0052860128, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4250, Train loss: 0.0052861057, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4251, Train loss: 0.0052860195, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4252, Train loss: 0.0052860975, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4253, Train loss: 0.0052868849, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4254, Train loss: 0.0052861206, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4255, Train loss: 0.0052857637, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4256, Train loss: 0.0052858678, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4257, Train loss: 0.0052863342, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4258, Train loss: 0.0052863062, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4259, Train loss: 0.0052864243, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4260, Train loss: 0.0052855552, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4261, Train loss: 0.0052866275, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4262, Train loss: 0.0052864188, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4263, Train loss: 0.0052854687, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4264, Train loss: 0.0052859801, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4265, Train loss: 0.0052865226, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4266, Train loss: 0.0052866163, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4267, Train loss: 0.0052864116, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4268, Train loss: 0.0052864286, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4269, Train loss: 0.0052865180, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4270, Train loss: 0.0052868298, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4271, Train loss: 0.0052855107, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4272, Train loss: 0.0052870734, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4273, Train loss: 0.0052866650, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4274, Train loss: 0.0052862615, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4275, Train loss: 0.0052856603, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4276, Train loss: 0.0052863663, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4277, Train loss: 0.0052866557, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4278, Train loss: 0.0052866469, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4279, Train loss: 0.0052864087, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4280, Train loss: 0.0052864666, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4281, Train loss: 0.0052863671, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4282, Train loss: 0.0052858124, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4283, Train loss: 0.0052867992, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4284, Train loss: 0.0052863691, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4285, Train loss: 0.0052867336, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4286, Train loss: 0.0052869462, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4287, Train loss: 0.0052865090, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4288, Train loss: 0.0052864119, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4289, Train loss: 0.0052862757, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4290, Train loss: 0.0052864715, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4291, Train loss: 0.0052864645, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4292, Train loss: 0.0052863576, Validation loss: 0.0053138986, LR: 1.0000000000000004e-08\n",
      "Epoch 4293, Train loss: 0.0052859790, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4294, Train loss: 0.0052861591, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4295, Train loss: 0.0052850176, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4296, Train loss: 0.0052863335, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4297, Train loss: 0.0052871703, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4298, Train loss: 0.0052857077, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4299, Train loss: 0.0052866625, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4300, Train loss: 0.0052859443, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4301, Train loss: 0.0052866671, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4302, Train loss: 0.0052861300, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4303, Train loss: 0.0052869028, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4304, Train loss: 0.0052858052, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4305, Train loss: 0.0052861335, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4306, Train loss: 0.0052862652, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4307, Train loss: 0.0052869271, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4308, Train loss: 0.0052862251, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4309, Train loss: 0.0052865687, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4310, Train loss: 0.0052853195, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4311, Train loss: 0.0052867910, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4312, Train loss: 0.0052855834, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4313, Train loss: 0.0052856178, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4314, Train loss: 0.0052865777, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4315, Train loss: 0.0052862384, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4316, Train loss: 0.0052859907, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4317, Train loss: 0.0052859153, Validation loss: 0.0053138985, LR: 1.0000000000000004e-08\n",
      "Epoch 4318, Train loss: 0.0052859428, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4319, Train loss: 0.0052867191, Validation loss: 0.0053138984, LR: 1.0000000000000004e-08\n",
      "Epoch 4320, Train loss: 0.0052864253, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4321, Train loss: 0.0052865413, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4322, Train loss: 0.0052861967, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4323, Train loss: 0.0052867347, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4324, Train loss: 0.0052864617, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4325, Train loss: 0.0052853603, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4326, Train loss: 0.0052863844, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4327, Train loss: 0.0052867530, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4328, Train loss: 0.0052860993, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4329, Train loss: 0.0052869793, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4330, Train loss: 0.0052857503, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4331, Train loss: 0.0052858577, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4332, Train loss: 0.0052853654, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4333, Train loss: 0.0052870157, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4334, Train loss: 0.0052861933, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4335, Train loss: 0.0052866377, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4336, Train loss: 0.0052862812, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4337, Train loss: 0.0052860434, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4338, Train loss: 0.0052863803, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4339, Train loss: 0.0052870109, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4340, Train loss: 0.0052865567, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4341, Train loss: 0.0052857061, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4342, Train loss: 0.0052863164, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4343, Train loss: 0.0052861884, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4344, Train loss: 0.0052861840, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4345, Train loss: 0.0052870151, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4346, Train loss: 0.0052862882, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4347, Train loss: 0.0052871885, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4348, Train loss: 0.0052865096, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4349, Train loss: 0.0052864883, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4350, Train loss: 0.0052863670, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4351, Train loss: 0.0052863529, Validation loss: 0.0053138983, LR: 1.0000000000000004e-08\n",
      "Epoch 4352, Train loss: 0.0052868011, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4353, Train loss: 0.0052860918, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4354, Train loss: 0.0052858476, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4355, Train loss: 0.0052861675, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4356, Train loss: 0.0052856678, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4357, Train loss: 0.0052866882, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4358, Train loss: 0.0052861614, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4359, Train loss: 0.0052858158, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4360, Train loss: 0.0052869590, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4361, Train loss: 0.0052858196, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4362, Train loss: 0.0052863543, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4363, Train loss: 0.0052869117, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4364, Train loss: 0.0052858959, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4365, Train loss: 0.0052863616, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4366, Train loss: 0.0052866966, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4367, Train loss: 0.0052854500, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4368, Train loss: 0.0052871593, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4369, Train loss: 0.0052861195, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4370, Train loss: 0.0052858232, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4371, Train loss: 0.0052870138, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4372, Train loss: 0.0052863610, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4373, Train loss: 0.0052861940, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4374, Train loss: 0.0052866746, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4375, Train loss: 0.0052866648, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4376, Train loss: 0.0052860613, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4377, Train loss: 0.0052861647, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4378, Train loss: 0.0052852228, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4379, Train loss: 0.0052866050, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4380, Train loss: 0.0052861519, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4381, Train loss: 0.0052869307, Validation loss: 0.0053138982, LR: 1.0000000000000004e-08\n",
      "Epoch 4382, Train loss: 0.0052869206, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4383, Train loss: 0.0052863367, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4384, Train loss: 0.0052864182, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4385, Train loss: 0.0052859570, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4386, Train loss: 0.0052862396, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4387, Train loss: 0.0052866146, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4388, Train loss: 0.0052861745, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4389, Train loss: 0.0052867022, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4390, Train loss: 0.0052863213, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4391, Train loss: 0.0052867078, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4392, Train loss: 0.0052862870, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4393, Train loss: 0.0052867017, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4394, Train loss: 0.0052868593, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4395, Train loss: 0.0052865763, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4396, Train loss: 0.0052860155, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4397, Train loss: 0.0052866429, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4398, Train loss: 0.0052864123, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4399, Train loss: 0.0052870472, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4400, Train loss: 0.0052865065, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4401, Train loss: 0.0052863711, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4402, Train loss: 0.0052866634, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4403, Train loss: 0.0052865832, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4404, Train loss: 0.0052866288, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4405, Train loss: 0.0052849727, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4406, Train loss: 0.0052865501, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4407, Train loss: 0.0052870030, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4408, Train loss: 0.0052867769, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4409, Train loss: 0.0052865440, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4410, Train loss: 0.0052865451, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4411, Train loss: 0.0052865559, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4412, Train loss: 0.0052866650, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4413, Train loss: 0.0052861010, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4414, Train loss: 0.0052860583, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4415, Train loss: 0.0052866041, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4416, Train loss: 0.0052868607, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4417, Train loss: 0.0052860351, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4418, Train loss: 0.0052864988, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4419, Train loss: 0.0052860894, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4420, Train loss: 0.0052856936, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4421, Train loss: 0.0052864617, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4422, Train loss: 0.0052860010, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4423, Train loss: 0.0052861098, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4424, Train loss: 0.0052859945, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4425, Train loss: 0.0052866401, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4426, Train loss: 0.0052862108, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4427, Train loss: 0.0052858293, Validation loss: 0.0053138980, LR: 1.0000000000000004e-08\n",
      "Epoch 4428, Train loss: 0.0052861506, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4429, Train loss: 0.0052860887, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4430, Train loss: 0.0052863797, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4431, Train loss: 0.0052859751, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4432, Train loss: 0.0052864558, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4433, Train loss: 0.0052865689, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4434, Train loss: 0.0052864478, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4435, Train loss: 0.0052864735, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4436, Train loss: 0.0052861656, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4437, Train loss: 0.0052866500, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4438, Train loss: 0.0052869873, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4439, Train loss: 0.0052870139, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4440, Train loss: 0.0052860895, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4441, Train loss: 0.0052863510, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4442, Train loss: 0.0052872747, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4443, Train loss: 0.0052869898, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4444, Train loss: 0.0052863263, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4445, Train loss: 0.0052860507, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4446, Train loss: 0.0052857887, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4447, Train loss: 0.0052864247, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4448, Train loss: 0.0052861785, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4449, Train loss: 0.0052859968, Validation loss: 0.0053138981, LR: 1.0000000000000004e-08\n",
      "Epoch 4450, Train loss: 0.0052865753, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4451, Train loss: 0.0052860015, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4452, Train loss: 0.0052863585, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4453, Train loss: 0.0052862655, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4454, Train loss: 0.0052858978, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4455, Train loss: 0.0052860868, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4456, Train loss: 0.0052865705, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4457, Train loss: 0.0052863665, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4458, Train loss: 0.0052868931, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4459, Train loss: 0.0052858594, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4460, Train loss: 0.0052857097, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4461, Train loss: 0.0052871868, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4462, Train loss: 0.0052852162, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4463, Train loss: 0.0052868720, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4464, Train loss: 0.0052862380, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4465, Train loss: 0.0052856214, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4466, Train loss: 0.0052857027, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4467, Train loss: 0.0052862925, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4468, Train loss: 0.0052866748, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4469, Train loss: 0.0052865427, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4470, Train loss: 0.0052865547, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4471, Train loss: 0.0052864267, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4472, Train loss: 0.0052862703, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4473, Train loss: 0.0052860568, Validation loss: 0.0053138978, LR: 1.0000000000000004e-08\n",
      "Epoch 4474, Train loss: 0.0052865092, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4475, Train loss: 0.0052862629, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4476, Train loss: 0.0052860572, Validation loss: 0.0053138979, LR: 1.0000000000000004e-08\n",
      "Epoch 4477, Train loss: 0.0052865789, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4478, Train loss: 0.0052857901, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4479, Train loss: 0.0052859641, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4480, Train loss: 0.0052862816, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4481, Train loss: 0.0052859872, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4482, Train loss: 0.0052863727, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4483, Train loss: 0.0052863530, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4484, Train loss: 0.0052862837, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4485, Train loss: 0.0052863721, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4486, Train loss: 0.0052864986, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4487, Train loss: 0.0052858417, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4488, Train loss: 0.0052865250, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4489, Train loss: 0.0052862723, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4490, Train loss: 0.0052861909, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4491, Train loss: 0.0052858705, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4492, Train loss: 0.0052863929, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4493, Train loss: 0.0052862604, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4494, Train loss: 0.0052856017, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4495, Train loss: 0.0052860825, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4496, Train loss: 0.0052867890, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4497, Train loss: 0.0052861396, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4498, Train loss: 0.0052859184, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4499, Train loss: 0.0052859365, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4500, Train loss: 0.0052868641, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4501, Train loss: 0.0052857682, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4502, Train loss: 0.0052866653, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4503, Train loss: 0.0052860091, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4504, Train loss: 0.0052858325, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4505, Train loss: 0.0052862994, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4506, Train loss: 0.0052865798, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4507, Train loss: 0.0052867871, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4508, Train loss: 0.0052866851, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4509, Train loss: 0.0052859562, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4510, Train loss: 0.0052863323, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4511, Train loss: 0.0052861651, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4512, Train loss: 0.0052864368, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4513, Train loss: 0.0052862399, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4514, Train loss: 0.0052856952, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4515, Train loss: 0.0052857128, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4516, Train loss: 0.0052862367, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4517, Train loss: 0.0052864228, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4518, Train loss: 0.0052864129, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4519, Train loss: 0.0052862770, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4520, Train loss: 0.0052863937, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4521, Train loss: 0.0052857396, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4522, Train loss: 0.0052859721, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4523, Train loss: 0.0052866253, Validation loss: 0.0053138977, LR: 1.0000000000000004e-08\n",
      "Epoch 4524, Train loss: 0.0052866229, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4525, Train loss: 0.0052864088, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4526, Train loss: 0.0052861705, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4527, Train loss: 0.0052867156, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4528, Train loss: 0.0052864430, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4529, Train loss: 0.0052864624, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4530, Train loss: 0.0052857621, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4531, Train loss: 0.0052863927, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4532, Train loss: 0.0052857541, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4533, Train loss: 0.0052851366, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4534, Train loss: 0.0052856823, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4535, Train loss: 0.0052861907, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4536, Train loss: 0.0052860421, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4537, Train loss: 0.0052858443, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4538, Train loss: 0.0052861488, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4539, Train loss: 0.0052860880, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4540, Train loss: 0.0052867155, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4541, Train loss: 0.0052860096, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4542, Train loss: 0.0052864798, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4543, Train loss: 0.0052867182, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4544, Train loss: 0.0052858555, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4545, Train loss: 0.0052864689, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4546, Train loss: 0.0052856057, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4547, Train loss: 0.0052866591, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4548, Train loss: 0.0052862996, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4549, Train loss: 0.0052865181, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4550, Train loss: 0.0052862329, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4551, Train loss: 0.0052864867, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4552, Train loss: 0.0052863545, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4553, Train loss: 0.0052855515, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4554, Train loss: 0.0052862814, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4555, Train loss: 0.0052865451, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4556, Train loss: 0.0052861159, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4557, Train loss: 0.0052865545, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4558, Train loss: 0.0052863348, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4559, Train loss: 0.0052856538, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4560, Train loss: 0.0052861491, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4561, Train loss: 0.0052871017, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4562, Train loss: 0.0052866116, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4563, Train loss: 0.0052863093, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4564, Train loss: 0.0052862472, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4565, Train loss: 0.0052860591, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4566, Train loss: 0.0052861993, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4567, Train loss: 0.0052859717, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4568, Train loss: 0.0052866524, Validation loss: 0.0053138976, LR: 1.0000000000000004e-08\n",
      "Epoch 4569, Train loss: 0.0052862234, Validation loss: 0.0053138975, LR: 1.0000000000000004e-08\n",
      "Epoch 4570, Train loss: 0.0052865785, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4571, Train loss: 0.0052856966, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4572, Train loss: 0.0052860697, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4573, Train loss: 0.0052866753, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4574, Train loss: 0.0052861364, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4575, Train loss: 0.0052866128, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4576, Train loss: 0.0052865473, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4577, Train loss: 0.0052863986, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4578, Train loss: 0.0052855506, Validation loss: 0.0053138969, LR: 1.0000000000000004e-08\n",
      "Epoch 4579, Train loss: 0.0052863637, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4580, Train loss: 0.0052860666, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4581, Train loss: 0.0052861365, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4582, Train loss: 0.0052866047, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4583, Train loss: 0.0052862792, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4584, Train loss: 0.0052867557, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4585, Train loss: 0.0052854305, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4586, Train loss: 0.0052862764, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4587, Train loss: 0.0052862150, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4588, Train loss: 0.0052865488, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4589, Train loss: 0.0052867888, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4590, Train loss: 0.0052861094, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4591, Train loss: 0.0052864719, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4592, Train loss: 0.0052857587, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4593, Train loss: 0.0052858171, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4594, Train loss: 0.0052859823, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4595, Train loss: 0.0052864210, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4596, Train loss: 0.0052861742, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4597, Train loss: 0.0052861273, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4598, Train loss: 0.0052863930, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4599, Train loss: 0.0052864336, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4600, Train loss: 0.0052859835, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4601, Train loss: 0.0052863817, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4602, Train loss: 0.0052866396, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4603, Train loss: 0.0052866856, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4604, Train loss: 0.0052860077, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4605, Train loss: 0.0052856197, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4606, Train loss: 0.0052861569, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4607, Train loss: 0.0052861832, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4608, Train loss: 0.0052861765, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4609, Train loss: 0.0052860480, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4610, Train loss: 0.0052863630, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4611, Train loss: 0.0052868448, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4612, Train loss: 0.0052861000, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4613, Train loss: 0.0052857330, Validation loss: 0.0053138969, LR: 1.0000000000000004e-08\n",
      "Epoch 4614, Train loss: 0.0052866632, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4615, Train loss: 0.0052864491, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4616, Train loss: 0.0052864703, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4617, Train loss: 0.0052867346, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4618, Train loss: 0.0052863542, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4619, Train loss: 0.0052861655, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4620, Train loss: 0.0052858353, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4621, Train loss: 0.0052858315, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4622, Train loss: 0.0052867267, Validation loss: 0.0053138969, LR: 1.0000000000000004e-08\n",
      "Epoch 4623, Train loss: 0.0052866233, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4624, Train loss: 0.0052859012, Validation loss: 0.0053138969, LR: 1.0000000000000004e-08\n",
      "Epoch 4625, Train loss: 0.0052864268, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4626, Train loss: 0.0052861638, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4627, Train loss: 0.0052863364, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4628, Train loss: 0.0052863667, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4629, Train loss: 0.0052863704, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4630, Train loss: 0.0052868284, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4631, Train loss: 0.0052863403, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4632, Train loss: 0.0052853644, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4633, Train loss: 0.0052867207, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4634, Train loss: 0.0052857079, Validation loss: 0.0053138969, LR: 1.0000000000000004e-08\n",
      "Epoch 4635, Train loss: 0.0052869035, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4636, Train loss: 0.0052862070, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4637, Train loss: 0.0052870351, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4638, Train loss: 0.0052867231, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4639, Train loss: 0.0052861566, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4640, Train loss: 0.0052857814, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4641, Train loss: 0.0052865922, Validation loss: 0.0053138969, LR: 1.0000000000000004e-08\n",
      "Epoch 4642, Train loss: 0.0052864250, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4643, Train loss: 0.0052861310, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4644, Train loss: 0.0052866719, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4645, Train loss: 0.0052862845, Validation loss: 0.0053138969, LR: 1.0000000000000004e-08\n",
      "Epoch 4646, Train loss: 0.0052868235, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4647, Train loss: 0.0052860531, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4648, Train loss: 0.0052869224, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4649, Train loss: 0.0052867751, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4650, Train loss: 0.0052851856, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4651, Train loss: 0.0052853802, Validation loss: 0.0053138973, LR: 1.0000000000000004e-08\n",
      "Epoch 4652, Train loss: 0.0052868461, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4653, Train loss: 0.0052859618, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4654, Train loss: 0.0052865070, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4655, Train loss: 0.0052867291, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4656, Train loss: 0.0052863500, Validation loss: 0.0053138974, LR: 1.0000000000000004e-08\n",
      "Epoch 4657, Train loss: 0.0052868873, Validation loss: 0.0053138972, LR: 1.0000000000000004e-08\n",
      "Epoch 4658, Train loss: 0.0052869034, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4659, Train loss: 0.0052870551, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4660, Train loss: 0.0052864411, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4661, Train loss: 0.0052863985, Validation loss: 0.0053138969, LR: 1.0000000000000004e-08\n",
      "Epoch 4662, Train loss: 0.0052858443, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n",
      "Epoch 4663, Train loss: 0.0052854833, Validation loss: 0.0053138969, LR: 1.0000000000000004e-08\n",
      "Epoch 4664, Train loss: 0.0052859575, Validation loss: 0.0053138969, LR: 1.0000000000000004e-08\n",
      "Epoch 4665, Train loss: 0.0052862276, Validation loss: 0.0053138969, LR: 1.0000000000000004e-08\n",
      "Epoch 4666, Train loss: 0.0052857344, Validation loss: 0.0053138969, LR: 1.0000000000000004e-08\n",
      "Epoch 4667, Train loss: 0.0052863840, Validation loss: 0.0053138970, LR: 1.0000000000000004e-08\n",
      "Epoch 4668, Train loss: 0.0052860452, Validation loss: 0.0053138969, LR: 1.0000000000000004e-08\n",
      "Epoch 4669, Train loss: 0.0052866630, Validation loss: 0.0053138971, LR: 1.0000000000000004e-08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m validation_loader \u001b[38;5;241m=\u001b[39m DataLoader(validation_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(validation_loader)\n",
      "File \u001b[0;32m~/Desktop/bioinfmsc/diss/init_model_lstm.py:90\u001b[0m, in \u001b[0;36mDeconvolutionModel.fit\u001b[0;34m(self, train_dataloader, val_dataloader, epochs, patience)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 90\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     93\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ww/lib/python3.9/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ww/lib/python3.9/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ww/lib/python3.9/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size=128\n",
    "num_layers=1\n",
    "model = DeconvolutionModel(input_size, hidden_size, output_size, num_layers, device)\n",
    "\n",
    "for i in range(7):\n",
    "    batch_size_=snv_freqs_splits[0].shape[0]\n",
    "    seq_len=1\n",
    "    input_size = snv_freqs_splits[0].shape[1]\n",
    "    output_size = known_freqs_splits[0].shape[1]\n",
    "\n",
    "    snv_freqs=snv_freqs_splits[i].view(batch_size_, seq_len, input_size)\n",
    "    \n",
    "    dataset=TensorDataset(snv_freqs, known_freqs_splits[i])\n",
    "\n",
    "    train_dataset, validation_dataset, test_dataset = random_split(\n",
    "        dataset, [0.8, 0.1, 0.1]\n",
    "    )\n",
    "\n",
    "    batch_size = 64  # Arbitrarily chosen\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model.fit(train_loader, validation_loader, epochs=10000)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.evaluate(validation_loader)\n",
    "\n",
    "    # Predict using he model\n",
    "    predictions, actuals = model.predict(test_loader)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(predictions.flatten(), actuals.flatten(), alpha=0.5)\n",
    "    plt.xlabel('Predicted Frequencies')\n",
    "    plt.ylabel('Actual Frequencies')\n",
    "    plt.title(f'Predicted vs Actual Frequencies of Baseline LSTM Model RMSE Loss, Hidden Size 128, 7 Chunks of 10000 Examples')\n",
    "    plt.savefig(f'Predicted vs Actual Hidden Size 128, 7 Chunks of 10000 Examples, Plateau LR, Split {i+1}.png')\n",
    "\n",
    "    torch.save(model.model.state_dict(), 'model_weights.pth')\n",
    "    torch.save(model.optimizer.state_dict(), 'optimizer_state.pth')\n",
    "\n",
    "    # Load model and optimizer state for next chunk\n",
    "    model.model.load_state_dict(torch.load('model_weights.pth'))\n",
    "    model.optimizer.load_state_dict(torch.load('optimizer_state.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbb93d88-8827-43b7-94ae-b7e897dd9b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(predictions.flatten(), actuals.flatten(), alpha=0.5)\n",
    "plt.xlabel('Predicted Frequencies')\n",
    "plt.ylabel('Actual Frequencies')\n",
    "plt.title(f'Predicted vs Actual Frequencies of Baseline LSTM Model RMSE Loss, Hidden Size 128, 7 Chunks of 10000 Examples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da5690ef-8697-40e3-96e8-63fd25955cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_freqs=snv_freqs_splits[1].view(batch_size, seq_len, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9f62055-964f-46a0-904a-3d114403799b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 0.0054292479, Validation loss: 0.0054231915, LR: 1e-05\n",
      "Epoch 2, Train loss: 0.0054276782, Validation loss: 0.0054227132, LR: 1e-05\n",
      "Epoch 3, Train loss: 0.0054277224, Validation loss: 0.0054223704, LR: 1e-05\n",
      "Epoch 4, Train loss: 0.0054261585, Validation loss: 0.0054221908, LR: 1e-05\n",
      "Epoch 5, Train loss: 0.0054270548, Validation loss: 0.0054219839, LR: 1e-05\n",
      "Epoch 6, Train loss: 0.0054262442, Validation loss: 0.0054218658, LR: 1e-05\n",
      "Epoch 7, Train loss: 0.0054255664, Validation loss: 0.0054219037, LR: 1e-05\n",
      "Epoch 8, Train loss: 0.0054251463, Validation loss: 0.0054216722, LR: 1e-05\n",
      "Epoch 9, Train loss: 0.0054249536, Validation loss: 0.0054216609, LR: 1e-05\n",
      "Epoch 10, Train loss: 0.0054257624, Validation loss: 0.0054215424, LR: 1e-05\n",
      "Epoch 11, Train loss: 0.0054250293, Validation loss: 0.0054215683, LR: 1e-05\n",
      "Epoch 12, Train loss: 0.0054249428, Validation loss: 0.0054215165, LR: 1e-05\n",
      "Epoch 13, Train loss: 0.0054243683, Validation loss: 0.0054214957, LR: 1e-05\n",
      "Epoch 14, Train loss: 0.0054249493, Validation loss: 0.0054214378, LR: 1e-05\n",
      "Epoch 15, Train loss: 0.0054243831, Validation loss: 0.0054213698, LR: 1e-05\n",
      "Epoch 16, Train loss: 0.0054246529, Validation loss: 0.0054214275, LR: 1e-05\n",
      "Epoch 17, Train loss: 0.0054236279, Validation loss: 0.0054213436, LR: 1e-05\n",
      "Epoch 18, Train loss: 0.0054242584, Validation loss: 0.0054212096, LR: 1e-05\n",
      "Epoch 19, Train loss: 0.0054239674, Validation loss: 0.0054212405, LR: 1e-05\n",
      "Epoch 20, Train loss: 0.0054238848, Validation loss: 0.0054212507, LR: 1e-05\n",
      "Epoch 21, Train loss: 0.0054228939, Validation loss: 0.0054210885, LR: 1e-05\n",
      "Epoch 22, Train loss: 0.0054231299, Validation loss: 0.0054211659, LR: 1e-05\n",
      "Epoch 23, Train loss: 0.0054229570, Validation loss: 0.0054210531, LR: 1e-05\n",
      "Epoch 24, Train loss: 0.0054231706, Validation loss: 0.0054210979, LR: 1e-05\n",
      "Epoch 25, Train loss: 0.0054233906, Validation loss: 0.0054210689, LR: 1e-05\n",
      "Epoch 26, Train loss: 0.0054231574, Validation loss: 0.0054210351, LR: 1e-05\n",
      "Epoch 27, Train loss: 0.0054227032, Validation loss: 0.0054210100, LR: 1e-05\n",
      "Epoch 28, Train loss: 0.0054227268, Validation loss: 0.0054209527, LR: 1e-05\n",
      "Epoch 29, Train loss: 0.0054220520, Validation loss: 0.0054209983, LR: 1e-05\n",
      "Epoch 30, Train loss: 0.0054227997, Validation loss: 0.0054210652, LR: 1e-05\n",
      "Epoch 31, Train loss: 0.0054225280, Validation loss: 0.0054208971, LR: 1e-05\n",
      "Epoch 32, Train loss: 0.0054225155, Validation loss: 0.0054208869, LR: 1e-05\n",
      "Epoch 33, Train loss: 0.0054221640, Validation loss: 0.0054208603, LR: 1e-05\n",
      "Epoch 34, Train loss: 0.0054219008, Validation loss: 0.0054209804, LR: 1e-05\n",
      "Epoch 35, Train loss: 0.0054212174, Validation loss: 0.0054208866, LR: 1e-05\n",
      "Epoch 36, Train loss: 0.0054228752, Validation loss: 0.0054208144, LR: 1e-05\n",
      "Epoch 37, Train loss: 0.0054216865, Validation loss: 0.0054207937, LR: 1e-05\n",
      "Epoch 38, Train loss: 0.0054220107, Validation loss: 0.0054207631, LR: 1e-05\n",
      "Epoch 39, Train loss: 0.0054218277, Validation loss: 0.0054208469, LR: 1e-05\n",
      "Epoch 40, Train loss: 0.0054214494, Validation loss: 0.0054208486, LR: 1e-05\n",
      "Epoch 41, Train loss: 0.0054211298, Validation loss: 0.0054207784, LR: 1e-05\n",
      "Epoch 42, Train loss: 0.0054216296, Validation loss: 0.0054207356, LR: 1e-05\n",
      "Epoch 43, Train loss: 0.0054216958, Validation loss: 0.0054207121, LR: 1e-05\n",
      "Epoch 44, Train loss: 0.0054216622, Validation loss: 0.0054207706, LR: 1e-05\n",
      "Epoch 45, Train loss: 0.0054214865, Validation loss: 0.0054207206, LR: 1e-05\n",
      "Epoch 46, Train loss: 0.0054215682, Validation loss: 0.0054207009, LR: 1e-05\n",
      "Epoch 47, Train loss: 0.0054213792, Validation loss: 0.0054206562, LR: 1e-05\n",
      "Epoch 48, Train loss: 0.0054216943, Validation loss: 0.0054206600, LR: 1e-05\n",
      "Epoch 49, Train loss: 0.0054210312, Validation loss: 0.0054206553, LR: 1e-05\n",
      "Epoch 50, Train loss: 0.0054208036, Validation loss: 0.0054206363, LR: 1e-05\n",
      "Epoch 51, Train loss: 0.0054207797, Validation loss: 0.0054206404, LR: 1e-05\n",
      "Epoch 52, Train loss: 0.0054212879, Validation loss: 0.0054205923, LR: 1e-05\n",
      "Epoch 53, Train loss: 0.0054207466, Validation loss: 0.0054206630, LR: 1e-05\n",
      "Epoch 54, Train loss: 0.0054209574, Validation loss: 0.0054205781, LR: 1e-05\n",
      "Epoch 55, Train loss: 0.0054202823, Validation loss: 0.0054205644, LR: 1e-05\n",
      "Epoch 56, Train loss: 0.0054212880, Validation loss: 0.0054205885, LR: 1e-05\n",
      "Epoch 57, Train loss: 0.0054209486, Validation loss: 0.0054205578, LR: 1e-05\n",
      "Epoch 58, Train loss: 0.0054209213, Validation loss: 0.0054205350, LR: 1e-05\n",
      "Epoch 59, Train loss: 0.0054211349, Validation loss: 0.0054205043, LR: 1e-05\n",
      "Epoch 60, Train loss: 0.0054211770, Validation loss: 0.0054205948, LR: 1e-05\n",
      "Epoch 61, Train loss: 0.0054203283, Validation loss: 0.0054205219, LR: 1e-05\n",
      "Epoch 62, Train loss: 0.0054212136, Validation loss: 0.0054205086, LR: 1e-05\n",
      "Epoch 63, Train loss: 0.0054206794, Validation loss: 0.0054204740, LR: 1e-05\n",
      "Epoch 64, Train loss: 0.0054201229, Validation loss: 0.0054204953, LR: 1e-05\n",
      "Epoch 65, Train loss: 0.0054204274, Validation loss: 0.0054204967, LR: 1e-05\n",
      "Epoch 66, Train loss: 0.0054207532, Validation loss: 0.0054204727, LR: 1e-05\n",
      "Epoch 67, Train loss: 0.0054200430, Validation loss: 0.0054205182, LR: 1e-05\n",
      "Epoch 68, Train loss: 0.0054206201, Validation loss: 0.0054204477, LR: 1e-05\n",
      "Epoch 69, Train loss: 0.0054202942, Validation loss: 0.0054205150, LR: 1e-05\n",
      "Epoch 70, Train loss: 0.0054203862, Validation loss: 0.0054204878, LR: 1e-05\n",
      "Epoch 71, Train loss: 0.0054211488, Validation loss: 0.0054204220, LR: 1e-05\n",
      "Epoch 72, Train loss: 0.0054203654, Validation loss: 0.0054204570, LR: 1e-05\n",
      "Epoch 73, Train loss: 0.0054199698, Validation loss: 0.0054204333, LR: 1e-05\n",
      "Epoch 74, Train loss: 0.0054198126, Validation loss: 0.0054204480, LR: 1e-05\n",
      "Epoch 75, Train loss: 0.0054202961, Validation loss: 0.0054204260, LR: 1e-05\n",
      "Epoch 76, Train loss: 0.0054198387, Validation loss: 0.0054204350, LR: 1e-05\n",
      "Epoch 77, Train loss: 0.0054201433, Validation loss: 0.0054203739, LR: 1e-05\n",
      "Epoch 78, Train loss: 0.0054199886, Validation loss: 0.0054203791, LR: 1e-05\n",
      "Epoch 79, Train loss: 0.0054194630, Validation loss: 0.0054203992, LR: 1e-05\n",
      "Epoch 80, Train loss: 0.0054202880, Validation loss: 0.0054203843, LR: 1e-05\n",
      "Epoch 81, Train loss: 0.0054197287, Validation loss: 0.0054204020, LR: 1e-05\n",
      "Epoch 82, Train loss: 0.0054198650, Validation loss: 0.0054203971, LR: 1e-05\n",
      "Epoch 83, Train loss: 0.0054193910, Validation loss: 0.0054204337, LR: 1e-05\n",
      "Epoch 84, Train loss: 0.0054204573, Validation loss: 0.0054203711, LR: 1e-05\n",
      "Epoch 85, Train loss: 0.0054201693, Validation loss: 0.0054203538, LR: 1e-05\n",
      "Epoch 86, Train loss: 0.0054200641, Validation loss: 0.0054203785, LR: 1e-05\n",
      "Epoch 87, Train loss: 0.0054202427, Validation loss: 0.0054204468, LR: 1e-05\n",
      "Epoch 88, Train loss: 0.0054200454, Validation loss: 0.0054202848, LR: 1e-05\n",
      "Epoch 89, Train loss: 0.0054198691, Validation loss: 0.0054202771, LR: 1e-05\n",
      "Epoch 90, Train loss: 0.0054195979, Validation loss: 0.0054203241, LR: 1e-05\n",
      "Epoch 91, Train loss: 0.0054196889, Validation loss: 0.0054204580, LR: 1e-05\n",
      "Epoch 92, Train loss: 0.0054200720, Validation loss: 0.0054202755, LR: 1e-05\n",
      "Epoch 93, Train loss: 0.0054193553, Validation loss: 0.0054203043, LR: 1e-05\n",
      "Epoch 94, Train loss: 0.0054193736, Validation loss: 0.0054203639, LR: 1e-05\n",
      "Epoch 95, Train loss: 0.0054193449, Validation loss: 0.0054203092, LR: 1e-05\n",
      "Epoch 96, Train loss: 0.0054202618, Validation loss: 0.0054202942, LR: 1e-05\n",
      "Epoch 97, Train loss: 0.0054196645, Validation loss: 0.0054202782, LR: 1e-05\n",
      "Epoch 98, Train loss: 0.0054186923, Validation loss: 0.0054202797, LR: 1e-05\n",
      "Epoch 99, Train loss: 0.0054195995, Validation loss: 0.0054202947, LR: 1e-05\n",
      "Epoch 100, Train loss: 0.0054193520, Validation loss: 0.0054202492, LR: 1e-05\n",
      "Epoch 101, Train loss: 0.0054191914, Validation loss: 0.0054202844, LR: 1e-05\n",
      "Epoch 102, Train loss: 0.0054194694, Validation loss: 0.0054202941, LR: 1e-05\n",
      "Epoch 103, Train loss: 0.0054199632, Validation loss: 0.0054203025, LR: 1e-05\n",
      "Epoch 104, Train loss: 0.0054193536, Validation loss: 0.0054202742, LR: 1e-05\n",
      "Epoch 105, Train loss: 0.0054190835, Validation loss: 0.0054202251, LR: 1e-05\n",
      "Epoch 106, Train loss: 0.0054189765, Validation loss: 0.0054202268, LR: 1e-05\n",
      "Epoch 107, Train loss: 0.0054186533, Validation loss: 0.0054202418, LR: 1e-05\n",
      "Epoch 108, Train loss: 0.0054197593, Validation loss: 0.0054202772, LR: 1e-05\n",
      "Epoch 109, Train loss: 0.0054192510, Validation loss: 0.0054202501, LR: 1e-05\n",
      "Epoch 110, Train loss: 0.0054198035, Validation loss: 0.0054201379, LR: 1e-05\n",
      "Epoch 111, Train loss: 0.0054195820, Validation loss: 0.0054201898, LR: 1e-05\n",
      "Epoch 112, Train loss: 0.0054189113, Validation loss: 0.0054202325, LR: 1e-05\n",
      "Epoch 113, Train loss: 0.0054193946, Validation loss: 0.0054202140, LR: 1e-05\n",
      "Epoch 114, Train loss: 0.0054190906, Validation loss: 0.0054201765, LR: 1e-05\n",
      "Epoch 115, Train loss: 0.0054193882, Validation loss: 0.0054201833, LR: 1e-05\n",
      "Epoch 116, Train loss: 0.0054188010, Validation loss: 0.0054201866, LR: 1e-05\n",
      "Epoch 117, Train loss: 0.0054187802, Validation loss: 0.0054202619, LR: 1e-05\n",
      "Epoch 118, Train loss: 0.0054193912, Validation loss: 0.0054201474, LR: 1e-05\n",
      "Epoch 119, Train loss: 0.0054194767, Validation loss: 0.0054201766, LR: 1e-05\n",
      "Epoch 120, Train loss: 0.0054191473, Validation loss: 0.0054202221, LR: 1e-05\n",
      "Epoch 121, Train loss: 0.0054194208, Validation loss: 0.0054202061, LR: 1e-05\n",
      "Epoch 122, Train loss: 0.0054187083, Validation loss: 0.0054202192, LR: 1e-05\n",
      "Epoch 123, Train loss: 0.0054188745, Validation loss: 0.0054201956, LR: 1e-05\n",
      "Epoch 124, Train loss: 0.0054192866, Validation loss: 0.0054201402, LR: 1e-05\n",
      "Epoch 125, Train loss: 0.0054188604, Validation loss: 0.0054200992, LR: 1e-05\n",
      "Epoch 126, Train loss: 0.0054195037, Validation loss: 0.0054201682, LR: 1e-05\n",
      "Epoch 127, Train loss: 0.0054191850, Validation loss: 0.0054201156, LR: 1e-05\n",
      "Epoch 128, Train loss: 0.0054191071, Validation loss: 0.0054201193, LR: 1e-05\n",
      "Epoch 129, Train loss: 0.0054192878, Validation loss: 0.0054201412, LR: 1e-05\n",
      "Epoch 130, Train loss: 0.0054187424, Validation loss: 0.0054200913, LR: 1e-05\n",
      "Epoch 131, Train loss: 0.0054193602, Validation loss: 0.0054201075, LR: 1e-05\n",
      "Epoch 132, Train loss: 0.0054187421, Validation loss: 0.0054201194, LR: 1e-05\n",
      "Epoch 133, Train loss: 0.0054189920, Validation loss: 0.0054201382, LR: 1e-05\n",
      "Epoch 134, Train loss: 0.0054187619, Validation loss: 0.0054200963, LR: 1e-05\n",
      "Epoch 135, Train loss: 0.0054188150, Validation loss: 0.0054200733, LR: 1e-05\n",
      "Epoch 136, Train loss: 0.0054187686, Validation loss: 0.0054201394, LR: 1e-05\n",
      "Epoch 137, Train loss: 0.0054185825, Validation loss: 0.0054200992, LR: 1e-05\n",
      "Epoch 138, Train loss: 0.0054183701, Validation loss: 0.0054200825, LR: 1e-05\n",
      "Epoch 139, Train loss: 0.0054189437, Validation loss: 0.0054200997, LR: 1e-05\n",
      "Epoch 140, Train loss: 0.0054184429, Validation loss: 0.0054201112, LR: 1e-05\n",
      "Epoch 141, Train loss: 0.0054187125, Validation loss: 0.0054201032, LR: 1e-05\n",
      "Epoch 142, Train loss: 0.0054185937, Validation loss: 0.0054200747, LR: 1e-05\n",
      "Epoch 143, Train loss: 0.0054184645, Validation loss: 0.0054201440, LR: 1e-05\n",
      "Epoch 144, Train loss: 0.0054185036, Validation loss: 0.0054201187, LR: 1e-05\n",
      "Epoch 145, Train loss: 0.0054186193, Validation loss: 0.0054200554, LR: 1e-05\n",
      "Epoch 146, Train loss: 0.0054189255, Validation loss: 0.0054200998, LR: 1e-05\n",
      "Epoch 147, Train loss: 0.0054190842, Validation loss: 0.0054201406, LR: 1e-05\n",
      "Epoch 148, Train loss: 0.0054188269, Validation loss: 0.0054200981, LR: 1e-05\n",
      "Epoch 149, Train loss: 0.0054185935, Validation loss: 0.0054200774, LR: 1e-05\n",
      "Epoch 150, Train loss: 0.0054181205, Validation loss: 0.0054200296, LR: 1e-05\n",
      "Epoch 151, Train loss: 0.0054189429, Validation loss: 0.0054200728, LR: 1e-05\n",
      "Epoch 152, Train loss: 0.0054184264, Validation loss: 0.0054200650, LR: 1e-05\n",
      "Epoch 153, Train loss: 0.0054187889, Validation loss: 0.0054200157, LR: 1e-05\n",
      "Epoch 154, Train loss: 0.0054190794, Validation loss: 0.0054201240, LR: 1e-05\n",
      "Epoch 155, Train loss: 0.0054177386, Validation loss: 0.0054201029, LR: 1e-05\n",
      "Epoch 156, Train loss: 0.0054184740, Validation loss: 0.0054201304, LR: 1e-05\n",
      "Epoch 157, Train loss: 0.0054184664, Validation loss: 0.0054200829, LR: 1e-05\n",
      "Epoch 158, Train loss: 0.0054186074, Validation loss: 0.0054200489, LR: 1e-05\n",
      "Epoch 159, Train loss: 0.0054178344, Validation loss: 0.0054201197, LR: 1e-05\n",
      "Epoch 160, Train loss: 0.0054182370, Validation loss: 0.0054200439, LR: 1e-05\n",
      "Epoch 161, Train loss: 0.0054190428, Validation loss: 0.0054200589, LR: 1e-05\n",
      "Epoch 162, Train loss: 0.0054175607, Validation loss: 0.0054200059, LR: 1e-05\n",
      "Epoch 163, Train loss: 0.0054188041, Validation loss: 0.0054200708, LR: 1e-05\n",
      "Epoch 164, Train loss: 0.0054182713, Validation loss: 0.0054200990, LR: 1e-05\n",
      "Epoch 165, Train loss: 0.0054183198, Validation loss: 0.0054200387, LR: 1e-05\n",
      "Epoch 166, Train loss: 0.0054178768, Validation loss: 0.0054199792, LR: 1e-05\n",
      "Epoch 167, Train loss: 0.0054180893, Validation loss: 0.0054200266, LR: 1e-05\n",
      "Epoch 168, Train loss: 0.0054173851, Validation loss: 0.0054200052, LR: 1e-05\n",
      "Epoch 169, Train loss: 0.0054187527, Validation loss: 0.0054200697, LR: 1e-05\n",
      "Epoch 170, Train loss: 0.0054185605, Validation loss: 0.0054199929, LR: 1e-05\n",
      "Epoch 171, Train loss: 0.0054180712, Validation loss: 0.0054200908, LR: 1e-05\n",
      "Epoch 172, Train loss: 0.0054181907, Validation loss: 0.0054199810, LR: 1e-05\n",
      "Epoch 173, Train loss: 0.0054178290, Validation loss: 0.0054200530, LR: 1e-05\n",
      "Epoch 174, Train loss: 0.0054182244, Validation loss: 0.0054200112, LR: 1e-05\n",
      "Epoch 175, Train loss: 0.0054186068, Validation loss: 0.0054200077, LR: 1e-05\n",
      "Epoch 176, Train loss: 0.0054185950, Validation loss: 0.0054199602, LR: 1e-05\n",
      "Epoch 177, Train loss: 0.0054187236, Validation loss: 0.0054200608, LR: 1e-05\n",
      "Epoch 178, Train loss: 0.0054180169, Validation loss: 0.0054200412, LR: 1e-05\n",
      "Epoch 179, Train loss: 0.0054191910, Validation loss: 0.0054199886, LR: 1e-05\n",
      "Epoch 180, Train loss: 0.0054182394, Validation loss: 0.0054199822, LR: 1e-05\n",
      "Epoch 181, Train loss: 0.0054182723, Validation loss: 0.0054200198, LR: 1e-05\n",
      "Epoch 182, Train loss: 0.0054186773, Validation loss: 0.0054200086, LR: 1e-05\n",
      "Epoch 183, Train loss: 0.0054181930, Validation loss: 0.0054200290, LR: 1e-05\n",
      "Epoch 184, Train loss: 0.0054181600, Validation loss: 0.0054200146, LR: 1e-05\n",
      "Epoch 185, Train loss: 0.0054181268, Validation loss: 0.0054199996, LR: 1e-05\n",
      "Epoch 186, Train loss: 0.0054170770, Validation loss: 0.0054199392, LR: 1e-05\n",
      "Epoch 187, Train loss: 0.0054180977, Validation loss: 0.0054200219, LR: 1e-05\n",
      "Epoch 188, Train loss: 0.0054176893, Validation loss: 0.0054199780, LR: 1e-05\n",
      "Epoch 189, Train loss: 0.0054179244, Validation loss: 0.0054200118, LR: 1e-05\n",
      "Epoch 190, Train loss: 0.0054179812, Validation loss: 0.0054200008, LR: 1e-05\n",
      "Epoch 191, Train loss: 0.0054181445, Validation loss: 0.0054199700, LR: 1e-05\n",
      "Epoch 192, Train loss: 0.0054185641, Validation loss: 0.0054199756, LR: 1e-05\n",
      "Epoch 193, Train loss: 0.0054178478, Validation loss: 0.0054200263, LR: 1e-05\n",
      "Epoch 194, Train loss: 0.0054180443, Validation loss: 0.0054200297, LR: 1e-05\n",
      "Epoch 195, Train loss: 0.0054180169, Validation loss: 0.0054199931, LR: 1e-05\n",
      "Epoch 196, Train loss: 0.0054184400, Validation loss: 0.0054199557, LR: 1e-05\n",
      "Epoch 197, Train loss: 0.0054181938, Validation loss: 0.0054199460, LR: 1e-05\n",
      "Epoch 198, Train loss: 0.0054177819, Validation loss: 0.0054199497, LR: 1e-05\n",
      "Epoch 199, Train loss: 0.0054179778, Validation loss: 0.0054199310, LR: 1e-05\n",
      "Epoch 200, Train loss: 0.0054180314, Validation loss: 0.0054199706, LR: 1e-05\n",
      "Epoch 201, Train loss: 0.0054172956, Validation loss: 0.0054200121, LR: 1e-05\n",
      "Epoch 202, Train loss: 0.0054184454, Validation loss: 0.0054199523, LR: 1e-05\n",
      "Epoch 203, Train loss: 0.0054187948, Validation loss: 0.0054199407, LR: 1e-05\n",
      "Epoch 204, Train loss: 0.0054183639, Validation loss: 0.0054199232, LR: 1e-05\n",
      "Epoch 205, Train loss: 0.0054180857, Validation loss: 0.0054199471, LR: 1e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m validation_loader \u001b[38;5;241m=\u001b[39m DataLoader(validation_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(validation_loader)\n",
      "File \u001b[0;32m~/Desktop/bioinfmsc/diss/init_model_lstm.py:85\u001b[0m, in \u001b[0;36mDeconvolutionModel.fit\u001b[0;34m(self, train_dataloader, val_dataloader, epochs, patience)\u001b[0m\n\u001b[1;32m     82\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Compute prediction and loss\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(pred, y)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ww/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ww/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/bioinfmsc/diss/init_model_lstm.py:52\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(out)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Apply Sparsemax to the output\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparsemax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ww/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ww/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/bioinfmsc/diss/sparsemax.py:81\u001b[0m, in \u001b[0;36mSparsemax.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msparsemax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ww/lib/python3.9/site-packages/torch/autograd/function.py:598\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    602\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ww/lib/python3.9/site-packages/torch/cuda/amp/autocast_mode.py:115\u001b[0m, in \u001b[0;36mcustom_fwd.<locals>.decorate_fwd\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cast_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fwd_used_autocast \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_enabled()\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfwd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     autocast_context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_enabled()\n",
      "File \u001b[0;32m~/Desktop/bioinfmsc/diss/sparsemax.py:53\u001b[0m, in \u001b[0;36mSparsemaxFunction.forward\u001b[0;34m(ctx, input, dim)\u001b[0m\n\u001b[1;32m     51\u001b[0m max_val, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m max_val  \u001b[38;5;66;03m# same numerical stability trick as for softmax\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m tau, supp_size \u001b[38;5;241m=\u001b[39m \u001b[43m_threshold_and_support\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28minput\u001b[39m \u001b[38;5;241m-\u001b[39m tau, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     55\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(supp_size, output)\n",
      "File \u001b[0;32m~/Desktop/bioinfmsc/diss/sparsemax.py:33\u001b[0m, in \u001b[0;36m_threshold_and_support\u001b[0;34m(input, dim)\u001b[0m\n\u001b[1;32m     31\u001b[0m support_size \u001b[38;5;241m=\u001b[39m support\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39mdim)\u001b[38;5;241m.\u001b[39munsqueeze(dim)\n\u001b[1;32m     32\u001b[0m tau \u001b[38;5;241m=\u001b[39m input_cumsum\u001b[38;5;241m.\u001b[39mgather(dim, support_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m tau \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43msupport_size\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tau, support_size\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset=TensorDataset(snv_freqs, known_freqs_splits[i])\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = random_split(\n",
    "        dataset, [0.8, 0.1, 0.1]\n",
    "    )\n",
    "\n",
    "batch_size = 64  # Arbitrarily chosen\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model.fit(train_loader, validation_loader, epochs=10000)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(validation_loader)\n",
    "\n",
    "# Predict using he model\n",
    "predictions, actuals = model.predict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47fd7c24-926a-4aa0-939e-dcaae79f9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = TensorDataset(snv_freqs_splits[0], known_freqs_splits[0])\n",
    "\n",
    "total_size = len(dataset_1)\n",
    "test_size = total_size // 10  # 10% for test\n",
    "validation_size = total_size // 10  # 10% for validation\n",
    "train_size = total_size - test_size - validation_size  # 80% train\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = random_split(\n",
    "        dataset_1, [train_size, validation_size, test_size]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55f63d54-55d6-446c-b7be-8e5630622177",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Arbitrarily chosen\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fb64393-f601-407e-958d-9fabc86e52b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "hidden_size=126\n",
    "num_layers=1\n",
    "model = DeconvolutionModel(input_size, hidden_size, output_size, num_layers, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8a80b21-0f66-437f-9a62-4f6520805257",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Adam' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Adam' object is not callable"
     ]
    }
   ],
   "source": [
    "model.optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3155d08-a8f4-422d-8ae8-af040f519c43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_loader, validation_loader, epochs=10000)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(validation_loader)\n",
    "\n",
    "# Predict using he model\n",
    "predictions, actuals = model.predict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05f340-a907-45bb-991f-a5715e027dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(predictions.flatten(), actuals.flatten(), alpha=0.5)\n",
    "plt.xlabel('Predicted Frequencies')\n",
    "plt.ylabel('Actual Frequencies')\n",
    "plt.title(f'Predicted vs Actual Frequencies of Baseline LSTM Model RMSE Loss, Hidden Size 256 Variable LR, 250 Patience, More Samples')\n",
    "plt.savefig(f'Predicted vs Actual Split [i+1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff84ff81-cfbb-4365-84db-68a715cd6a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(predictions.flatten(), actuals.flatten(), alpha=0.5)\n",
    "plt.xlabel('Predicted Frequencies')\n",
    "plt.ylabel('Actual Frequencies')\n",
    "plt.title(f'Predicted vs Actual Frequencies of Baseline LSTM Model RMSE Loss, Hidden Size 128 Variable LR, 250 Patience')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d091545a-d3ac-45a4-878f-c5daa13d66f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(predictions.flatten(), actuals.flatten(), alpha=0.5)\n",
    "plt.xlabel('Predicted Frequencies')\n",
    "plt.ylabel('Actual Frequencies')\n",
    "plt.title(f'Predicted vs Actual Frequencies of Baseline LSTM Model RMSE Loss, Hidden Size 128 Variable LR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62c52645-8b42-4500-a914-a6a46280d298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAPdCAYAAABba9tpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzde5wT5b0/8M/MJDOTZJNssrvssiuXFRGkaEWoCBy81Iq3WrVasSraFk+l2iNIe6x4qdcjxarFG15aldoL0lat9hQVvFSxUlst2Fat9SiwyO4Cu8km2SQzk7n8/tjfphuShc2SvX/er1deNc88M/OdVDfPfvd5vo/gOI4DIiIiIiIiIiKifiQOdABERERERERERDTyMClFRERERERERET9jkkpIiIiIiIiIiLqd0xKERERERERERFRv2NSioiIiIiIiIiI+h2TUkRERERERERE1O+YlCIiIiIiIiIion7HpBQREREREREREfU7JqWIiIiIiIiIiKjfMSlFNIIJgtCj1x/+8IcBjfP444+HIAg45ZRT8o5t27YNgiDgzjvvHIDI8r3//vu46aabsG3btrxjX/va1zB+/Ph+j6nTN77xjexn2PmZ7u910003AQDGjx8PQRCwaNGivOv+4Q9/gCAI+M1vfpNte/TRR1FXV4dkMtkvz0ZERDQYDLWxVefL4/Hgs5/9LFauXAnbtkt+v9WrV0MQhJzx0S9/+UusXLmyYP+uY5D+1tbWhsrKSjz55JPZcWZPXtu2bcuOiTpfkiShuroaX/nKV/DBBx9k7/Gvf/0Lsizjr3/964A8I9Fg4hroAIho4GzatCnn/a233opXX30Vr7zySk77lClT+jOsbr344ot45ZVX8PnPf36gQ+nW+++/j5tvvhnHH398XgLqhhtuwOLFiwckrs2bN+OnP/0p3nrrLQDAqlWrEI/Hs8d///vf47bbbsPjjz+OyZMnZ9sPOuignOs8+uijuOqqqzBp0qR93u+SSy7BihUrcMcdd+Dmm28u4ZMQERENXkNpbHXwwQfjF7/4BQBg9+7deOihh3DVVVehqakJK1asKOm9Tj/9dGzatAmjR4/Otv3yl7/EP/7xDyxZsiSv/6ZNm/LGIP3l5ptvRm1tLebPnw/DMPL+P7388ssRi8Wyn12n0aNHZ5Nut99+O0444QQYhoG3334bt9xyC15++WX8/e9/R11dHQ499FBceOGFuOqqq/Daa6/116MRDUpMShGNYMccc0zO+6qqKoiimNe+t1QqBa/X25eh5Tn00ENhmiauvvpq/OUvf4EgCP16/1KYMGHCgN37Bz/4AY4++mjMmDEDQP5g+J///CcAYOrUqdk+e5s1axbef/99XHvttXjqqaf2eT+Xy4XLLrsMt956K773ve/1+78vREREA2Eoja08Hk9OXKeeeiomT56M+++/H7fddhvcbnfJ7lVVVYWqqqoe99/f59VXIpEIHn74YfzoRz+CIAhQFCUvlkAgAMMw9hnjxIkTs8ePPfZYlJeXY+HChVi9ejWuu+46AMC3v/1tzJgxA2+++SZmz57ddw9FNMhx+R4R7dPxxx+PqVOn4vXXX8fs2bPh9XrxjW98A0D3U6vHjx+Pr33tazltzc3NuOyyy3DQQQdBlmXU19fj5ptvhmmaPYrD7Xbjf/7nf/DOO+9g7dq1++3f0/t9+umnOPfcc+H3+1FeXo4LL7wwm/RavXp1tt/bb7+N888/H+PHj4fH48H48ePx1a9+Fdu3b8/2Wb16Nb7yla8AAE444YTs1O3O6+y9fG/atGmYO3duXuyWZaGurg5f/vKXs22GYeC2227D5MmToSgKqqqq8PWvfx179uzZ72exa9cuPPPMM1iwYMF+++5LOBzGNddcg6effhp/+tOf9tv/wgsvRDwex5NPPnlA9yUiIhpOBsvYam9utxvTp09HKpXKji/+8Y9/4Mwzz0QoFIKqqjjyyCPx05/+NOc827Zx2223YdKkSfB4PCgvL8cRRxyBe+65J9tn7+V7xx9/PH7/+99j+/btOcvdOnX9HN59910IgoBHH300L+bnn38egiDgueeey7Z99NFHuOCCCzBq1CgoioLDDjsMDzzwQI8+g9WrV8M0TcyfP79H/XuqM0HVddw4ffp0HHbYYXjooYdKei+ioYYzpYhov5qamnDRRRfh6quvxu233w5RLC6f3dzcjKOPPhqiKOL73/8+JkyYgE2bNuG2227Dtm3b8Pjjj/foOvPnz8edd96J66+/Huecc063f8Hr6f2SySROOOEERCIRrFixAocccgheeOGFggORbdu2YdKkSTj//PMRDofR1NSEBx98EJ/73Ofw/vvvo7KyEqeffjpuv/12XHvttXjggQdw1FFHAeh+htTXv/51LF68GB999BEmTpyYbV+/fj0aGxvx9a9/HUDHYO/MM8/Exo0bcfXVV2P27NnYvn07brzxRhx//PF4++234fF4uv3c1q9fj0wmgxNOOKFHn/O+LF68GPfffz+uvvpqvP766/vsW1NTg8mTJ+P3v/99drBNREREg2dstbePP/4YLpcLoVAIH374IWbPno1Ro0bh3nvvRUVFBX7+85/ja1/7Gnbt2oWrr74aAHDHHXfgpptuwvXXX49jjz0WmUwG//znP9HW1tbtfVatWoVvfvOb+Pjjj/HMM8/sM6bPfvazmDZtGh5//HEsXLgw59jq1asxatQonHbaaQA6yijMnj0bY8eOxV133YWamhq8+OKLuPLKK9HS0oIbb7xxn/f6/e9/j2nTpqG8vHz/H1YR/u///g8A8maLHX/88fj1r38Nx3GG5CoAopJwiIj+v0suucTx+Xw5bccdd5wDwHn55Zfz+gNwbrzxxrz2cePGOZdcckn2/WWXXeaUlZU527dvz+l35513OgCc9957b59xHXfccc5nPvMZx3Ec56WXXnIAOPfdd5/jOI6zdetWB4Dzwx/+sOj7PfDAAw4A5/nnn8/pd9lllzkAnMcff7zbmEzTdNrb2x2fz+fcc8892fZf//rXDgDn1VdfzTvnkksuccaNG5d939LS4siy7Fx77bU5/c477zynurrayWQyjuM4zpo1axwAzlNPPZXT7y9/+YsDwFm1alW3cTqO43zrW99yPB6PY9t2t30ef/xxB4Dzl7/8peDxcePGOaeffrrjOI7z4x//2AHg/O53v3Mcx3FeffVVB4Dz61//Ou+8Cy+80Kmurt5nfERERMPVYB9bZTIZJ5PJOI2Njc4111zjAHC+8pWvOI7jOOeff76jKIrT0NCQc+6pp57qeL1ep62tzXEcx/niF7/oHHnkkfu8X+c4Y+vWrdm2008/PWdc1NXen8O9997rAHA+/PDDbFskEnEURXG+853vZNtOPvlk56CDDnJisVjO9b797W87qqo6kUhkn3F6vV5n0aJF++zTdVy6t84x0dq1a51MJuOkUinn9ddfdw455BBHkiTn3XffzenfOab64IMP9nlPouGMy/eIaL9CodABFRf/3//9X5xwwgmora2FaZrZ16mnngoARRV4PPHEEzFv3jzccsstSCQSB3S/1157DX6/P29Xv69+9at512xvb8f3vvc9HHLIIXC5XHC5XCgrK0MymczZTaUYFRUVOOOMM/DTn/40u9NNNBrFs88+i4svvhgulyv7POXl5TjjjDNynufII49ETU3NfnfwaWxsRFVVVcn+Avf1r38dU6ZMwTXXXLPfHXpGjRqF3bt393opARER0XA0GMZW7733HtxuN9xuN2pra3HXXXfhwgsvxI9//GMAwCuvvIITTzwRY8aMyTnva1/7GlKpVLYA+NFHH413330Xl19+OV588cWcjVRK5cILL4SiKDmlFdasWQNd17MzyzVNw8svv4yzzz4bXq8353M57bTToGnaPssPtLW1IZVKYdSoUQcc7/z58+F2u+H1enHsscfCsiz85je/wRFHHJHTr/NeO3fuPOB7Eg1VXL5HRPvVdaeU3ti1axd+97vfdbvcrqWlpajrrVixAkcddRTuvPPO7ECkN/drbW1FdXV13vFCbRdccAFefvll3HDDDfjc5z6HQCAAQRBw2mmnIZ1OFxV/V9/4xjfw1FNPYcOGDTj55JOzA6yudSN27dqFtrY2yLK8z+fpTjqdhqqqvY5xb5Ik4fbbb8dZZ52Fn/70p6ivr++2r6qqcBwHmqahrKysZDEQERENZYNhbDVhwgQ8+eSTEAQBqqqivr4+p9h6a2trwThra2uzxwFg2bJl8Pl8+PnPf46HHnoIkiTh2GOPxYoVK7rdPKVY4XAYX/rSl/DEE0/g1ltvhSRJWL16NY4++mh85jOfycZjmibuu+8+3HfffQWvs6/PpXM8V4ox04oVK/D5z38ekiShsrIyL7HXqfNeBzKWJBrqmJQiov3qboaNoijQdT2vvXOQ0qmyshJHHHEE/ud//qfgdToHNz115JFH4qtf/SruvvvubA2B3tyvoqICf/7zn/OONzc357yPxWL43//9X9x444245pprsu26riMSiRQV+95OPvlk1NbW4vHHH8fJJ5+Mxx9/HDNnzszZHa+yshIVFRV44YUXCl7D7/fv8x6VlZX461//ekBx7u3MM8/EnDlzcOONN+KRRx7ptl8kEoGiKExIERERdTEYxlaqqu4zaVRRUYGmpqa89sbGxmwMQMeOu0uXLsXSpUvR1taGl156Cddeey1OPvlk7Nixo2S7Cn7961/Hr3/9a2zYsAFjx47FX/7yFzz44IPZ46FQCJIkYcGCBbjiiisKXmNff0irqKgAgAMe2wHAwQcf3KOEXOe9Oj9LopGISSki6rXx48fjb3/7W07bK6+8gvb29py2L37xi1i3bh0mTJiAUChUknvfdttt+M1vfoObb74571hP73fcccfhV7/6FZ5//vnsdHcAebvFCYIAx3GgKEpO+09+8hNYlpXT1tmnp3/x6hw8rVy5Ehs3bsTbb7+Nhx9+OO95nnzySViWhZkzZ/boul1NnjwZa9asQSwWQzAYLPr87qxYsQL/8R//gXvvvbfbPp988klOgo2IiIi6N5Bjq72deOKJeOaZZ9DY2JiT5HriiSfg9XqzO8p1VV5ejnPPPRc7d+7EkiVLsG3btm7HAYqiFDVDaN68eairq8Pjjz+OsWPHQlXVnJILXq8XJ5xwAjZv3owjjjii2xnm3ZFlGQcffDA+/vjjos47EJ988glEUcSkSZP67Z5Egw2TUkTUawsWLMANN9yA73//+zjuuOPw/vvv4/77789LfNxyyy3YsGEDZs+ejSuvvBKTJk2CpmnYtm0b1q1bh4ceeggHHXRQUfeur6/Ht771rZzthou93yWXXIIf/ehHuOiii3DbbbfhkEMOwfPPP48XX3wRALI74QQCARx77LH44Q9/iMrKSowfPx6vvfYaHn300bzdWaZOnQoAeOSRR+D3+7PT4Tv/+lbIN77xDaxYsQIXXHABPB5P3u5/559/Pn7xi1/gtNNOw+LFi3H00UfD7Xbj008/xauvvoozzzwTZ599drfXP/744+E4Dt566y3MmzevR59vT8yZMwdnnnkmnn322YLHbdvGn//857ydcoiIiKiwgRxb7e3GG2/M1q76/ve/j3A4jF/84hf4/e9/jzvuuCMb0xlnnIGpU6dixowZqKqqwvbt27Fy5UqMGzcuZ3fhvR1++OF4+umn8eCDD2L69OkQRXGfs4skScLFF1+Mu+++G4FAAF/+8pfzPpd77rkH//Ef/4G5c+fiW9/6FsaPH49EIoH/+7//w+9+9zu88sor+3zm448/Hs8//3wRn9KB+dOf/oQjjzyyzxKLREPCABdaJ6JBpLsdYrrbYUTXdefqq692xowZ43g8Hue4445ztmzZkrdDjOM4zp49e5wrr7zSqa+vd9xutxMOh53p06c71113ndPe3r7PuLqLYc+ePU4gEMjbfa+Y+zU0NDhf/vKXnbKyMsfv9zvnnHOOs27dOgeA8+yzz2b7ffrpp84555zjhEIhx+/3O6eccorzj3/8o+Czrly50qmvr3ckScrZxW/v3fe6mj17tgPAufDCCwsez2Qyzp133ul89rOfdVRVdcrKypzJkyc7l112mfPRRx/t8/OzLMsZP368c/nll3fbp5jd97p6//33s8+59+57L7/8sgPAeeedd/YZHxER0XA11MZWe/v73//unHHGGU4wGHRkWXY++9nP5u1OfNdddzmzZ892KisrHVmWnbFjxzoLFy50tm3blu1TaPe9SCTinHvuuU55ebkjCILT9VdTdLML4b/+9S8HgAPA2bBhQ8GYt27d6nzjG99w6urqHLfb7VRVVTmzZ892brvttv0+b+fY5c9//nO3fXqy+16hHYn3lkgkHK/X69x111377Us0nAmO4zgDkQwjIhqsbr/9dlx//fVoaGg44L8yDhZ33XUX/ud//gc7d+6Ex+Ppl3suWLAAn3zyCf74xz/2y/2IiIiIDtQRRxyBOXPm5NSr6guPPvooFi9ejB07dnCmFI1oTEoR0Yh2//33A+iou5TJZPDKK6/g3nvvxfz58/HEE08McHSlo2kaDjvsMFxxxRX47ne/2+f3+/jjj3HYYYfhlVdewX/8x3/0+f2IiIiISuGFF17A2WefjY8++qjP/jhpmiamTJmCSy65BNddd12f3INoqGBNKSIa0bxeL370ox9h27Zt0HUdY8eOxfe+9z1cf/31Ax1aSamqip/97GfYvHlzv9yvoaEB999/PxNSRERENKSccsop+OEPf4itW7f2WVJqx44duOiii/Cd73ynT65PNJRwphQREREREREREfU7caADICIiIiIiIiKikYdJKSIiIiIiIiIi6nesKVUCtm2jsbERfr8fgiAMdDhERERUQo7jIJFIoLa2FqLIv+eVCsdPREREw1dPx09MSpVAY2MjxowZM9BhEBERUR/asWNHnxW9HYk4fiIiIhr+9jd+YlKqBPx+P4CODzsQCAxwNERERFRK8XgcY8aMyX7fU2lw/ERERDR89XT8xKRUCXROOQ8EAhxUERERDVNcYlZaHD8RERENf/sbP7EwAhERERERERER9TsmpYiIiIiIiIiIqN8xKUVERERERERERP2OSSkiIiIiIiIiIup3TEoREREREREREVG/Y1KKiIiIiIiIiIj6HZNSRERERCPAqlWrUF9fD1VVMX36dGzcuLFH5/3xj3+Ey+XCkUcemXfsqaeewpQpU6AoCqZMmYJnnnmmxFETERHRcMakFBEREdEwt3btWixZsgTXXXcdNm/ejLlz5+LUU09FQ0PDPs+LxWK4+OKLceKJJ+Yd27RpE+bPn48FCxbg3XffxYIFC3Deeefhrbfe6qvHICIiomFGcBzHGegghrp4PI5gMIhYLIZAIDDQ4RAREVEJDYfv+ZkzZ+Koo47Cgw8+mG077LDDcNZZZ2H58uXdnnf++edj4sSJkCQJv/3tb7Fly5bssfnz5yMej+P555/Ptp1yyikIhUJYs2ZN3rV0XYeu69n38XgcY8aMGdKfKxERERXW0/ETZ0oRERERDWOGYeCdd97BvHnzctrnzZuHN998s9vzHn/8cXz88ce48cYbCx7ftGlT3jVPPvnkbq+5fPlyBIPB7GvMmDFFPgkRERENN0xKEREREQ1jLS0tsCwL1dXVOe3V1dVobm4ueM5HH32Ea665Br/4xS/gcrkK9mlubi7qmsuWLUMsFsu+duzY0YunISIiouGk8CiDiIiIiIYVQRBy3juOk9cGAJZl4YILLsDNN9+MQw89tCTXBABFUaAoSpFRExFRMXRTh+3YEAURios/c2nwY1KKiIiIaBirrKyEJEl5M5h2796dN9MJABKJBN5++21s3rwZ3/72twEAtm3DcRy4XC6sX78en//851FTU9PjaxIRUd/STA2RVAQJIwHLtiCJEvyyH2FvGKpLHejwiLrF5XtEREREw5gsy5g+fTo2bNiQ075hwwbMnj07r38gEMDf//53bNmyJftatGgRJk2ahC1btmDmzJkAgFmzZuVdc/369QWvSUREfUczNeyM70RUi0JxKQiqQSguBVEtip3xndBMbaBDJOoWZ0oRERERDXNLly7FggULMGPGDMyaNQuPPPIIGhoasGjRIgAd9Z527tyJJ554AqIoYurUqTnnjxo1Cqqq5rQvXrwYxx57LFasWIEzzzwTzz77LF566SW88cYb/fpsREQjXSQVgWZqCHlC2TZZkiF7ZETTUURSEdQGagcwQqLuMSlFRERENMzNnz8fra2tuOWWW9DU1ISpU6di3bp1GDduHACgqakJDQ0NRV1z9uzZePLJJ3H99dfjhhtuwIQJE7B27drsTCoiIup7uqkjYSTgk30Fj/tkHxJGArqps8YUDUqC4zjOQAcx1MXjcQSDQcRiMQQCgYEOh4iIiEqI3/N9g58rEdGBS2fS2BrdiqAaLLjRhOM4iGkx1Ifq4XF7BiBCGql6+j3PmlJEREREREREQ5AoiJBECRk7U/B4xs5AEiWIAn/1p8GJ/2YSERERERERDUGKS4Ff9iNpJAseTxpJ+GU/l+7RoMWkFBEREREREdEQFfaGobpURNNRGJYBx3FgWAai6ShUl4qwNzzQIRJ1i4XOiYiIiIiIiIYo1aWiLlCHSCqChJFAyk5BEiWE1FA2YUU0WDEpRURERERERDSEqS4VtYFa6KYO27EhCiKX7NGQwKQUERERERER0TDARBQNNawpRURERERERERE/Y5JKSIiIiIiIiIi6ndMShERERERERERUb9jUoqIiIiIiIiIiPodk1JERERERERERNTvmJQiIiIiIiIiIqJ+5xroAIiIiIiIiIiIqH/ppg7bsSEKIhSXMiAxMClFRERERERERDRCaKaGSCqChJGAZVuQRAl+2Y+wNwzVpfZrLExKERERERERERGNAJqpYWd8JzRTg0/2wS26kbEziGpRpM006gJ1/ZqYYk0pIiIiIiIiIqIRIJKKQDM1hDwhyJIMQRAgSzJCnlB2BlV/YlKKiIiIiIiIiGiY000dCSMBn+wreNwn+5AwEtBNvd9iYlKKiIiIiIiIiGiYsx0blm3BLboLHneLbli2Bdux+y0mJqWIiIiIiIiIiIY5URAhiRIydqbg8YydgSRKEIX+SxUxKUVERERERERENMwpLgV+2Y+kkSx4PGkk4Zf9UFxKv8XEpBQRERERERER0QgQ9oahulRE01EYlgHHcWBYBqLpKFSXirA33K/xuPr1bkRERERERERENCBUl4q6QB0iqQgSRgIpOwVJlBBSQ9mEVX9iUoqIiIiIiIiIaIRQXSpqA7XQTR22Y0MUxH5dstcVk1JERERERERERCPMQCWiumJNKSIiIiIiIiIi6ndMShERERERERERUb9jUoqIiIiIiIiIiPodk1JERERERERERNTvmJQiIiIiIiIiIqJ+x6QUERERERERERH1OyaliIiIiIiIiIio3zEpRURERERERERE/Y5JKSIiIiIiIiIi6ndDLim1atUq1NfXQ1VVTJ8+HRs3btxn/9deew3Tp0+Hqqo4+OCD8dBDD3Xb98knn4QgCDjrrLNKHDUREREREREREXU1pJJSa9euxZIlS3Dddddh8+bNmDt3Lk499VQ0NDQU7L9161acdtppmDt3LjZv3oxrr70WV155JZ566qm8vtu3b8d3v/tdzJ07t68fg4iIiIiIiIhoxBMcx3EGOoiemjlzJo466ig8+OCD2bbDDjsMZ511FpYvX57X/3vf+x6ee+45fPDBB9m2RYsW4d1338WmTZuybZZl4bjjjsPXv/51bNy4EW1tbfjtb3/b47ji8TiCwSBisRgCgUDvHo6IiIgGJX7P9w1+rkRERMNXT7/nh8xMKcMw8M4772DevHk57fPmzcObb75Z8JxNmzbl9T/55JPx9ttvI5PJZNtuueUWVFVVYeHChT2KRdd1xOPxnBcREREREREREfXckElKtbS0wLIsVFdX57RXV1ejubm54DnNzc0F+5umiZaWFgDAH//4Rzz66KP48Y9/3ONYli9fjmAwmH2NGTOmyKchIiIi6l/F1OV84403MGfOHFRUVMDj8WDy5Mn40Y9+lNNn9erVEAQh76VpWl8/ChEREQ0TroEOoFiCIOS8dxwnr21//TvbE4kELrroIvz4xz9GZWVlj2NYtmwZli5dmn0fj8eZmCIiIqJBq7Mu56pVqzBnzhw8/PDDOPXUU/H+++9j7Nixef19Ph++/e1v44gjjoDP58Mbb7yByy67DD6fD9/85jez/QKBAD788MOcc1VV7fPnISIiouFhyCSlKisrIUlS3qyo3bt3582G6lRTU1Owv8vlQkVFBd577z1s27YNZ5xxRva4bdsAAJfLhQ8//BATJkzIu66iKFAU5UAfiYiIiKhf3H333Vi4cCEuvfRSAMDKlSvx4osv4sEHHyxYl3PatGmYNm1a9v348ePx9NNPY+PGjTlJKUEQUFNT06MYdF2HruvZ9yx/QERERENm+Z4sy5g+fTo2bNiQ075hwwbMnj274DmzZs3K679+/XrMmDEDbrcbkydPxt///nds2bIl+/rSl76EE044AVu2bOHsJyIiIhryelOXc2+bN2/Gm2++ieOOOy6nvb29HePGjcNBBx2EL37xi9i8eXO312D5AyIiItrbkElKAcDSpUvxk5/8BI899hg++OADXHXVVWhoaMCiRYsAdCyru/jii7P9Fy1ahO3bt2Pp0qX44IMP8Nhjj+HRRx/Fd7/7XQAd08unTp2a8yovL4ff78fUqVMhy/KAPCcRERFRqfSmLmengw46CIqiYMaMGbjiiiuyM60AYPLkyVi9ejWee+45rFmzBqqqYs6cOfjoo48KXmvZsmWIxWLZ144dOw784YiIiGhIGzLL9wBg/vz5aG1txS233IKmpiZMnToV69atw7hx4wAATU1NaGhoyPavr6/HunXrcNVVV+GBBx5AbW0t7r33XpxzzjkD9QhEREREA6LYupwAsHHjRrS3t+NPf/oTrrnmGhxyyCH46le/CgA45phjcMwxx2T7zpkzB0cddRTuu+8+3HvvvXnXYvkDIiIi2tuQSkoBwOWXX47LL7+84LHVq1fntR133HH461//2uPrF7oGERER0VDVm7qcnerr6wEAhx9+OHbt2oWbbropm5TamyiK+NznPtftTCkiIiKivQ2p5XtEREREVJze1OUsxHGcnELlhY5v2bIFo0eP7nWsRERENLIMuZlSRERERFScpUuXYsGCBZgxYwZmzZqFRx55JK8u586dO/HEE08AAB544AGMHTsWkydPBgC88cYbuPPOO/Ff//Vf2WvefPPNOOaYYzBx4kTE43Hce++92LJlCx544IH+f0AiIiIakpiUIiIiIhrmiq3Lads2li1bhq1bt8LlcmHChAn4wQ9+gMsuuyzbp62tDd/85jfR3NyMYDCIadOm4fXXX8fRRx/d789HREREQ5PgOI4z0EEMdfF4HMFgELFYDIFAYKDDISIiohLi93zf4OdKREQ0fPX0e541pYiIiIiIiIiIqN8xKUVERERERERERP2OSSkiIiIiIiIiIup3TEoREREREREREVG/Y1KKiIiIiIiIiIj6nWugAyAiIiIiIiIi6ind1GE7NkRBhOJSBjocOgBMShERERERERHRoKeZGiKpCBJGApZtQRIl+GU/wt4wVJc60OFRLzApRURERERERESDmmZq2BnfCc3U4JN9cItuZOwMoloUaTONukAdE1NDEGtKEREREREREdGgFklFoJkaQp4QZEmGIAiQJRkhTyg7g4qGHialiIiIiIiIiGjQ0k0dCSMBn+wreNwn+5AwEtBNvZ8jowPFpBQRERERERERDVq2Y8OyLbhFd8HjbtENy7ZgO3Y/R0YHikkpIiIiIiIiIhq0REGEJErI2JmCxzN2BpIoQRSY4hhq+P8YEREREREREQ1aikuBX/YjaSQLHk8aSfhlPxSX0s+R0YFiUoqIiIiIiIiIBrWwNwzVpSKajsKwDDiOA8MyEE1HobpUhL3hgQ6ResE10AEQEREREREREe2L6lJRF6hDJBVBwkggZacgiRJCaiibsKKhh0kpIiIiIiIiIhr0VJeK2kAtdFOH7dgQBZFL9oY4JqWIiIiIiIiIaMhgImr4YE0pIiIiIiIiIiLqd0xKERERERERERFRv2NSioiIiIiIiIiI+h2TUkRERERERERE1O+YlCIiIiIiIiIion7HpBQREREREREREfU7JqWIiIiIiIiIiKjfMSlFRERERERERET9jkkpIiIiIiIiIiLqd0xKERERERERERFRv2NSioiIiIiIiIiI+h2TUkRERERERERE1O9cAx0AEREREREREQ1OuqnDdmyIggjFpQx0ODTMMClFREREREREQw6TJX1LMzVEUhEkjAQs24IkSvDLfoS9YagudaDDo2GCSSkiIiIiIiIaMpgs6XuaqWFnfCc0U4NP9sEtupGxM4hqUaTNNOoCdfysqSRYU4qIiIiIiIiGhM5kSVSLQnEpCKpBKC4FUS2aTaLQgYukItBMDSFPCLIkQxAEyJKMkCeUTQoSlQKTUkRERERERDQkMFnS93RTR8JIwCf7Ch73yT4kjAR0U+/nyGg4YlKKiIiIiIiIBj0mS/qH7diwbAtu0V3wuFt0w7It2I7dz5HRcMSkFBEREREREQ16TJb0D1EQIYkSMnam4PGMnYEkShAFphPowPHfIiIiIiIiIhr0mCzpH4pLgV/2I2kkCx5PGkn4ZT93PKSS4H+tRERERCPAqlWrUF9fD1VVMX36dGzcuLHbvm+88QbmzJmDiooKeDweTJ48GT/60Y/y+j311FOYMmUKFEXBlClT8Mwzz/TlIxDRCMdkSf/p3Mkwmo7CsAw4jgPDMhBNR6G6VIS94YEOkYYJJqWIiIiIhrm1a9diyZIluO6667B582bMnTsXp556KhoaGgr29/l8+Pa3v43XX38dH3zwAa6//npcf/31eOSRR7J9Nm3ahPnz52PBggV49913sWDBApx33nl46623+uuxiGgEYrKkf6guFXWBOoTUEHRTR0yLQTd1hNQQ6gJ1UF3qQIdIw4TgOI4z0EEMdfF4HMFgELFYDIFAYKDDISIiohIaDt/zM2fOxFFHHYUHH3ww23bYYYfhrLPOwvLly3t0jS9/+cvw+Xz42c9+BgCYP38+4vE4nn/++WyfU045BaFQCGvWrMk7X9d16Pq/iw/H43GMGTNmSH+uRDQwOnfZSxgJWLYFSZTgl/3ZhBWVlm7qsB0boiByFhr1WE/HT5wpRURERDSMGYaBd955B/PmzctpnzdvHt58880eXWPz5s148803cdxxx2XbNm3alHfNk08+udtrLl++HMFgMPsaM2ZMkU9CRNRBdamoDdRifPl41IfqMb58PGoDtUxI9RHFpcDj9jAhRX2CSSkiIiKiYaylpQWWZaG6ujqnvbq6Gs3Nzfs896CDDoKiKJgxYwauuOIKXHrppdljzc3NRV1z2bJliMVi2deOHTt6+URERB2YLCEa+lwDHQARERER9T1BEHLeO46T17a3jRs3or29HX/6059wzTXX4JBDDsFXv/rVXl1TURQoCn9xJCIion9jUoqIiIhoGKusrIQkSXkzmHbv3p0302lv9fX1AIDDDz8cu3btwk033ZRNStXU1PTqmkRERESduHyPiIiIaBiTZRnTp0/Hhg0bcto3bNiA2bNn9/g6juPkFCqfNWtW3jXXr19f1DWJiIhoZONMKSIiIqJhbunSpViwYAFmzJiBWbNm4ZFHHkFDQwMWLVoEoKPe086dO/HEE08AAB544AGMHTsWkydPBgC88cYbuPPOO/Ff//Vf2WsuXrwYxx57LFasWIEzzzwTzz77LF566SW88cYb/f+ARERENCQxKUVEREQ0zM2fPx+tra245ZZb0NTUhKlTp2LdunUYN24cAKCpqQkNDQ3Z/rZtY9myZdi6dStcLhcmTJiAH/zgB7jsssuyfWbPno0nn3wS119/PW644QZMmDABa9euxcyZM/v9+YiIiGhoEhzHcQY6iKEuHo8jGAwiFoshEAgMdDhERERUQvye7xv8XImIiIavnn7Ps6YUERERERERERH1OyaliIiIiIiIiIio37GmFBEREREREZWcbuqwHRuiIEJxKQMdDhENQkxKERERERERUclopoZIKoKEkYBlW5BECX7Zj7A3DNWlDnR4RDSIMClFREREREREJaGZGnbGd0IzNfhkH9yiGxk7g6gWRdpMoy5Qx8QUEWWxphQRERERERGVRCQVgWZqCHlCkCUZgiBAlmSEPKHsDCoiok5MShEREREREdEB000dCSMBn+wreNwn+5AwEtBNvZ8jI6LBikkpIiIiIiIiOmC2Y8OyLbhFd8HjbtENy7ZgO3Y/R0ZEgxWTUkRERERERHTAREGEJErI2JmCxzN2BpIoQRT4aygRdeBPAyIiIiIiIjpgikuBX/YjaSQLHk8aSfhlPxSX0s+REdFgxaQUERERERERlUTYG4bqUhFNR2FYBhzHgWEZiKajUF0qwt7wQIdIRIOIa6ADICIiIiIiouFBdamoC9QhkoogYSSQslOQRAkhNZRNWBERdWJSioiIiIiIiEpGdamoDdRCN3XYjg1RELlkj4gKGnLL91atWoX6+nqoqorp06dj48aN++z/2muvYfr06VBVFQcffDAeeuihnOM//vGPMXfuXIRCIYRCIXzhC1/An//85758BCIiIiIiomFPcSnwuD1DIiGlmzrSmTR0Ux/oUIhGlCGVlFq7di2WLFmC6667Dps3b8bcuXNx6qmnoqGhoWD/rVu34rTTTsPcuXOxefNmXHvttbjyyivx1FNPZfv84Q9/wFe/+lW8+uqr2LRpE8aOHYt58+Zh586d/fVYRERERERENAA0U0NjvBHb2rZha3QrtrVtQ2O8EZqpDXRoRCOC4DiOM9BB9NTMmTNx1FFH4cEHH8y2HXbYYTjrrLOwfPnyvP7f+9738Nxzz+GDDz7Iti1atAjvvvsuNm3aVPAelmUhFArh/vvvx8UXX1ywj67r0PV/Z9Dj8TjGjBmDWCyGQCDQ28cjIiKiQSgejyMYDPJ7vsT4uRLRQNNMDTvjO6GZGnyyD27RjYydQdJIZmtjsQYWUe/09Ht+yMyUMgwD77zzDubNm5fTPm/ePLz55psFz9m0aVNe/5NPPhlvv/02MplMwXNSqRQymQzC4e53hVi+fDmCwWD2NWbMmCKfhoiIiIiIiAZSJBWBZmoIeUKQJRmCIECWZIQ8IWimhkgqMtAhEg17QyYp1dLSAsuyUF1dndNeXV2N5ubmguc0NzcX7G+aJlpaWgqec80116Curg5f+MIXuo1l2bJliMVi2deOHTuKfBoiIiIiIiIaKLqpI2Ek4JN9BY/7ZB8SRoI1poj62JDbfU8QhJz3juPkte2vf6F2ALjjjjuwZs0a/OEPf4Cqdj9NU1EUKMrgL9ZHRERERERE+WzHhmVbcIvugsfdohspOwXbsfs5MqKRZcjMlKqsrIQkSXmzonbv3p03G6pTTU1Nwf4ulwsVFRU57XfeeSduv/12rF+/HkcccURpgyciIiIiIqJBQxRESKKEjF24rEvGzkASJYjCkPmVmWhIGjL/hcmyjOnTp2PDhg057Rs2bMDs2bMLnjNr1qy8/uvXr8eMGTPgdv87I/7DH/4Qt956K1544QXMmDGj9METERERERHRoKG4FPhlP5JGsuDxpJGEX/ZDcXGFDFFfGjJJKQBYunQpfvKTn+Cxxx7DBx98gKuuugoNDQ1YtGgRgI5aT113zFu0aBG2b9+OpUuX4oMPPsBjjz2GRx99FN/97nezfe644w5cf/31eOyxxzB+/Hg0NzejubkZ7e3t/f58RERERERE1D/C3jBUl4poOgrDMuA4DgzLQDQdhepSEfZ2v/kVEZXGkKopNX/+fLS2tuKWW25BU1MTpk6dinXr1mHcuHEAgKamJjQ0NGT719fXY926dbjqqqvwwAMPoLa2Fvfeey/OOeecbJ9Vq1bBMAyce+65Ofe68cYbcdNNN/XLcxEREREREVH/Ul0q6gJ1iKQiSBgJpOwUJFFCSA1lE1ZE1LcEp7PyN/VaPB5HMBhELBZDIBAY6HCIiIiohPg93zf4uRLRYKKbOmzHhiiIXLJHVAI9/Z4fUjOliIiIiIiIiEqNiSiigcGkFBEREREREfUJzkAion1hUoqIiIiIiIhKSjO1bK0my7YgiRL8sp+1mogoB5NSREREREREVDKaqWFnfCc0U4NP9sEtupGxM4hqUaTNNOoCdUxMEREAQDzQC8Tjcfz2t7/FBx98UIp4iIiIiGgvHG8R0VASSUWgmRpCnhBkSYYgCJAlGSFPKDuDiogI6EVS6rzzzsP9998PAEin05gxYwbOO+88HHHEEXjqqadKHiARERHRSMPxFhENVbqpI2Ek4JN9BY/7ZB8SRgK6qR/wfdKZ9AFfh4gGVtFJqddffx1z584FADzzzDNwHAdtbW249957cdttt5U8QCIiIqKRhuMtIhqqbMeGZVtwi+6Cx92iG5ZtwXbsXl1fMzU0xhuxrW0btka3YlvbNjTGG6GZ2oGETUQDpOikVCwWQzgcBgC88MILOOecc+D1enH66afjo48+KnmARERERCMNx1tENFSJgghJlJCxMwWPZ+wMJFGCKBRfSaazVlVUi0JxKQiqQSguBVEtmq1hRURDS9E/CcaMGYNNmzYhmUzihRdewLx58wAA0WgUqspidUREREQHiuMtIhqqFJcCv+xH0kgWPJ40kvDLfigupehrs1YV0fBT9O57S5YswYUXXoiysjKMHTsWxx9/PICOaeaHH354qeMjIiIiGnE43iKioSzsDSNtphFNR3N230saSaguFWFvuOhrFlOrqjcJLyIaGEUnpS6//HIcffTR2LFjB0466SSIYsdkq4MPPpg1DoiIiIhKgOMtIhrKVJeKukAdIqkIEkYCKTsFSZQQUkMIe8NQXcXP+OxJraqUnep1rSoiGhiC4zhOb040DANbt27FhAkT4HIVndsaVuLxOILBIGKxGAKBwECHQ0RERCU0kN/zw3m8xfET0cigmzpsx4YoiAc0g0k3dWxr2wbFpUCW5LzjhmVAN3WMLx/PmVJEg0BPv+eLrimVSqWwcOFCeL1efOYzn0FDQwMA4Morr8QPfvCD3kdMRERERAD6Zry1atUq1NfXQ1VVTJ8+HRs3buy279NPP42TTjoJVVVVCAQCmDVrFl588cWcPqtXr4YgCHkvTWOhYSL6N8WlwOP2HHCiqC9rVRHRwCk6KbVs2TK8++67+MMf/pBTaPMLX/gC1q5dW9LgiIiIiEaiUo+31q5diyVLluC6667D5s2bMXfuXJx66qnZZNfeXn/9dZx00klYt24d3nnnHZxwwgk444wzsHnz5px+gUAATU1NOS8WYieivtK59C+ajsKwDDiOA8MyEE1He12riogGVtHzwH/7299i7dq1OOaYYyAIQrZ9ypQp+Pjjj0saHBEREdFIVOrx1t13342FCxfi0ksvBQCsXLkSL774Ih588EEsX748r//KlStz3t9+++149tln8bvf/Q7Tpk3LtguCgJqamqLjISLqjZ7UqirVckEi6h9FJ6X27NmDUaNG5bUnk8mcQRMRERER9U4px1uGYeCdd97BNddck9M+b948vPnmmz26hm3bSCQSCIdzZyG0t7dj3LhxsCwLRx55JG699dacpFVXuq5D1/Xs+3g8XtRzEBEBHYmp2kBtXvJJMzU0xhuRMBKwbAuSKMEv+3tdWJ2I+kfRy/c+97nP4fe//332fefA6Mc//jFmzZpVusiIiIiIRqhSjrdaWlpgWRaqq6tz2qurq9Hc3Nyja9x1111IJpM477zzsm2TJ0/G6tWr8dxzz2HNmjVQVRVz5szBRx99VPAay5cvRzAYzL7GjBlT1HMQEXXVtVaVZmrYGd+JqBaF4lIQVINQXAqiWhQ74zuhmax1RzRYFT1Tavny5TjllFPw/vvvwzRN3HPPPXjvvfewadMmvPbaa30RIxEREdGI0hfjrb1nWDmO06NZV2vWrMFNN92EZ599Nmf21jHHHINjjjkm+37OnDk46qijcN999+Hee+/Nu86yZcuwdOnS7Pt4PM7EFBGVRCQVgWZqCHlC2TZZkiF7ZETTUURSEdQGagcwQiLqTtEzpWbPno0//vGPSKVSmDBhAtavX4/q6mps2rQJ06dP74sYiYiIiEaUUo63KisrIUlS3qyo3bt3582e2tvatWuxcOFC/OpXv8IXvvCFffYVRRGf+9znup0ppSgKAoFAzouI6EDppo6EkYBP9hU87pN9SBgJ6KZe8DgRDayiZ0oBwOGHH46f/vSnpY6FiIiIiP6/Uo23ZFnG9OnTsWHDBpx99tnZ9g0bNuDMM8/s9rw1a9bgG9/4BtasWYPTTz99v/dxHAdbtmzB4YcffsAxExH1lO3YsGwLbtFd8LhbdCNlp2A7dj9HRkQ90aOkVDwez/41a39FKflXLyIiIqLi9eV4a+nSpViwYAFmzJiBWbNm4ZFHHkFDQwMWLVoEoGNp3c6dO/HEE08A6EhIXXzxxbjnnntwzDHHZGdZeTweBINBAMDNN9+MY445BhMnTkQ8Hse9996LLVu24IEHHigqNiKiAyEKIiRRQsbOQJbkvOMZOwNJlCAKRS8SIqJ+0KOkVCgUQlNTE0aNGoXy8vKC9Qc66xJYllXyIImIiIiGu74cb82fPx+tra245ZZb0NTUhKlTp2LdunUYN24cAKCpqQkNDQ3Z/g8//DBM08QVV1yBK664Itt+ySWXYPXq1QCAtrY2fPOb30RzczOCwSCmTZuG119/HUcffXQvnp6IqHcUlwK/7EdUi0L25CelkkYSITUExaUMQHREtD+C4zjO/jq99tprmDNnDlwu136Lax533HElC26oiMfjCAaDiMVinClGREQ0zPTX9/xIG29x/EREpdK5+55mavDJPrhFNzJ2BkkjCdWloi5QB9WlDnSYRCNKT7/ne5SUon3joIqIiGj44vd83+DnSkSlpJkaIqkIEkYClm1BEiX4ZT/C3jATUkQDoKff80UXOn/88cdRVlaGr3zlKzntv/71r5FKpXDJJZcUHy0RERERZXG8RURUHNWlojZQC93UYTs2REHs1yV7A3VfoqGu6GpvP/jBD1BZWZnXPmrUKNx+++0lCYqIiIhoJON4i4iodxSXAo/b02+JIc3U0BhvxLa2bdga3YptbdvQGG+EZmr9cn+ioa7omVLbt29HfX19Xvu4ceNyCmQSERERUe9wvEVENPh1V8sqqkWRNtOsZUXUA0XPlBo1ahT+9re/5bW/++67qKioKElQRERERCMZx1tERINfJBWBZmoIeUKQJRmCIECWZIQ8oWyNKyLat6KTUueffz6uvPJKvPrqq7AsC5Zl4ZVXXsHixYtx/vnn90WMRERERCMKx1tERIObbupIGAn4ZF/B4z7Zh4SRgG7q/RwZ0dBS9PK92267Ddu3b8eJJ54Il6vjdNu2cfHFF7PGAREREVEJcLxFRDS42Y4Ny7bgFt0Fj7tFN1J2CrZj93NkREOL4DiO05sT//Wvf+Hdd9+Fx+PB4YcfjnHjxpU6tiGDWxoTERENXwP5PT+cx1scPxEdOO74NnB0U8e2tm1QXApkSc47blgGdFPH+PLx/P+GRqSefs8XPVOq06GHHopDDz20t6cTERER0X5wvEVEhXTWK0oYCVi2BUmU4Jf9CHvDLKzdTxSXAr/sR1SLQvbkJ6WSRhIhNcSEFNF+FJ2UsiwLq1evxssvv4zdu3fDtnOnI77yyislC46IiIhoJOJ4i4i6wx3fBo+wN4y0mUY0Hc35/yJpJKG6VIS94YEOkWjQKzoptXjxYqxevRqnn346pk6dCkEQ+iIuIiIiohGL4y0i6k7XHd86yZIM2SMjmo4ikoqgNlA7gBGOHKpLRV2gLjtrLWWnIIkSQmqIs9aIeqjopNSTTz6JX/3qVzjttNP6Ih4iIiKiEY/jLSIqpJgd37hsrH+oLhW1gVrW9yLqpaKTUrIs45BDDumLWIiIiIgIHG8RUWHc8W3wYiKKqHfEYk/4zne+g3vuuQe93LSPiIiIiPaD4y0iKkQUREiihIydKXg8Y2cgiRJEoehf84iIBkTRM6XeeOMNvPrqq3j++efxmc98Bm53bpb+6aefLllwRERERCMRx1tEVAh3fCOi4abopFR5eTnOPvvsvoiFiIiIiMDxFhF1jzu+EdFwUnRS6vHHH++LOIiIiIjo/+N4i4i6U6od31iYm4gGg6KTUgBgmib+8Ic/4OOPP8YFF1wAv9+PxsZGBAIBlJWVlTpGIiIiohGH4y0i6s6B7PimmVo2oWXZFiRRgl/2F5XQIiIqlaKTUtu3b8cpp5yChoYG6LqOk046CX6/H3fccQc0TcNDDz3UF3ESERERjRgcbxFRTxQ7w0kzNeyM74RmajlL/6JaFGkzjbpAHRNTRNSvit6WYfHixZgxYwai0Sg8Hk+2/eyzz8bLL79c0uCIiIiIRiKOt4ioL0RSEWimhpAnBFmSIQgCZElGyBPKzqAiIupPvdp9749//CNkOXe3h3HjxmHnzp0lC4yIiIhopOJ4i4hKTTd1JIwEfLKv4HGf7EPCSEA3ddaYIqJ+U/RMKdu2YVlWXvunn34Kv99fkqCIiIiIRjKOt4io1GzHhmVbcIvugsfdohuWbcF27H6OjIhGsqKTUieddBJWrlyZfS8IAtrb23HjjTfitNNOK2VsRERERCMSx1tEw5du6khn0tBNvV/vKwoiJFFCxs4UPJ6xM5BECaJQ9K+IRES9JjiO4xRzQmNjI0444QRIkoSPPvoIM2bMwEcffYTKykq8/vrrGDVqVF/FOmjF43EEg0HEYjEEAoGBDoeIiIhKaCC+50fCeIvjJxppBsOud43xRkS1KEKeUN6xaDqKkBpCbaC2X2IhouGtp9/zRdeUqq2txZYtW7BmzRr89a9/hW3bWLhwIS688MKcQpxERERE1DscbxENL4Nl17uwN4y0mUY0Hc2JI2kkobpUhL3hPo+BiKiromdKUT7+pY+IiGj44vd83+DnSiPJYJqhNBhmbBHR8NdnM6WeeOKJfR6/+OKLi70kEREREXXB8RbR8DHYdr1TXSpqA7XQTR22Y0MURO62R0QDpuiZUqFQbnY/k8kglUpBlmV4vV5EIpGSBjgU8C99REREw9dAfM+PhPEWx080UqQzaWyNbkVQDUIQhLzjjuMgpsVQH6qHx83luTQ0MclJe+uzmVLRaDSv7aOPPsK3vvUt/Pd//3exlyMiIiKivXC8RTR8dN31TpbkvOPc9Y6GMi4HpQNVkp98EydOxA9+8AMsXry4FJcjIiIior1wvEU0NCkuBX7Zj6SRLHg8aSThl/2cXUJDTmcB/6gWheJSEFSDUFwKolo0W9ifaH9Klo6XJAmNjY2luhwRERER7YXjLaKhqXPWSDQdhWEZcBwHhmUgmo5y1zsasiKpCDRTQ8gTgizJEAQBsiQj5AllZ1AR7U/Ry/eee+65nPeO46CpqQn3338/5syZU7LAiIiIiEYqjreIhhfVpaIuUJdd5pSyU5BECSE1xGVONCQNtgL+NHQVnZQ666yzct4LgoCqqip8/vOfx1133VWquIiIiIhGLI63iIYf7npHw4nt2LBsC27RXfC4W3QjZadgO3Y/R0ZDTdFJKdvmv1REREREfYnjLaLhi4koGg5YwJ9Khf+GEBEREREREVGPsYA/lUrRM6WWLl3a47533313sZcnIiIiGvE43iIiosEu7A0jbaYRTUfhk31wi25k7AySRpIF/KnHik5Kbd68GX/9619hmiYmTZoEAPjXv/4FSZJw1FFHZfsJglC6KImIiIhGEI63iIhosGMBfyqFopfvnXHGGTjuuOPw6aef4q9//Sv++te/YseOHTjhhBPwxS9+Ea+++ipeffVVvPLKK30RLxEREdGw1xfjrVWrVqG+vh6qqmL69OnYuHFjt32ffvppnHTSSaiqqkIgEMCsWbPw4osv5vV76qmnMGXKFCiKgilTpuCZZ57p1fMSUe/opo50Jg3d1Ac6lB4bijFT9zoL+I8vH4/6UD3Gl49HbaCWCSnqMcFxHKeYE+rq6rB+/Xp85jOfyWn/xz/+gXnz5qGxsbGkAQ4F8XgcwWAQsVgMgUBgoMMhIiKiEhqI7/lSj7fWrl2LBQsWYNWqVZgzZw4efvhh/OQnP8H777+PsWPH5vVfsmQJamtrccIJJ6C8vByPP/447rzzTrz11luYNm0aAGDTpk2YO3cubr31Vpx99tl45pln8P3vfx9vvPEGZs6cud+YOH4i6j3N1LKzUyzbgiRK8Mv+PpmdUqrdAvszZiIaeD39ni86KeX3+/Hss8/i85//fE77K6+8gjPPPBOJRKJ3EQ9hHFQRjSxdV8sU9xOUiIaigfieL/V4a+bMmTjqqKPw4IMPZtsOO+wwnHXWWVi+fHmPrvGZz3wG8+fPx/e//30AwPz58xGPx/H8889n+5xyyikIhUJYs2bNfq/H8RNR72imhp3xndBMrWAdn7pAXUmSPKVMIvVXzEQ0ePT0e77o5Xtnn302vv71r+M3v/kNPv30U3z66af4zW9+g4ULF+LLX/7yAQVNRDSYCUJuQqq7NiKiA1XK8ZZhGHjnnXcwb968nPZ58+bhzTff7NE1bNtGIpFAOPzvorWbNm3Ku+bJJ5/c7TV1XUc8Hs95EVHxIqkINFNDyBOCLMkQBAGyJCPkCWUTSQeqM4kU1aJQXAqCahCKS0FUi2aTS4MtZiIamopOSj300EM4/fTTcdFFF2HcuHEYN24cLrzwQpx66qlYtWpVX8SYo5h6CADw2muvYfr06VBVFQcffDAeeuihvD6sh0BE+7O/xBMTU0RUSqUcb7W0tMCyLFRXV+e0V1dXo7m5uUfXuOuuu5BMJnHeeedl25qbm4u65vLlyxEMBrOvMWPGFPUcRNSxlC5hJOCTfQWP+2QfEkbigOs1lTKJ1F8xE9HQVHRSyuv1YtWqVWhtbc3uDBOJRLBq1Sr4fIV/0JTK2rVrsWTJElx33XXYvHkz5s6di1NPPRUNDQ0F+2/duhWnnXYa5s6di82bN+Paa6/FlVdeiaeeeirbZ9OmTZg/fz4WLFiAd999FwsWLMB5552Ht956q0+fhYiIiKg7fTHe2nunPsdxerR735o1a3DTTTdh7dq1GDVqVK+vuWzZMsRisexrx44dRT4BEdmODcu24BbdBY+7RTcs24Lt2L2+R6mTSP0RMxENXUUnpTo1NTWhqakJhx56KHw+H4osTdUrd999NxYuXIhLL70Uhx12GFauXIkxY8bk1Efo6qGHHsLYsWOxcuVKHHbYYbj00kvxjW98A3feeWe2z8qVK3HSSSdh2bJlmDx5MpYtW4YTTzwRK1eu7DYOTj8nGll6OguKs6WIqNRKMd6qrKyEJEl5M5h2796dN9Npb2vXrsXChQvxq1/9Cl/4whdyjtXU1BR1TUVREAgEcl5EVBxRECGJEjJ2puDxjJ2BJEoQhV7/mlfyJFJ/xExEQ1fR/+W3trbixBNPxKGHHorTTjsNTU1NAIBLL70U3/nOd0oeYKfe1EPortbB22+/jUwms88++6qxwOnnRERE1JdKOd6SZRnTp0/Hhg0bcto3bNiA2bNnd3vemjVr8LWvfQ2//OUvcfrpp+cdnzVrVt41169fv89rEtGBUVwK/LIfSSNZ8HjSSMIv+w9ol7xSJ5H6I2YiGrqKTkpdddVVcLvdaGhogNfrzbbPnz8fL7zwQkmD66o39RC6q3VgmiZaWlr22WdfNRY4/ZyIiIj6UqnHW0uXLsVPfvITPPbYY/jggw9w1VVXoaGhAYsWLQLQMba5+OKLs/3XrFmDiy++GHfddReOOeYYNDc3o7m5GbFYLNtn8eLFWL9+PVasWIF//vOfWLFiBV566SUsWbKk9w9ORPvVuftdNB2FYRlwHAeGZSCajkJ1qQh7w/u/yD70RRKpr2MmoqHLVewJ69evx4svvoiDDjoop33ixInYvn17yQLrTrH1EAr137u92GsqigJFYSafaKRwnJ4tzeuHVcxENEKUerw1f/58tLa24pZbbkFTUxOmTp2KdevWYdy4cQA6lgl2rdH58MMPwzRNXHHFFbjiiiuy7ZdccglWr14NAJg9ezaefPJJXH/99bjhhhswYcIErF27FjNnzuzFExNRT6kuFXWBOkRSESSMBFJ2CpIoIaSGssmf3tBNHbZjQxREhL1hpM00oukofLIPbtGNjJ1B0kj2KonUVzET0dBXdFIqmUzm/MWuU0tLS58manpTD6G7WgculwsVFRX77LO/GgtEREREfaUvxluXX345Lr/88oLHOhNNnf7whz/06Jrnnnsuzj333F7FQ0S9p7pU1AZqcxJJvV3+1rmbXsJIwLItSKIEv+xHhbcCKSNVsiRSKWMmouGj6OV7xx57LJ544onse0EQYNs2fvjDH+KEE04oaXBd9aYeQne1DmbMmAG3273PPqyHQERd7W8WFGdJEVEpDdR4i4iGFsWlwOP2HFBCamd8J6JaFIpLQVANQnEpiGpRtKZaEfaGMb58POpD9RhfPh61gdoDntV0oDET0fBS9EypH/7whzj++OPx9ttvwzAMXH311XjvvfcQiUTwxz/+sS9izFq6dCkWLFiAGTNmYNasWXjkkUfy6iHs3LkzO4hbtGgR7r//fixduhT/+Z//iU2bNuHRRx/FmjVrstdcvHgxjj32WKxYsQJnnnkmnn32Wbz00kt44403+vRZiGjo6Uw8dV3Kx2QUEfWFgRxvEdHIEUlFoJkaQp5Qtk2WZMgeGdF0FJFUBLWB2gGMkIiGu6KTUlOmTMHf/vY3PPjgg5AkCclkEl/+8pdxxRVXYPTo0X0RY1ax9RDq6+uxbt06XHXVVXjggQdQW1uLe++9F+ecc062D+shEFGxmIgior42kOMtIhoZdFNHwkjAJ/sKHvfJPiSMBHRT56wmIuozguP0/NerTCaDefPm4eGHH8ahhx7al3ENKfF4HMFgELFYDIFAYKDDISIiohLq7+/5kTLe4viJaGClM2lsjW5FUA0W3OTJcRzEtBjqQ/XwuD0DECERDWU9/Z4vqqaU2+3GP/7xj33uTEdEREREvcfxFhEdKN3Ukc6koZt6t31EQYQkSsjYmYLHM3YGkihBFIouQ0xE1GNF/4S5+OKL8eijj/ZFLEREREQEjreIqHc0U0NjvBHb2rZha3QrtrVtQ2O8EZqp5fVVXAr8sh9JI1nwWkkjCb/s59I9IupTRdeUMgwDP/nJT7BhwwbMmDEDPl/uGuS77767ZMERERERjUQcbxFRsTp30tNMDT7ZB7foRsbOIKpFkTbTqAvU5e2cF/aGkTbTiKajOeckjSRUl4qwNzxAT0NEI0XRSal//OMfOOqoowAA//rXv3KOcZo5ERER0YHjeIuIitWbnfRUl4q6QB0iqQgSRgIpOwVJlBBSQwh7w3lJLCKiUutxUuqTTz5BfX09Xn311b6Mh4iIiGjE4niLiHrjQHbSU10qagO10E0dtmNDFEQu2SOiftPjmlITJ07Enj17su/nz5+PXbt29UlQRERERCMRx1tE1Bu2Y8OyLbhFd8HjbtENy7ZgO3a311BcCjxuDxNSRNSvepyUchwn5/26deuQTBYuikdERERExeN4i4h6gzvpEdFQxZ9KREREREREQxh30iOioarHSSlBEPIKa7LQJhEREVHpcLxFRL3VWZg8mo7CsAw4jgPDMhBNR7mTHhENWj0udO44Dr72ta9BUTqy65qmYdGiRXlbFD/99NOljZCIiIhohOB4i4h6izvpEdFQ1OOk1CWXXJLz/qKLLip5MEREREQjGcdbRHQguJMeEQ01PU5KPf74430ZBxEREdGIx/EWEZUCE1FENFT0OClFREREREREvccZTEREuZiUIiIiIiIi6kOaqWVrPVm2BUmU4Jf9rPVERCMek1JEREREREQHYF8zoDRTw874TmimBp/sg1t0I2NnENWiSJtp1AXqmJgiohGLSSkiIiIiIqJe6MkMqEgqAs3UEPKEsufJkgzZIyOajiKSiqA2UDtQj0BENKCYlCIiIiIiIipST2ZACRCQMBLwyb6C1/DJPiSMBHRTZ40pIhqRepSUeu6553p8wS996Uu9DoaIiIhopOJ4i2ho6ckMqJAnBMu24BbdBa/hFt1I2SnYjt1fYRMRDSo9SkqdddZZPbqYIAiwLOtA4iEiIiIakTjeIho6dFPv0QyoMrkMkighY2cgS3Jev4ydgSRKEAWxr0MmIhqUepSUsm1m7omIiIj6EsdbREOH7dg9mgHlltzwy35EtShkT35SKmkkEVJDXLpHRCMWU/JERERERERFEAUxOwOqkK4zoDqLnkfTURiWAcdxYFgGoukoVJeKsDfcz9EfON3Ukc6koZv6QIdCRENcrwqdJ5NJvPbaa2hoaIBhGDnHrrzyypIERkRERDSScbxFNHgpLiVnBpRu6rAdG6IgQnEpeTOg6gJ12V36UnYKkighpIZydukbCnqy2yARUTGKTkpt3rwZp512GlKpFJLJJMLhMFpaWuD1ejFq1CgOkoiIiIgOEMdbRINf2BtGVIviwz0fwoYNEWL2f0eVjcqZAaW6VNQGavOSV0NJT3YbZGKKiIpV9PK9q666CmeccQYikQg8Hg/+9Kc/Yfv27Zg+fTruvPPOvoiRiIiIaETheItoaBAgdH1TuL0LxaXA4/YMuYQUkLvboCzJEAQBsiQj5AllZ1ARERWr6KTUli1b8J3vfAeSJEGSJOi6jjFjxuCOO+7Atdde2xcxEhEREY0oHG8RDX6RVAQOHEyqmoSDQwdjbHAsDg4djElVk+DAGVZJmp7uNsgaU0RUrKKTUm63G4LQkfmvrq5GQ0MDACAYDGb/mYiIiIh6j+MtosFt7yTN3jOghluSpie7DVq2BdvhLqJEVJyia0pNmzYNb7/9Ng499FCccMIJ+P73v4+Wlhb87Gc/w+GHH94XMRIRERGNKBxvEQ0ue9eC6kmSJmWncpI0Q7meVNfdBmVJzjvedbdBIqJiFP1T4/bbb8fo0aMBALfeeisqKirwrW99C7t378YjjzxS8gCJiIiIRhqOt4gGB83U0BhvxLa2bdga3YptbdvQGG+EYRnZJE0hXZM03V1DM7V+fpre69xtMGkkCx5PGkn4Zf+QS7YR0cATHMdxBjqIoS4ejyMYDCIWiyEQCAx0OERERFRC/J7vG/xcabDrbre5pJGE6lIhQEDaTCPkCeXNgoqmowipIYS94X1eYyjtWLe/z2MoPQsR9b2efs8XvXyPiIiIiIhouOu621wnWZIhe2RE01F43B4IEPDhng9hoyMhZTs2RIioLqtG2BvOu0Zn8srr9iKVSSGSiqA2UDtQj1iUzsRTJBVBwkggZacgiVI2+caEFBH1RtFJqfr6+mzhzUI++eSTAwqIiIiIaKTjeItoYPVkt7m4FoflWP9udLr+o5NzDc3U0JZuQ3umHbZtQxRFKKICy7FQ4a0YMsveVJeK2kDtkK6PRUSDS9FJqSVLluS8z2Qy2Lx5M1544QX893//d6niIiIiIhqxON4iGlg9KWQeSUXgV/2YVDWp4PK91lQrLNuCZVvY1b4LuqXD6/bC5XbBtE0kjSTatDaMCYwZcomdoRYvEQ1eRSelFi9eXLD9gQcewNtvv33AARERERGNdBxvEQ2s/e021260Q7M0jJY7NiTYO0njk31I6AkAQEuyBbqlI6gGs8fdkhs+2Yc9yT1oS7flLBEkIhpJSrZn56mnnoqnnnqqVJcjIiIior0cyHhr1apVqK+vh6qqmD59OjZu3Nht36amJlxwwQWYNGkSRFHMm7kFAKtXr4YgCHkvTRs6O4oRdafQbnO6qSOdSUM3dbQb7VBdKsrksoLnu0U3JEGCS3RhT3oPvG5vXp9UJoUqXxUM24Bu6n32LEREg1nJCp3/5je/QTgcLtXliIiIiGgvvR1vrV27FkuWLMGqVaswZ84cPPzwwzj11FPx/vvvY+zYsXn9dV1HVVUVrrvuOvzoRz/q9rqBQAAffvhhTpuqstgxDQ9hbxhpM43m9mZkzAw0S4NhGtBtHWWuMvgUX7czqTJ2BpIoIagE4YILSSMJn+yDS+xYupfKpKBICiq9ldmlf0REI1HRSalp06blFN50HAfNzc3Ys2cPVq1aVdLgiIiIiEaiUo+37r77bixcuBCXXnopAGDlypV48cUX8eCDD2L58uV5/cePH4977rkHAPDYY491e11BEFBTU1N0PERDgepSUeGtwK72XYikI1BcChSXgoArALfohmZqiKQjqCnL/28gaSQRUkMIeUKoDdQibaahWzrSZhqiICKoBFHuKc8uExSFki1gISIaUopOSp155pk5gyRRFFFVVYXjjz8ekydPLmlwRERERCNRKcdbhmHgnXfewTXXXJPTPm/ePLz55psHFGd7ezvGjRsHy7Jw5JFH4tZbb8W0adMK9tV1Hbr+7yVK8Xj8gO5N1B9SRgpBNYjR/tF5u801J5qhGRqi6Sh8sg9u0Y2MnUHSSEJ1qQh7w1BcHbOholoUo9yj8q4RTUcRUkMsHE5EI1bRSambbrqpD8IgIiIiok6lHG+1tLTAsixUV1fntFdXV6O5ubnX1508eTJWr16Nww8/HPF4HPfccw/mzJmDd999FxMnTszrv3z5ctx88829vh9Rf9NNHQkjAZ/sK7hEL+wNI67F4XV7oZs6UnYKkighpIYQ9oahutRsv7SZRiqTyiavDMvISV4REY1URc8TlSQJu3fvzmtvbW2FJEklCYqIiIhoJOuL8VbXmVdAx5LAvduKccwxx+Ciiy7CZz/7WcydOxe/+tWvcOihh+K+++4r2H/ZsmWIxWLZ144dO3p9b6L+YDs2LNuCW3QXPO4W3XCJLtSU1WB8+XjUh+oxvnw8agO12YQU0LEMsC5Qh5Aagm7qiGkx6KaOkBpCXaAupy+QW1CdiGi4K3qmlOM4Bdt1XYcs5/8FgYiIiIiKU8rxVmVlJSRJypsVtXv37rzZUwdCFEV87nOfw0cffVTwuKIoUBQuUaKho7Pe0/6KmXddjtcdAQJCnhDK5DK4JXfBczRTQyQVQcJIwLItSKIEv+zPmXVFRDTc9Dgpde+99wLo+CvbT37yE5SV/Xv7U8uy8Prrr7OmFBEREdEB6IvxlizLmD59OjZs2ICzzz47275hwwaceeaZpQkcHYm0LVu24PDDDy/ZNYkGkuJS4Jf9iGpRyJ78pFRnMfN9JaT2lWjau9/O+E5oppZTnyqqRZE20wVnVBERDQc9Tkp1bgfsOA4eeuihnKnjsixj/PjxeOihh0ofIREREdEI0VfjraVLl2LBggWYMWMGZs2ahUceeQQNDQ1YtGgRgI6ldTt37sQTTzyRPWfLli0AOoqZ79mzB1u2bIEsy5gyZQoA4Oabb8YxxxyDiRMnIh6P495778WWLVvwwAMP9PbxiQadznpQ+ypm3p1iEk2RVASaqSHkCWXPlyUZskdGNB1FJBVBbaC2z5+XiKi/9TgptXXrVgDACSecgKeffhqhUGg/ZxARERFRMfpqvDV//ny0trbilltuQVNTE6ZOnYp169Zh3LhxAICmpiY0NDTknNN1F7133nkHv/zlLzFu3Dhs27YNANDW1oZvfvObaG5uRjAYxLRp0/D666/j6KOPLknMRINBZz2oztlO3RUzL6SniaauBdUL8ck+JIwEdFPnLn1ENOwITndFC6jH4vE4gsEgYrEYAoHAQIdDREREJcTv+b7Bz5WGGt3UYTt2j2pI6aaObW3boLiUgvWoDMuAbuoYXz4etmNja3Qrgmqw4OYDjuMgpsVQH6qHx+0p2fMQEfWlnn7PF7373rnnnosf/OAHee0//OEP8ZWvfKXYyxERERHRXjjeIhp8FJcCj9vTo9lKnTv32bZdcCc9t+juOP7/k1ydBdUL6VpQnYhouCn6J9trr72G008/Pa/9lFNOweuvv16SoIiIiIhGMo63aDjTTb1gomY4MSwDLakWbG3bih3xHdgR34HmRDM0UwOQv3OfX/YjaSQLXitpJOGX/Vy6R0TDUo9rSnVqb28vuBWx2+1GPB4vSVBEREREIxnHWzQc7WsnuuG0s5xmamhJtcCyLVi2hXK1HKZtIqbHoJkaavw1SGfSOTv3HUhBdSKioazomVJTp07F2rVr89qffPLJ7G4sRERERNR7HG/RcNO5E11Ui0JxKQiqQSguBVEtmt2hbrjoLHA+LjQOZXIZ4npHIjmgBNCeacf26Pa8RFNnQfWQGoJu6ohpMeimjpAaytmlj4houCl6ptQNN9yAc845Bx9//DE+//nPAwBefvllrFmzBr/+9a9LHiARERHRSMPxFg03Pd2Jbl+KKTQ+ULrupCdLMmr8NWhLt6E90450Jg1JkCCJEiq9lXmJJtWlZnfjG+zPSURUKkUnpb70pS/ht7/9LW6//Xb85je/gcfjwRFHHIGXXnoJxx13XF/ESERERDSicLxFw0nXRE0hPtmHhJGAbuoFkzCdy/5a063IWBm4JTcqPBWDctlfZ4Fzt+gG0JFoqvHXZBNNAgRoplZwR75OTEQR0UhSdFIKAE4//fSCxTe3bNmCI4888kBjIiIiIhrxON6i4cJ2Onagk0QJjuPkJV3cohspOwXbsfPO1UwNn0Q+wa72XbDRMXvIdmy0JFtQXVaNg8MHD6rEVNed9Lomnjqf2bAM7qRHRNTFAf80jMViWLVqFY466ihMnz69FDERERERURccb9FQpZkamtub0dzejK3RrXm70AG5O9HtrTHeiO1t2wEBKJPLEFACKJPLAAHY3rYdjfHG/nyc/eJOekRExel1UuqVV17BhRdeiNGjR+O+++7DaaedhrfffruUsRERERGNaBxv0VDWWdw8lUkhpIYgCRIUSUFMj+UkprpL1Oimjk/jn0KSJATVINySG4IgwC25EVSDkCQJn8Y/hW7qA/F43epcVhhNR2FYBhzHgWEZiKaj3EmPiGgvRS3f+/TTT7F69Wo89thjSCaTOO+885DJZPDUU09xJxgiIiKiEuB4i4aLrsXNPW4PrISFVCYFr9uLpJHEnuQelMll3SZq0pk0EnoCFd6KgtcPyAG0plqRzqQH1cyjzp30IqkIEkYCKTsFSZQQUkODsg4WEdFA6vFMqdNOOw1TpkzB+++/j/vuuw+NjY247777+jI2IiIiohGF4y0aLvYubt5Z8DuoBKFbOizbQjQdhdflRV2gbtglajp30htfPh71oXqMLx+P2kDtsHtOIqID1eOZUuvXr8eVV16Jb33rW5g4cWJfxkREREQ0InG8RcPF3rvQAbk70Vm2hXajHTX+mm4TNR63B37Fj7geR6WrMu94XI/Dr/jhcXv67DkO1GCawUVENBj1eKbUxo0bkUgkMGPGDMycORP3338/9uzZ05exEREREY0oHG/RcNF1F7q9KS4FLskFj9uzz13oFJeCg4IHwXZsxLQYMlYGjuMgY2UQ02KwHRsHBQ9i4oeIaAjrcVJq1qxZ+PGPf4ympiZcdtllePLJJ1FXVwfbtrFhwwYkEom+jJOIiIho2ON4i4aLUu1CV+uvxZjgGMAB2o12xLU42o12wAHGBMeg1l/bF+ETEVE/ERzHcXp78ocffohHH30UP/vZz9DW1oaTTjoJzz33XCnjGxLi8TiCwSBisRgCgcBAh0NEREQlNNDf88N1vDXQnyv1vc7d9zRTg0/2wS26kbEzSBrJbDHwntRY0kwNkVQErelWZKwM3JIbFZ4KFg0nIhrEevo93+OZUoVMmjQJd9xxBz799FOsWbPmQC5FRERERAVwvEVDVWfiKaSGoJs6YloMuqkjpIaKKm7eWTT80IpDcVjVYTi04tD9Fg3XTR3pTBq6qZfqcYiIqA8c0Ewp6sC/9BEREQ1f/J7vG/xcRxbd1GE7NkRB7NMaUJ2zqhJGApZtQRIl+GU/Z1UREfWznn7P93j3PSIiIiIiot7oj2Lk3S0XjGpRpM10UbOziIiofxzQ8j0iIiIiIqLBIJKKQDM1hDwhyJIMQRAgSzJCnlB2BhUREQ0unClFRERERDRE9deyuMFm7+fWTR0JIwGf7CvY3yf7kDAS0E19RH1ORESD3ZCZKRWNRrFgwQIEg0EEg0EsWLAAbW1t+zzHcRzcdNNNqK2thcfjwfHHH4/33nsvezwSieC//uu/MGnSJHi9XowdOxZXXnklYrFYHz8NEREREVHvaaaGxngjtrVtw9boVmxr24bGeCM0Uxvo0PpU1+f+sOVD/LPln9ga3YpUJgXLtuAW3QXPc4tuWLYF27H7OWIiItqXIZOUuuCCC7Blyxa88MILeOGFF7BlyxYsWLBgn+fccccduPvuu3H//ffjL3/5C2pqanDSSSchkUgAABobG9HY2Ig777wTf//737F69Wq88MILWLhwYX88EhERERFR0TprJ0W1KBSXgqAahOJSENWi2ZpKw1Hnczcnm9GWbkNMj2F3+268t+c9vNv0LpKZJDJ2puC5GTsDSZQgCkPm1x8iohFhSOy+98EHH2DKlCn405/+hJkzZwIA/vSnP2HWrFn45z//iUmTJuWd4zgOamtrsWTJEnzve98DAOi6jurqaqxYsQKXXXZZwXv9+te/xkUXXYRkMgmXq2erG7l7DBER0fDF7/m+wc+19xrjjYhqUYQ8obxj0XQUITWE2kDtAETWtxrjjWhONkPLaNAtHV63Fy7RBdM20dzeDDjAmPIxqCmryTt3X5/LSF0CSUTUl3r6PT8k/lSwadMmBIPBbEIKAI455hgEg0G8+eabBc/ZunUrmpubMW/evGyboig47rjjuj0HQPYD21dCStd1xOPxnBcRERERUV8rpnbSUKebOtKZNHRTzz53xsxAt3QE1SDckhuCIMAtuVFTVgPLsRBPxxFNR2FYBhzHgWEZiKajUF0qwt5wzvVH6hJIIqLBZEgUOm9ubsaoUaPy2keNGoXm5uZuzwGA6urqnPbq6mps37694Dmtra249dZbu51F1Wn58uW4+eabexI6EREREVHJ2I6939pJKTs1KGsn9XRGUudOeQkjAcu2IIkSXKILMS0GzdLgdXvzznGJLiiSAlEU4RJc0E0dKTsFSZQQUkMIe8NQXWrOPTqXOvpkH9yiGxk7g6gWRdpMoy5Ql9OfiIj6xoDOlLrpppsgCMI+X2+//TYAQBCEvPMdxynY3tXex7s7Jx6P4/TTT8eUKVNw44037vOay5YtQywWy7527Nixv0clIiIiIjpgoiBCEqUhVTupuxlJMS2WnQnVtW+hellxPY5dyV1o19rhEnP/rq6bOpriTYimo9iT2gPN0iCLMkb7R2N8+XjUBmrzEkyRVASaqSHkCUGWZAiCAFmSEfKEskmxve+xd6xERHTgBnSm1Le//W2cf/75++wzfvx4/O1vf8OuXbvyju3ZsydvJlSnmpqOteTNzc0YPXp0tn337t155yQSCZxyyikoKyvDM888A7e78F+eOimKAkXhenMiIiIi6l+KS4Ff9iOqRSF75LzjSSOJkBrKzkQa6HpJhWYkJYwEPmz5EBk7gypvFbyyF37Zj7A3nJMs6iRLMqrLqrG7fTeak82oLKuEW3Jnn293cjci6QjKlfLsjKiUmYKdtuFxe/JiKmYJpAMnb9ZWZ6ycSUVEdOAGNClVWVmJysrK/fabNWsWYrEY/vznP+Poo48GALz11luIxWKYPXt2wXPq6+tRU1ODDRs2YNq0aQAAwzDw2muvYcWKFdl+8XgcJ598MhRFwXPPPQdV5ZcLEREREQ1eYW8YaTONaDqas/QsaSSztZMKLYEbiGRKU6IJbVobwp4wZEn+9ywkAYDQsRxRcSnYldyF5mQzbMdGpbeyYDJtfGg8IukIdsR2YExwDFyiC63JVkTSkY7nklT4ZT/8ih9AR3HzSCqSV9y8p0sgU5kUIukIl/gREfWhIVFT6rDDDsMpp5yC//zP/8TDDz8MAPjmN7+JL37xizk7702ePBnLly/H2WefDUEQsGTJEtx+++2YOHEiJk6ciNtvvx1erxcXXHABgI4ZUvPmzUMqlcLPf/7znKLlVVVVkCSp/x+WiIiIiGgfVJeKukBdNum0d+0kAANeL0kzNTTFm/Bh64eQBAnJTBJl7jLolp4tVJ6xMohoEWTsDAzbwK72XYjrcdSW1cIlueAW3RBFEWXuMpR7ylEml6E+VI90Jo09yT0QIKBNa0O5Up5NSJV7yrMxdJ3x1HWWWNclkLKUP9uscwlkW7qt4Kwt2SN3m/AiIqLiDImkFAD84he/wJVXXpndTe9LX/oS7r///pw+H374IWKxWPb91VdfjXQ6jcsvvxzRaBQzZ87E+vXr4fd3/PXknXfewVtvvQUAOOSQQ3KutXXrVowfP74Pn4iIiIiIqHdUl4raQG3BGUWdO8gNVDKlc8lem9aWTZZZjoWWVAta062oC9QBACzbwu723bC8FkKeEMrVcnwS/QS6qaO6rBqjy0ZDEiXE9Bg0U0PYG0bIE8JhVYchkopgd2o3NKujvTMh1TXZ1l3R954sgfS6vTAso0dL/AZiWSQR0XAxZJJS4XAYP//5z/fZx3GcnPeCIOCmm27CTTfdVLD/8ccfn3cOEREREdFQsXdCpJh6SX2VTOmsCxX2hJHMJGE5FtySG2VyGXa270RKT6FMLkMkFYHpmCj3lMMtuWFZFlySC0ElCMdxENfjGFU2CkEpiJgWQ1O8CZMqJyGoBhFUg6jwVkB1qVBdanbJXlf7Kvq+vyWQ5Wo5mhJNQ3KXQyKioWTwbMtBREREREQHpCf1kizb6rNkStekmOJSUOYuQyqTAtCxbM7r8iJmxNCut6NVa0WFpwKyJMMwDcSMGKq91VBcCjJ2BnE9Dt3UkbEyyNgdr67JtoAaQJW3CqZtFowlaSThl/0Fk2+dSyBDagi6qSOmxZDQE1BdKiq9lfC6vUNul0MioqGIP0WJiIiIiIaJrvWSCunrZMreSbFyTzkUSUFMi0EQBATcAcT1OKJaFC7RhbAnnD0vlUmh0lPZkSxSQtBMrSMxZemoUCsQVIKwbAu6qWfv11m4PZqOwrAMOI4DwzIQTUezRd+707kEsqasJrvsTzd1NLc3ozXVCrfoRtJIZvvrpo50Jg3d1PeZ8CIiop4bMsv3iIiIiIho33pSLymkhvosmbJ3EXHVpaLGX4O2dBvaM+3QbR2mbcKyLIQ9YYiCiIyVQbvRDgkSJEmCIAgIeUNwSS7UBmohQMgmshpiDfC4PTk7CXZX9N0n++A4zj6XKmqmhpZUCzRTg1/x5xSFBwABAprbm5ExM9AsDYZpQLd1hJVwtjYWERH1HpNSRERERETDyP7qJe1r9tCBKpQUU10qyj3lMCwDlm1hTGAMAkoAe5J7kDSSCKpB2I4NWZLxafxTBNUgLMvCQYGDoLpUNCeasSe1BzW+GlT5qgruJNi16LthGUgaSTS3N8OyLUiilJPE6qqz/lV3ReEFQYCW0RBJR6C4FCguBQFXAG7RjdZUa7amFRER9Q6TUkREREREw8i+Zg8VSsx0VWg3v2J1TYq5RBdM28TO+E6kzTQqvZU4KHgQJFGCLMnY1b4LMS2GgBrAaP9o7Enu6Vg6J7mRNtP4NPYpoloUVd4qVJVVQRCEbncSVFxKzsynrgm5vZNYnc+6v6LwDW0N8Ct+fMb/mbzPpT92MiQiGu6YlCIiIiIiGmb2nj20vySTZmrZJNb+Zhf15N4V3gp80voJdqR2oKm9CYZpYHxwPEaVjYLH7QEAjC0fizatDRktA9WlwrZtlHvL4Zf9kCQJkXTHLKaJ4YmoKqvKi6PQToL7m/nUNYm0v6Lwtm0joScwqmxUwc+uP3YyJCIa7ljonIiIiGgEWLVqFerr66GqKqZPn46NGzd227epqQkXXHABJk2aBFEUsWTJkoL9nnrqKUyZMgWKomDKlCl45pln+ih66i3FpcDj9uw3IbUzvhNRLQrFpSCoBqG4FES1KHbGd0Iztf3ep2sRcM3U0JpqheJWUBeoQ52/DodUHALZ3ZEY6ryebupwS26EfCFUe6sxJjgGE0ITcPjowzEhPAGHhA9BmVyGKl9+QgrI30mwJzOfOpNIwP6LwutWRz9ZzK/NVej+RERUPCaliIiIiIa5tWvXYsmSJbjuuuuwefNmzJ07F6eeeioaGhoK9td1HVVVVbjuuuvw2c9+tmCfTZs2Yf78+ViwYAHeffddLFiwAOeddx7eeuutvnwU6gNdZxfJkpxdIhfyhLIzqLqjmRoa443Y1rYNW6Nbsa1tG97f9T5iWgwhTwhetxeyS0a5Wo6gGoRu6WhLtwFAdgaXCBEuyZWTPFNcCgJKR+0mwzYK3nvvnQT3N/Np7yRSZ/2rrjvs7f1sfsUPUSz8K1Nf72RIRDQS8CcoERER0TB39913Y+HChbj00ktx2GGHYeXKlRgzZgwefPDBgv3Hjx+Pe+65BxdffDGCwWDBPitXrsRJJ52EZcuWYfLkyVi2bBlOPPFErFy5sg+fhEqtJ7OLWtOtaEu3ZWcYdSo0wwoAGpONSBgJaKbWkXQSRJi2CQDwur0du/CZOkRBhO3YsGEXTOyIogi/4kc6ky4YW9JIwi/7s4ms/c18KpRE8sk+OHCwq30XDMuA4zgwLAPRdBQBJYCDAgd1m7Ta+/5ERFQ8JqWIiIiIhjHDMPDOO+9g3rx5Oe3z5s3Dm2++2evrbtq0Ke+aJ598crfX1HUd8Xg850UDb1+zizRTQ2uyFQ1tDfgk+gm2tW1DY7wxu/yu0Awrl+hCmbsMlm2hLd0GxaWgzF2GVCYFwzJg2ia0jAbbsaG4FJiWiYxVOImUNJI4KHgQAkoA0XQ0L2m0906C+5v51DWJ1DnDq7m9GRkzg4SeQENbA3Ynd0M3dYTUEOoCdagN1EJ1qT26PxERFY+FzomIiIiGsZaWFliWherq6pz26upqNDc39/q6zc3NRV1z+fLluPnmm3t9P+obXWcXydK/aydppobmRDPaM+1Q3SrK1XKIopjdxa7SW1lwhpUoiBBFES640J5pR1yLQxAEtCZbkTSTkCDBgQNBEGDZFkzHhOVYeG/Pe6jyVKHSVwlJlJA0kh3F2v0dRck7i7C3ZdogCAICcgCjA6Pzak113fmv6+57SSMJQRDgcXsQ02I5O/SVyWUI2SFE01HIkoyasprsrC8Avd7JkIiI9o9JKSIiIqIRQBCEnPeO4+S19eU1ly1bhqVLl2bfx+NxjBkz5oDuP1L1dEe9nuicXRTVopA9/05KtaXboFs63KIbHpcHDhw4joOQpyN505pqzZth1RmXLMpo09rQbrQjrscR02JIZ9Jwi26krTRkl4ytbVvhlbw4vOZwlMllaEm1YE9yD9q0NowOjEalpzIn6RP2hqFbHUXUHceBYRuIpCJ5iSHVpeYlkUzbhGmZcLlcaEo0oSXVAsu2MC40LpuIkyUZ1WXViKajSBrJnKRUsTsZEhFRzzEpRURERDSMVVZWQpKkvBlMu3fvzpvpVIyampqirqkoChSFv8gfiM6i4wkjAcu2IIkS/LL/gGfs7D27yLbtjhlRmTQs20JKSiGmxyCJEsJqGD7Zh2SmY4lcxs7Admy0pdvQnmmH7dhIGSlsjWxFxslgdNlouAU3fF4fdid3w+1yo0KtgNvlhizJsGwLHrcHY4JjMMo3CpF0BH63H7WB2pzn7twFMKgGs7OfOmdt1QXq8hJTnUmkVCaFpkQTJFHKPlvGzsCyLTQnmlHjr8k5t+sOfXsnnpiIIiIqPdaUIiIiIhrGZFnG9OnTsWHDhpz2DRs2YPbs2b2+7qxZs/KuuX79+gO6JnWvUFFxxaUgqkWzCZu96aaOdCadV6B8b52zi0JqCLqpo01rQ1yLI51Jo91oR9JIIq7HEUlF8HHkY2yLbkO73g6X6EIkFUFzohkxPQbBEeAW3NBMDSkzBRdcaNM6Zly1pFogCiJSWgpb27YiY3YUHe8seg50JH0qvBUwbCMn5t7uDqi4FKQzaThwsuc6cCCJEiq8FTk7AXbae4c+IiLqW5wpRURERDTMLV26FAsWLMCMGTMwa9YsPPLII2hoaMCiRYsAdCyt27lzJ5544onsOVu2bAEAtLe3Y8+ePdiyZQtkWcaUKVMAAIsXL8axxx6LFStW4Mwzz8Szzz6Ll156CW+88Ua/P99I0DUx00mWZMgeGdF0FJFUJDu7qDczqrrOLkpn0tjVvgvNqWb43X6oLhUu0YVkJonWZCs+inyEUd5ROHL0kdgZ24l2sx1BJQjDMhBJR/BJ9BO4BBccxUFGz6DCVwGPy4MKbwU0U8P22HbE9Tgsp2OWVNcEkFt0I2Wnsm092R2wu5lNhc7tuhtg150AO88ttEMfERH1HSaliIiIiIa5+fPno7W1FbfccguampowdepUrFu3DuPGjQMANDU1oaGhIeecadOmZf/5nXfewS9/+UuMGzcO27ZtAwDMnj0bTz75JK6//nrccMMNmDBhAtauXYuZM2f223ONFMUkZhw42ZlTXQt9d7fUbW+dyZlUJgXTNOEv83fEYOmI63E4ggMBAmx07J7XuewvrsXhEl3Yk9qDpJ6EV/EipncUFI8bcRwcPhgOHMiSDJfoguySkcqkYDlWTgJo76TQvnYHBPKTWF0VOrdzN8CYHkNACSCdSeecmzSSCKkhLtUjIuonTEoRERERjQCXX345Lr/88oLHVq9endfmOM5+r3nuuefi3HPPPdDQaD+KScxE09Eez6jqTjqThiiKCKkhxPU4PC4PEukE0kYaktSx9K1zxz4bNnRTh8ftQSKTQJvWBpfkQkAJQMtoyJgZWC4Le1J7IEsyqrxV8Lq9MCyjYFH8vZNCoiDCcizE9ThUl5qXLNrXzKbudhYs95RDMzW0plshCRIECDAsI7vjX9gb3ufnQ0REpcOkFBERERHRINZdcqVTZ2ImY2V6vdRtb7Ioo8xTBi2joU1vQ0u6BbJLht/th+JSkMwkkTSSaEo0QYAA0zahZTSUyWVo19uxo20H3JIbqUwKfsWPlkQLHMuBLMqoUCuQMlOADShuBZZtFUwKaaaGpkRTtmbVqLJRKHOXodxTnp3tta+ZTd3tLKi6VNT4a7A9uh2SKEEzNUiihJAaOuCi8UREVBwmpYiIiIiIBrHO5Mqu5C4ElABEQcxJwnQmZtySu9dL3bryuD3wK35opoaqsiqoLhWWZaFMKYPiUhBJR1Aml8GyLQiiAK/khWZpSJtp+GV/xz8n00gZKZTJZajwVCCmx/BJ2ycIe8MYVTkKo92jkbEzSGVSaDfa4XF7cpJCbVob3t/1PiJ6BILTMZNpZ2wn/Iof6UwaFb4KWLa135lNe+8s2LmcMZ1JY2z5WFR6KyFLct5nSkRE/YNJKSIiIiKiQUwzNWimhj3JPdgR2wGf7EO5Ug6f4stJzAgQ8mZU6aYO27EhCiIEQehREW/FpeCg4EH4V8u/ENNikEQJiluB7dgdBcptCxVlFcg4GYzyjsru1OfYDlJ6CrZto8JXgaSRhEt0wXAMVPoqIULEmOAYHBI+pGPnwHQUY1xjUOOvyUkKaaaG93e/jz3pPagpq4FLdMGv+LGrfRfa9XZolgbLsXBI+JD9zmzq3Fmws/B7yk5xVhQR0SDCpBQRERER0SClmVq2cPm48nFo19vRprfh0/ZP4dE8OCR8CGr9tdnkSudyNdttoy3dhvZMezYpZVkWxpWP69GMoFp/LdKZNHa370bGysC2bbQZbQjKQdQF6lDlq8Lu5G5UeCuQyqQw2j8aW9u2Ylf7LoS8IZS7O5bY1fpqIbkktKZaMS40Dh63B4ZlIJVJQXWpGB0YnZcYaoo3IZKOoKasBm6pY9ZXmVKGMqUMe5J7oEoqQp4QKrwVPXqWrjsLdn4WnBVFRDQ4MClFRERERDRIRVKRnMLlfsWPsBnOzlpSJTUnqRP2htGmteHDPR9CkiQE5AAAIK7HYTs20mYamqntd4aQAAG1/lp43V60G+3wuX1oTbfC6/Ki1l8Lt+iG5ViwHAvlajmCahAiRKSMFFRRhW7pkAQJATUAQRRgZAxUeCqy96/yVhWcqaSbOuJGHIpLgUvM/1WlXO0oUm7Z1n6XIe6tMxGlm3pHMXcmp4iIBhyTUkREREREg5Bu6gULl3cmUiRRyitcLkAAhI7i6KpLhWZqEEURld5KlHvKkc6k97kDn2Zq2aVulm1BEiWUuctwUOAgiIKISCqCuBFH2knDLbphCiYmVkyEbuowbRNlchki6QgM20BYCWN3ejd8Lh8OrToUo8tGw4GD+vJ6BNRAwfvbjg3HcaBICkzbzM6U6uQSXTBMA4Iq7HcZYk+ezS/7uYyPiGgAMSlFRERERDQI2Y7d48LlnQmX1nQrGtoaoLpVyKKMgCcAj9uTTVqJgtjtDnxdlwp2LQqeNJJIJ9JQ3Soydga6qUMzNeimjoyTQUO8AWXuMvjcPoz2j4bt2AgqQYQ9YbgkFxRJ6UgyOSZqfDXdJqQ64/O4PdAtHalMCkEpmHPctE3oto6AEihqllN3zxbVokibadQF6piYIiIaAExKERERERENQqIg5hUu7ypjZyCJEgzLQEuqBZqpwSW64HV74XF7kDbTsB0bqvvfyZZ97cDXlGhCm9aGsCecvZ8sybDdNj7c8yFEQUS5pxwxPYaGaAPaM+0IKSGMDY6FDRtb27YiY2UwddRUqG4VATnQsbOdKKK5vRmyKCNc1f1OecC/dxpMGkkokoKYFoPX7YVLdMG0TTS3N6PKU4XR/tFFfZZ7L4PsfDbZIyOaju5z9hgREfUdJqWIiIiIiAahzgRNVItC9uQnpZJGEiE1hKSRzCZcdFOHJEkQBAFBNYiYFkNbug01/hoA/05kZawMgI7ElwMHTfEmfNj6ISRBQjKTRJm7DOWejmLlbek2WLDQprXBsA00J5rRlm6D7JKxs30nLFiYFJ6EKm8VUu4UqrxVUN0qDNuAbusQHRE1ZTXwuDwdywv3I+wNI22mAa1jiaJu6ohbceimjipvFaaMmlLUrKbulkF28sm+bmePERFR32JSioiIiIioDxSz21t3fTsTNNF0NG9JnepS4ZN9aG5vziZcFJeCMncZYnoMQSnYUag8055NuERSEcABmtAEy7ZgOiba9XYAHQmgkBqC5VjYk9qDmBZD2BtGe6Ydju0gmowikoygMdEIxa0AYkcNq/f3vI/mRDPckhuSKKEx0YhJFZMQ8oQQUDqWD8qSjJgW61FxctWloi5QB4/Lg4SRQDqThiAICMiBgrv17U8xyyCJiKh/MSlFRERERFRCxRTU3l/fzgRNZ5+Uncomj8LeMBzHyUu4lHs6dqiLaTGIgoh0Jo24HoeV7pjt5HV74XE8UF0q9iT3YE9qD4JKR+2mVCaFllQL2o12RNNRlLnLYKOj+HhruhWCJMAn++CX/dAsDa3pVsS1jllMASWAMcExSGaSiGpRiKKYXT7YOUOrp8XJVZeK2kBtUYm97vR0GWSxhdOJiOjAMSlFRERERFQixRTU7mnffSVodFPPS7ioLhUhTwgN0QY0J5uRNJMwLANAx8wmB0521lLaTKPSVwnLtrCnfQ8+iXyCmBFDKpNCu9EO0zKhulQk9AQqfZU4ouYItGfaYcGCYRmQBAkA4DgOfG4fNFNDUP3/xckdQLd0tKXboLgUhNRQ0YmlUiyn6+kySC7dIyLqf0xKERERERGVSDEFtYstvl0oaVIo4aKZGqLpKGS3jApfBQ5RDoHiUvDnnX+GntFRVVYFRVKgmRr2pPYgnUnD4/bgb7v+hrgehwgRhmnALblhmAaSehJtWhskSUKb1lFLKplJQrM02I4Nl+SCLMpQ3ErHUjnLgtfjRTKThEtyoTHRiIPDByPs3XeR8760v2WQAxkbEdFIxqQUEREREVEJ9LSgdlyLw3ZstKZb4Vf8++zbk+Lbeydcoqko2o12uCU3wmoYNf4aNLQ1oF1vhyRJsBwLfsUPy7GQ0BPYk9wD3dSxJ7UHtYFatGvtsEUbLsEFv+oHHMCECd3UsSu+C2NCYwAHaE21okwugwsuiELHUr2D/AfBJ/uQsTOIG3GUyWUok8swuqz4WlCltL9lkAMZGxHRSMakFBERERFRCeyvoLZlW2iKN0EztY5/TjShpqwGIW8oLynSWXw7nUnvt6ZS14RLa7oVze3NUN0qgkoQ5Z5yCBCwq30XJFFCuVreMUMok0TaTMPj8iCWjmF3cjdkSUZLsgWpTCqbWPK4PQgoAZiOiYyVQUSLwJv2okKtQLlaDtM2YQs2HMFBlbcK40PjobgUtBvtCCgB1PhqILtkeN3ekn/exSplnSoiIioNJqWIiIiIiEpgXwW1NVPDp/FP0W62Y7RrNNyiG1EtitZ0K3RLR9gThltyZxMlCSOBllQLLMeCJEj7LJYO/Dvh4nV7kbEyKFfLobo7+sXSMeiWjgpvBXRThyAKiGtxpDIplHvKEUlF0NjeiCpvFQzLQHumHYZloM5fh6AnCNMyYdkW6gJ1cAkuwAH8Hj/K1DKkjTQSesfssEmVk7JJHsu2UOGpgCiK8Mv+QZX8GUyxEBGNdExKERERERGVwL4Karel29CmtWFMYEx2yV5IDWFPag92xneiub0ZYU8YoijCLbixO7UbATkAv+LfZ7H0vXncHvhkH0Tx3zvJGZYBwzJQJpfBsAy0Jlth2iaAjiWHje2NHR0FIGNloLpUWLYF0zEhQQIkQBAEeCUvRvlHQZEUjPKNgmEZ2OPsgV/xo8pXhXQmDcvuUgBdAOs1ERHRPjEpRURERERUIoUKarcb7WhMNKJcKUe5pzzb1+P2IKbFENNj8Lq9kEUZNmz8s+WfcODg0IpDszOu9lUAvauuiTHbbaMt3YZIOoKYFkNLqgWSIEHLaGhJt0AWZSSt/8fenYdXUd19AP/Odu/cPTcJSQgkLC4sAsqigJSirQWXWre3UrFYfV1K6059xLWiVnFpFRfAHVxaa6vWqrVW1EqtxCoUlAoFZBeSkPXu28yc9495c+GaQAJmIcn30+c+l3vmzMyZM2ky/u45vxNDOpOG3+GHYRko8ZYgmo5CkiXAAqLpKCKpCIrcRchz58Hn8KEsUAa/0w9JkjCscBgcmgPRVBT18XpE01HIkgyv7kVQD6Kvr2tzSRER0aGNQSkiIiIionbSUkLtjJWB1+FF/0D/nABNIpNAQA/A5/ShJlaDSDoCRVbg1/1wKs7s9r21JQF6vjsf1dFqfFn/pZ3jStKgSRq2hbchmona0+8cPjg1JxoSDUhZKQDA7thupIwU3KobqUwKpmUiGU4iqAdR5ClCQ6IBAwMDUR4oR56eB5fmyrYhZaQQz8RRHa1GykxBCIG0mUZ9vJ6JxImIaJ8YlCIiIiIiakdN+Z3CyTAMy87HpKs6FFnJJtnOmBlEM1Hk6XkAAE3R0M/XDwICakyFruiIZqLNgk9NCdAtYbV47qSRtBOex+uwO7Ib4UwYpjARcATQ398f62rWoSHZgFAyhLSZRigVQp4zD308fWAKE0kzCUVS4FSckCDB5XBhYHAgCtwFgAQkjATW165HX39fFLoKswEnAYH6RL19Lj1wQFMOiYio92JQioiIiIioHTUFhiLpCEzLhCIrqE/UI5wMw+VwwbIsZKwMQskQSn2ldqJzPR8BPYCUkYIs2fmgLMtqFnzKWBkospKts7dQMmQnU09HYQgDHocH4UwYkpAQToftgBgslHhKsDO8E7vju2EKEy7NBSEE8lx5qE3UotBbiAJ3AfL1fJT6SpHvzkdNrAY+zYeyvDLE0jEk0gk0SHsCTvXxeiSNJIKuYLY9bZ1ySEREvReDUkRERERE7SRpJLEzvBPhVBiyJEOVVaSMFGpiNaiJ1aDYV4xCVyFkU0YoFUIsHUN5Xnk215RTdcKreVGbqIWu6s2CT7F0DG7VDUtY2VFUSSOJynAlvqz/ErXxWkiQsLVxKxqTjXCoDuTr+Yimokhbabg1N1LpFAzTgNfhhaZqiKai2NS4CX6HH5qkQZVUxJNx5Ov58Dl8SKQT0GQN/QL9oCkaPA4PUmYKRVoR4pk4KiOVSJtpeByeFvukLVMOiYiod2JQioiIiIionewK78LGuo2IZ+KIpqMAgJRp52kq8hZBlVSkrTQsWMjT8xBOhqEres7UtjxXHqqj1TAlE5IkQQiBjJXJjkYynSYSDQkosgJLWKiKVKEx1WjnczLs/FB18TrEjBgGugcinomjLllnB40EUJOoQSgTgiIp8GgeyJART8cRToXhc/iQp+fhq8RXUFUVg/IGQVM0lHvLswElVVaRyCRgCQsehwehZAhCCHgd3hb7pLUph0RE1HsxKEVERERE1A5CyRDW1qxFbbwWTtWJoB5E2kxjd2w3olIUkiShj6cPitxF0BQNJZ4SVMeqUZesQ34qH16HFxkrg0QmgQF5A6Brup1A3IrDsAwkM0noDh1+px+arCGSjuDjrz5GNBlFWaAMGSMDCEBRlexxGhINsGAHriABQgjsju1GQ6IBXqcXDsUBWZZhwAAEYFomTMuE1+lFgbsAbs0Np+rMGQVlWAZkWYYsydBkDUIISJKEjJXJrha4t/1NOSQiot6NQSkiIiIionZQF69DTbwGHs2TXTXPggW/7oewBMKpMByKA4ODg+HSXHBpLmiKhh2NO+wRUP+ffyqoB7MJxJsSo1dFq+xt/5+zKWkksbF2I3ZGdiKZSaI6Xo1wMgy/7ociKYhmomhMNGJT3SY4FSeSVtIesaW4IckSZEWGZVqoT9YDwm5/obsQqqxCQNhtcObDoToQTUft5OWKBgCIZ+IIOANwqk6kzTRcmgsO2YFYOgaHq3lQKpaOIagHOXWPiIiaYVCKiIiIiOgbShkp1CfqIcMeDZQ0k5BhjyaSJRmSIiGRTiCSiiBjZuDSXAAARVbQ198Xfb19oSkaZEnOCd44VSdSRionZ1PSSOLL+i+xqWETQskQ3IobpjCRNtPY0bgDLocLiXQCjclGhNNhuDU34pk4hBDQoMG07NX4EmYCqmTnvMp324nWI6kIapO1OLzgcDg0BxLpBDJmBo2JRuS58hDPxOFUnNkcWE0Bp3x3PnaGd6Ih0QCPw5NdfS+WjkFXdeS78zv3hhARUbfAoBQRERER0TdkCcueYpdOoj5ZD4/DA1mS4VJcUCUVSSOJtJVGUAlmRxwBe4I6ft2/32OblglN1uwRUjUbsalxE7bUb0FtohYuxYWEkUAsE0MsHYPH4UFVpAp1iToUe4vhUB0wLAOqrEJTNFRHqlGgF8CpOCELGVAARVIQy8TgkB2QFbvdEEDciCOeiUOWZGREBn1cfVDoKYQsyWhINGQDTrqqZ1fhi6QjiFvxZqO+iIiIvo5BKSIiIiKibyhtplEXr4OQBZyyE5ZlQZEVRNNRmJaJSCYCU5jwOX2QICFtpts8ikiWZCiygkg6gu2N27GpcROiyShSVgopM4Xtoe1IGSkYloG0kYamaggnw0gaSWTMDHRVh2mZUGUVlmlBFjJqojUo8BXYq+uZCaStNIocRXBpLvidfuiaDp/DhyJvEUKpEEq8JQjqQUiShJSRajHgpKs6Sv2l2SmHXx/1RURE9HUMShERERERHYCWgi6xdAxuzY1CVyHSZhoAEDfjkGQJaSMNt+ZGvp6PPD0PSSN5wKOITMvE6srViBkxO3F6MorqaDWqolVIpBMwTAOmMGFYBhJGAikjBRkyTNOEIQxIkgQA8OpeFKEIOyM7IUOGz+mDy3ShMdWItJFGnp6H/r7+MCwDLs0FSZIwIDAATtUJv9OPAndBqwEnBqKIiKitGJQiIiIiImqDpJHMTk9rSkruc/jgcXgQSUdQ6i8FJGBneKcddNKCEEJAkRSYlonhRcMxODjYXvGulVFEKSOFeCaOxkQjIukINtRvwOaGzdBkDYl0AnWJOlRFqhBJRaAoCgwYiGVicGkuWKYFS1jwaB5kkIETTuQF8tCQaIDP4YNpmQi6gvA7/Ihn4kgYCWSsDDY1bkLSTMKlueB1eNGQbIDf6UeeKw+yJCOSjqDAXZDNh0VERPRNMShFRERERNSKpJHEzvBOJI1kTiLvhmQD6pP1yBgZFHmLMCBvAHRVR2WkEtF0FAAQcAbgd/oxMG8gAnogO9IqZaSaBaaaAl+1iVpUhiuRsTIAAE3SUB4oRygZwprda1AbrYWmaFAVFaYwoUgKJEiIpqNwqS5oqgZFViCEgAEDmqTBITmQyCRgWAZ8Dh90VUfCSCDoCkJYAjWJGhiWgd2x3Sj1lcKreQF7gBU0WUPcisMSVqf2OxER9WwMShERERERtaI+Xo+kkUTQFcyWORQHHC4HqqPViKQjCFpB6KqOAXkDUOItQdJIQsAeKQXYuaF2hXc1G2nVNIVv78BXIp2Apmhwa26sr1sPTdYgyzKKfEWQJRlJKwnTNJHIJNCYaoQKFSmRggoVaSsNh+SAaZlIGSk0Jhvh1tzQFA3RTBRO1Qmf7INTdaLIV4Q8pz2lsMBdAE3R4NE8yNfzMbhgMELJEBoTjch350ORFciS3FW3gIiIeiAGpYiIiIiI9iNlpBBJR+BxeFrcHnQFEUlF0JBoQLG3GICdV6lpFFRDogEuzYXaeG2zkVbVsWrUJ+tR5i9DLB1D0kjCrblRl6iDqqioT9Qjlo7BtExYsJDOpBHLxJAxMrAkO7eTEAKGZUCWZUiSBFVS4dE9iKfjdvJzM41EJoE8PQ957jyUeEoQy8TQx9MHprADV6qswuv0wiE7MDBvIFJmCtFUFG7NjWgmCikhodhTzHxRRETUrhiUIiIiIiLaD0tYMC0Tmqy1uF2TNficPjgUBxoSDTlBp6YV9iCQM9IqaSTRmGhENBNFY6IRVZEqAEChuxBJJJHMJBFKhVATq0HCSECTNURSEWyu34xd4V1IGkkAgCIp9ugoKQ1d0SFBgmVZMEwDfT19YQgDmqyhLK8Mpd5SWJKFVDoFl+qCW3VDVVSEU2F4NA9URYUsy9AUDREjAsMy4BAONCQbUOAqaHWVQCIiogPFoBQRERER0X7IkgxFVpCxMnAojmbbM1YGbs2NEm8JYukYIukI4lY8u8Kex+FBVbQqO9IqaSRRFalCykzBrbkRcAawI7wD9fF6FLgK4HV68Xnl56hOVEOGjNpELWqjtZBkCQ7JgWgqiphhJzWPZ+JQJAUaNEiSHZCCBDu45NDghBPFnmIMyBuAw4OHozHZiKpoFWoSNYhmoihyFMGn+eDUnAi4AvBpPoSSISADJDIJCAgEnUH09/dv0yqBREREB4JBKSIiIiKi/XCqTvgcPjQkG+BwNQ9KxdIxuFU3HIoDultHgbsAlrCyK+wlMomckVaNiUakzFQ26XlDsgHxTBxBVxCGMLCxbiO+qPsCpmWiPFAOy7TQmGyEIQzkOfOgqzrimThcqguWsKA4FAhLIGWmkLbS8Dl8OCzvMHs0lOZGeV65vRKfyKDAXYBiXzEa441oTDWi2FOMaCYKy7JQ4CqAU3Eiko5gaMFQDO0zFOFUGMWeYgT0QGd3OxER9QIMShERERERtSLfnY+EkWg2Pa8+Xo/aWC10TUdNvAYBPZBNXt6Uf2nvkVZCCEQzdq4mAAgnw0gYCRR6CqHJGraHtmNHeAfcqhuKrGBz42bUx+uhKios08K20DYYlgFFVhBLx5CxMpBl2c4HZTognMJeaU9xoNhXjEJ3Ifp4+mBY4TCUeEugyAqi6SiKy4vxWdVnCKfCKPOXIWkkEUqEkDST8Dv8KM8rR9JIwu/0c9oeERF1GC6fQURERNQLLFy4EIMGDYKu6xg7diw+/PDD/dZftmwZxo4dC13XMXjwYDz22GM525csWQJJkpq9kslkR15Gl9FVHYXuQrhUFyKpCELJEL4KfYXVlauxvn491tevx4baDdhYsxHbQtuyq+gBe0ZaxdIxWMKCZVlQZRVpI42YEQME4Fbd8Dv8SKTt1fQcqgOheAi7wrtQG6tFJB2xjycASUgIOAPQHTosWAilQoimo/A5fShwFyCgB+CUnXAqTqTMFPJd+SjLK4NP90FVVLg0F/Jd+ZhQNgGHBw8HABjCgCRJKNALMDA4ELqqI6gH0c/fj9P2iIiow3CkFBEREVEP99JLL+Gaa67BwoULMWnSJDz++OM45ZRTsHbtWpSXlzerv2XLFpx66qm49NJL8cILL+Cjjz7Cz3/+c/Tp0wfnnHNOtp7f78f69etz9tX1nhfASBpJ1MfrEUlHYFomACBlprCxbiNiRgxl/rJsAKgmWYO4GQcAuFQXSv2lAPaMtAqnwjCFiYyZQcpIIZQKIV/Pt6fiwYJDdsAhObArtAs18RrE03EkjSQEBGTIkGQJQghYsOBW3IhLcSiaAl3VkTbS0GQNLocLXpcXGTODPD0PQwqGZANLsXQMQT2YXR1wTL8xCCfDMCwDqqzCqTpzph4SERF1JAaliIiIiHq4Bx54ABdffDEuueQSAMD8+fPxt7/9DYsWLcK8efOa1X/sscdQXl6O+fPnAwCGDRuGFStW4Ne//nVOUEqSJJSUlHTKNXSVpJHMjnrae9pexdYKbGvchpElI+HSXAAAl+yCS3NhV2QX6qJ1yHflI2Wk4FSdkCAh35UPWZIRSUVQHa+GR/VAl3WYponKaCWSZhKbQ5uxI7QDUSMKU5j2FD0zY49EkyXAstslQYJH9aBRaoQsyQi6g/A7/fBpPvT19kWxvxjxTBzl/nL4nD6kzXR2JcCvT8fz6/7O7lYiIiIADEoRERER9WjpdBorV67EDTfckFM+depULF++vMV9KioqMHXq1JyyadOm4emnn0Ymk4Gm2Qm7o9EoBgwYANM0ccwxx+DOO+/E6NGjWzxmKpVCKpXKfg6Hw9/ksjpNfbweSSOJoCuYLUtlUkhaSeiqjnAyDFVWIUtydmW+oB5EY6oRoWQI8UwcdfG67CgrRVbQx9MHHocHGTOD3dHd2NqwFZIsoSZeg20N21AVrULatEc9eRwexNIxxI04Mhl79T+PwwNFVmDAQKmvFD7NhwJPAfJceejv7488PQ8BPQBZkgEJaEw2wuPwIKgHke/O53Q8IiI6ZDAoRURERNSD1dbWwjRNFBcX55QXFxejqqqqxX2qqqparG8YBmpra9G3b18MHToUS5YswciRIxEOh/HQQw9h0qRJ+Oyzz3DEEUc0O+a8efNw++23t9+FdYKUkUIkHYHH4ckpN4SBhJGAEALbQtuQyCTg0BxwK254dS+cihM1Vg2SRhKV0UoIIXJGWcXSsWxuqsZUI2JmDLFEDJFUBLqiQ1M0VEerocka8jx5gAxYwoKAgAIFAgIpIwVd0VHkL0LQFYRTsfNWBfUgZFlGibcE+e58ZMwMyvxlcGkuTscjIqJDDoNSRERERL2AJEk5n4UQzcpaq793+YQJEzBhwoTs9kmTJmHMmDF45JFH8PDDDzc73o033ojZs2dnP4fDYZSVlR34hXQiS1gwLROarOWUm5aJhJFAxszAEAZcmguyLCOSiSBlpeDW3LBMC0IICCFyRlk5FAccLgeqo9Woj9djQGAAXKoLq6tWY2d4J3ZGdqI2Xou0mYZhGpATdh4ph+SALMsQEEgaSXg1L4LuILwOL/KceSjPK0d5Xjl0RUfGzKDAVQDDMlDgskdQERERHYoYlCIiIiLqwQoLC6EoSrNRUbt37242GqpJSUlJi/VVVUVBQUGL+8iyjGOPPRYbN25scbvT6YTT2b1G6siSDEVWkLEy2al5AGBYBryqF0k1CRdciBkx+B1+eDUvGlON2BneiaGFQxF0BZuNsgLsEVj1iXpsbNiIElcJ/rP7P6iN16IuVodwIoyMmYFDdiAt0khlUnA5XSjyFiGSjiBjZOBxeuDX/VCEgqSRRMbKAAJIG2nUxevgVJzY2LAR+c589PP368wuIyIiOiAMShERERH1YA6HA2PHjsXSpUtx1llnZcuXLl2KM844o8V9Jk6ciDfeeCOn7J133sG4ceOy+aS+TgiB1atXY+TIke3X+C7mVO0pcQ3JBjhcdlAqZaQQzURxWMFhiFZFYQgDKlREkhEkzSTimTg8Tg9GFo2EKXJHWSWNJLY3bsfG+o34KvQV1tasRTKTRMyIQRUqahO1iGViMCwDiqxAGAKmbCJlpBBTYtBkDX6vHx7VA1VWARko9BRiUN4gAEB1rBoehwcFngIEnAFosoa6eB10VWceKSIiOiQxKEVERETUw82ePRszZ87EuHHjMHHiRDzxxBPYvn07Zs2aBcCeWrdz504899xzAIBZs2bh0UcfxezZs3HppZeioqICTz/9NF588cXsMW+//XZMmDABRxxxBMLhMB5++GGsXr0aCxYs6JJrbG8pIwVLWPA4PEgYCTQkGuBxeGBaJlKZFBRZwZEFR6I2XovaeC3iRhyapKGfrx8OCx6GYm8xqmPV2VFWSSOJjXUbsWrXKqStNJyyE8IS2BnZiZSZQjgZhmEaMIUJIQQSZgISJKREClCAUCKEwXmDURooRZG7CP3y+kGXdaTMFNwONzIig+GFw1HoKYRL3ZM/qiHRgPp4PUr9pV3co0RERM0xKEVERETUw02fPh11dXW44447UFlZiREjRuCtt97CgAEDAACVlZXYvn17tv6gQYPw1ltv4dprr8WCBQtQWlqKhx9+GOecc062TmNjIy677DJUVVUhEAhg9OjR+Mc//oHjjjuu06+vPSWNJOrj9Tmr5WmKBpfqQspIIZFJwBQmnLITXqcXXqcXJd6S7P6KoiBlpSBJUs4oq+pINVZ8tQLbI9shSRJqY7X4KvwVIqkI0pk0wukwPKqdDD0pkhCWgATJnkIoFMiajIzIwKW5MKJ4BMryypDIJJA0ksjX8yFJEvr5+8GluXKux+PwIJKOIGWkmOiciIgOOZJoylp5iGtoaMBVV12F119/HQDwgx/8AI888gjy8vL2uY8QArfffjueeOIJNDQ0YPz48ViwYAGOOuqoFuueeuqpePvtt/GnP/0JZ555ZpvbFg6HEQgEEAqF4Pf7D/TSiIiI6BDGv/Md41Ds16SRxM7wTiSNZLPV8nRVR6G7EA7FgapIFbY2bkXaSgMCiBkxWJYFWZZhmib8uh8ji0Yi352PneGdqInV4OMdH2Nl5UqkzTRM04QhDHwV+gpVsSrE03GkzTQcqgNO2QlTmJBlGYZpwKE4EHAG4NSc6O/rjwn9J+CY0mOQMOyRVE1BKK/Di/JAebPAkxACoWQIg4KDmgWsiIiIOkpb/87Lndimb2TGjBlYvXo13n77bbz99ttYvXo1Zs6cud997rvvPjzwwAN49NFH8emnn6KkpATf+973EIlEmtWdP3/+flegISIiIqKerT5ej6SRRNAVhENxQJIkOBQHgq4gkkYSsXQMLs2FfHc+YpkYqiJVqE/UQ5M1OFUnIqkIopkoDNNAbaIWEiR4HV7saNyBNdVrsCO0A5XRSsSMGCABQhKAsANHqqTCNE1AshOsN42Sytfz4XF6UOwpRpG3CKqqIpaxE6v7nD4UuAoghICu6C2OhMpYGSiyAlnqNo/9RETUi3SL6Xvr1q3D22+/jY8//hjjx48HADz55JOYOHEi1q9fjyFDhjTbRwiB+fPn4+abb8bZZ58NAHj22WdRXFyM3/3ud/jpT3+arfvZZ5/hgQcewKeffoq+fft2zkURERER0SEjZaQQSUdaXC0PyJ0G51AccMgOuFQXVFVFNBVFLBODgIDX4UVNvAahRAimZWJj7UasqFyBqnAV6uP1cDqccKku1CXq0JhsRMpIQUDAsiz7C1IB+Bw+xDNxyIoMWbGDSQODAzG8cDicmp18XVM0KLICh+JAvisfmtpyAvpYOoagHuTUPSIiOiR1i6BURUUFAoFANiAFABMmTEAgEMDy5ctbDEpt2bIFVVVVmDp1arbM6XRiypQpWL58eTYoFY/Hcd555+HRRx9FSUlJs+O0JJVKIZVKZT+Hw+GDvTQiIiIiOgRYwoJp5a6WtzdN1hC34rCEhYyZgQULpf5SmMLEbnM33JobfqcfqqyiLl6H/9b9FxsaNqA2WouaeA3qU/VoSDRAMzREk1FYsGBYBhyqA2bans6nqRpkRUbKSkFVVHslPVcB+rj7YFTRKPQP9EcoFYJhGZAhI6gHUeguhNvhRl28LpuM/evTDvPd+Z3cm0RERG3TLYJSVVVVKCoqalZeVFSEqqqqfe4DAMXFxTnlxcXF2LZtW/bztddei+OPP36fSyK3ZN68ebj99tvbXJ+IiIiIDm2yJEORlexqeV+39zQ4TdGgKzrSZhoZMwNIQIG7IFu3PlGPWCqG2nitnXdKAmTIkGUZ9dF6SLKEoCsIFSqELAAFcEpOeFQPgnoQqqraI6GgoCyvDBNKJ+DIoiPh03wYWTwShe5CaIoGWZKzI6B0Vc8maI9bcSiygqAeRL47H7qqd1o/EhERHYgunVw+d+5cSJK039eKFSsAoMV8T0KIVvNAfX373vu8/vrreP/99zF//vwDaveNN96IUCiUfe3YseOA9iciIiKiQ4tTtafFxdKxFrfH0jH4HD44Vaed68mdD8MyUBWrghAC4VQY9cl6VEWr0JhshClMxDNxJFIJ1MfrUZ+sR8bMwBAGLMtCY7wRcSMOp+JE0BmEpmpwOBxQVRV+zQ+fw4fBwcGYXD4ZRxUfhXg6Do/Tg1J/Kfy6Hy7NlTMlT1d1lPpLMTBvIAYFB2Fg3kCU+ksZkCIiokNal46UuuKKK/CjH/1ov3UGDhyIzz//HNXV1c221dTUNBsJ1aRpKl5VVVVOnqjdu3dn93n//fexadOmZiv4nXPOOZg8eTI++OCDFo/tdDrhdHJePhEREVFPku/OR8JItDoNzqk6UeguRF28DtFUFNsatyFhJOyRS7ITuyK7kDbSqIxUIpQKIWNmEE/HYVpmNm+ULMvImBm4NTfynHmoj9fDq3vhcXjQ39cfqqqizFeGEl8JDGEgT89Dmb+s1SATc0cREVF30qVBqcLCQhQWFrZab+LEiQiFQvjkk09w3HHHAQD+9a9/IRQK4fjjj29xn0GDBqGkpARLly7F6NGjAQDpdBrLli3DvffeCwC44YYbcMkll+TsN3LkSDz44IM4/fTTv8mlEREREVE3o6s6+vn7tWkanNvhRiQdQU28Bm7VjRJPCUzLxM7ITuwK70IkHUFdog6xdAyKrMCUTKRMOydp2koDMqBJGpJGEg6vA0eXHg1N1uB3+jGkcAiKvEVwqk4UuArg0lwo9hQjoAe6qmuIiIg6RLfIKTVs2DCcfPLJuPTSS/H4448DAC677DJ8//vfz0lyPnToUMybNw9nnXUWJEnCNddcg7vvvhtHHHEEjjjiCNx9991wu92YMWMGAHs0VUvJzcvLyzFo0KDOuTgiIiIiOmQ0TYNLGSlYwsrJ29QkZaRQH6+HBAmlnlLEzTgMywAke5W+tJXG9vB2GKaBlJmCBg0ZMwMhCRiGAUVSoKkaPIoHhmUg4AhgQHAAvgp9Bb/Lj/K8cuS78mEJC/WJegx2DWayciIi6pG6RVAKAH7729/iqquuyq6m94Mf/ACPPvpoTp3169cjFAplP19//fVIJBL4+c9/joaGBowfPx7vvPMOfD5fp7adiIiIiLqXlqbBJY0k6uP1qEvUYVPdJjSkGuB3+2HEDDSmGhFJRbC1cSs21W9CfawemmJP/zNMA5IsQYFi502FBBUqCj2FSGfSUCQFhmVgVPEojCoeBafmRNpMQ5IkeB1e9PX2ZW4oIiLqkSQhhOjqRnR34XAYgUAAoVAIfr+/q5tDRERE7Yh/5ztGd+vXpJHEzvBOJI0kFFnB1oatqI5VI5wII27GkcqksKlxE9buXotdoV0QlkBapBFPxyEgoMmaHYxSVaiyigJXAfL0PAhJIOAM4Fvl38L3h34fRZ6i7CgtwzIAAAPzBjJXFBERdStt/TvfbUZKERERERF1lfp4PZJGEkFXMBs0akw0QoKEjJlBVawKoUQIwhJwOVxIpVOQLRmaoiFmxiAsAU2xA1NO2YkSbwk0VUMfVx/ku/MxongEAk47Z1RTAKoh0YCgHmRAioiIeiwGpYiIiIiI9iNlpBBJR+BxeJA0kmhM2FP1dkZ3IplOoiHZgFAyBEWyk6LXxmuRslLQZA26S4cVs5ARGUAAhmVP5YMM9PP3w1EFR0HXdBiWYSc9VxwtrvhHRETUEzEoRURERES0H5awYFomTMtEdbQadYk6hJNh1MfrsTO0E7vju5ExMyhwFcAQhr2ynqIBApAgwev0IpKJQJZkqJKKgDOAoDMITdHgc/swKDAITtUJwzLs4NY+VvwjIiLqaRiUIiIiIqJea3+r7DWRJRmKrGBneCe+Cn2FXeFd2BzajLpoHWKpGFLpFOqSdqDKqTqhSioUh4JoKoqMkYEma/BqXgBAobsQ/QL9UOAugAoVPtWHAk8BSjwlKHAXtNoWIiKinoRBKSIiIiLqdZpW0oukIzAtE4qswOfwtTg6yak6IYTA+rr1iKfi+LLhS8QzcRjCQNJKwqk5ERRBCIjsND1d0aHpGiKpiL2KntOLQlch/LofTsWJPFceir3FgIzsND0GooiIqLdhUIqIiIiIepW9V9JTZRUOxQFTmKiOVaMh2YD+/v4I6IHcfTJJ7AztxL93/RvVsWoYwkA0HUUynYTH6YFH86Ah2QBLsgABWJZlB5mcgEtzwe/0Y3BwMDJmBvnufBwePBwuzYUCVwH6evtymh4REfVKDEoRERERUa9SH69HKBUCBFCXqUMyk0QkHYEECRYs1MXrcHj+4dkk45WRSny661Os3LUSG+s3whQmJEuCIQzIsoxkJmnvK1vIZDJQFRWQANM0kefMw2EFh6HAVYCYEUN/b38c2+9YeDQP3Jobxd5iuDV3F/cIERFR12BQioiIiIh6jZSRQm2iFpFkBBYsKJKChJFA2kgDEqBJGmKZGHaEdqAyWgkZMhJGAv+t+S9imRg0SUMyk0TCSECRFDgUB9IijUwyg5JACRzCAUVVkDEzcGkuFLoKYVkW6hP1sCwLbr8bSSOJfFc+vA4vfA4fp+0REVGvxaAUEREREfUalrBQH6+HJSzkufKwO7o7O6UOAGpjtahvrIear2Jr/VYIWUCBgu3h7fZoKMlCykxBCAEBgVg6BgBwqA4k00kEvAH09fRFvjsfGZGBBAmJTAKyLKOPqw/KAmWQICGcDKPYU5w9LxERUW/EoBQRERER9RoZM4OkkYTX4UXaTCOUDEGRFaTNNAQEQqkQqqPV0GQNDckGJDNJVEYr8WXdlzAtE5ZlwRAGIICEmYAiK7BgQRMaNFmDz+lDaV4p+vv6w6W4kBZplOeVoy5aB4fmQIGrALqmwzRN6JrOXFJERNSrMShFRERERL2GpmjQFR31yXokM0nsiOyAT/NBURREkhFURiqRMlPYhm2ojdeiMdmIqnAVauO1ME0TmqLBp/rswFQG2dX2TMmE1+FFQA8gmUnCpbngUT3QoUOVVBxReATyXfnQFA2yJEOSJKSMFFJGitP3iIio12JQioiIiIh6jbSZRtyIY0PNBkSNKAzLgCxkCElgQ+0GpMwUgnoQhmVgW+M27I7vBgSgSAqimSgsWHBqTkiSBKfmhC50pM00XE4X+vr6IqgHMbRgKPp6+6IyUgld1ZHnzEORryhnVJQQAnErDktYXdgbREREXYtBKSIiIiLqFZJGErXxWsRTcbgdbpT4SvBV+CvsjOyEYRmQIMGpOFEfq8fnkc+xM7QThjAgIBBNRyFkgbSVhkM44JAdcGgOpI00gloQZYEy9Pf1x/Di4ZhUNsk+n5lEkbsI5cHyZm3JWBkosgJZkju7G4iIiA4ZDEoRERERUa9QH69HOBVGnjsPkiIhaSQRcAQQTUexpX4LkkYSjclGbG7YjFg6BkVW4JAdkCQJpjABC1AUBSkjBcWhQBMaPJoH+a58FHmL0MfXB4cHD4eu6YilY+jr7QtdazlnVCwdQ1APcuoeERH1agxKEREREVGPlzJSiKQj0FUdqqwiX8/H1satSIs0AnoAiqJgV/0ubGvchoZkA1RZhVNxIi2ls8EoU5iABPgcPhR7i1HoLoSqqvA7/Ojj6YNSXyn8uh8pw54C2M/fD3XxOjQkGuBxeKDJGjJWBrF0DLqqc+U9IiLq9RiUIiIiIqIezxIWTMuEruqQZRnhZBg+pw+KpGBD3QZsbdiK6lg1wukwDBhwyk44FAcMy0BCJOAQDvh0Hyxh55Tyal64VBfy3flwa26M6zsOUwZNgd/phyzJ2RFQuqqjPl6PSDqCuBWHIisI6kHku/O58h4REfV6DEoRERERUY8nS7Kdw0mW4ZAdqIpWIZaO4bOqz7C5cTO2NW5DKBFCxsoAsPNPNe0jQULGysDIGFAUBR7NgyJfEYq9xejr7YtCdyGmDJqCYm9xs/Pqqo5SfylSRgqWsHICVkRERL0dg1JERERE1OM5VSd8Dh8akg1wqk7Uxmvxxe4vUBOrQTKTRDqThiUsWLAgQ0YaaSADuB1ue9qdmUFGycC0TPRx9cGIPiPg031wKS4c1/+4FgNSXz8/ERER5WJQioiIiIh6BY/Dg4ZkA7bUb0FjshF1sTqEU2HUxmphWAZURYViKbBgQf3/x2RhCsiKDIfmgCIp6OPpg0kDJmFC+YTs6CcGnIiIiA4Og1JERERE1KMljSTq4/WoTdRiU90mfLTjI3y641NsCW2BJSwYlgETJkxhwiE7kLSSkCFDlmRIkgTLsqA7dPicPowoGoF8dz4yVgaF7kK4HW5kzAxSRorBKSIiogPEoBQRERER9VhJI4md4Z0IpUKojdVifd16rK9djx2RHQgnwlBVFUIISJIECMAUJpT//58syzAsA7Iso9BViNF9R2Pa4dNQ4C5AP18/BPQAhBAIJUOwhNXVl0pERNTtMChFRERERD3K3knF6+P1SBpJpDIpVOyowAdbPsCm+k2IpCPIWBmk0ilIkKBKKhTVDkSZpgkLFjRo8Dq90B06RvUdhRMGn4D+gf6AhOzKeRkrA0VWkDHtBOlMZE5ERNR2DEoRERERUY/QNE0vko4gkUkgY2UQSobgUl34cOuHeGfjO9ga3opUOoWMkQEkQAiBNNLIiAx0S4dTdUJYAoqkIN+Vj0JfIYo9xZjYbyKGFg5F0kgi4AhkA0/18XpAAJWohGmZUGQFPocP+e78bOCKiIiIWsagFBERERF1e3tP08sYGSTNJCLJCDY1bkJtrBarK1fjq/BXSGaSMIQBAWFP24MEAQETJlJmCm7NjSJfEXRVx5CCISh0F2Jon6E4svBI7I7tRp6eh4AeQNpMoz5ej8ZkI/JceXCqTnuVPiuDhmQDEkYC/fz9GJgiIiLaDwaliIiIiKjbq4/XI5QKIZlJImWmoMoqHIoDtdFafFr5qT1lLxWBCRMAoCoq0mYakpCgQYMJO5eUChV9PH1Q5C7CoOAg5LnsIFTQHUSBKICqqEgZKSiyAgggz5WHEm9Jth0OxQGHy4GGRAPq4/Uo9Zd2VZcQEREd8hiUIiIiIqJuLWWk7BxRRgaRdAQpI4WNdRuxuWEzPtv1GbaHt6MuVocMMtkRTYZlj5ZSZRWSkCALGW7VDY/Tg0K9EEcVHYUSXwkOCx6GPp4+ODx4OPJcedl8VRkzg0pU7jN/lMfhybaFOaaIiIhaxqAUEREREXVrlrCQyCQQSodQFa3ChtoN2NSwCVWhKmyq34SGVANSSAEAMkYGOnSoir3qXlqkIUMGALgcLvTx9kF/f38UuAtQ7ClGWaAMLs0Fl+YCgJwAk2mZ0GStxTZpsoa4FeeqfERERPshd3UDiIiIiKjjLVy4EIMGDYKu6xg7diw+/PDD/dZftmwZxo4dC13XMXjwYDz22GPN6rzyyisYPnw4nE4nhg8fjj/96U8d1fz9kiUZkiShKlSF7Y3bURWtQkOiAZWxSiRFEqqU+z1sEkkYpgEJEgBAggRd03FY/mGY1H8STjjsBBR7i+2k5xDwOXzNRjvJkmyvumdlWmxT06p8ssTHbSIion3hX0kiIiKiHu6ll17CNddcg5tvvhmrVq3C5MmTccopp2D79u0t1t+yZQtOPfVUTJ48GatWrcJNN92Eq666Cq+88kq2TkVFBaZPn46ZM2fis88+w8yZM3HuuefiX//6V2ddVpZTdcKpOLE9vB2NyUakjTTq4nVIm2nosg6H6oALLmjQoEABAJgwIUOGJmkI6AEMCAzAsMJhOLLoSAT1ICRJQiQdgVNxIt+d3+I5fQ4fYulYi22KpWMtBrOIiIhoD0kIIbq6Ed1dOBxGIBBAKBSC3+/v6uYQERFRO+oJf+fHjx+PMWPGYNGiRdmyYcOG4cwzz8S8efOa1Z8zZw5ef/11rFu3Lls2a9YsfPbZZ6ioqAAATJ8+HeFwGH/961+zdU4++WQEg0G8+OKLzY6ZSqWQSqWyn8PhMMrKytqtX6siVXj6309jW8M2bAttw7aGbRCSQDQdRdpKw8gYSJkpSJCQRhoA4IADPt2HIm8Rji09Fsf2PxZezYuMyECXdeS783Fc/+MQdAVbPGfTin9JIwmPw5NdfS+WjkFXda6+R0REvVZbn584UoqIiIioB0un01i5ciWmTp2aUz516lQsX768xX0qKiqa1Z82bRpWrFiBTCaz3zr7Oua8efMQCASyr7KysoO9pBbpqo4BgQEIuAKIp+P2tD1ZhUt1QZM0ODQHdIcOl+aCV/HCK3lR5C3C4fmHY1zpOBw/4HgMDg5Gib8EQwqGYETJCAwMDoRbc+/3nP38/RDUg0gZKYSSIaSMFIJ6kAEpIiKiNmCicyIiIqIerLa2FqZpori4OKe8uLgYVVVVLe5TVVXVYn3DMFBbW4u+ffvus86+jnnjjTdi9uzZ2c9NI6Xai0tzoTyvHEkjiW2N27ArtgsCAi6HC7IsI2kmoVl2UnJhCeiajsPzD8fh+Yfj1CGnYnif4bCEBVmS4VSdaEg0tGn6na7qKPWXZlfla9qfiIiIWsegFBEREVEvIElSzmchRLOy1up/vfxAjul0OuF0dlywxqk60d/fHw3JBowtHYutjVtRF6+Dz+mDQ3XAsAxAAXwOH0yYGBQYhG8P+jYG+Aegr68vJEmCrujIWBk0JBqgq3qLuaT2d34iIiI6MAxKEREREfVghYWFUBSl2Qim3bt3Nxvp1KSkpKTF+qqqoqCgYL919nXMzlDqL0XSSEKChG/1/xaWbl6KhngDZFmGW3HDpblgwkSBXoBx/cZhXN9xGFY0DJZlIZKOIG7FocgKgnoQ+e58Tr8jIiLqYAxKEREREfVgDocDY8eOxdKlS3HWWWdly5cuXYozzjijxX0mTpyIN954I6fsnXfewbhx46BpWrbO0qVLce211+bUOf744zvgKtpGV3UMzh+MPD0Ppf5SHFF4BJZtWYZd0V0whQmX6kJZoAyTyifhW+XfwsD8gdnAE6ffERERdT4GpYiIiIh6uNmzZ2PmzJkYN24cJk6ciCeeeALbt2/HrFmzANj5nnbu3InnnnsOgL3S3qOPPorZs2fj0ksvRUVFBZ5++umcVfWuvvpqfPvb38a9996LM844A3/+85/x7rvv4p///GeXXGOTphxPBe4CHNXnKJx/9PnY0bgD4UwYuqJjUHAQXJqrWeCJgSgiIqLOx6AUERERUQ83ffp01NXV4Y477kBlZSVGjBiBt956CwMGDAAAVFZWYvv27dn6gwYNwltvvYVrr70WCxYsQGlpKR5++GGcc8452TrHH388fv/73+OWW27BrbfeisMOOwwvvfQSxo8f3+nX15KmIJNLc+GokqO6uDVERETUEkk0Za2kgxYOhxEIBBAKheD3+7u6OURERNSO+He+Y7BfiYiIeq62/p2XO7FNREREREREREREABiUIiIiIiIiIiKiLsCgFBERERERERERdToGpYiIiIiIiIiIqNMxKEVERERERERERJ2OQSkiIiIiIiIiIup0DEoREREREREREVGnY1CKiIiIiIiIiIg6HYNSRERERERERETU6RiUIiIiIiIiIiKiTqd2dQN6AiEEACAcDndxS4iIiKi9Nf19b/p7T+2Dz09EREQ9V1ufnxiUageRSAQAUFZW1sUtISIioo4SiUQQCAS6uhk9Bp+fiIiIer7Wnp8kwa/9vjHLsrBr1y74fD5IktTVzTkkhMNhlJWVYceOHfD7/V3dnB6P/d252N+di/3dudjfzQkhEIlEUFpaCllm5oP28k2en/hzeujjPTq08f4c+niPDn28R/vX1ucnjpRqB7Iso3///l3djEOS3+/n/0E7Efu7c7G/Oxf7u3Oxv3NxhFT7a4/nJ/6cHvp4jw5tvD+HPt6jQx/v0b615fmJX/cREREREREREVGnY1CKiIiIiIiIiIg6HYNS1CGcTiduu+02OJ3Orm5Kr8D+7lzs787F/u5c7G/qDvhzeujjPTq08f4c+niPDn28R+2Dic6JiIiIiIiIiKjTcaQUERERERERERF1OgaliIiIiIiIiIio0zEoRUREREREREREnY5BKSIiIiIiIiIi6nQMShERERERERERUadjUIoOSkNDA2bOnIlAIIBAIICZM2eisbFxv/sIITB37lyUlpbC5XLhhBNOwBdffLHPuqeccgokScJrr73W/hfQzXREf9fX1+PKK6/EkCFD4Ha7UV5ejquuugqhUKiDr+bQs3DhQgwaNAi6rmPs2LH48MMP91t/2bJlGDt2LHRdx+DBg/HYY481q/PKK69g+PDhcDqdGD58OP70pz91VPO7nfbu7yeffBKTJ09GMBhEMBjESSedhE8++aQjL6Fb6Yif7ya///3vIUkSzjzzzHZuNVHH/uxS+ziQe1RZWYkZM2ZgyJAhkGUZ11xzTec1tJc6kPvz6quv4nvf+x769OkDv9+PiRMn4m9/+1sntrZ3OpB79M9//hOTJk1CQUEBXC4Xhg4digcffLATW9v7HOjfoSYfffQRVFXFMccc07EN7CkE0UE4+eSTxYgRI8Ty5cvF8uXLxYgRI8T3v//9/e5zzz33CJ/PJ1555RWxZs0aMX36dNG3b18RDoeb1X3ggQfEKaecIgCIP/3pTx10Fd1HR/T3mjVrxNlnny1ef/118eWXX4r33ntPHHHEEeKcc87pjEs6ZPz+978XmqaJJ598Uqxdu1ZcffXVwuPxiG3btrVYf/PmzcLtdourr75arF27Vjz55JNC0zTx8ssvZ+ssX75cKIoi7r77brFu3Tpx9913C1VVxccff9xZl3XI6oj+njFjhliwYIFYtWqVWLdunbjoootEIBAQX331VWdd1iGrI/q7ydatW0W/fv3E5MmTxRlnnNHBV0K9TUf+7FL7ONB7tGXLFnHVVVeJZ599VhxzzDHi6quv7twG9zIHen+uvvpqce+994pPPvlEbNiwQdx4441C0zTx73//u5Nb3nsc6D3697//LX73u9+J//znP2LLli3i+eefF263Wzz++OOd3PLe4UDvT5PGxkYxePBgMXXqVHH00Ud3TmO7OQal6ICtXbtWAMj5D+yKigoBQPz3v/9tcR/LskRJSYm45557smXJZFIEAgHx2GOP5dRdvXq16N+/v6isrGRQSnR8f+/tD3/4g3A4HCKTybTfBRzijjvuODFr1qycsqFDh4obbrihxfrXX3+9GDp0aE7ZT3/6UzFhwoTs53PPPVecfPLJOXWmTZsmfvSjH7VTq7uvjujvrzMMQ/h8PvHss89+8wZ3cx3V34ZhiEmTJomnnnpK/OQnP2FQitpdZ/yuoG/mQO/R3qZMmcKgVAf7JvenyfDhw8Xtt9/e3k2j/9ce9+iss84SP/7xj9u7aSQO/v5Mnz5d3HLLLeK2225jUKqNOH2PDlhFRQUCgQDGjx+fLZswYQICgQCWL1/e4j5btmxBVVUVpk6dmi1zOp2YMmVKzj7xeBznnXceHn30UZSUlHTcRXQjHdnfXxcKheD3+6GqavtdwCEsnU5j5cqVOf0EAFOnTt1nP1VUVDSrP23aNKxYsQKZTGa/dfbX971BR/X318XjcWQyGeTn57dPw7upjuzvO+64A3369MHFF1/c/g2nXq+zflfQwTuYe0Sdpz3uj2VZiEQivf5vaUdpj3u0atUqLF++HFOmTOmIJvZqB3t/Fi9ejE2bNuG2227r6Cb2KAxK0QGrqqpCUVFRs/KioiJUVVXtcx8AKC4uzikvLi7O2efaa6/F8ccfjzPOOKMdW9y9dWR/762urg533nknfvrTn37DFncftbW1ME3zgPqpqqqqxfqGYaC2tna/dfZ1zN6io/r762644Qb069cPJ510Uvs0vJvqqP7+6KOP8PTTT+PJJ5/smIZTr9dZvyvo4B3MPaLO0x735ze/+Q1isRjOPffcjmhir/dN7lH//v3hdDoxbtw4XH755bjkkks6sqm90sHcn40bN+KGG27Ab3/7217zBX97YVCKsubOnQtJkvb7WrFiBQBAkqRm+wshWizf29e3773P66+/jvfffx/z589vnws6xHV1f+8tHA7jtNNOw/Dhw3tlZL+t/bS/+l8vP9Bj9iYd0d9N7rvvPrz44ot49dVXoet6O7S2+2vP/o5EIvjxj3+MJ598EoWFhe3fWKK9dOTvCmof/Ft3aDvY+/Piiy9i7ty5eOmll1r8YpTaz8Hcow8//BArVqzAY489hvnz5+PFF1/syCb2am29P6ZpYsaMGbj99ttx5JFHdlbzegyG8CjriiuuwI9+9KP91hk4cCA+//xzVFdXN9tWU1PTLJrcpGkqXlVVFfr27Zst3717d3af999/H5s2bUJeXl7Ovueccw4mT56MDz744ACu5tDX1f3dJBKJ4OSTT4bX68Wf/vQnaJp2oJfSbRUWFkJRlGbfeLTUT01KSkparK+qKgoKCvZbZ1/H7C06qr+b/PrXv8bdd9+Nd999F6NGjWrfxndDHdHfX3zxBbZu3YrTTz89u92yLACAqqpYv349DjvssHa+EuptOvp3BX1zB3OPqPN8k/vz0ksv4eKLL8Yf//jHXj/iuCN9k3s0aNAgAMDIkSNRXV2NuXPn4rzzzuuwtvZGB3p/IpEIVqxYgVWrVuGKK64AYD8fCSGgqireeecdfOc73+mUtndHHClFWYWFhRg6dOh+X7quY+LEiQiFQjlLrv/rX/9CKBTC8ccf3+KxBw0ahJKSEixdujRblk6nsWzZsuw+N9xwAz7//HOsXr06+wKABx98EIsXL+64C+8iXd3fgD1CaurUqXA4HHj99dd73cgSh8OBsWPH5vQTACxdunSffTtx4sRm9d955x2MGzcuG9DbV519HbO36Kj+BoD7778fd955J95++22MGzeu/RvfDXVEfw8dOhRr1qzJ+T39gx/8ACeeeCJWr16NsrKyDrse6j068ncFtY+DuUfUeQ72/rz44ou48MIL8bvf/Q6nnXZaRzezV2uv/w8JIZBKpdq7eb3egd4fv9/f7Plo1qxZGDJkCFavXp2TG5ha0MmJ1amHOPnkk8WoUaNERUWFqKioECNHjhTf//73c+oMGTJEvPrqq9nP99xzjwgEAuLVV18Va9asEeedd57o27evCIfD+zwPuPqeEKJj+jscDovx48eLkSNHii+//FJUVlZmX4ZhdOr1daWm5V6ffvppsXbtWnHNNdcIj8cjtm7dKoQQ4oYbbhAzZ87M1m9advzaa68Va9euFU8//XSzZcc/+ugjoSiKuOeee8S6devEPffcI1RVzVlBsbfqiP6+9957hcPhEC+//HLOz3EkEun06zvUdER/fx1X36OO0Bk/u/TNHOg9EkKIVatWiVWrVomxY8eKGTNmiFWrVokvvviiK5rf4x3o/fnd734nVFUVCxYsyPlb2tjY2FWX0OMd6D169NFHxeuvvy42bNggNmzYIJ555hnh9/vFzTff3FWX0KMdzO+4vXH1vbZjUIoOSl1dnTj//POFz+cTPp9PnH/++aKhoSGnDgCxePHi7GfLssRtt90mSkpKhNPpFN/+9rfFmjVr9nseBqVsHdHff//73wWAFl9btmzpnAs7RCxYsEAMGDBAOBwOMWbMGLFs2bLstp/85CdiypQpOfU/+OADMXr0aOFwOMTAgQPFokWLmh3zj3/8oxgyZIjQNE0MHTpUvPLKKx19Gd1Ge/f3gAEDWvw5vu222zrhag59HfHzvTcGpaijdPTPLn1zB3qPWvpdPWDAgM5tdC9yIPdnypQpLd6fn/zkJ53f8F7kQO7Rww8/LI466ijhdruF3+8Xo0ePFgsXLhSmaXZBy3uHA/0dtzcGpdpOEuL/s0ASERERERERERF1EuaUIiIiIiIiIiKiTsegFBERERERERERdToGpYiIiIiIiIiIqNMxKEVERERERERERJ2OQSkiIiIiIiIiIup0DEoREREREREREVGnY1CKiIiIiIiIiIg6HYNSRNTp5s6di2OOOSb7+cILL8SZZ57Z6e3YunUrJEnC6tWrO/3c3cGSJUuQl5fX1c0gIiKi/8dnqO6Bz1BEbcegFBEBsB9qJEmCJEnQNA2DBw/Gddddh1gs1uHnfuihh7BkyZI21e3sh6ATTjgh2y97vwzD6JTzd6Xp06djw4YNXd0MIiKiQxqfoVrGZyg+QxG1hdrVDSCiQ8fJJ5+MxYsXI5PJ4MMPP8Qll1yCWCyGRYsWNaubyWSgaVq7nDcQCLTLcTrKpZdeijvuuCOnTFWb//pMp9NwOByd1awO53K54HK5uroZREREhzw+Q7WMz1BE1BqOlCKiLKfTiZKSEpSVlWHGjBk4//zz8dprrwHYM1z8mWeeweDBg+F0OiGEQCgUwmWXXYaioiL4/X585zvfwWeffZZz3HvuuQfFxcXw+Xy4+OKLkUwmc7Z/fei5ZVm49957cfjhh8PpdKK8vBx33XUXAGDQoEEAgNGjR0OSJJxwwgnZ/RYvXoxhw4ZB13UMHToUCxcuzDnPJ598gtGjR0PXdYwbNw6rVq1qU7+43W6UlJTkvABg4MCB+NWvfoULL7wQgUAAl156KQBg+fLl+Pa3vw2Xy4WysjJcddVVOd+W7t69G6effjpcLhcGDRqE3/72txg4cCDmz58PoOVvMhsbGyFJEj744INs2dq1a3HqqafC6/WiuLgYM2fORG1tbXb7CSecgKuuugrXX3898vPzUVJSgrlz5+ZcW2NjIy677DIUFxdD13WMGDECb775JoCWh56/8cYbGDt2LHRdx+DBg3H77bfnfOM5d+5clJeXw+l0orS0FFdddVWb+piIiKg74zNUy/gMtQefoYhaxqAUEe2Ty+VCJpPJfv7yyy/xhz/8Aa+88kr2j/1pp52GqqoqvPXWW1i5ciXGjBmD7373u6ivrwcA/OEPf8Btt92Gu+66CytWrEDfvn2bPeh83Y033oh7770Xt956K9auXYvf/e53KC4uBmA/FAHAu+++i8rKSrz66qsAgCeffBI333wz7rrrLqxbtw533303br31Vjz77LMAgFgshu9///sYMmQIVq5ciblz5+K66677xn10//33Y8SIEVi5ciVuvfVWrFmzBtOmTcPZZ5+Nzz//HC+99BL++c9/4oorrsjuc+GFF2Lr1q14//338fLLL2PhwoXYvXv3AZ23srISU6ZMwTHHHIMVK1bg7bffRnV1Nc4999yces8++yw8Hg/+9a9/4b777sMdd9yBpUuXArAfXE855RQsX74cL7zwAtauXYt77rkHiqK0eM6//e1v+PGPf4yrrroKa9euxeOPP44lS5ZkH3ZffvllPPjgg3j88cexceNGvPbaaxg5cuQBXRcREVFPwGeo1vEZis9QRAAAQUQkhPjJT34izjjjjOznf/3rX6KgoECce+65QgghbrvtNqFpmti9e3e2znvvvSf8fr9IJpM5xzrssMPE448/LoQQYuLEiWLWrFk528ePHy+OPvroFs8dDoeF0+kUTz75ZIvt3LJliwAgVq1alVNeVlYmfve73+WU3XnnnWLixIlCCCEef/xxkZ+fL2KxWHb7okWLWjzW3qZMmSI0TRMejyf7mj17thBCiAEDBogzzzwzp/7MmTPFZZddllP24YcfClmWRSKREOvXrxcAxMcff5zdvm7dOgFAPPjgg/u8xoaGBgFA/P3vfxdCCHHrrbeKqVOn5pxnx44dAoBYv359tu3f+ta3cuoce+yxYs6cOUIIIf72t78JWZaz9b9u8eLFIhAIZD9PnjxZ3H333Tl1nn/+edG3b18hhBC/+c1vxJFHHinS6XSLxyMiIuqJ+AzVMj5DBbKf+QxFtG/MKUVEWW+++Sa8Xi8Mw0Amk8EZZ5yBRx55JLt9wIAB6NOnT/bzypUrEY1GUVBQkHOcRCKBTZs2AQDWrVuHWbNm5WyfOHEi/v73v7fYhnXr1iGVSuG73/1um9tdU1ODHTt24OKLL84O/wYAwzCyuRbWrVuHo48+Gm63O6cdbXH++efj5ptvzn7eezj2uHHjcuquXLkSX375JX77299my4QQsCwLW7ZswYYNG6Cqas5+Q4cOPeAVWlauXIm///3v8Hq9zbZt2rQJRx55JABg1KhROdv69u2b/UZx9erV6N+/f7ZuW8756aefZr/VAwDTNJFMJhGPx/HDH/4Q8+fPx+DBg3HyySfj1FNPxemnn95i7ggiIqKehM9QLeMz1J5z8hmKqGX8KSeirBNPPBGLFi2CpmkoLS1tloTT4/HkfLYsC3379s2Zo9/kYJfBPZikkJZlAbCHn48fPz5nW9MwaiHEQbUHsJOIHn744S1ua6lPfvrTn7aYB6C8vBzr168HAEiStM/zybI9s3rvNu89BaDpPKeffjruvffeZvv37ds3+++v30NJkrL9daB9bVkWbr/9dpx99tnNtum6jrKyMqxfvx5Lly7Fu+++i5///Oe4//77sWzZsnZL6EpERHQo4jNUy/gMteecfIYiahmDUkSU5fF49vng0JIxY8agqqoKqqpi4MCBLdYZNmwYPv74Y1xwwQXZso8//nifxzziiCPgcrnw3nvv4ZJLLmm2vWllFtM0s2XFxcXo168fNm/ejPPPP7/F4w4fPhzPP/88EolE9kFif+04WGPGjMEXX3yxz34cNmwYDMPAihUrcNxxxwEA1q9fj8bGxmydpm9SKysrMXr0aABotnzzmDFj8Morr2DgwIEH/S3aqFGj8NVXX2HDhg1t+qZvzJgxWL9+/X5/RlwuF37wgx/gBz/4AS6//HIMHToUa9aswZgxYw6qjURERN0Bn6G+OT5D8RmKeicmOieig3bSSSdh4sSJOPPMM/G3v/0NW7duxfLly3HLLbdgxYoVAICrr74azzzzDJ555hls2LABt912G7744ot9HlPXdcyZMwfXX389nnvuOWzatAkff/wxnn76aQBAUVERXC5XNillKBQCYK9YMm/ePDz00EPYsGED1qxZg8WLF+OBBx4AAMyYMQOyLOPiiy/G2rVr8dZbb+HXv/51u/fJnDlzUFFRgcsvvxyrV6/Gxo0b8frrr+PKK68EAAwZMgQnn3wyLr30UvzrX//CypUrcckll+R84+ZyuTBhwgTcc889WLt2Lf7xj3/glltuyTnP5Zdfjvr6epx33nn45JNPsHnzZrzzzjv43//935yHzf2ZMmUKvv3tb+Occ87B0qVLsWXLFvz1r3/F22+/3WL9X/7yl3juuecwd+5cfPHFF1i3bh1eeumlbNuWLFmCp59+Gv/5z3+wefNmPP/883C5XBgwYMDBdCUREVGPxWeo5vgMxWco6p0YlCKigyZJEt566y18+9vfxv/+7//iyCOPxI9+9CNs3bo1u9LL9OnT8ctf/hJz5szB2LFjsW3bNvzsZz/b73FvvfVW/OIXv8Avf/lLDBs2DNOnT8/O4VdVFQ8//DAef/xxlJaW4owzzgAAXHLJJXjqqaewZMkSjBw5ElOmTMGSJUuyyx97vV688cYbWLt2LUaPHo2bb765xWHb39SoUaOwbNkybNy4EZMnT8bo0aNx66235gwHX7x4McrKyjBlyhScffbZ2eWg9/bMM88gk8lg3LhxuPrqq/GrX/0qZ3tpaSk++ugjmKaJadOmYcSIEbj66qsRCASyQ9fb4pVXXsGxxx6L8847D8OHD8f111+/zweyadOm4c0338TSpUtx7LHHYsKECXjggQeyD0x5eXl48sknMWnSJIwaNQrvvfce3njjjWb5MoiIiHo7PkM1x2coPkNR7ySJbzJJmIiI2sXAgQNxzTXX4JprrunqphARERF1G3yGIureOFKKiIiIiIiIiIg6HYNSRERERERERETU6Th9j4iIiIiIiIiIOh1HShERERERERERUadjUIqIiIiIiIiIiDodg1JERERERERERNTpGJQiIiIiIiIiIqJOx6AUERERERERERF1OgaliIiIiIiIiIio0zEoRUREREREREREnY5BKSIiIiIiIiIi6nQMShERERERERERUadjUIqIiIiIiIiIiDodg1JERERERERERNTpGJQiIiIiIiIiIqJOx6AUERERERERERF1OgaliIiIiIiIiIio0zEoRdRLLVmyBJIktfi67rrr2nycrVu3QpIkLFmypOMau49zSpKE3//+9822z507F5Ikoba2ttPatD+/+93vMH/+/Ba3SZKEuXPndmp7mjQ2NqKwsDCnD5v6rqXXo48+mq3XVHbPPfc0O27Tz9aKFSuyZbfeeivGjBkDy7I69qKIiIiIiKjbYFCKqJdbvHgxKioqcl5XXXVVVzerzW6++WZkMpmubsZ+7S8oVVFRgUsuuaRzG/T/br/9dpSWlmL69OnNtr399tvNfi5++MMfNqt3zz33oL6+vtVzXXfdddiyZQueffbZdmk7ERHRoaSnfNknSRJkWUZBQQFOPfVUVFRUdMg5TzjhBJxwwgnZz/F4HHPnzsUHH3zQrG5T327durVD2tKa5557Dn369EEkEsmWDRw4cJ/3OxqN5rS76aWqKvr374+LLroIO3fuzB7rvffeg9frzSkj6k3Urm4AEXWtESNGYNy4cV3djINyyimn4K9//Ssee+wxXHnllV3dnIMyYcKELjlvfX09Hn/8cTz44IOQJKnZ9rFjx6KwsHC/xzjppJPwwQcf4K677sJvfvOb/dYNBAL48Y9/jHvuuQcXXnhhi+ckIiLq7hYvXoyhQ4fmlJWWlnZRaw7MlVdeiRkzZsA0TXzxxRe4/fbbceKJJ6KiogKjR49u13MtXLgw53M8Hsftt98OADnBKgA47bTTUFFRgb59+7ZrG9oiHo/jpptuwpw5c+Dz+XK2TZo0Cb/+9a+b7eN2u3M+N/1MJBIJ/OMf/8C8efOwbNkyrFmzBh6PB9/97ndx3HHH4aabbuKXd9QrcaQUEbXoyy+/xEUXXYQjjjgCbrcb/fr1w+mnn441a9a0um9NTQ0uu+wylJWVwel0ok+fPpg0aRLefffdnHrvvvsuvvvd78Lv98PtdmPSpEl477332tzG73znO5g2bRruvPPOnG+v9qWt5/vzn/+MUaNGwel0YvDgwXjooYey09r2tmDBAnz7299GUVERPB4PRo4cifvuuy9n5NYJJ5yAv/zlL9i2bVvOt2VN9p6+99lnn0GSJDz99NPN2vTXv/4VkiTh9ddfz5Zt3LgRM2bMQFFREZxOJ4YNG4YFCxa02g+A/e2dYRgtjpJqqyFDhuDiiy/GggULsG3btlbrz5w5Exs2bMDf//73gz4nERHRoWzEiBGYMGFCzqu8vLyrm9Um5eXlmDBhAiZNmoTLLrsMzz//PFKpVLMAUnsYPnw4hg8f3qa6ffr0wYQJE+B0Otu9Ha159tlnUVdX1+Ko9ry8vGb3esKECZDl3P/EbvqZOPHEE3Hbbbfh+uuvx5YtW/Daa69l61x++eX47W9/ix07dnT0JREdchiUIurlTNOEYRg5LwDYtWsXCgoKcM899+Dtt9/GggULoKoqxo8fj/Xr1+/3mDNnzsRrr72GX/7yl3jnnXfw1FNP4aSTTkJdXV22zgsvvICpU6fC7/fj2WefxR/+8Afk5+dj2rRpBxSYuvfee1FbW4v7779/v/Xaer63334bZ599NgoKCvDSSy/hvvvuw4svvtjiN1ebNm3CjBkz8Pzzz+PNN9/ExRdfjPvvvx8//elPs3UWLlyISZMmoaSkJGcqXEuOPvpojB49GosXL262bcmSJSgqKsKpp54KAFi7di2OPfZY/Oc//8FvfvMbvPnmmzjttNNw1VVXZb9p3J+//OUvGD16NPLy8lrc/vWfC9M0W6w3d+5cKIqCW2+9tdVzjh07Fl6vF3/5y19arUtERNSTdIcv+76uaTT33l88PfPMMzj66KOh6zry8/Nx1llnYd26dTn7bd68GT/60Y9QWloKp9OJ4uJifPe738Xq1auzdfaevrd161b06dMHgJ1aoOkLvAsvvBBA8+l711xzDTweD8LhcLM2T58+HcXFxTlfEL700kuYOHEiPB4PvF4vpk2bhlWrVrWpDxYtWoTTTz99n89LB6Olfj399NPh9Xrx5JNPttt5iLoNQUS90uLFiwWAFl+ZTKZZfcMwRDqdFkcccYS49tprs+VbtmwRAMTixYuzZV6vV1xzzTX7PHcsFhP5+fni9NNPzyk3TVMcffTR4rjjjttv25vOef/99wshhDj//POFx+MRlZWVQgghbrvtNgFA1NTUHPD5jj32WFFWViZSqVS2LBKJiIKCArG/X5mmaYpMJiOee+45oSiKqK+vz2477bTTxIABA1rcD4C47bbbsp8ffvhhAUCsX78+W1ZfXy+cTqf4xS9+kS2bNm2a6N+/vwiFQjnHu+KKK4Su6znnb4nb7RazZs1qVt7Ud19/9evXr1m7L7/8ciGEEDfffLOQZVl89tlnQog9P1uffvpps+NPmjRJjB8/fr9tIyIi6m6a/vZ9/PHHIpPJ5LyEEGLZsmXiF7/4hXj55ZfFsmXLxJ/+9Cdx5plnCpfLJf773/9mj9PSc9W0adNEnz59xBNPPCE++OAD8dprr4lf/vKX4ve//322zvPPPy8kSRJnnnmmePXVV8Ubb7whvv/97wtFUcS7776737Z//bmqyWeffSYAiBkzZgghhLj77rsFAHHeeeeJv/zlL+K5554TgwcPFoFAQGzYsCG735AhQ8Thhx8unn/+ebFs2TLxyiuviF/84hfi73//e7bOlClTxJQpU4QQQiSTSfH2228LAOLiiy8WFRUVoqKiQnz55Zc5fbtly5acdj355JM57W1oaBBOp1PMnj07W3bXXXcJSZLE//7v/4o333xTvPrqq2LixInC4/GIL774Yr/9smPHDgFALFy4sNm2AQMGiFNPPbXZvTZNM1tnX89DDz30kAAgnnjiiZzyU045RYwZM2a/bSLqiRiUIuqlmv5QPvfcc+LTTz/NeQkhRCaTEXfddZcYNmyY0DQtJ0Bx8sknZ4/T0sPTd77zHZGXlyfuvPNOUVFRIdLpdM65ly5dKgCIl19+udkf8zlz5ghJkkQ0Gt1n27/+8LRlyxbhcDiyQZavB6Xaer5oNCokSRJXXnlls3NeeOGFzYJS//73v8Xpp58u8vPzmwVxPv7442y9AwlK1dXVCafTKW688cZs2YIFCwQA8Z///EcIIUQikRCqqoorr7yy2fW89dZbAoB466239tl/DQ0NAoD45S9/2WxbU9+9++67OT8TTQGnvdvdFJQKhUKisLAw+3Oxv6DUWWedJfr377/PthEREXVHPeHLvnvvvVdkMhmRTCbFypUrxbHHHisAiL/85S+ioaFBuFwuceqpp+bsu337duF0OrOBq9raWgFAzJ8/f7/n3DsoJYQQNTU1zZ6Jmnw9KCWEEGPGjBHHH398Tr2FCxcKAGLNmjXZtjU9L+0tEomIkpISce655+63jS+99FKzZ7omAwYMaPFe33zzzc3a3RSojEQi4s033xR9+vQRPp9PVFVV5Ryz6Uu+/T0DE/VETHRO1MsNGzasxUTns2fPxoIFCzBnzhxMmTIFwWAQsizjkksuQSKR2O8xX3rpJfzqV7/CU089hVtvvRVerxdnnXUW7rvvPpSUlKC6uhoA8D//8z/7PEZ9fT08Hk+brmHgwIH4+c9/jkcffRSzZ89utr2t55MkCUIIFBcXN9v+9bLt27dj8uTJGDJkCB566CEMHDgQuq7jk08+weWXX95qH+1Lfn4+fvCDH+C5557DnXfeCUVRsGTJEhx33HE46qijAAB1dXUwDAOPPPIIHnnkkRaPU1tbu89zNLVN1/V91jn66KNbTXTexO/345ZbbsE111zTar4oXdcPum+IiIgOdc899xyGDRuWU6aqKgzDwH333YcXXngBX375Zc70sq9Pf/u64447DkuWLEFBQQFOOukkjB07FpqmZbcvX74c9fX1+MlPfpJNw9Dk5JNPxn333YdYLNbqc9WcOXMwZ86c7Ofi4mI8/vjjOPXUU/HXv/4ViUQiO6WuSVlZGb7zne9kpwnm5+fjsMMOw/333w/TNHHiiSfi6KOPbpZn6Zu66KKLcOWVV2L9+vUYMmQIADuh+LHHHosRI0YAAP72t7/BMAxccMEFOf2i6zqmTJnS6jPLrl27AABFRUUtbv/Wt76FBx98MKespaT2X1/UZuTIkVi0aFGzZ8uioiJYloWqqiocdthh+20bUU/CoBQRteiFF17ABRdcgLvvvjunvLa2ttV59YWFhZg/fz7mz5+P7du34/XXX8cNN9yA3bt34+23384GOx555JF9rj7XUmBof2655RY888wzuOmmm7LBm73b05bzZTIZSJKUDWLtraqqKufza6+9hlgshldffRUDBgzIlu+dL+FgXXTRRfjjH/+IpUuXory8HJ9++ikWLVqU3R4MBqEoCmbOnInLL7+8xWMMGjRon8cvKCgAYAfi2svPfvYzPPTQQ5gzZw5+9rOf7bNefX19m4NdRERE3U13/rLv6quvxo9//GPIsoy8vDwMGjQouzhLU17QllbAKy0txdKlSwHYC7i89957uOOOO3DffffhF7/4BfLz83H++efjrrvuaraC3cE6//zzcd1112HJkiWYN28e1q5di08//TQnKXtTvxx77LEtHqO1QFlrX+IFAoE2rWDdFKhUVRXFxcX7XEWw6Tz88o56GwaliKhFkiQ1W+XkL3/5C3bu3InDDz+8zccpLy/HFVdcgffeew8fffQRAHsJ3by8PKxduxZXXHFFu7S3oKAAc+bMwc0334xYLJazra3nczgcGDduHF577TX8+te/hsPhAABEo1G8+eabOXWbHtL27iMhRIsJKp1O5wE9YEydOhX9+vXD4sWLUV5eDl3Xcd5552W3u91unHjiiVi1ahVGjRqVbWdbORwODB48GJs2bTqg/Vo75q9+9Sucf/75+w06bd68OfsNJhERUW/RHb7s69+//z6DLE1faFVWVjbbtmvXrpy//QMGDMiuJLxhwwb84Q9/wNy5c5FOp/HYY4+12o62CAaDOOOMM/Dcc8/hV7/6FRYvXtzseampTS+//HLOF4ht1bR/fX39PgNJbbGvQOXXNX1ZyC/vqLdhUIqIWvT9738fS5YswdChQzFq1CisXLkS999/P/r377/f/UKhEE488UTMmDEDQ4cOhc/nw6effppd1Q4AvF4vHnnkEfzkJz9BfX09/ud//gdFRUWoqanBZ599hpqampyRQW11zTXXYMGCBfjrX/+aU34g57vjjjtw2mmnYdq0abj66qthmibuv/9+eL3enJFF3/ve9+BwOHDeeefh+uuvRzKZxKJFi9DQ0NCsXSNHjsSrr76KRYsWYezYsZBleb8PJ4qi4IILLsADDzwAv9+Ps88+G4FAIKfOQw89hG9961uYPHkyfvazn2HgwIGIRCL48ssv8cYbb+D999/fb1+dcMIJzfrpmzrvvPPw61//ep/Hraurw8aNG3HllVe263mJiIgOdd3ty76vmzhxIlwuF1544QX88Ic/zJZ/9dVXeP/99/c5SuvII4/ELbfcgldeeQX//ve/93n8pr45kC/xLrroIvzhD3/AW2+9hRdeeAFnnXVWToBv2rRpUFUVmzZtwjnnnNPm4zYZOnQoAHu15a+Pwu8ImzdvRkFBwQHPFiDq7hiUIqIWPfTQQ9A0DfPmzUM0GsWYMWPw6quv4pZbbtnvfrquY/z48Xj++eexdetWZDIZlJeXY86cObj++uuz9X784x+jvLwc9913H376058iEomgqKgIxxxzTLN8BW3ldrsxd+5cXHbZZc22tfV8J598Ml555RX88pe/xPTp01FSUoKf//zn2LVrF55//vlsvaFDh+KVV17BLbfcgrPPPhsFBQWYMWMGZs+ejVNOOSXn3FdffTW++OIL3HTTTQiFQhD2IhP7vZaLLroI8+bNQ01NDS666KJm24cPH45///vfuPPOO3HLLbdg9+7dyMvLwxFHHIFTTz211b46//zz8cwzz+DTTz/d57D2AyVJEu69915MnTq1xe1//vOfoWkazj333HY5HxERUXfRHb/s21teXh5uvfVW3HTTTbjgggtw3nnnoa6uDrfffjt0Xcdtt90GAPj8889xxRVX4Ic//CGOOOIIOBwOvP/++/j8889xww037PP4Pp8PAwYMwJ///Gd897vfRX5+PgoLCzFw4MB97jN16lT0798fP//5z1FVVdXseWngwIG44447cPPNN2Pz5s04+eSTEQwGUV1djU8++QQejwe33377Po8/fvx4uFwufPzxx/jBD35wYB12ED7++GNMmTIlOxqfqNfo2jzrRESHvnQ6LYYPHy6+973vdXVT2tXIkSOzKxZ2hm9961vZ1XmIiIh6kv2tPCuEvfLtxRdfLIqKioTb7Rbf+ta3xIcffthsFbqvr76XTCbFrFmzxKhRo4Tf7xcul0sMGTJE3HbbbSIWi+WcY9myZeK0004T+fn5QtM00a9fP3HaaaeJP/7xj/tt+9dXNd6fp556SowaNUo4HA4RCATEGWecIb744ovs9urqanHhhReKoUOHCo/HI7xerxg1apR48MEHhWEY2Xpfv24hhHj33XfF6NGjhdPpFADET37yEyFEy6vvNbnpppsEAFFWViZM02yxza+99po48cQThd/vF06nUwwYMED8z//8j3j33Xdbvd6ZM2eK4cOHNysfMGCAOO200/a7b2s/E3v78ssvBQDxyiuvtFqXqKeRhGjl63oiol7m4osvxve+9z307dsXVVVVeOyxx7Bs2TK88847OOmkk7q6ee3m7bffxllnnYWNGze2+k3tN/WPf/wDU6dOxdq1azF48OAOPRcRERFRe1ixYgWOPfZYfPzxxxg/fnyHnefWW2/Fc889h02bNkFVOZmJehcGpYiIvubcc8/F8uXLUVNTA03TMGbMGNx00004+eSTu7pp7e7RRx/F0UcfjcmTJ3foef70pz8hk8lw6h4RERF1K9OnT0csFmu26E17aWxsxODBg/HII4/g/PPP75BzEB3KGJQiIiIiIiIiasFXX32Fp59+GrNnz4bP52v3469atQrvvvsurrvuOuaTol6JQSkiIiIiIiIiIup0clc3gIiIiIiIiIiIeh8GpYiIiIiIiIiIqNMxtX87sCwLu3btgs/n4zxgIiKiHkYIgUgkgtLSUsgyv89rL3x+IiIi6rna+vzEoFQ72LVrF8rKyrq6GURERNSBduzYgf79+3d1M3oMPj8RERH1fK09PzEo1Q6aVmHYsWMH/H5/F7eGiIiI2lM4HEZZWVmHrLrUm/H5iYiIqOdq6/MTg1LtoGnIud/v50MVERFRD8UpZu2Lz09EREQ9X2vPT0yMQEREREREREREnY5BKSIiIiIiIiIi6nQMShERERERERERUadjUIqIiIiIiIiIiDodg1JERERERERERNTpGJQiIiIiIiIiIqJOx6AUERERERERERF1OgaliIiIiIiIiIio0zEoRUREREREREREnY5BKSIiIiIiIiIi6nQMShERERERERERUadTu7oBRETdTioFWBYgy4DT2dWtISIiIiIi6pYYlCIiaqtkEqivByIRwDQBRQF8PiA/H9D1rm4dERERERFRt8Lpe0REbZFMAjt3Ag0N9meHw35vaLDLk8muaxsREREREVE3xJFSRERtUV8PhEL2v+vq9kzf83rt6XwuF1Ba2rVtJCIiIiIi6kYYlCIiak0qBdTW2tP2LAtwuwFVBQzDDlTJsv25oIA5poiIiIiIiNqI0/eIiFpjWfZIKdMEAgFACDtQJYT92TTt7ZbV1S0lIiIiIiLqNjhSioioNZmMnTNK04CaGjuPVNP0vWDQHiWVTNr1XK6ubi0REREREVG3wKAUEVFrNA2QJGDbNnvKnmnaASnLAsJhOyjVr59dj4iIiIiIiNqE0/eIiFojy3YgqqYGiEbtlfc8Hvs9GrXLmwJVRERERERE1Cb8LygiorZIJgGfDygutnNJxeP2e3GxXZ5MdnULiYiIiIiIuhVO3yMiak0iYY+CKiqyA1Fu957pe4Zhl8uyXY+r7xEREREREbUJg1JERG2haXZS82QSiMXspOayDPj9gK7b0/iIiIiIiIiozRiUIiJqjcu1Z4penz5AILBn9T2HA6ittbdz5T0iIiIiIqI2Y04pIqLWOJ1A//52MvNQyF6Jz+m030Mhu7x/f07dIyIiIiIiOgAcKUVE1BalpfZIqepqe6peU04pWQYGDLC3ExERERERUZsxKEVE1Ba6DgweDOTlAXV1dk4pTQMKCoD8fHs7ERERERERtRmDUkREbaXr9oiogoI9o6Q4ZY+IiIiIiOigMChFRHSgGIgiIiIiIiL6xhiUIiI6UOEwYBiAqgJ+f1e3hoiIiIiIqFtiUIqIqK0aG4HNm4Hdu4F0GnA4gKKiPbmmiIiIiIiIqM0YlCIiaovGRuDf/wYiETunlK7bq/Ht2GFvGzOGgSkiIiIiIqIDIHd1A4iIuoXNm+2AVFmZPW0vnbbfy8rs8s2bu7qFRERERERE3QpHShERtSYctqfseb1ATY09Mqopp1Renl2+e7ddjzmmiIiIiIiI2oRBKSKi1hgGEIsBpgk0NABCAJJkvzc2AsEgoCh2PSIiIiIiImoTTt8jImqNqgKhELB9ux2MymSAVMp+lyS7PBSy6xEREREREVGb8L+giIha43Tao6AqK+1penV1e6bvFRTYI6j8frseERERERERtQlHShERtSaRACwLqK4GNmywR0fl5dnvGzbY5ZZl1yMiIiIiIqI24UgpIqK2qKoC3G57RFRtrT1aStOA0lJ71FRVVVe3kIiIiIiIqFthUIqIqDXRqJ3QHLCn7Lnde5Kdq6odlGpstOvl5XVhQ4mIiIiIiLoPBqWIiFrTtNJefb2dPyqV2rMtFLJX3nO57HpERERERETUJgxKERG1Rgg7ENXYaL8bhp1DSpbtkVJOJ1BYaNcjIiIiIiKiNumRic4XLlyIQYMGQdd1jB07Fh9++GGb9vvoo4+gqiqOOeaYjm0gEXUvXi+QTNpBKUWxc0npuv2uKHZ5MmnXIyIiIiIiojbpcUGpl156Cddccw1uvvlmrFq1CpMnT8Ypp5yC7du373e/UCiECy64AN/97nc7qaVE1G2Ew/YIKUWxR0h5PEAwaL9bll2eStn1iIiIiIiIqE16XFDqgQcewMUXX4xLLrkEw4YNw/z581FWVoZFixbtd7+f/vSnmDFjBiZOnNjqOVKpFMLhcM6LiHqwZNLOJdWvH1BUZAeiolH7vajILjdNux4RERERERG1SY8KSqXTaaxcuRJTp07NKZ86dSqWL1++z/0WL16MTZs24bbbbmvTeebNm4dAIJB9lZWVfaN2E9EhTgg7b5TPZwegBg0CDj/cfu/Xzy53OplTioiIiIiI6AD0qKBUbW0tTNNEcXFxTnlxcTGqqqpa3Gfjxo244YYb8Nvf/haq2ra87zfeeCNCoVD2tWPHjm/cdiI6hOXlAX372knNhbBflrXn36pqb8/L6+qWEhERERERdRs9cvU96WvLsgshmpUBgGmamDFjBm6//XYceeSRbT6+0+mE0+n8xu0kom4iLw846ijgo4+A2logHgckyQ5Iud12gvOjjmJQioiIiIiI6AD0qKBUYWEhFEVpNipq9+7dzUZPAUAkEsGKFSuwatUqXHHFFQAAy7IghICqqnjnnXfwne98p1PaTkSHMKcTGDoUWLECCIXsBOeaBmQygGHs2c5gNRERERERUZv1qKCUw+HA2LFjsXTpUpx11lnZ8qVLl+KMM85oVt/v92PNmjU5ZQsXLsT777+Pl19+GYMGDerwNhNRN2FZwODBQP/+QGOjndhcUezRUQ6HvZ2IiIiIiIjarEfllAKA2bNn46mnnsIzzzyDdevW4dprr8X27dsxa9YsAHY+qAsuuAAAIMsyRowYkfMqKiqCrusYMWIEPB5PV14KER0qwmF7hNSoUcAxxwAjRgDDhtnvxxxjl4dCdj0iokPUwoULMWjQIOi6jrFjx+LDDz/cb/1ly5Zh7Nix0HUdgwcPxmOPPbbPur///e8hSRLOPPPMdm41ERER9WQ9aqQUAEyfPh11dXW44447UFlZiREjRuCtt97CgAEDAACVlZXYvn17F7eSiLoVwwDSaaCwEJBlIBCwR0bJ8p5RUrt22fWIiA5BL730Eq655hosXLgQkyZNwuOPP45TTjkFa9euRXl5ebP6W7ZswamnnopLL70UL7zwAj766CP8/Oc/R58+fXDOOefk1N22bRuuu+46TJ48ubMuh4iIiHoISQiuYf5NhcNhBAIBhEIh+P3+rm4OEbW3cBhYvtxOaO522wGqvYNS8TgQjQLHHw/wdwBRj9MT/s6PHz8eY8aMwaJFi7Jlw4YNw5lnnol58+Y1qz9nzhy8/vrrWLduXbZs1qxZ+Oyzz1BRUZEtM00TU6ZMwUUXXYQPP/wQjY2NeO2111psQyqVQiqVyn4Oh8MoKyvr1v1KRERELWvr81OPm75HRNTu/H6gqAioqgJqaoCtW/e8amrs8qIiBqSI6JCUTqexcuVKTJ06Nad86tSpWL58eYv7VFRUNKs/bdo0rFixAplMJlt2xx13oE+fPrj44otbbce8efMQCASyr7KysoO4GiIiIupJGJQiImqL0lJ7xNQnnwDV1XYOqepq+3M4bG8nIjoE1dbWwjTNZisRFxcXN1uxuElVVVWL9Q3DQG1tLQDgo48+wtNPP40nn3yyTe248cYbEQqFsq8dO3YcxNUQERFRT9LjckoREXWIeBzw+ewRUbEYkEjY5UVFdnk83rXtIyJqhSRJOZ+FEM3KWqvfVB6JRPDjH/8YTz75JAoLC9t0fqfTCafTeYCtJiIiop6MQSkiotakUsBXX9kJzg87zB4hlU7b+aSKi4HaWnt7v34A/4OLiA4xhYWFUBSl2aio3bt3NxsN1aSkpKTF+qqqoqCgAF988QW2bt2K008/PbvdsiwAgKqqWL9+PQ477LB2vhIiIiLqaRiUIiJqTSIBRCJ2EOq//wXq6/cEpRoagD597O2JBINSRHTIcTgcGDt2LJYuXYqzzjorW7506VKcccYZLe4zceJEvPHGGzll77zzDsaNGwdN0zB06FCsWbMmZ/stt9yCSCSChx56iPmiiIiIqE0YlCIiaoto1E5qnk7bK/A1rcJXVWUHqfr06eoWEhHt0+zZszFz5kyMGzcOEydOxBNPPIHt27dj1qxZAOx8Tzt37sRzzz0HwF5p79FHH8Xs2bNx6aWXoqKiAk8//TRefPFFAICu6xgxYkTOOfLy8gCgWTkRERHRvjAoRUTUGpfLTmZeVQWUlNjBKdMEFAUIBu1yp9OuR0R0CJo+fTrq6upwxx13oLKyEiNGjMBbb72FAQMGAAAqKyuxffv2bP1BgwbhrbfewrXXXosFCxagtLQUDz/8MM4555yuugQiIiLqgSTRlLWSDlo4HEYgEEAoFIKfS8IT9TzhMPDii8DatXZCc8sCZHnPu9sNDB8OnHcewN8BRD0O/853DPYrERFRz9XWv/NyJ7aJiKh7Mgw7GJVK2VP2VBXQdfs9nbbL43G7HhEREREREbUJp+8REbXGNIG6OntEVFkZEIvZZT4f4PHY2+rq7DIiIiIiIiJqEwaliIhaY1mAEHbeqLw8e9W9vafuRaP29v9fDp2IiIiIiIhax6AUEVFrLAvIz7dzS335pR2UUhR7ZFQ6beeR8vsZlCIiIiIiIjoADEoREbXG47GDUtHonul6hmHnlCoosEdM5efb24iIiIiIiKhNmOiciKg1fr8dfGpstEdLhcNAJLLn342N9nauHkVERERERNRmDEoREbUmlQI0zR4ptX27PXUvELDft2+3yzXNrkdERERERERtwul7REStsSw7+BQM2tP0duywR0cpCjBkiJ3kfPt25pQiIiIiIiI6ABwpRUTUmro6YOdOO3dUImEnOnc67fdEwi7fudOuR0RERERERG3CkVJERK2RJCAUAmpr7WTmPp+d5NwwgGTSDkYVFtr1iIiIiIiIqE0YlCIiao0QQCxm54zSdTu5eRNVtctjMbseERERERERtQmDUkRErdE0e6peJmMHn9JpOwAlSXvKHQ67HhEREREREbUJg1JERK2xLHvaHgDE4/bKe06nPUIqFLKDUx4PE50TEREREREdAAaliIhao6p2EKq01A5A1dXZI6Y0Dejf3x415XTa9YiIiIiIiKhN+F9QRESt0TQgL89eac/lsgNTlmWvuhcM2uV5eZy+R0REREREdAAYlCIiaoviYqC6Gti+3f6sKIBpApGIva24uGvbR0RERERE1M3IXd0AIqJDnstlT81TFHtElGHYo6MMw/6sKPZ2l6urW0pERERERNRtcKQUEVFbNK28p2lAnz721D3LsgNSsZi9nYiIiIiIiNqMI6WIiFqTSNir7jWNhFLVPS/ALo/H7XpERERERETUJhwpRUTUmlQKCIXspOaWBezebY+M0jSgqMgeNRUK2fWIiIiIiIioTRiUIiJqi6bpe4pir77ndAJC2KOjTBPweLq6hURERERERN0Kg1JERK1xOu2petXVdlBKlvfklIrF7KDUkUfa9YiIiIiIiKhNGJQiImqNLNujo9LpPaOjJMn+t8tl/1uS7HpERERERETUJgxKERG1xrLslxD2yKhIxP63JNnlHs+eOkRERERERNQmDEoREbUmlbKDUfE4EA4DhrFnWzhsB6diMSY6JyIiIiIiOgAMShERtUV1NRCNAoGAPUqqiSTZ5dXVXdc2IiIiIiKibohBKSKi1qRSduBJlu1k5qa5Z5ui2COoolGOlCIiIiIiIjoADEoREbUmmbTfdd0OPEmSHYwyTXsqn67n1iMiIiIiIqJWMShFRNQah8NeZS+TAVTVDj6Zph2c0nU7MOVy2fWIiIiIiIioTRiUIiJqjccDBINAY6M9hc/nswNSQtjBKcuyt3s8Xd1SIiIiIiKiboNBKSKi1ni9QFmZnczc47FHRsmyHYxSVfvfZWV2PSIiIiIiImoTuasbQER0yMtkgH79gCOPtANR8TgQidjvlmWX9+tn1yMiIiIiIqI24UgpIqLWaBoQCAD5+Xaic9O0X4oCFBXZ5YGAXY+IiIiIiIjahEEpIqLWyLI9Za+xcU+AyrLsck2zy5um9BEREREREVGbMChFRNQW4TDQ0ADU1wM1NXuCUn362COlwuGubiEREREREVG3wqAUEVFrEglg1y5g27Y9o6UUxZ7Ct2OHnV+qXz+7ntPZ1a0lIiIiIiLqFhiUIiJqTSoFrFsHhEKAzwdI0p7V93TdLl+3zq5HREREREREbcIEKERErQmHgaoqe3SUz2fnj0om7Xefzy6vquIUPiIiIiIiogPAkVJERK1JJOwAVCoFfPll7oio2lp7yp4k2fWIiIiIiIioTRiUIiJqjdNpT9errQWEsANQkmT/O5Wy/11eznxSREREREREB4DT94iIWpOfbyc1j8ftAJRhAOm0/S5Jdrlp2vWIiIiIiIioTThSioioNYkEoKp2ACqTsXNINY2UymTsf6sqp+8REREREREdAAaliIhaE4vZgaiCAnulvbo6e2SUogB5eXa5otj1iIiIiIiIqE0YlCIiao1l2dP1olH7lUzaZbJsf1YUe7tldXVLiYiIiIiIug0GpYiIWpOfbwefvvpqz7Q9wH6PRoFIxK7DnFJERERERERtxqAUEVFr4nGgvt4eDSXL9sgowA5KGYY9Qqq+3q5HREREREREbcLV94iIWlNdDTQ02MnMnU57tFTTy+m0yxsa7HpERERERETUJhwpRUTUml277FFSmgbouj06Sog9q+4B9vZdu7q2nURERERERN0Ig1JERK1xOPaMjDJNIJXak+h871FTDkdXt5SIiIiIiKjb4PQ9IqLW9OsHuN1AImG/mkZISdKeMrfbrkdERERERERtwqAUEVFr+vcHgkF7yp5p2lP1Uin73TTt8mDQrkdERERERERtwqAUEVFrolHA7wc8HnvlPVm2A1FNK/F5PPb2aLSrW0pERERERNRtMKcUEVFrUil7ul5Bgf3vRGJPonOXa88KfKlUV7eUiIiIiIio22BQioioNamUveJeMGiPjorF9iQ693jsfxsGg1JEREREREQHgNP3iIhaEwzaI6KEAPLzAV23V9rTdfuzEPb2YLCrW0pERERERNRtcKQUEVFrZBkoLQV27wbWrrVHRSmKneS8pgYIBOztMuP8REREREREbcWgFBFRa/x+wOu1c0nFYvaqe00cDvvl9dr1iIiIiIiIqE0YlCIiao0s2yOi4nE7obll7Ul0rqp2eU0NR0oREREREREdAP4XFBFRa6qrgR077Ol6hmEHpUxzT4Jz07S3V1d3dUuJiIiIiIi6DQaliIhaU1Vlj4TKZPaMjnI47HdJsstraux6RERERERE1CacvkdE1JpEAgiF7BFRbnfz7ZGIvT2R6Py2ERERERERdVMMShERtcbhsEdECQHouh2caqIoQDhsb3c4uq6NRERERERE3QyDUkRErXE4AJ/PDj41NDTfrmn2dgaliIiIiIiI2oxBKSKi1hQWAn37ArEYkEzaI6WaVt9TFHv0VN++dj0iIiIiIiJqEyY6JyJqTUmJHXSSZTunlKbZSc41zf4sy/b2kpKubikR0T4tXLgQgwYNgq7rGDt2LD788MP91l+2bBnGjh0LXdcxePBgPPbYYznbn3zySUyePBnBYBDBYBAnnXQSPvnkk468BCIiIuphGJQiImqLvDzA6QQMA0in7RX30mn7s9NpbyciOkS99NJLuOaaa3DzzTdj1apVmDx5Mk455RRs3769xfpbtmzBqaeeismTJ2PVqlW46aabcNVVV+GVV17J1vnggw9w3nnn4e9//zsqKipQXl6OqVOnYufOnZ11WURERNTNSUII0dWN6O7C4TACgQBCoRD8fn9XN4eI2tvWrcCNNwKffGJP4bOsPdtkGfB4gOOOA+bNAwYO7KpWElEH6Ql/58ePH48xY8Zg0aJF2bJhw4bhzDPPxLx585rVnzNnDl5//XWsW7cuWzZr1ix89tlnqKioaPEcpmkiGAzi0UcfxQUXXNBqm3pCvxIREVHL2vp3niOliIhak0oB27bZAajCQnvanqLY74WFdvm2bXY9IqJDTDqdxsqVKzF16tSc8qlTp2L58uUt7lNRUdGs/rRp07BixQpkMpkW94nH48hkMsjPz29xeyqVQjgcznkRERFR79Yjg1IHkjPhn//8JyZNmoSCggK4XC4MHToUDz74YCe2logOeY2N9qp7yaT9nk7vee1d3tjY1S0lImqmtrYWpmmiuLg4p7y4uBhVVVUt7lNVVdVifcMwUFtb2+I+N9xwA/r164eTTjqpxe3z5s1DIBDIvsrKyg7iaoiIiKgn6XFBqQPNmeDxeHDFFVfgH//4B9atW4dbbrkFt9xyC5544olObjkRHbIsyw48NTYCiYSd5FzX7fdEwi5PJnOn9RERHWIkScr5LIRoVtZa/ZbKAeC+++7Diy++iFdffRW6rrd4vBtvvBGhUCj72rFjx4FeAhEREfUwalc3oL098MADuPjii3HJJZcAAObPn4+//e1vWLRoUYs5E0aPHo3Ro0dnPw8cOBCvvvoqPvzwQ1x22WUtniOVSiG11zQdDj8n6uFk2U5sLkl2ICqdBoTY89kw7O1yj4vzE1EPUFhYCEVRmo2K2r17d7PRUE1KSkparK+qKgoKCnLKf/3rX+Puu+/Gu+++i1GjRu2zHU6nE06n8yCvgoiIiHqiHvVfUAeTM+HrVq1aheXLl2PKlCn7rMPh50S9jGXZOaQUxQ5CaZq94p6m2Z+btnGkFBEdghwOB8aOHYulS5fmlC9duhTHH398i/tMnDixWf133nkH48aNg6Zp2bL7778fd955J95++22MGzeu/RtPREREPVqPCkodTM6EJv3794fT6cS4ceNw+eWXZ0datYTDz4l6GUmyV9hzOOzAkyTZo6Ikyf7scNjb9zMNhoioK82ePRtPPfUUnnnmGaxbtw7XXnsttm/fjlmzZgGwn232XjFv1qxZ2LZtG2bPno1169bhmWeewdNPP43rrrsuW+e+++7DLbfcgmeeeQYDBw5EVVUVqqqqEI1GO/36iIiIqHvqcdP3gAPPmQAAH374IaLRKD7++GPccMMNOPzww3Heeee1WJfDz4l6GV0HAgF72l4mA8Rie6bveTz2iKlAwK5HRHQImj59Ourq6nDHHXegsrISI0aMwP+1d+/xUdT3/sffm2Q3F0iWewIaICpXgZaLQrAIVgkIKio9oihqC1aKLbf2oByrpGq5iCIqgogI6q8iKuihPRwkCuIF0EJBKXBQEcRLwp1sCCGX3e/vj0kWlt2EIJudXF7Px2Mfyc58ZuYzM9nsdz/7ne+sXLlSrVq1kiRlZ2cHjL+ZlpamlStXasKECXruuefUokULPfPMMxo6dKg/Zu7cuSoqKtKvfvWrgG1NmTJFmZmZEdkvAABQs9WqotRPGTOhTFpamiSpc+fO2r9/vzIzM8stSgGoY1q2lJKTpf37rV5RxcXWOFIxMdZzr9ea37Kl3ZkCQLnGjBmjMWPGhJy3ePHioGl9+/bVv/71r3LXt3fv3jBlBgAA6qpadfneTxkzIRRjTMBA5gDqOK9XSkmxekcdPnzqTnsnT1rPjbHme712ZwoAAAAANUat6iklWWMmjBgxQj169FB6erpeeOGFoDETfvjhB73yyiuSpOeee04tW7ZU+/btJUkff/yxnnjiCf3hD3+wbR8AVDNOp3T8uDW4eVKSdOKEVYiKiZESEqzpx49bcQAAAACASql1RalzHTPB5/Np8uTJ2rNnj2JiYnTxxRdr+vTpuvfee+3aBQDVzcGD1qV7UVFWUSou7tSYUi6XdSnf/v1WXIMGdmcLAAAAADWCwxhj7E6ipvN4PHK73crNzVVSUpLd6QAIt02bpDFjpIIC63lx8al5Zb2j4uOluXMlbokO1Dq8z1cNjisAALVXZd/nq92YUh6PR++884527txpdyoAYDHGuvNeSYnVMyou7tSjrKdUUZEVBwCVQHsHAACgGhSlbrnlFs2ZM0eSVFBQoB49euiWW25Rly5dtGzZMpuzAwBZ40a5XNbA5mV33vN6rZ/FxdZ0l8uKA4AQaO8AAAAEs70o9eGHH6pPnz6SpLffflvGGB07dkzPPPOMHnvsMZuzAwBJ9epZY0U5HFJhoTXQ+fHj1s/CQmt6gwZWHACEQHsHAAAgmO1FqdzcXDVq1EiStGrVKg0dOlQJCQkaPHiwvvrqK5uzAwBZA5w3bmzdZe/oUenIkVOPo0et6Y0bW3EAEALtHQAAgGC2f4JKTU3Vhg0blJ+fr1WrVikjI0OSdPToUcXFxdmcHQDIKjqV9ZKKjZUSE6278CUmWs/LekvFxtqdKYBqivYOAABAsBi7Exg/frxuv/121a9fXy1btlS/fv0kWd3cO3fubG9yAFDm8GEpOlpq2NC6bM/hsAY2T0iQPB5rPgCUg/YOAABAMNuLUmPGjNHll1+u7777Tv3791dU6eUvF110EWMsAKgefvxRKiiwekeVDXReprjYml5QYMUlJ9uXJ4Bqi/YOAABAMNuLUpLUo0cPdenSRXv27NHFF1+smJgYDR482O60AMBizKnHmZfoxcZad+Irmw8A5aC9AwAAEMj2MaVOnDihkSNHKiEhQZdeeqn27dsnSRo7dqymT59uc3YAICkuzhrEvKDAulTvwIFTD4/Hmh4VZcUBQAi0dwAAAILZXpSaPHmyPv/8c33wwQcBA31ec801Wrp0qY2ZAUCpxo0ll8saNyovzxpbquyRl2dNd7msOAAIgfYOAABAMNsv33vnnXe0dOlS9erVSw6Hwz+9Y8eO2r17t42ZAUApn8/66fVaY0j5fNaleg6H1UOqdGwYfxwAnIH2DgAAQDDbe0odPHhQzZo1C5qen58f0GgDANvs3y8dPWr1hpKs4lTZQ7KmHz1qxQFACLR3AAAAgtlelLrsssv0P//zP/7nZQ2zBQsWKD093a60AOAUr9caO6q4WIqPt8aOio21fsbHW9M9nlNFKgA4A+0dAACAYLZfvjdt2jQNHDhQO3bsUElJiZ5++mlt375dGzZs0Lp16+xODwCsXlAnTkglJdYlelFR1nhSxkgnT1rTTpyw4gAgBNo7AAAAwWzvKdW7d2998sknOnHihC6++GKtXr1aycnJ2rBhg7p37253egAgJSVZBaiSEutSvZISqago8LkxVhwAhEB7BwAAIJjtPaUkqXPnznr55ZftTgMAQisokGJirMKTx2P9LFNUZA14HhNjxQFAOWjvAAAABLKlKOXxeJRU2qPA4/FUGJtEzwMAdmvYUHI6T40ZVVx8ap7Teepnw4aRzw1AtUV7BwAAoGK2FKUaNmyo7OxsNWvWTA0aNAh51xljjBwOh7wMHAzAbtHR1rhRxli/l/Wacjis8aW8Xmt+dLTdmQKoRmjvAAAAVMyWotSaNWvUqFEjSdLatWvtSAEAKq+w0Bo3qux3n+/UvKgoq0hVUmLNA4BStHcAAAAqZktRqm/fviF/B4Bq6dgxq+BUXBw4npRkFaiKi635x47ZkR2Aaor2DgAAQMVsv/veokWL9OabbwZNf/PNNxkMFED1EBVlDWJujDV2lMNx6uF0WtMLCqw4AAiB9g4AAEAw2z9BTZ8+XU2aNAma3qxZM02dOtWGjADgDMeOBQ5uXlZ8Or0IVVxMTykA5aK9AwAAEMyWy/dO9+233yotLS1oeqtWrbRv3z4bMgKAM5w8afWKkgKLU17vqTvyORxWHACEQHsHAAAgmO09pZo1a6YvvvgiaPrnn3+uxo0b25ARAJwhNja8cQDqHNo7AAAAwWwvSt16660aO3as1q5dK6/XK6/XqzVr1mjcuHG69dZb7U4PAKTmzYMHOD+TMVYcAIRAewcAACCY7ZfvPfbYY/r222919dVXKybGSsfn8+nOO+9kjAUA1UNBx/WiFAAARiNJREFUwanL98rjcFhxABAC7R0AAIBgthelXC6Xli5dqkcffVSff/654uPj1blzZ7Vq1cru1ADAcuRIeOMA1Dm0dwAAAILZXpQq07ZtW7Vt29buNAAgmDFSSUnFMSUlZ7/ED0CdR3sHAADgFNuLUl6vV4sXL9b777+vAwcOyOfzBcxfs2aNTZkBQCmfr3JFqTP+fwFAGdo7AAAAwWwvSo0bN06LFy/W4MGD1alTJznONm4LAERaVJT18HrPHgMAIdDeAQAACGZ7Uer111/XG2+8oUGDBtmdCgCE5nJV7u57Lldk8gFQ49DeAQAACGb71/oul0uXXHKJ3WkAQPkKC8MbB6DOob0DAAAQzPai1B//+Ec9/fTTMgwQDKC6KiyUoqMrjomOpigFoFy0dwAAAILZfvnexx9/rLVr1+p///d/demll8rpdAbMX758uU2ZAUCphATr0ryywc5P/1BZNi6My2XFAUAItHcAAACC2V6UatCggW666Sa70wCA8qWlSfXrSydOSDExVnHKGKsgVfa8fn0rDgBCoL0DAAAQzPai1KJFi+xOAQAq1rCh9Th4UPL5rIJUVJT1u89nFafKYgAgBNo7AAAAwWwfU0qSSkpK9N5772n+/PnKy8uTJP344486fvy4zZkBgKT8fOvSvNjYU5fu+XzWT2Os6QkJVhwAlIP2DgAAQCDbe0p9++23GjhwoPbt26fCwkL1799fiYmJevzxx3Xy5Ek9//zzdqcIoK7zeqWCAqt3lNMZOKC502lNLyiw4gAgBNo7AAAAwWzvKTVu3Dj16NFDR48eVXx8vH/6TTfdpPfff9/GzACg1IkTUm6uVFRkFZ6iok49vF5rem6uFQcAIdDeAQAACGZ7T6mPP/5Yn3zyiVwuV8D0Vq1a6YcffrApKwA4TUGBdWlecbE1ftTpd98zxnrk51txABAC7R0AAIBgtveU8vl88oa45OX7779XYmKiDRkBwBmOHz91yd7pBanTnxcWWnEAEALtHQAAgGC2F6X69++v2bNn+587HA4dP35cU6ZM0aBBg+xLDADK5OdLJSXW79HRgfPKnpeUMNA5gHLR3gEAAAhm++V7Tz31lK666ip17NhRJ0+e1PDhw/XVV1+pSZMmWrJkid3pAYA1ZlSZsrvuhXp+ehwAnIb2DgAAQDDbi1ItWrTQ1q1btWTJEv3rX/+Sz+fTyJEjdfvttwcMBAoAtqlXT4qJsXpDlXf5XkyMFQcAIdDeAQAACOYw5sxPWDhXHo9Hbrdbubm5SkpKsjsdAOG2YYN0zTUV310vIUF67z0pPT1yeQGICN7nqwbHFQCA2quy7/O295R65ZVXKpx/5513RigTAChHVJT1ON8YAHUW7R0AAIBgthelxo0bF/C8uLhYJ06ckMvlUkJCAo00APbLyalcUSonJzL5AKhxaO8AAAAEs/1r/aNHjwY8jh8/rl27dukXv/gFA38CqB4cDinErdwDeL1WHACEQHsHAAAgmO1FqVDatGmj6dOnB32rCAC2cDqD77p3Jp/PigOASqK9AwAA6rpqWZSSpOjoaP344492pwEA1iDmZ7snhDFWHACcA9o7AACgLrN9TKkVK1YEPDfGKDs7W3PmzNEVV1xhU1YAcJoDB8IbB6DOob0DAAAQzPai1I033hjw3OFwqGnTpvrlL3+pJ5980p6kAOB0CQlnHy/K4aCnFIBy0d4BAAAIZntRyne2cVoAwG4lJeGNA1Dn0N4BAAAIVm3HlAKAaqNx48qNKdW4cWTyAQAAAIBawPaeUhMnTqx07KxZs6owEwAoR26uFHWWGn5UlBUHACHQ3gEAAAhme1Fqy5Yt+te//qWSkhK1a9dOkvTll18qOjpa3bp188c5zjaeCwBUFa9XKi6uOKa42IoDgBBo7wAAAASzvSh1/fXXKzExUS+//LIaNmwoSTp69Kh+/etfq0+fPvrjH/9oc4YAoMoVpQCgHLR3AAAAgtk+ptSTTz6padOm+RtoktSwYUM99thj3I0GQPWwZ0944wDUObR3AAAAgtlelPJ4PNq/f3/Q9AMHDigvL8+GjADgDPn54Y0DUOfQ3gEAAAhm++V7N910k37961/rySefVK9evSRJGzdu1H/+53/q5ptvtjk7AJBUVBTeOAB1Du2dCMv5WFpzjaRCuzM5Tw5JcZKSJEWXPndKzgQptr5kfFJimhTjlhJSpZIjUlwzyeWWVCydyJVc8VJCSym+gZT3vXTysOSMk+q3lqKckvFKMXGSiZFUJDlc1sN3QvKWSNHRkrOx5KovxcRL0bFSkUcqKZB8xZIrUTIOKdopRcdbMUXHpOJ8KSpGimtaOs0jnTwkRUVL8SnWeozPWkeUU3JEWdMkyVsoFR6T5JNi6gXGGp813yHJyJpXlteZvIVW/OnrLi8mVB6nx5QUWD/L215lthUp1SmXc1FT8wZqsmrwurO9KPX888/rT3/6k+644w4Vl47JEhMTo5EjR2rmzJk2ZwcAktLSwhsHoM6pDu2duXPnaubMmcrOztall16q2bNnq0+fPuXGr1u3ThMnTtT27dvVokULTZo0SaNHjw6IWbZsmR566CHt3r1bF198sf7617/qpptuqupdKd8P70vrrrFv+2FnJBWUPk5TXPqQpPxN57H+aEmxsio8DgV+NDCSoqxCTUy8VVyKbWYtUlwgmULJW2x9kHEmWsWwmHqSr0jylUgOYxW3XA2s7fgKJFNibSY6SUq8WEq4wFp/dJwU20iKqW8Vr/J3WwUsb6HkcFhFtph6UmGuVHxEKjpubScmQUpobhXdEi+WElpY6/KelAqPSCV5VtHNES3FJFrbiI6zdq8spvCQVHREKjl5Ko/YJtZPSTrxo5S3WyrIlrwFpcei+antSWffVqRUZr+ro5qaN1CTVaPXncMYYyK6xXLk5+dr9+7dMsbokksuUb169exOqdI8Ho/cbrdyc3OVlJRkdzoAwu3dd6XBgyu+u150tPQ//yMNGBC5vABERDjf5+1q7yxdulQjRozQ3LlzdcUVV2j+/Pl68cUXtWPHDrVs2TIofs+ePerUqZPuuece3Xvvvfrkk080ZswYLVmyREOHDpUkbdiwQX369NGjjz6qm266SW+//bYefvhhffzxx+rZs+dZcwp7+6nWFaSqA5es0T6ckmKkGKf1e3SsFOOSfD6rOBQdL0XXk1RapIqpLyVcKDmcUt4uyXtCikuVki621ndyv2SKpAadpCa9SntCeaWTB6T8fZLTbX0wKsqVCvdLBYesD0zORKn4uOQ7afUWi4qTnElW4Ss+5VShq/Cw9YErpp6VgymWSvKtD1oJF1i7duIHa/3FpR/Iol2St8jqyeVMlKJiraLYie+t9UXFWsv7TlpxsY2sfYyOk2TK31akPtx5T1r7VNF+V8cCT03NG6jJIvS6q+z7vO1jSpXJzs5Wdna22rZtq3r16qma1MoAQGrYUHK5Ko5xuaw4AKiAXe2dWbNmaeTIkRo1apQ6dOig2bNnKzU1VfPmzQsZ//zzz6tly5aaPXu2OnTooFGjRuk3v/mNnnjiCX/M7Nmz1b9/f02ePFnt27fX5MmTdfXVV2v27NkR2acgexbbs91aI+qM32NKf0Zbl+apRCo5IclXeumckaKiSr9Vd0rFx6yeRI44KTrGmu89Yf10OK0vb0ryJYdPqt/S6iF14kerl5KrgbV8/vdWgcjlLv3m3iG5GluXARYfsWKc8VYRzNnQKkip9DXkK5QKDkh531gftFwNpSiXtY4ol/Xc3zvqiPW7ZF224mogRSdYP42vtIPaAauHlK+wtPdAY+vDm6v0p6/Q2tbJ/RVvK1LK9qk65HIuamreQE1WzV53thelDh8+rKuvvlpt27bVoEGDlJ2dLUkaNWoUt0cGUD0UFUklJRXHlJQwphSActnZ3ikqKtLmzZuVkZERMD0jI0Pr168PucyGDRuC4gcMGKBNmzb5Lz8sL6a8dRYWFsrj8QQ8wibnY2nf/wvf+uok3xm/e0sfPusyPZVYz70nS3sLnfTXg+QrsQpQPq91WZ+irSJSwQ9Wz6OYelaPJO8xq5hTkm8Vd3yF0vFvrQ9Axcel4lyrIFXkkYo9pevxWB+YfLIutfMWWJfteU9KiiotfhWWjvuUZ/VscpQzQklMPavXU+FhK6bkuLWugJgEqeiolW/xsdKeYGf0GIiOl0qKrLiybYfaVkle6HnhVrbvMeX0vIxkLueipuYN1GTV8HVne1FqwoQJcjqd2rdvnxISTr0pDBs2TKtWrbIxMwAo9fXXlStKff11ZPIBUOPY2d45dOiQvF6vkpOTA6YnJycrJycn5DI5OTkh40tKSnTo0KEKY8pb57Rp0+R2u/2P1NTUn7pLwYrDWOBCqbKRxHXaT1lFIEn+IpY5fXqU1dNI0dZ0X7H1u1xWzyevtzTOJ0XFly5XaI015ZP1MypBkvfUwLvGZ63XEWWtw8i6lE7Gmnb6xxljrCKSI7qcXXKWDpZebMUYX4gCVoyVh0zpAOgKjil7XpZPQEHvtG2Z0v2oasZX2rPMGXp+JHM5FzU1b6Amq4avO9sHOl+9erXeffddXXjhhQHT27Rpo2+//damrADgNPn5pzXCy2GMFQcAIVSH9o7D4Qh4bowJmna2+DOnn8s6J0+erIkTJ/qfezye8BWmnIzpGX5GVmFKp/2U1WtJkr8Y5Dh9emkhSV7rZ5TT+l2lhaLo6NK4KGvgc0lyxFpFnihZP30nJMWU1sTK1ucr/T3amu4rtDZsfAooCDkc1uDqppwxIE3pHfak0g9lUaWDr5/+4ayktOjkKN0HBceY0i+qyvIJ9T1/WeHLEYE+AI6o0iJbsbX/duZyLmpq3kBNVg1fd7a/wvPz8wO+MSxz6NAhxcZyK1AA1UBlx4piTCkA5bCzvdOkSRNFR0cH9WA6cOBAUE+nMikpKSHjY2Ji1Lhx4wpjyltnbGyskpKSAh5hk/ILqeUd4VtfnXTmmFLRpY+o0jGlYqzn0XHWAOPRcacKUlEx1phMUdFWkUleydlIir/AuqSvJN8aPDy6gdXLKaaeVFQ6eHj9Vta4VM761gDnRbmSK6m00Oi1fhpjpRTbpPTSuROll9T5rEJUdGzp4OuJ1uDjppzezSX51thQsY2tmJj6peNknR5zwhpXxZkoORtY46yUjT9VxltgDfTuanhq26G2FZMYmVusl+17STlfjkUyl3NRU/MGarJq+LqzvSh15ZVX6pVXXvE/dzgc8vl8mjlzpq666iobMwOAUpW9O1YNumsogMiys73jcrnUvXt3ZWVlBUzPyspS7969Qy6Tnp4eFL969Wr16NFDTqezwpjy1lnl0u62Z7u1xpljSpXIP7aUt1jW3fcSZF2ip9JxnnylA+YWWwWc6HjJnJS8JaXFogTrpym2Lt2LqSeZKOn4PusyuoQWkquRVHTMWr7ehdY39EW5pd/kG6t45SuxilzOBlJxgVUUKj5aetlmaWUsKlaKbyYlXmQVrIqOWpfylV3SV3TUmh7bKPCW544oa/veE9ZPR5S1yvhm1t38omKt8VUKD1sf1opKf0bFWtuKS654W5FStk/VIZdzUVPzBmqyava6s/3yvZkzZ6pfv37atGmTioqKNGnSJG3fvl1HjhzRJ598Ynd6ACAdOxbeOAB1jt3tnYkTJ2rEiBHq0aOH0tPT9cILL2jfvn0aPXq0JOvSuh9++MFfOBs9erTmzJmjiRMn6p577tGGDRu0cOFCLVmyxL/OcePG6corr9SMGTM0ZMgQ/fd//7fee+89ffzxx1W+PyFdcLXU9z1p3TX2bL9GipYUK6sK41DgR4PSMaKinFJMvBTXVIptZi1SXGCNBeUttoo4zkQprlnpXemKrCKSo3TMp6bp1nZ8pcs4ZBWfEi+2bjvuKL1MLq6JNc19qZS/Wzp5yLpMz9VQqt+6dJDyXGsA9aLjpwYgj2ssJbQsXV8La1p0nFUsK8mTzAmrwOVqGFiMSrjAKqJFxVh3ACw+bs1zNbR6ZJV9KHM1sO7CV5AtFR60jkXCBae2J519W5FQdhv36pDLuaipeQM1WTV73dlelOrYsaO++OILzZs3T9HR0crPz9fNN9+s++67T82bN7c7PQCQDh4MbxyAOsfu9s6wYcN0+PBhPfLII8rOzlanTp20cuVKtWrVSpKUnZ2tffv2+ePT0tK0cuVKTZgwQc8995xatGihZ555RkOHDvXH9O7dW6+//rr+/Oc/66GHHtLFF1+spUuXqmfPnlW+P+W64GppuLHuxrfmGkk1/a5dDklxkpJkVYMckpySM0GKrW+NqZSYJsW4pYRUqeSIVRxyuSUVSydyJVe8VbSJbyDlfS+dPCw546xCT1TpgLYxcZKJkTX2k8t6+E5YPZ6ioyVnY8lV3yrIRMdad8crKbB6O7kSJeOwLvGLjrdiio5JxflWwSeuaek0j1VoioqW4lOs9RiftY4op1WYKrtcpEEHqfCYJJ9VjDo91visu0KVjcMeHXsqrzLRcVbByFt4alyqMy9FKYuJbVx+HpLVGyrhAmt/vYWht3e2bUVKZfa7OqqpeQM1WTV63TmMOdvovVWnuLhYGRkZmj9/vtq2bWtXGufN4/HI7XYrNzc3vOMjAKgeFi6URo06e9yLL0ojR1Z9PgAi6nzf52tLeyfcaD8BAFB7VfZ93tYxpZxOp/79739XeOcXALBdYmJ44wDUKbR3AAAAQrN9oPM777xTCxcutDsNAChfSTl38fmpcQDqHNo7AAAAwWwfU6qoqEgvvviisrKy1KNHD9U74+5Vs2bNsikzACj1ww/hjQNQ59DeAQAACGZ7Uerf//63unXrJkn68ssvA+bRzR1AteD1hjcOQJ1DewcAACCYbUWpb775RmlpaVq7dm3Y1z137lzNnDlT2dnZuvTSSzV79mz16dMnZOzy5cs1b948bd26VYWFhbr00kuVmZmpAQMGhD0vADVUUVF44wDUGVXZ3gEAAKjpbBtTqk2bNjp42u3Thw0bpv3795/3epcuXarx48frwQcf1JYtW9SnTx9de+21Abc5Pt2HH36o/v37a+XKldq8ebOuuuoqXX/99dqyZct55wKglmjcOLxxAOqMqmrvAAAA1Aa2FaWMMQHPV65cqfz8/PNe76xZszRy5EiNGjVKHTp00OzZs5Wamqp58+aFjJ89e7YmTZqkyy67TG3atNHUqVPVpk0b/f3vfz/vXADUEpX93xSG/2EAapeqau8AAADUBrbffS+cioqKtHnzZmVkZARMz8jI0Pr16yu1Dp/Pp7y8PDVq1KjcmMLCQnk8noAHgFosJye8cQAAAAAA+4pSDocjaGDP8x3o89ChQ/J6vUpOTg6YnpycrJxKflh88sknlZ+fr1tuuaXcmGnTpsntdvsfqamp55U3gGru8OHwxgGoM6qivQMAAFBb2DbQuTFGd999t2JjYyVJJ0+e1OjRo4Nukbx8+fJzXveZjT1jTKUagEuWLFFmZqb++7//W82aNSs3bvLkyZo4caL/ucfjoTAF1GYuV3jjANQZVdneAQAAqOlsK0rdddddAc/vuOOO815nkyZNFB0dHdQr6sCBA0G9p860dOlSjRw5Um+++aauueaaCmNjY2P9jUsAdUBiYnjjANQZVdHeAQAAqC1sK0otWrQo7Ot0uVzq3r27srKydNNNN/mnZ2VlaciQIeUut2TJEv3mN7/RkiVLNHjw4LDnBaCG83rDGwegzqiK9g4AAEBtYVtRqqpMnDhRI0aMUI8ePZSenq4XXnhB+/bt0+jRoyVZl9798MMPeuWVVyRZBak777xTTz/9tHr16uXvZRUfHy+3223bfgAAAAAAANRmta4oNWzYMB0+fFiPPPKIsrOz1alTJ61cuVKtWrWSJGVnZ2vfvn3++Pnz56ukpET33Xef7rvvPv/0u+66S4sXL450+gCqI6czvHEAAAAAgNpXlJKkMWPGaMyYMSHnnVlo+uCDD6o+IQAAAAAAAASIsjsBAKj2jh8PbxwAAAAAgKIUAJxVVCX/VVY2DgAAAABgz+V7K1asqHTsDTfcUIWZAAAAVA3aOwAAABWzpSh14403VirO4XDIyy3WAditfv3wxgGoE2jvAAAAVMyWopTP57NjswDw02RnhzcOQJ1AewcAAKBiDIACAGdTVBTeOAAAAACAPT2lzpSfn69169Zp3759KjrjQ93YsWNtygoASh07Ft44AHUS7R0AAIBAtheltmzZokGDBunEiRPKz89Xo0aNdOjQISUkJKhZs2Y00gDYLykpvHEA6hzaOwAAAMFsv3xvwoQJuv7663XkyBHFx8dr48aN+vbbb9W9e3c98cQTdqcHAJLLFd44AHUO7R0AAIBgtheltm7dqj/+8Y+Kjo5WdHS0CgsLlZqaqscff1z/9V//ZXd6AEBRCsB5o70DAAAQzPailNPplMPhkCQlJydr3759kiS32+3/HQBs5XSGNw5AnUN7BwAAIJjtY0p17dpVmzZtUtu2bXXVVVfp4Ycf1qFDh/Tqq6+qc+fOdqcHANLx4+GNA1Dn0N4BAAAIZntPqalTp6p58+aSpEcffVSNGzfW7373Ox04cEAvvPCCzdkBgCSvN7xxAOoc2jsAAADBbO8p1aNHD//vTZs21cqVK23MBgBCKCkJbxyAOof2DgAAQDDbe0oBQLUXU8n6fWXjAAAAAAD295RKS0vzD/wZyjfffBPBbAAghPj48MYBqHNo7wAAAASzvSg1fvz4gOfFxcXasmWLVq1apf/8z/+0JykAOF1+fnjjANQ5tHcAAACC2V6UGjduXMjpzz33nDZt2hThbAAghOLi8MYBqHNo7wAAAASrtmNKXXvttVq2bJndaQCAdPx4eOMAoBTtHQAAUJdV26LUW2+9pUaNGtmdBgBILld44wCgFO0dAABQl9l++V7Xrl0DBv40xignJ0cHDx7U3LlzbcwMAEoVFIQ3DkCdQ3sHAAAgmO1FqSFDhgQ00qKiotS0aVP169dP7du3tzEzACiVkBDeOAB1Du0dAACAYLYXpTIzM+1OAQAq5vOFNw5AnUN7BwAAIJjtY0pFR0frwIEDQdMPHz6s6OhoGzICgDMwphSA80R7BwAAIJjtRSljTMjphYWFcvEBD0B18N134Y0DUOfQ3gEAAAhm2+V7zzzzjCTJ4XDoxRdfVP369f3zvF6vPvzwQ8ZYAFA9eL3hjQNQZ9DeAQAAKJ9tRamnnnpKkvXN4fPPPx/Qdd3lcql169Z6/vnn7UoPAE6pVy+8cQDqDNo7AAAA5bOtKLVnzx5J0lVXXaXly5erYcOGdqUCABVr0CC8cQDqDNo7AAAA5bP97ntr1661OwUAqFhRUXjjANQ5tHcAAACC2T7Q+a9+9StNnz49aPrMmTP1H//xHzZkBABnKCwMbxyAOof2DgAAQDDbi1Lr1q3T4MGDg6YPHDhQH374oQ0ZAcAZEhLCGwegzqG9AwAAEMz2otTx48dD3grZ6XTK4/HYkBEAnMHnC28cgDqH9g4AAEAw24tSnTp10tKlS4Omv/766+rYsaMNGQHAGY4cCW8cgDqH9g4AAEAw2wc6f+ihhzR06FDt3r1bv/zlLyVJ77//vpYsWaI333zT5uwAQFJubnjjANQ5tHcAAACC2V6UuuGGG/TOO+9o6tSpeuuttxQfH68uXbrovffeU9++fe1ODwCk4uLwxgGoc2jvAAAABHMYY4zdSZRn69at+vnPf253Gmfl8XjkdruVm5urpKQku9MBEG4pKdL+/WePS06WcnKqPh8AEVXV7/M1pb0TbrSfAACovSr7Pm/7mFJnys3N1dy5c9WtWzd1797d7nQAAADCjvYOAABANSpKrVmzRrfffruaN2+uZ599VoMGDdKmTZvsTgsApBB3zDqvOAB1Fu0dAACAU2wdU+r777/X4sWL9dJLLyk/P1+33HKLiouLtWzZMu5EA6D6KCkJbxyAOoX2DgAAQGi29ZQaNGiQOnbsqB07dujZZ5/Vjz/+qGeffdaudACgfF5veOMA1Bm0dwAAAMpnW0+p1atXa+zYsfrd736nNm3a2JUGAJxdUVF44wDUGbR3AAAAymdbT6mPPvpIeXl56tGjh3r27Kk5c+bo4MGDdqUDAAAQdrR3AAAAymdbUSo9PV0LFixQdna27r33Xr3++uu64IIL5PP5lJWVpby8PLtSA4BAXL4H4CeivQMAAFA+hzHG2J1EmV27dmnhwoV69dVXdezYMfXv318rVqywO62z8ng8crvdys3NVVJSkt3pAAi3Zs2kyvRsaNpUOnCg6vMBEFHhfp+vqe2dcKP9BABA7VXZ93nbekqF0q5dOz3++OP6/vvvtWTJErvTAQAACDvaOwAAAJZq1VOqpuKbPqCWS0mR9u8/e1xyspSTU/X5AIgo3uerBscVAIDaq0b2lAKAaqm4OLxxAAAAAACKUgBwVpXtUErHUwAAAACoNIpSAHA29JQCAAAAgLCjKAUAZxMTE944AAAAAABFKQA4K683vHEAEEFHjx7ViBEj5Ha75Xa7NWLECB07dqzCZYwxyszMVIsWLRQfH69+/fpp+/bt/vlHjhzRH/7wB7Vr104JCQlq2bKlxo4dq9zc3CreGwAAUJtQlAKAs4mq5L/KysYBQAQNHz5cW7du1apVq7Rq1Spt3bpVI0aMqHCZxx9/XLNmzdKcOXP0z3/+UykpKerfv7/y8vIkST/++KN+/PFHPfHEE9q2bZsWL16sVatWaeTIkZHYJQAAUEs4jGFk3vPFLY2BWi4pSSr9IFahxETJ46n6fABEVE1+n9+5c6c6duyojRs3qmfPnpKkjRs3Kj09Xf/3f/+ndu3aBS1jjFGLFi00fvx43X///ZKkwsJCJScna8aMGbr33ntDbuvNN9/UHXfcofz8fMWEuJy5sLBQhYWF/ucej0epqak18rgCAICKVbb9xNf6AAAAtdSGDRvkdrv9BSlJ6tWrl9xut9avXx9ymT179ignJ0cZGRn+abGxserbt2+5y0jyNzpDFaQkadq0af5LCN1ut1JTU3/iXgEAgNqCohQAnM2JE+GNA4AIycnJUbNmzYKmN2vWTDk5OeUuI0nJyckB05OTk8td5vDhw3r00UfL7UUlSZMnT1Zubq7/8d1331V2NwAAQC1FUQoAzsbhCG8cAJynzMxMORyOCh+bNm2SJDlC/G8yxoScfroz55e3jMfj0eDBg9WxY0dNmTKl3PXFxsYqKSkp4AEAAOo27l8OAGfDQOcAqpnf//73uvXWWyuMad26tb744gvt378/aN7BgweDekKVSUlJkWT1mGrevLl/+oEDB4KWycvL08CBA1W/fn29/fbbcjqd57orAACgDqMoBQBnU1QU3jgAOE9NmjRRkyZNzhqXnp6u3NxcffbZZ7r88sslSZ9++qlyc3PVu3fvkMukpaUpJSVFWVlZ6tq1qySpqKhI69at04wZM/xxHo9HAwYMUGxsrFasWKG4uLgw7BkAAKhL+FofAACglurQoYMGDhyoe+65Rxs3btTGjRt1zz336Lrrrgu481779u319ttvS7Iu2xs/frymTp2qt99+W//+97919913KyEhQcOHD5dk9ZDKyMhQfn6+Fi5cKI/Ho5ycHOXk5Mjr9dqyrwAAoOahpxQAAEAt9re//U1jx471303vhhtu0Jw5cwJidu3apdzcXP/zSZMmqaCgQGPGjNHRo0fVs2dPrV69WomJiZKkzZs369NPP5UkXXLJJQHr2rNnj1q3bl2FewQAAGoLhzHG2J1ETefxeOR2u/23QgZQy5zLAOb8SwVqHd7nqwbHFQCA2quy7/NcvgcAAAAAAICIoygFAAAAAACAiKMoBQAAAAAAgIijKAUAAAAAAICIoygFAAAAAACAiKMoBQAAAAAAgIijKAUAAAAAAICIoygFAAAAAACAiKMoBQAAAAAAgIijKAUAAAAAAICIoygFAAAAAACAiKMoBQAAAAAAgIijKAUAAAAAAICIoygFAAAAAACAiKMoBQAAAAAAgIirlUWpuXPnKi0tTXFxcerevbs++uijcmOzs7M1fPhwtWvXTlFRURo/fnzkEgUAAAAAAKijal1RaunSpRo/frwefPBBbdmyRX369NG1116rffv2hYwvLCxU06ZN9eCDD+pnP/tZhLMFAAAAAACom2pdUWrWrFkaOXKkRo0apQ4dOmj27NlKTU3VvHnzQsa3bt1aTz/9tO6880653e5KbaOwsFAejyfgAQAAAAAAgMqrVUWpoqIibd68WRkZGQHTMzIytH79+rBtZ9q0aXK73f5Hampq2NYNAAAAAABQF9SqotShQ4fk9XqVnJwcMD05OVk5OTlh287kyZOVm5vrf3z33XdhWzcAAAAAAEBdEGN3AlXB4XAEPDfGBE07H7GxsYqNjQ3b+gAAAAAAAOqaWtVTqkmTJoqOjg7qFXXgwIGg3lMAAAAAAACwT60qSrlcLnXv3l1ZWVkB07OystS7d2+bsgIAAAAAAMCZat3lexMnTtSIESPUo0cPpaen64UXXtC+ffs0evRoSdZ4UD/88INeeeUV/zJbt26VJB0/flwHDx7U1q1b5XK51LFjRzt2AQAAAAAAoNardUWpYcOG6fDhw3rkkUeUnZ2tTp06aeXKlWrVqpUkKTs7W/v27QtYpmvXrv7fN2/erNdee02tWrXS3r17I5k6AAAAAABAneEwxhi7k6jpPB6P3G63cnNzlZSUZHc6AMLtXG6UwL9UoNbhfb5qcFwBAKi9Kvs+X6vGlAIAAAAAAEDNQFEKAAAAAAAAEUdRCgAAAAAAABFHUQoAAAAAAAARR1EKAAAAAAAAEUdRCgAAAAAAABFHUQoAAAAAAAARR1EKAAAAAAAAEUdRCgAAAAAAABFHUQoAAAAAAAARR1EKAAAAAAAAEUdRCgAAAAAAABFHUQoAAAAAAAARR1EKAAAAAAAAEUdRCgAAAAAAABFHUQoAAAAAAAARR1EKAAAAAAAAEUdRCgAAAAAAABFHUQoAAAAAAAARR1EKAAAAAAAAEUdRCgAAAAAAABFHUQoAAAAAAAARR1EKAAAAAAAAEUdRCgAAAAAAABFHUQoAAAAAAAARR1EKAAAAAAAAEUdRCgAAAAAAABFHUQoAAAAAAAARR1EKAAAAAAAAEUdRCgAAAAAAABFHUQoAAAAAAAARR1EKAAAAAAAAEUdRCgAAAAAAABFHUQoAAAAAAAARR1EKAAAAAAAAEUdRCgAAAAAAABFHUQoAAAAAAAARR1EKAAAAAAAAEUdRCgAAoBY7evSoRowYIbfbLbfbrREjRujYsWMVLmOMUWZmplq0aKH4+Hj169dP27dvLzf22muvlcPh0DvvvBP+HQAAALUWRSkAAIBabPjw4dq6datWrVqlVatWaevWrRoxYkSFyzz++OOaNWuW5syZo3/+859KSUlR//79lZeXFxQ7e/ZsORyOqkofAADUYjF2JwAAAICqsXPnTq1atUobN25Uz549JUkLFixQenq6du3apXbt2gUtY4zR7Nmz9eCDD+rmm2+WJL388stKTk7Wa6+9pnvvvdcf+/nnn2vWrFn65z//qebNm1eYS2FhoQoLC/3PPR5POHYRAADUYPSUAgAAqKU2bNggt9vtL0hJUq9eveR2u7V+/fqQy+zZs0c5OTnKyMjwT4uNjVXfvn0Dljlx4oRuu+02zZkzRykpKWfNZdq0af5LCN1ut1JTU89jzwAAQG1AUQoAAKCWysnJUbNmzYKmN2vWTDk5OeUuI0nJyckB05OTkwOWmTBhgnr37q0hQ4ZUKpfJkycrNzfX//juu+8quxsAAKCWoigFAABQw2RmZsrhcFT42LRpkySFHO/JGHPWcaDOnH/6MitWrNCaNWs0e/bsSuccGxurpKSkgAcAAKjbGFMKAACghvn973+vW2+9tcKY1q1b64svvtD+/fuD5h08eDCoJ1SZskvxcnJyAsaJOnDggH+ZNWvWaPfu3WrQoEHAskOHDlWfPn30wQcfnMPeAACAuoqiFAAAQA3TpEkTNWnS5Kxx6enpys3N1WeffabLL79ckvTpp58qNzdXvXv3DrlMWlqaUlJSlJWVpa5du0qSioqKtG7dOs2YMUOS9MADD2jUqFEBy3Xu3FlPPfWUrr/++vPZNQAAUIdQlAIAAKilOnTooIEDB+qee+7R/PnzJUm//e1vdd111wXcea99+/aaNm2abrrpJjkcDo0fP15Tp05VmzZt1KZNG02dOlUJCQkaPny4JKs3VajBzVu2bKm0tLTI7BwAAKjxKEoBAADUYn/72980duxY/930brjhBs2ZMycgZteuXcrNzfU/nzRpkgoKCjRmzBgdPXpUPXv21OrVq5WYmBjR3AEAQO3mMMYYu5Oo6Twej9xut3Jzcxm0E6iNzjIYcAD+pQK1Du/zVYPjCgBA7VXZ93nuvgcAAAAAAICIoygFAAAAAACAiKMoBQAAAAAAgIijKAUAAAAAAICIoygFAAAAAACAiKMoBQAAAAAAgIijKAUAAAAAAICIoygFAAAAAACAiKMoBQAAAAAAgIijKAUAAAAAAICIoygFAAAAAACAiKMoBQAAAAAAgIijKAUAAAAAAICIoygFAAAAAACAiKMoBQAAAAAAgIijKAUAAAAAAICIoygFAAAAAACAiKMoBQAAAAAAgIijKAUAAAAAAICIoygFAAAAAACAiKMoBQAAAAAAgIijKAUAAAAAAICIoygFAAAAAACAiKMoBQAAAAAAgIijKAUAAAAAAICIoygFAAAAAACAiKuVRam5c+cqLS1NcXFx6t69uz766KMK49etW6fu3bsrLi5OF110kZ5//vkIZQoAAAAAAFA31bqi1NKlSzV+/Hg9+OCD2rJli/r06aNrr71W+/btCxm/Z88eDRo0SH369NGWLVv0X//1Xxo7dqyWLVsW4cwBAAAAAADqDocxxtidRDj17NlT3bp107x58/zTOnTooBtvvFHTpk0Lir///vu1YsUK7dy50z9t9OjR+vzzz7Vhw4ZKbdPj8cjtdis3N1dJSUnnvxMAqheHo/KxtetfKgDxPl9VOK4AANRelX2fr1U9pYqKirR582ZlZGQETM/IyND69etDLrNhw4ag+AEDBmjTpk0qLi4OuUxhYaE8Hk/AAwAAAAAAAJVXq4pShw4dktfrVXJycsD05ORk5eTkhFwmJycnZHxJSYkOHToUcplp06bJ7Xb7H6mpqeHZAQAAAAAAgDqiVhWlyjjOuNTGGBM07WzxoaaXmTx5snJzc/2P77777jwzBgAAAAAAqFti7E4gnJo0aaLo6OigXlEHDhwI6g1VJiUlJWR8TEyMGjduHHKZ2NhYxcbGhidpANWfMZUbV4rxpAAAAACg0mpVTymXy6Xu3bsrKysrYHpWVpZ69+4dcpn09PSg+NWrV6tHjx5yOp1VlisAAAAAAEBdVquKUpI0ceJEvfjii3rppZe0c+dOTZgwQfv27dPo0aMlWZfe3Xnnnf740aNH69tvv9XEiRO1c+dOvfTSS1q4cKH+9Kc/2bULAKqjs/WCopcUAAAAAJyTWnX5niQNGzZMhw8f1iOPPKLs7Gx16tRJK1euVKtWrSRJ2dnZ2rdvnz8+LS1NK1eu1IQJE/Tcc8+pRYsWeuaZZzR06FC7dgFAdVVWeDr9Uj6KUQAAAADwkziM4RPV+fJ4PHK73crNzVVSUpLd6QAAgDDifb5qcFwBAKi9Kvs+X+su3wMAAAAAAED1R1EKAAAAAAAAEUdRCgAAAAAAABFHUQoAAAAAAAARR1EKAAAAAAAAEUdRCgAAAAAAABFHUQoAAAAAAAARR1EKAAAAAAAAEUdRCgAAAAAAABFHUQoAAAAAAAARR1EKAAAAAAAAERdjdwK1gTFGkuTxeGzOBAAAhFvZ+3vZ+z3Cg/YTAAC1V2XbTxSlwiAvL0+SlJqaanMmAACgquTl5cntdtudRq1B+wkAgNrvbO0nh+Frv/Pm8/n0448/KjExUQ6Hw+50qgWPx6PU1FR99913SkpKsjudWo/jHVkc78jieEcWxzuYMUZ5eXlq0aKFoqIY+SBcqrL9xN9x9cB5sB/nwH6cA/txDuxR2fYTPaXCICoqShdeeKHdaVRLSUlJvPAjiOMdWRzvyOJ4RxbHOxA9pMIvEu0n/o6rB86D/TgH9uMc2I9zEHmVaT/xdR8AAAAAAAAijqIUAAAAAAAAIo6iFKpEbGyspkyZotjYWLtTqRM43pHF8Y4sjndkcbxRG/B3XD1wHuzHObAf58B+nIPqjYHOAQAAAAAAEHH0lAIAAAAAAEDEUZQCAAAAAABAxFGUAgAAAAAAQMRRlAIAAAAAAEDEUZTCT3L06FGNGDFCbrdbbrdbI0aM0LFjxypcxhijzMxMtWjRQvHx8erXr5+2b99ebuy1114rh8Ohd955J/w7UMNUxfE+cuSI/vCHP6hdu3ZKSEhQy5YtNXbsWOXm5lbx3lQ/c+fOVVpamuLi4tS9e3d99NFHFcavW7dO3bt3V1xcnC666CI9//zzQTHLli1Tx44dFRsbq44dO+rtt9+uqvRrnHAf7wULFqhPnz5q2LChGjZsqGuuuUafffZZVe5CjVIVf99lXn/9dTkcDt14441hzhoIxv9q+4X7HCxevFgOhyPocfLkyarcjRrtXM5Bdna2hg8frnbt2ikqKkrjx48PGcfr4NyE+xzwOjh353IOli9frv79+6tp06ZKSkpSenq63n333aA4Xgc2MsBPMHDgQNOpUyezfv16s379etOpUydz3XXXVbjM9OnTTWJiolm2bJnZtm2bGTZsmGnevLnxeDxBsbNmzTLXXnutkWTefvvtKtqLmqMqjve2bdvMzTffbFasWGG+/vpr8/7775s2bdqYoUOHRmKXqo3XX3/dOJ1Os2DBArNjxw4zbtw4U69ePfPtt9+GjP/mm29MQkKCGTdunNmxY4dZsGCBcTqd5q233vLHrF+/3kRHR5upU6eanTt3mqlTp5qYmBizcePGSO1WtVUVx3v48OHmueeeM1u2bDE7d+40v/71r43b7Tbff/99pHar2qqK411m79695oILLjB9+vQxQ4YMqeI9QV3H/2r7VcU5WLRokUlKSjLZ2dkBD4R2rudgz549ZuzYsebll182P//5z824ceOCYngdnJuqOAe8Ds7NuZ6DcePGmRkzZpjPPvvMfPnll2by5MnG6XSaf/3rX/4YXgf2oiiFc7Zjxw4jKeBFumHDBiPJ/N///V/IZXw+n0lJSTHTp0/3Tzt58qRxu93m+eefD4jdunWrufDCC012djZFKVP1x/t0b7zxhnG5XKa4uDh8O1DNXX755Wb06NEB09q3b28eeOCBkPGTJk0y7du3D5h27733ml69evmf33LLLWbgwIEBMQMGDDC33nprmLKuuarieJ+ppKTEJCYmmpdffvn8E67hqup4l5SUmCuuuMK8+OKL5q677qIohSrH/2r7VcU5WLRokXG73WHPtbY613Nwur59+4YsiPA6ODdVcQ54HZyb8zkHZTp27Gj+8pe/+J/zOrAXl+/hnG3YsEFut1s9e/b0T+vVq5fcbrfWr18fcpk9e/YoJydHGRkZ/mmxsbHq27dvwDInTpzQbbfdpjlz5iglJaXqdqIGqcrjfabc3FwlJSUpJiYmfDtQjRUVFWnz5s0Bx0mSMjIyyj1OGzZsCIofMGCANm3apOLi4gpjKjr2dUFVHe8znThxQsXFxWrUqFF4Eq+hqvJ4P/LII2ratKlGjhwZ/sSBM/C/2n5V+f/k+PHjatWqlS688EJdd9112rJlS/h3oBb4KeegMngdVF5VnQOJ10FlheMc+Hw+5eXlBbQTeR3Yi6IUzllOTo6aNWsWNL1Zs2bKyckpdxlJSk5ODpienJwcsMyECRPUu3dvDRkyJIwZ12xVebxPd/jwYT366KO69957zzPjmuPQoUPyer3ndJxycnJCxpeUlOjQoUMVxpS3zrqiqo73mR544AFdcMEFuuaaa8KTeA1VVcf7k08+0cKFC7VgwYKqSRw4A/+r7VdV56B9+/ZavHixVqxYoSVLliguLk5XXHGFvvrqq6rZkRrsp5yDyuB1UHlVdQ54HVReOM7Bk08+qfz8fN1yyy3+abwO7EVRCn6ZmZkhB9k7/bFp0yZJksPhCFreGBNy+unOnH/6MitWrNCaNWs0e/bs8OxQNWf38T6dx+PR4MGD1bFjR02ZMuU89qpmquxxqij+zOnnus66pCqOd5nHH39cS5Ys0fLlyxUXFxeGbGu+cB7vvLw83XHHHVqwYIGaNGkS/mSBCvC/2n7hPge9evXSHXfcoZ/97Gfq06eP3njjDbVt21bPPvtsmDOvParib5bXwbkJ9/HidXDufuo5WLJkiTIzM7V06dKgL/15Hdinblyjg0r5/e9/r1tvvbXCmNatW+uLL77Q/v37g+YdPHgwqMJcpuxSvJycHDVv3tw//cCBA/5l1qxZo927d6tBgwYByw4dOlR9+vTRBx98cA57U/3ZfbzL5OXlaeDAgapfv77efvttOZ3Oc92VGqtJkyaKjo4O+hYk1HEqk5KSEjI+JiZGjRs3rjCmvHXWFVV1vMs88cQTmjp1qt577z116dIlvMnXQFVxvLdv3669e/fq+uuv98/3+XySpJiYGO3atUsXX3xxmPcEdR3/q+1X1f+/y0RFRemyyy6jh0gIP+UcVAavg8qrqnNwJl4H5Tufc7B06VKNHDlSb775ZlBvel4H9qKnFPyaNGmi9u3bV/iIi4tTenq6cnNzA265/umnnyo3N1e9e/cOue60tDSlpKQoKyvLP62oqEjr1q3zL/PAAw/oiy++0NatW/0PSXrqqae0aNGiqttxm9h9vCWrh1RGRoZcLpdWrFhR53qWuFwude/ePeA4SVJWVla5xzY9PT0ofvXq1erRo4e/oFdeTHnrrCuq6nhL0syZM/Xoo49q1apV6tGjR/iTr4Gq4ni3b99e27ZtC/g/fcMNN+iqq67S1q1blZqaWmX7g7qL/9X2q8r/36czxmjr1q0BX6jB8lPOQWXwOqi8qjoHZ+J1UL6feg6WLFmiu+++W6+99poGDx4cNJ/Xgc0iOKg6apGBAweaLl26mA0bNpgNGzaYzp07m+uuuy4gpl27dmb58uX+59OnTzdut9ssX77cbNu2zdx2222mefPmxuPxlLsdcfc9Y0zVHG+Px2N69uxpOnfubL7++uuAW9CWlJREdP/sVHZb2YULF5odO3aY8ePHm3r16pm9e/caY4x54IEHzIgRI/zxZbe4njBhgtmxY4dZuHBh0C2uP/nkExMdHW2mT59udu7caaZPn85tZUtVxfGeMWOGcblc5q233gr4O87Ly4v4/lU3VXG8z8Td9xAJ/K+2X1Wcg8zMTLNq1Sqze/dus2XLFvPrX//axMTEmE8//TTi+1cTnOs5MMaYLVu2mC1btpju3bub4cOHmy1btpjt27f75/M6ODdVcQ54HZybcz0Hr732momJiTHPPfdcQDvx2LFj/hheB/aiKIWf5PDhw+b22283iYmJJjEx0dx+++3m6NGjATGSzKJFi/zPfT6fmTJliklJSTGxsbHmyiuvNNu2batwOxSlLFVxvNeuXWskhXzs2bMnMjtWTTz33HOmVatWxuVymW7dupl169b55911112mb9++AfEffPCB6dq1q3G5XKZ169Zm3rx5Qet88803Tbt27YzT6TTt27c3y5Ytq+rdqDHCfbxbtWoV8u94ypQpEdib6q8q/r5PR1EKkcL/avuF+xyMHz/etGzZ0rhcLtO0aVOTkZFh1q9fH4ldqbHO9RyEen9s1apVQAyvg3MT7nPA6+Dcncs56Nu3b8hzcNdddwWsk9eBfRzGlI44CAAAAAAAAEQIY0oBAAAAAAAg4ihKAQAAAAAAIOIoSgEAAAAAACDiKEoBAAAAAAAg4ihKAQAAAAAAIOIoSgEAAAAAACDiKEoBAAAAAAAg4ihKAQAAAAAAIOIoSgGIuMzMTP385z/3P7/77rt14403RjyPvXv3yuFwaOvWrRHfdk2wePFiNWjQwO40AABAKdpQNQNtKKDyKEoBkGQ1ahwOhxwOh5xOpy666CL96U9/Un5+fpVv++mnn9bixYsrFRvpRlC/fv38x+X0R0lJSUS2b6dhw4bpyy+/tDsNAACqNdpQodGGog0FVEaM3QkAqD4GDhyoRYsWqbi4WB999JFGjRql/Px8zZs3Lyi2uLhYTqczLNt1u91hWU9Vueeee/TII48ETIuJCf73WVRUJJfLFam0qlx8fLzi4+PtTgMAgGqPNlRotKEAnA09pQD4xcbGKiUlRampqRo+fLhuv/12vfPOO5JOdRd/6aWXdNFFFyk2NlbGGOXm5uq3v/2tmjVrpqSkJP3yl7/U559/HrDe6dOnKzk5WYmJiRo5cqROnjwZMP/Mruc+n08zZszQJZdcotjYWLVs2VJ//etfJUlpaWmSpK5du8rhcKhfv37+5RYtWqQOHTooLi5O7du319y5cwO289lnn6lr166Ki4tTjx49tGXLlkodl4SEBKWkpAQ8JKl169Z67LHHdPfdd8vtduuee+6RJK1fv15XXnml4uPjlZqaqrFjxwZ8W3rgwAFdf/31io+PV1pamv72t7+pdevWmj17tqTQ32QeO3ZMDodDH3zwgX/ajh07NGjQINWvX1/JyckaMWKEDh065J/fr18/jR07VpMmTVKjRo2UkpKizMzMgH07duyYfvvb3yo5OVlxcXHq1KmT/vGPf0gK3fX873//u7p37664uDhddNFF+stf/hLwjWdmZqZatmyp2NhYtWjRQmPHjq3UMQYAoCajDRUabahTaEMBoVGUAlCu+Ph4FRcX+59//fXXeuONN7Rs2TL/m/3gwYOVk5OjlStXavPmzerWrZuuvvpqHTlyRJL0xhtvaMqUKfrrX/+qTZs2qXnz5kENnTNNnjxZM2bM0EMPPaQdO3botddeU3JysiSrUSRJ7733nrKzs7V8+XJJ0oIFC/Tggw/qr3/9q3bu3KmpU6fqoYce0ssvvyxJys/P13XXXad27dpp8+bNyszM1J/+9KfzPkYzZ85Up06dtHnzZj300EPatm2bBgwYoJtvvllffPGFli5dqo8//li///3v/cvcfffd2rt3r9asWaO33npLc+fO1YEDB85pu9nZ2erbt69+/vOfa9OmTVq1apX279+vW265JSDu5ZdfVr169fTpp5/q8ccf1yOPPKKsrCxJVsP12muv1fr16/X//t//044dOzR9+nRFR0eH3Oa7776rO+64Q2PHjtWOHTs0f/58LV682N/Yfeutt/TUU09p/vz5+uqrr/TOO++oc+fO57RfAADUBrShzo42FG0oQJJkAMAYc9ddd5khQ4b4n3/66aemcePG5pZbbjHGGDNlyhTjdDrNgQMH/DHvv/++SUpKMidPngxY18UXX2zmz59vjDEmPT3djB49OmB+z549zc9+9rOQ2/Z4PCY2NtYsWLAgZJ579uwxksyWLVsCpqempprXXnstYNqjjz5q0tPTjTHGzJ8/3zRq1Mjk5+f758+bNy/kuk7Xt29f43Q6Tb169fyPiRMnGmOMadWqlbnxxhsD4keMGGF++9vfBkz76KOPTFRUlCkoKDC7du0ykszGjRv983fu3GkkmaeeeqrcfTx69KiRZNauXWuMMeahhx4yGRkZAdv57rvvjCSza9cuf+6/+MUvAmIuu+wyc//99xtjjHn33XdNVFSUP/5MixYtMm632/+8T58+ZurUqQExr776qmnevLkxxpgnn3zStG3b1hQVFYVcHwAAtRFtqNBoQ7n9z2lDAeVjTCkAfv/4xz9Uv359lZSUqLi4WEOGDNGzzz7rn9+qVSs1bdrU/3zz5s06fvy4GjduHLCegoIC7d69W5K0c+dOjR49OmB+enq61q5dGzKHnTt3qrCwUFdffXWl8z548KC+++47jRw50t/9W5JKSkr8Yy3s3LlTP/vZz5SQkBCQR2XcfvvtevDBB/3PT++O3aNHj4DYzZs36+uvv9bf/vY3/zRjjHw+n/bs2aMvv/xSMTExAcu1b9/+nO/QsnnzZq1du1b169cPmrd79261bdtWktSlS5eAec2bN/d/o7h161ZdeOGF/tjKbPOf//yn/1s9SfJ6vTp58qROnDih//iP/9Ds2bN10UUXaeDAgRo0aJCuv/76kGNHAABQm9CGCo021Klt0oYCQuOvHIDfVVddpXnz5snpdKpFixZBg3DWq1cv4LnP51Pz5s0DrtEv81Nvg/tTBoX0+XySrO7nPXv2DJhX1o3aGPOT8pGsQUQvueSSkPNCHZN777035DgALVu21K5duyRJDoej3O1FRVlXVp+e8+mXAJRt5/rrr9eMGTOClm/evLn/9zPPocPh8B+vcz3WPp9Pf/nLX3TzzTcHzYuLi1Nqaqp27dqlrKwsvffeexozZoxmzpypdevWhW1AVwAAqiPaUKHRhjq1TdpQQGgUpQD41atXr9yGQyjdunVTTk6OYmJi1Lp165AxHTp00MaNG3XnnXf6p23cuLHcdbZp00bx8fF6//33NWrUqKD5ZXdm8Xq9/mnJycm64IIL9M033+j2228Pud6OHTvq1VdfVUFBgb8hUVEeP1W3bt20ffv2co9jhw4dVFJSok2bNunyyy+XJO3atUvHjh3zx5R9k5qdna2uXbtKUtDtm7t166Zly5apdevWP/lbtC5duuj777/Xl19+Walv+rp166Zdu3ZV+DcSHx+vG264QTfccIPuu+8+tW/fXtu2bVO3bt1+Uo4AANQEtKHOH20o2lComxjoHMBPds011yg9PV033nij3n33Xe3du1fr16/Xn//8Z23atEmSNG7cOL300kt66aWX9OWXX2rKlCnavn17ueuMi4vT/fffr0mTJumVV17R7t27tXHjRi1cuFCS1KxZM8XHx/sHpczNzZVk3bFk2rRpevrpp/Xll19q27ZtWrRokWbNmiVJGj58uKKiojRy5Ejt2LFDK1eu1BNPPBH2Y3L//fdrw4YNuu+++7R161Z99dVXWrFihf7whz9Iktq1a6eBAwfqnnvu0aeffqrNmzdr1KhRAd+4xcfHq1evXpo+fbp27NihDz/8UH/+858DtnPffffpyJEjuu222/TZZ5/pm2++0erVq/Wb3/wmoLFZkb59++rKK6/U0KFDlZWVpT179uh///d/tWrVqpDxDz/8sF555RVlZmZq+/bt2rlzp5YuXerPbfHixVq4cKH+/e9/65tvvtGrr76q+Ph4tWrV6qccSgAAai3aUMFoQ9GGQt1EUQrAT+ZwOLRy5UpdeeWV+s1vfqO2bdvq1ltv1d69e/13ehk2bJgefvhh3X///erevbu+/fZb/e53v6twvQ899JD++Mc/6uGHH1aHDh00bNgw/zX8MTExeuaZZzR//ny1aNFCQ4YMkSSNGjVKL774ohYvXqzOnTurb9++Wrx4sf/2x/Xr19ff//537dixQ127dtWDDz4Ystv2+erSpYvWrVunr776Sn369FHXrl310EMPBXQHX7RokVJTU9W3b1/dfPPN/ttBn+6ll15ScXGxevTooXHjxumxxx4LmN+iRQt98skn8nq9GjBggDp16qRx48bJ7Xb7u65XxrJly3TZZZfptttuU8eOHTVp0qRyG2QDBgzQP/7xD2VlZemyyy5Tr169NGvWLH+DqUGDBlqwYIGuuOIKdenSRe+//77+/ve/B42XAQBAXUcbKhhtKNpQqJsc5nwuEgYAhEXr1q01fvx4jR8/3u5UAAAAagzaUEDNRk8pAAAAAAAARBxFKQAAAAAAAEQcl+8BAAAAAAAg4ugpBQAAAAAAgIijKAUAAAAAAICIoygFAAAAAACAiKMoBQAAAAAAgIijKAUAAAAAAICIoygFAAAAAACAiKMoBQAAAAAAgIijKAUAAAAAAICI+//XFMKGdR0zBAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97273838\n",
      "Precision: 0.00416109\n",
      "Recall: 0.02228756\n",
      "F1 Score: 0.00701287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "y_pred=predictions.flatten()\n",
    "y_true= actuals.flatten()\n",
    "\n",
    "tn_mask = (y_true == 0) & (y_pred == 0)\n",
    "tp_mask = (y_true != 0) & (y_pred != 0)\n",
    "fn_mask = (y_true != 0) & (y_pred == 0)\n",
    "fp_mask = (y_true == 0) & (y_pred != 0)\n",
    "\n",
    "# Scatter plot\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Scatter plot for True Negatives (TN)\n",
    "axs[0, 0].scatter(y_pred[tn_mask], y_true[tn_mask], color='blue', alpha=0.1)\n",
    "axs[0, 0].set_title('True Negative (TN)')\n",
    "axs[0, 0].set_xlabel('Predicted Frequencies')\n",
    "axs[0, 0].set_ylabel('Actual Frequencies')\n",
    "\n",
    "# Scatter plot for True Positives (TP)\n",
    "axs[0, 1].scatter(y_pred[tp_mask], y_true[tp_mask], color='green', alpha=0.1)\n",
    "axs[0, 1].set_title('True Positive (TP)')\n",
    "axs[0, 1].set_xlabel('Predicted Frequencies')\n",
    "axs[0, 1].set_ylabel('Actual Frequencies')\n",
    "\n",
    "# Scatter plot for False Negatives (FN)\n",
    "axs[1, 0].scatter(y_pred[fn_mask], y_true[fn_mask], color='red', alpha=0.1)\n",
    "axs[1, 0].set_title('False Negative (FN)')\n",
    "axs[1, 0].set_xlabel('Predicted Frequencies')\n",
    "axs[1, 0].set_ylabel('Actual Frequencies')\n",
    "\n",
    "# Scatter plot for False Positives (FP)\n",
    "axs[1, 1].scatter(y_pred[fp_mask], y_true[fp_mask], color='orange', alpha=0.1)\n",
    "axs[1, 1].set_title('False Positive (FP)')\n",
    "axs[1, 1].set_xlabel('Predicted Frequencies')\n",
    "axs[1, 1].set_ylabel('Actual Frequencies')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n",
    "\n",
    "y_true_binary = (y_true != 0).astype(int)\n",
    "y_pred_binary = (y_pred != 0).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_true_binary, y_pred_binary)\n",
    "precision = precision_score(y_true_binary, y_pred_binary)\n",
    "recall = recall_score(y_true_binary, y_pred_binary)\n",
    "f1 = f1_score(y_true_binary, y_pred_binary)\n",
    "\n",
    "# Print out the metrics using f-strings\n",
    "print(f\"Accuracy: {accuracy:.8f}\")\n",
    "print(f\"Precision: {precision:.8f}\")\n",
    "print(f\"Recall: {recall:.8f}\")\n",
    "print(f\"F1 Score: {f1:.8f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
